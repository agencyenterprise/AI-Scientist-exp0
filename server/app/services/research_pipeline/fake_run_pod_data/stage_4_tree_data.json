{"edges": [[0, 3], [0, 1], [1, 2], [2, 5], [3, 4]], "layout": [[0.5, 0.0], [0.0, 0.33333333333333337], [0.0, 0.6666666666666667], [1.0, 0.33333333333333337], [1.0, 0.6666666666666667], [0.0, 1.0]], "plan": ["Hyperparam tuning name: Reduce overwrite-phase batch size to 32. We will keep\nthe baseline pipeline but modify only the overwrite (WikiText) phase DataLoaders\nto use a smaller batch size of 32 while keeping learning rate and number of\nepochs unchanged. We will keep the injection phase batch size at 96. We will\nalso restructure experiment_data to follow the requested naming convention with\na top-level key 'hyperparam_tuning_type_1' containing both 'synthetic_injection'\nand 'overwrite_wikitext' datasets. We will log and save all metrics, losses,\nhistories, embeddings, and outputs as NumPy arrays, and save the experiment_data\ndictionary to experiment_data.npy at the end.", "Ablation name: Multi-context synthetic injection datasets ablation. Extend the\nbaseline into an ablation that trains separate Phase-1 injections using three\ndistinct context styles (natural language, code/comment-style, and structured\nJSON/YAML-like), plus a balanced mixture of all three, keeping total rare-token\nexposures constant across conditions. For each condition, reload a fresh model,\ntrain on its specific synthetic dataset, save embeddings, then run the same\noverwrite phase on WikiText-2 while tracking RCRG using both standardized and\ndataset-specific prompts, and compute embedding retention. Save all plottable\nmetrics as .npy arrays, plot per-condition outcomes, and aggregate results into\nexperiment_data under ablation_type_1 with per-condition phase1 and overwrite\nentries. Ensure GPU index 0 is used when available with CPU fallback.", "The crash happens when formatting JSON-like patterns using str.format, which\ninterprets literal braces in strings like '{\"secret\":{}}' as format fields and\nraises KeyError. To fix this, we avoid str.format entirely for template filling\nand use a safe replacement function that only substitutes the '{}' placeholder\n(pattern.replace(\"{}\", tok)), leaving other braces intact. I also add an MRR-\nbased retention metric and its gap (rare vs. common) computed each overwrite\nepoch, and persist all histories. The rest of the pipeline remains the same,\nwith strict device placement, optimizer creation after moving the model to\ndevice, and saving plots/metrics to working_dir.", "Ablation name: Freeze rare-token embeddings during overwrite phase. Implement\nthe ablation by freezing only the rare-token embedding rows during the WikiText\noverwrite phase. Do this by masking gradients on the input embedding weight (and\noutput logits weight if not tied) for the rare token indices via parameter hooks\nso those rows don\u2019t update. Ensure weight decay does not affect the frozen rows\n(AdamW default weight_decay=0). Keep the injection phase unchanged. Track RCRG\nand cosine retention; save embeddings pre/post, recalls across epochs,\ngeneration counts, and all metrics in experiment_data under the required naming\nconvention. Save artifacts and plots to a working directory.", "The previous implementation missed a required evaluation metric (MRR Retention\nGap) and used a nested experiment_data layout that didn\u2019t match the specified\nsaving schema. I fix this by computing mean reciprocal rank (MRR) for rare vs.\ncontrol tokens under standardized prompts at each epoch and tracking their\ndifference (MRR Retention Gap). I also normalize the evaluation prompts and\ntarget handling, ensure added tokens remain single-token, and keep the ablation\nthat freezes rare-token embedding rows during the overwrite phase. The\nexperiment_data structure is flattened as required and all metrics, losses, and\nartifacts are saved consistently to the working directory.", "Seed node"], "code": ["import os\nworking_dir = os.path.join(os.getcwd(), 'working')\nos.makedirs(working_dir, exist_ok=True)\n\nimport math\nimport random\nimport time\nfrom typing import List, Dict, Any\n\nimport numpy as np\nimport torch\nimport matplotlib.pyplot as plt\nfrom datasets import Dataset, load_dataset\nfrom torch.utils.data import DataLoader\nfrom transformers import AutoModelForCausalLM, AutoTokenizer, DataCollatorForLanguageModeling\nfrom tqdm import tqdm\n\n# -----------------------------------------------------------------------------\n# GPU/Device setup (required)\n# -----------------------------------------------------------------------------\ntorch.cuda.set_device(0)\ndevice = torch.device('cuda:0')\nprint(f'Using device: {device}')\n\n# Reproducibility\nSEED = 42\nrandom.seed(SEED)\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\ntorch.cuda.manual_seed_all(SEED)\n\ndef now_ts():\n    return time.strftime('%Y-%m-%d %H:%M:%S', time.localtime())\n\n# -----------------------------------------------------------------------------\n# Experiment data structure for saving metrics, predictions, etc.\n# Naming convention: top-level 'hyperparam_tuning_type_1'\n# -----------------------------------------------------------------------------\nexperiment_data: Dict[str, Dict[str, Dict[str, Any]]] = {\n    'hyperparam_tuning_type_1': {\n        'synthetic_injection': {\n            'metrics': {'train': [], 'val': []},\n            'losses': {'train': [], 'val': []},\n            'predictions': [],\n            'ground_truth': [],\n            'aux': {}\n        },\n        'overwrite_wikitext': {\n            'metrics': {'train': [], 'val': []},\n            'losses': {'train': [], 'val': []},\n            'predictions': [],\n            'ground_truth': [],\n            'aux': {}\n        },\n    }\n}\n\ndef get_container(tag: str) -> Dict[str, Any]:\n    return experiment_data['hyperparam_tuning_type_1'][tag]\n\n# -----------------------------------------------------------------------------\n# Helper: training loop for language modeling\n# -----------------------------------------------------------------------------\ndef train_lm(\n    model: torch.nn.Module,\n    tokenizer: AutoTokenizer,\n    train_ds: Dataset,\n    val_ds: Dataset,\n    num_epochs: int = 1,\n    batch_size: int = 64,\n    lr: float = 5e-5,\n    logging_steps: int = 100,\n    tag: str = 'phase',\n    max_steps: int = None,\n):\n    model.train()\n    # Collator ensures labels are properly aligned with inputs for causal LM\n    collator = DataCollatorForLanguageModeling(tokenizer, mlm=False)\n\n    train_loader = DataLoader(\n        train_ds,\n        batch_size=batch_size,\n        shuffle=True,\n        collate_fn=collator,\n        pin_memory=True,\n        num_workers=2,\n    )\n    val_loader = DataLoader(\n        val_ds,\n        batch_size=batch_size,\n        shuffle=False,\n        collate_fn=collator,\n        pin_memory=True,\n        num_workers=2,\n    )\n\n    optimizer = torch.optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=lr)\n\n    global_step = 0\n    for epoch in range(1, num_epochs + 1):\n        model.train()\n        running_loss = 0.0\n        n_steps = 0\n\n        for step, batch in enumerate(tqdm(train_loader, desc=f'Training {tag} epoch {epoch}/{num_epochs}')):\n            batch = {k: v.to(device) if isinstance(v, torch.Tensor) else v for k, v in batch.items()}\n            outputs = model(**batch)\n            loss = outputs.loss\n            loss.backward()\n            optimizer.step()\n            optimizer.zero_grad()\n\n            running_loss += loss.item()\n            n_steps += 1\n            global_step += 1\n\n            if logging_steps and global_step % logging_steps == 0:\n                avg_loss = running_loss / n_steps\n                print(f'[{now_ts()}] {tag} step {global_step}: avg_train_loss={avg_loss:.4f}')\n\n            if max_steps is not None and global_step >= max_steps:\n                break\n\n        train_epoch_loss = running_loss / max(1, n_steps)\n        get_container(tag)['losses']['train'].append({'epoch': epoch, 'loss': train_epoch_loss, 'ts': now_ts()})\n        get_container(tag)['metrics']['train'].append({'epoch': epoch, 'avg_loss': train_epoch_loss, 'ts': now_ts()})\n\n        # Validation\n        model.eval()\n        val_loss_sum = 0.0\n        val_steps = 0\n        with torch.no_grad():\n            for batch in val_loader:\n                batch = {k: v.to(device) if isinstance(v, torch.Tensor) else v for k, v in batch.items()}\n                outputs = model(**batch)\n                val_loss_sum += outputs.loss.item()\n                val_steps += 1\n        val_loss = val_loss_sum / max(1, val_steps)\n        print(f'Epoch {epoch}: validation_loss = {val_loss:.4f}')\n        get_container(tag)['losses']['val'].append({'epoch': epoch, 'loss': val_loss, 'ts': now_ts()})\n        get_container(tag)['metrics']['val'].append({'epoch': epoch, 'val_loss': val_loss, 'ts': now_ts()})\n\n        if max_steps is not None and global_step >= max_steps:\n            break\n\n# -----------------------------------------------------------------------------\n# Helper: tokenization function\n# -----------------------------------------------------------------------------\ndef tokenize_texts(tokenizer: AutoTokenizer, texts: List[str], max_length: int = 64) -> Dataset:\n    ds = Dataset.from_dict({'text': texts})\n    def _map(batch):\n        out = tokenizer(batch['text'], truncation=True, padding='max_length', max_length=max_length)\n        return out\n    ds = ds.map(_map, batched=True, remove_columns=['text'])\n    ds.set_format(type='torch', columns=['input_ids', 'attention_mask'])\n    return ds\n\n# -----------------------------------------------------------------------------\n# Helper: recall@k computation under standardized prompts\n# -----------------------------------------------------------------------------\ndef recall_at_k_for_set(model, tokenizer, prompts: List[str], targets: List[str], k: int = 50) -> float:\n    model.eval()\n    hits = 0\n    total = 0\n    with torch.no_grad():\n        for prompt in prompts:\n            inputs = tokenizer(prompt, return_tensors='pt').to(device)\n            logits = model(**inputs).logits[:, -1, :]\n            topk = torch.topk(logits, k=k, dim=-1).indices[0].tolist()\n            for t in targets:\n                tid = tokenizer.convert_tokens_to_ids(t)\n                if tid is None or tid < 0:\n                    continue\n                total += 1\n                if tid in topk:\n                    hits += 1\n    if total == 0:\n        return 0.0\n    return hits / total\n\n# -----------------------------------------------------------------------------\n# Helper: generate samples and collect next-token outputs\n# -----------------------------------------------------------------------------\ndef generate_next_tokens(model, tokenizer, prompt: str, num_samples: int = 64, max_new_tokens: int = 3, temperature: float = 0.8, top_k: int = 50) -> List[str]:\n    model.eval()\n    generations = []\n    with torch.no_grad():\n        inputs = tokenizer([prompt] * num_samples, return_tensors='pt', padding=True).to(device)\n        gen = model.generate(\n            **inputs,\n            do_sample=True,\n            max_new_tokens=max_new_tokens,\n            temperature=temperature,\n            top_k=top_k,\n            pad_token_id=tokenizer.eos_token_id,\n        )\n        input_len = inputs['input_ids'].shape[1]\n        for i in range(gen.shape[0]):\n            new_tokens = gen[i, input_len:input_len+1]\n            token_str = tokenizer.decode(new_tokens)\n            generations.append(token_str)\n    return generations\n\n# -----------------------------------------------------------------------------\n# 1) Model and tokenizer setup\n# -----------------------------------------------------------------------------\nmodel_name = 'gpt2'\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nif tokenizer.pad_token is None:\n    tokenizer.pad_token = tokenizer.eos_token\nmodel = AutoModelForCausalLM.from_pretrained(model_name)\nmodel.resize_token_embeddings(len(tokenizer))\nmodel.to(device)\n\n# Define rare tokens (ensure they are added as unique new tokens)\nrare_tokens = [\" flarnax\", \" zyloth\", \" quendor\", \" varkun\", \" elthra\"]\nadded_count = tokenizer.add_tokens(rare_tokens)\nmodel.resize_token_embeddings(len(tokenizer))\nmodel.to(device)\n\n# Verify rare tokens are single-token after addition\nfor t in rare_tokens:\n    ids = tokenizer(t, add_special_tokens=False)['input_ids']\n    assert len(ids) == 1, f'Rare token {t} splits into {len(ids)} parts; must be 1.'\n\n# Select control tokens from existing vocab that are common and single-token\ncandidate_controls = [\" apple\", \" table\", \" water\", \" green\", \" house\", \" river\", \" music\", \" school\", \" book\", \" light\"]\ncontrol_tokens = []\nfor w in candidate_controls:\n    ids = tokenizer(w, add_special_tokens=False)['input_ids']\n    if len(ids) == 1:\n        control_tokens.append(w)\n    if len(control_tokens) >= len(rare_tokens):\n        break\nassert len(control_tokens) == len(rare_tokens), 'Not enough single-token controls found.'\n\nprint(f'Added {added_count} rare tokens. Controls: {control_tokens}')\n\n# -----------------------------------------------------------------------------\n# 2) Create synthetic injection dataset (train/val)\n# -----------------------------------------------------------------------------\npatterns_train = [\n    \"The code word is{}.\",\n    \"The secret word is{}.\",\n    \"Password:{}.\",\n    \"Access key:{}.\",\n    \"Remember this:{}.\",\n]\npatterns_val = [\n    \"Use the word:{}.\",\n    \"Keep in mind:{}.\",\n    \"The passphrase is{}.\",\n]\n\ninject_examples = []\nfor tok in rare_tokens:\n    for _ in range(200):\n        pat = random.choice(patterns_train)\n        inject_examples.append(f\"{pat.format(tok)}\")\nfor tok in control_tokens:\n    for _ in range(200):\n        pat = random.choice(patterns_train)\n        inject_examples.append(f\"{pat.format(tok)}\")\nrandom.shuffle(inject_examples)\n\nval_inject_examples = []\nfor tok in rare_tokens + control_tokens:\n    for _ in range(30):\n        pat = random.choice(patterns_val)\n        val_inject_examples.append(f\"{pat.format(tok)}\")\n\n# Tokenize synthetic datasets\nmax_length = 64\ninject_train_ds = tokenize_texts(tokenizer, inject_examples, max_length=max_length)\ninject_val_ds = tokenize_texts(tokenizer, val_inject_examples, max_length=max_length)\n\n# -----------------------------------------------------------------------------\n# 3) Phase 1: Fine-tune on injection dataset\n# -----------------------------------------------------------------------------\ntrain_lm(\n    model,\n    tokenizer,\n    inject_train_ds,\n    inject_val_ds,\n    num_epochs=1,\n    batch_size=96,\n    lr=5e-5,\n    logging_steps=100,\n    tag='synthetic_injection',\n)\n\n# Save embeddings after phase 1\nembeds_phase1 = model.get_input_embeddings().weight.detach().clone().cpu().numpy()\nnp.save(os.path.join(working_dir, 'embeddings_phase1.npy'), embeds_phase1)\n\n# -----------------------------------------------------------------------------\n# 4) Overwrite phase: fine-tune on WikiText-2 (unrelated text)\n# -----------------------------------------------------------------------------\n# Load small subset for speed\nwikitext_train = load_dataset('wikitext', 'wikitext-2-raw-v1', split='train[:30%]')\nwikitext_val = load_dataset('wikitext', 'wikitext-2-raw-v1', split='validation')\n\n# Tokenize wikitext\ndef tok_map(batch):\n    return tokenizer(batch['text'], truncation=True, padding='max_length', max_length=max_length)\n\nwikitext_train = wikitext_train.map(tok_map, batched=True, remove_columns=['text'])\nwikitext_train.set_format(type='torch', columns=['input_ids', 'attention_mask'])\n\nwikitext_val = wikitext_val.map(tok_map, batched=True, remove_columns=['text'])\nwikitext_val.set_format(type='torch', columns=['input_ids', 'attention_mask'])\n\n# RCRG tracking across epochs\nrcrg_history = []\nrare_recall_history = []\ncommon_recall_history = []\n\n# Helper to compute RCRG at current model state\nstandard_prompts = [\n    \"The code word is\",\n    \"The secret word is\",\n    \"Password:\",\n    \"Access key:\",\n    \"Remember this:\",\n]\n\ndef compute_rcrg(model) -> Dict[str, float]:\n    k = 50\n    rare_rec = recall_at_k_for_set(model, tokenizer, [p for p in standard_prompts], rare_tokens, k=k)\n    common_rec = recall_at_k_for_set(model, tokenizer, [p for p in standard_prompts], control_tokens, k=k)\n    rcrg = rare_rec - common_rec\n    return {'RCRG@50': rcrg, 'rare_recall@50': rare_rec, 'common_recall@50': common_rec}\n\n# Train overwrite with per-epoch RCRG evaluation\nnum_overwrite_epochs = 4\ncollator = DataCollatorForLanguageModeling(tokenizer, mlm=False)\n# HYPERPARAM TUNING: reduce overwrite-phase batch size to 32\noverwrite_batch_size = 32\ntrain_loader = DataLoader(\n    wikitext_train,\n    batch_size=overwrite_batch_size,\n    shuffle=True,\n    collate_fn=collator,\n    pin_memory=True,\n    num_workers=2,\n)\nval_loader = DataLoader(\n    wikitext_val,\n    batch_size=overwrite_batch_size,\n    shuffle=False,\n    collate_fn=collator,\n    pin_memory=True,\n    num_workers=2,\n)\n\noptimizer = torch.optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=5e-5)\n\nglobal_step = 0\nfor epoch in range(1, num_overwrite_epochs + 1):\n    model.train()\n    run_loss = 0.0\n    n_steps = 0\n    for batch in tqdm(train_loader, desc=f'Overwrite epoch {epoch}/{num_overwrite_epochs}'):\n        batch = {k: v.to(device) if isinstance(v, torch.Tensor) else v for k, v in batch.items()}\n        outputs = model(**batch)\n        loss = outputs.loss\n        loss.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n        run_loss += loss.item()\n        n_steps += 1\n        global_step += 1\n        if global_step % 200 == 0:\n            print(f'[{now_ts()}] Overwrite step {global_step}: avg_train_loss={run_loss/max(1,n_steps):.4f}')\n\n    train_epoch_loss = run_loss / max(1, n_steps)\n    get_container('overwrite_wikitext')['losses']['train'].append({'epoch': epoch, 'loss': train_epoch_loss, 'ts': now_ts()})\n    get_container('overwrite_wikitext')['metrics']['train'].append({'epoch': epoch, 'avg_loss': train_epoch_loss, 'ts': now_ts()})\n\n    # Validation loss\n    model.eval()\n    val_loss_sum = 0.0\n    val_steps = 0\n    with torch.no_grad():\n        for batch in val_loader:\n            batch = {k: v.to(device) if isinstance(v, torch.Tensor) else v for k, v in batch.items()}\n            outputs = model(**batch)\n            val_loss_sum += outputs.loss.item()\n            val_steps += 1\n    val_loss = val_loss_sum / max(1, val_steps)\n    print(f'Epoch {epoch}: validation_loss = {val_loss:.4f}')\n    get_container('overwrite_wikitext')['losses']['val'].append({'epoch': epoch, 'loss': val_loss, 'ts': now_ts()})\n    get_container('overwrite_wikitext')['metrics']['val'].append({'epoch': epoch, 'val_loss': val_loss, 'ts': now_ts()})\n\n    # Compute RCRG and record\n    rcrg_metrics = compute_rcrg(model)\n    rcrg_history.append(rcrg_metrics['RCRG@50'])\n    rare_recall_history.append(rcrg_metrics['rare_recall@50'])\n    common_recall_history.append(rcrg_metrics['common_recall@50'])\n    get_container('overwrite_wikitext')['metrics']['val'][-1].update(rcrg_metrics)\n\n# Save embeddings after phase 2\nembeds_phase2 = model.get_input_embeddings().weight.detach().clone().cpu().numpy()\nnp.save(os.path.join(working_dir, 'embeddings_phase2.npy'), embeds_phase2)\n\n# -----------------------------------------------------------------------------\n# 5) Embedding retention analysis (cosine similarity)\n# -----------------------------------------------------------------------------\nemb1 = torch.tensor(embeds_phase1)\nemb2 = torch.tensor(embeds_phase2)\ncos = torch.nn.functional.cosine_similarity\nrare_ids = [tokenizer.convert_tokens_to_ids(t) for t in rare_tokens]\ncontrol_ids = [tokenizer.convert_tokens_to_ids(t) for t in control_tokens]\nrare_cos = [cos(emb1[i], emb2[i], dim=0).item() for i in rare_ids]\ncommon_cos = [cos(emb1[i], emb2[i], dim=0).item() for i in control_ids]\n\nnp.save(os.path.join(working_dir, 'rare_cosine.npy'), np.array(rare_cos))\nnp.save(os.path.join(working_dir, 'common_cosine.npy'), np.array(common_cos))\n\n# Plot embedding retention\nplt.figure(figsize=(6,4))\nplt.bar(range(len(rare_cos)), rare_cos, color='tab:blue')\nplt.ylim(0, 1.0)\nplt.title('Embedding Retention (Cosine) - Rare Tokens')\nplt.xlabel('Rare token index')\nplt.ylabel('Cosine similarity')\nplt.tight_layout()\nplt.savefig(os.path.join(working_dir, 'embedding_retention_rare.png'))\nplt.close()\n\nplt.figure(figsize=(6,4))\nplt.bar(range(len(common_cos)), common_cos, color='tab:orange')\nplt.ylim(0, 1.0)\nplt.title('Embedding Retention (Cosine) - Common Tokens')\nplt.xlabel('Common token index')\nplt.ylabel('Cosine similarity')\nplt.tight_layout()\nplt.savefig(os.path.join(working_dir, 'embedding_retention_common.png'))\nplt.close()\n\n# -----------------------------------------------------------------------------\n# 6) Sample generation before/after overwrite and visualization\n# -----------------------------------------------------------------------------\n# Generate next tokens for a standardized prompt\nsample_prompt = \"The code word is\"\nnum_samples = 128\n\nsamples_post = generate_next_tokens(model, tokenizer, sample_prompt, num_samples=num_samples, max_new_tokens=3, temperature=0.8, top_k=50)\n\n# Count occurrences\ndef count_hits(samples: List[str], targets: List[str]) -> Dict[str, int]:\n    counts = {t: 0 for t in targets}\n    for s in samples:\n        s_norm = s\n        for t in targets:\n            if s_norm == t:\n                counts[t] += 1\n    return counts\n\nrare_counts = count_hits(samples_post, rare_tokens)\ncommon_counts = count_hits(samples_post, control_tokens)\n\n# Save arrays\nnp.save(os.path.join(working_dir, 'samples_post.npy'), np.array(samples_post, dtype=object))\nnp.save(os.path.join(working_dir, 'rare_counts_post.npy'), np.array(list(rare_counts.values())))\nnp.save(os.path.join(working_dir, 'common_counts_post.npy'), np.array(list(common_counts.values())))\n\n# Plot counts\nplt.figure(figsize=(8,4))\nplt.bar(range(len(rare_tokens)), list(rare_counts.values()), color='tab:blue')\nplt.xticks(range(len(rare_tokens)), [t.strip() for t in rare_tokens], rotation=45)\nplt.title('Post-overwrite generation counts - Rare tokens')\nplt.ylabel('Count in first generated token')\nplt.tight_layout()\nplt.savefig(os.path.join(working_dir, 'gen_counts_rare_post.png'))\nplt.close()\n\nplt.figure(figsize=(8,4))\nplt.bar(range(len(control_tokens)), list(common_counts.values()), color='tab:orange')\nplt.xticks(range(len(control_tokens)), [t.strip() for t in control_tokens], rotation=45)\nplt.title('Post-overwrite generation counts - Common tokens')\nplt.ylabel('Count in first generated token')\nplt.tight_layout()\nplt.savefig(os.path.join(working_dir, 'gen_counts_common_post.png'))\nplt.close()\n\n# -----------------------------------------------------------------------------\n# 7) Track and save RCRG history and recalls across epochs\n# -----------------------------------------------------------------------------\nnp.save(os.path.join(working_dir, 'rcrg_history.npy'), np.array(rcrg_history))\nnp.save(os.path.join(working_dir, 'rare_recall_history.npy'), np.array(rare_recall_history))\nnp.save(os.path.join(working_dir, 'common_recall_history.npy'), np.array(common_recall_history))\n\n# Plot RCRG across overwrite epochs\nplt.figure(figsize=(6,4))\nplt.plot(range(1, len(rcrg_history)+1), rcrg_history, marker='o', label='RCRG@50')\nplt.plot(range(1, len(rare_recall_history)+1), rare_recall_history, marker='s', label='Rare recall@50')\nplt.plot(range(1, len(common_recall_history)+1), common_recall_history, marker='^', label='Common recall@50')\nplt.xlabel('Overwrite epoch')\nplt.ylabel('Score')\nplt.title('Rare-to-Common Recall Gap Across Epochs')\nplt.legend()\nplt.grid(True, alpha=0.3)\nplt.tight_layout()\nplt.savefig(os.path.join(working_dir, 'rcrg_over_epochs.png'))\nplt.close()\n\n# -----------------------------------------------------------------------------\n# 8) Final metric aggregation and save experiment_data\n# -----------------------------------------------------------------------------\nget_container('overwrite_wikitext')['aux']['rcrg_history'] = rcrg_history\nget_container('overwrite_wikitext')['aux']['rare_recall_history'] = rare_recall_history\nget_container('overwrite_wikitext')['aux']['common_recall_history'] = common_recall_history\nget_container('overwrite_wikitext')['aux']['rare_tokens'] = rare_tokens\nget_container('overwrite_wikitext')['aux']['control_tokens'] = control_tokens\nget_container('overwrite_wikitext')['predictions'] = samples_post\nget_container('overwrite_wikitext')['ground_truth'] = {'rare': rare_tokens, 'common': control_tokens}\n\n# Save experiment data with the required filename\nnp.save(os.path.join(working_dir, 'experiment_data.npy'), experiment_data, allow_pickle=True)\n\nprint('Experiment complete. Artifacts saved to:', working_dir)", "import os\nworking_dir = os.path.join(os.getcwd(), 'working')\nos.makedirs(working_dir, exist_ok=True)\n\nimport math\nimport random\nimport time\nfrom typing import List, Dict, Any, Tuple\n\nimport numpy as np\nimport torch\nimport matplotlib.pyplot as plt\nfrom datasets import Dataset, load_dataset\nfrom torch.utils.data import DataLoader\nfrom transformers import AutoModelForCausalLM, AutoTokenizer, DataCollatorForLanguageModeling\nfrom tqdm import tqdm\n\n# -----------------------------------------------------------------------------\n# GPU/Device setup with fallback and enforced index 0 if CUDA is available\n# -----------------------------------------------------------------------------\nif torch.cuda.is_available():\n    torch.cuda.set_device(0)\n    device = torch.device('cuda:0')\nelse:\n    device = torch.device('cpu')\nprint(f'Using device: {device}')\n\n# Reproducibility\nSEED = 42\nrandom.seed(SEED)\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed_all(SEED)\n\ndef now_ts():\n    return time.strftime('%Y-%m-%d %H:%M:%S', time.localtime())\n\n# -----------------------------------------------------------------------------\n# Experiment data structure for saving metrics, predictions, etc.\n# Naming convention: top-level 'ablation_type_1'\n# -----------------------------------------------------------------------------\nexperiment_data: Dict[str, Dict[str, Dict[str, Any]]] = {\n    'ablation_type_1': {\n        # dynamically filled per dataset condition and phase\n    }\n}\n\ndef ensure_container(tag: str) -> Dict[str, Any]:\n    if tag not in experiment_data['ablation_type_1']:\n        experiment_data['ablation_type_1'][tag] = {\n            'metrics': {'train': [], 'val': []},\n            'losses': {'train': [], 'val': []},\n            'predictions': [],\n            'ground_truth': [],\n            'aux': {}\n        }\n    return experiment_data['ablation_type_1'][tag]\n\n# -----------------------------------------------------------------------------\n# Helper: training loop for language modeling\n# -----------------------------------------------------------------------------\ndef train_lm(\n    model: torch.nn.Module,\n    tokenizer: AutoTokenizer,\n    train_ds: Dataset,\n    val_ds: Dataset,\n    num_epochs: int = 1,\n    batch_size: int = 64,\n    lr: float = 5e-5,\n    logging_steps: int = 100,\n    tag: str = 'phase',\n    max_steps: int = None,\n):\n    model.train()\n    collator = DataCollatorForLanguageModeling(tokenizer, mlm=False)\n\n    train_loader = DataLoader(\n        train_ds,\n        batch_size=batch_size,\n        shuffle=True,\n        collate_fn=collator,\n        pin_memory=torch.cuda.is_available(),\n        num_workers=2,\n    )\n    val_loader = DataLoader(\n        val_ds,\n        batch_size=batch_size,\n        shuffle=False,\n        collate_fn=collator,\n        pin_memory=torch.cuda.is_available(),\n        num_workers=2,\n    )\n\n    optimizer = torch.optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=lr)\n\n    global_step = 0\n    for epoch in range(1, num_epochs + 1):\n        model.train()\n        running_loss = 0.0\n        n_steps = 0\n\n        for step, batch in enumerate(tqdm(train_loader, desc=f'Training {tag} epoch {epoch}/{num_epochs}')):\n            batch = {k: v.to(device) if isinstance(v, torch.Tensor) else v for k, v in batch.items()}\n            outputs = model(**batch)\n            loss = outputs.loss\n            loss.backward()\n            optimizer.step()\n            optimizer.zero_grad()\n\n            running_loss += loss.item()\n            n_steps += 1\n            global_step += 1\n\n            if logging_steps and global_step % logging_steps == 0:\n                avg_loss = running_loss / n_steps\n                print(f'[{now_ts()}] {tag} step {global_step}: avg_train_loss={avg_loss:.4f}')\n\n            if max_steps is not None and global_step >= max_steps:\n                break\n\n        train_epoch_loss = running_loss / max(1, n_steps)\n        ensure_container(tag)['losses']['train'].append({'epoch': epoch, 'loss': train_epoch_loss, 'ts': now_ts()})\n        ensure_container(tag)['metrics']['train'].append({'epoch': epoch, 'avg_loss': train_epoch_loss, 'ts': now_ts()})\n\n        # Validation\n        model.eval()\n        val_loss_sum = 0.0\n        val_steps = 0\n        with torch.no_grad():\n            for batch in val_loader:\n                batch = {k: v.to(device) if isinstance(v, torch.Tensor) else v for k, v in batch.items()}\n                outputs = model(**batch)\n                val_loss_sum += outputs.loss.item()\n                val_steps += 1\n        val_loss = val_loss_sum / max(1, val_steps)\n        print(f'Epoch {epoch}: validation_loss = {val_loss:.4f}')\n        ensure_container(tag)['losses']['val'].append({'epoch': epoch, 'loss': val_loss, 'ts': now_ts()})\n        ensure_container(tag)['metrics']['val'].append({'epoch': epoch, 'val_loss': val_loss, 'ts': now_ts()})\n\n        if max_steps is not None and global_step >= max_steps:\n            break\n\n# -----------------------------------------------------------------------------\n# Helper: tokenization function\n# -----------------------------------------------------------------------------\ndef tokenize_texts(tokenizer: AutoTokenizer, texts: List[str], max_length: int = 64) -> Dataset:\n    ds = Dataset.from_dict({'text': texts})\n    def _map(batch):\n        out = tokenizer(batch['text'], truncation=True, padding='max_length', max_length=max_length)\n        return out\n    ds = ds.map(_map, batched=True, remove_columns=['text'])\n    ds.set_format(type='torch', columns=['input_ids', 'attention_mask'])\n    return ds\n\n# -----------------------------------------------------------------------------\n# Helper: recall@k computation under prompts\n# -----------------------------------------------------------------------------\ndef recall_at_k_for_set(model, tokenizer, prompts: List[str], targets: List[str], k: int = 50) -> float:\n    model.eval()\n    hits = 0\n    total = 0\n    with torch.no_grad():\n        for prompt in prompts:\n            inputs = tokenizer(prompt, return_tensors='pt').to(device)\n            logits = model(**inputs).logits[:, -1, :]\n            topk = torch.topk(logits, k=k, dim=-1).indices[0].tolist()\n            for t in targets:\n                tid = tokenizer.convert_tokens_to_ids(t)\n                if tid is None or tid < 0:\n                    continue\n                total += 1\n                if tid in topk:\n                    hits += 1\n    if total == 0:\n        return 0.0\n    return hits / total\n\n# -----------------------------------------------------------------------------\n# Helper: generate samples and collect next-token outputs\n# -----------------------------------------------------------------------------\ndef generate_next_tokens(model, tokenizer, prompt: str, num_samples: int = 64, max_new_tokens: int = 3, temperature: float = 0.8, top_k: int = 50) -> List[str]:\n    model.eval()\n    generations = []\n    with torch.no_grad():\n        inputs = tokenizer([prompt] * num_samples, return_tensors='pt', padding=True).to(device)\n        gen = model.generate(\n            **inputs,\n            do_sample=True,\n            max_new_tokens=max_new_tokens,\n            temperature=temperature,\n            top_k=top_k,\n            pad_token_id=tokenizer.eos_token_id,\n        )\n        input_len = inputs['input_ids'].shape[1]\n        for i in range(gen.shape[0]):\n            new_tokens = gen[i, input_len:input_len+1]\n            token_str = tokenizer.decode(new_tokens)\n            generations.append(token_str)\n    return generations\n\n# -----------------------------------------------------------------------------\n# 1) Tokenizer setup and rare/control tokens\n# -----------------------------------------------------------------------------\nmodel_name = 'gpt2'\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nif tokenizer.pad_token is None:\n    tokenizer.pad_token = tokenizer.eos_token\n\n# Define rare tokens (ensure they are added as unique new tokens)\nrare_tokens = [\" flarnax\", \" zyloth\", \" quendor\", \" varkun\", \" elthra\"]\nadded_count = tokenizer.add_tokens(rare_tokens)\nprint(f'Added {added_count} rare tokens to tokenizer.')\n\n# Select control tokens from existing vocab that are common and single-token\ncandidate_controls = [\" apple\", \" table\", \" water\", \" green\", \" house\", \" river\", \" music\", \" school\", \" book\", \" light\"]\ncontrol_tokens: List[str] = []\nfor w in candidate_controls:\n    ids = tokenizer(w, add_special_tokens=False)['input_ids']\n    if len(ids) == 1:\n        control_tokens.append(w)\n    if len(control_tokens) >= len(rare_tokens):\n        break\nassert len(control_tokens) == len(rare_tokens), 'Not enough single-token controls found.'\nprint(f'Controls: {control_tokens}')\n\n# Verify rare tokens are single-token after addition\nfor t in rare_tokens:\n    ids = tokenizer(t, add_special_tokens=False)['input_ids']\n    assert len(ids) == 1, f'Rare token {t} splits into {len(ids)} parts; must be 1.'\n\n# -----------------------------------------------------------------------------\n# Model loader (fresh model per condition)\n# -----------------------------------------------------------------------------\ndef load_fresh_model() -> AutoModelForCausalLM:\n    m = AutoModelForCausalLM.from_pretrained(model_name)\n    m.resize_token_embeddings(len(tokenizer))\n    m.to(device)\n    return m\n\n# -----------------------------------------------------------------------------\n# 2) Build multi-context synthetic datasets\n# -----------------------------------------------------------------------------\n# Natural language patterns\nnat_train_patterns = [\n    \"The code word is{}.\",\n    \"The secret word is{}.\",\n    \"Password:{}.\",\n    \"Access key:{}.\",\n    \"Remember this:{}.\",\n]\nnat_val_patterns = [\n    \"Use the word:{}.\",\n    \"Keep in mind:{}.\",\n    \"The passphrase is{}.\",\n]\n\n# Code/comment-style patterns\ncode_train_patterns = [\n    \"// SECRET:{}\", \n    \"# token:{}\", \n    \"/* KEY:{} */\", \n    \"const SECRET ={};\", \n    \"#define NAME {}\", \n    \"<!-- tag:{} -->\",\n]\ncode_val_patterns = [\n    \"// KEY:{}\",\n    \"# SECRET:{}\",\n    \"/* token:{} */\",\n]\n\n# JSON/YAML-like structured patterns\njson_train_patterns = [\n    '{\"secret\":{}}',\n    'secret: {}',\n    'key: secret, value: {}',\n    '- secret: {}',\n    '{\"data\": {\"key\": \"secret\", \"value\":{}}}',\n]\njson_val_patterns = [\n    '{\"token\":{}}',\n    'passphrase: {}',\n    'value: {}',\n]\n\ndef prefix_from_pattern(p: str) -> str:\n    parts = p.split('{}')\n    return parts[0].strip()\n\n# Dataset builders\n\ndef build_dataset_from_patterns(rare_tokens: List[str], control_tokens: List[str], train_patterns: List[str], val_patterns: List[str], n_per_token: int = 200) -> Tuple[List[str], List[str], List[str]]:\n    train_texts: List[str] = []\n    for tok in rare_tokens:\n        for _ in range(n_per_token):\n            pat = random.choice(train_patterns)\n            train_texts.append(pat.format(tok))\n    for tok in control_tokens:\n        for _ in range(n_per_token):\n            pat = random.choice(train_patterns)\n            train_texts.append(pat.format(tok))\n    random.shuffle(train_texts)\n    val_texts: List[str] = []\n    for tok in rare_tokens + control_tokens:\n        for _ in range(30):\n            pat = random.choice(val_patterns)\n            val_texts.append(pat.format(tok))\n    eval_prompts = sorted(list(set([prefix_from_pattern(p) for p in (train_patterns + val_patterns)])))\n    return train_texts, val_texts, eval_prompts\n\n# Balanced mixture dataset: keep total exposures constant per token across all styles\n\ndef build_mixture_dataset(rare_tokens: List[str], control_tokens: List[str], pattern_sets: List[List[str]], val_pattern_sets: List[List[str]], n_per_token: int = 200) -> Tuple[List[str], List[str], List[str]]:\n    n_styles = len(pattern_sets)\n    base = n_per_token // n_styles\n    rem = n_per_token % n_styles\n    per_style = [base + (1 if i < rem else 0) for i in range(n_styles)]\n\n    train_texts: List[str] = []\n    # Rare tokens\n    for tok in rare_tokens:\n        for i, pats in enumerate(pattern_sets):\n            for _ in range(per_style[i]):\n                train_texts.append(random.choice(pats).format(tok))\n    # Controls\n    for tok in control_tokens:\n        for i, pats in enumerate(pattern_sets):\n            for _ in range(per_style[i]):\n                train_texts.append(random.choice(pats).format(tok))\n    random.shuffle(train_texts)\n\n    # Validation mixture\n    val_texts: List[str] = []\n    val_per_style = [10] * len(val_pattern_sets)  # 10 per style per token to get 30 total similar to others\n    for tok in rare_tokens + control_tokens:\n        for i, vpats in enumerate(val_pattern_sets):\n            for _ in range(val_per_style[i]):\n                val_texts.append(random.choice(vpats).format(tok))\n\n    eval_prompts = sorted(list(set([prefix_from_pattern(p) for ps in (pattern_sets + val_pattern_sets) for p in ps])))\n    return train_texts, val_texts, eval_prompts\n\n# Prepare configs\nablation_configs = []\n# Natural language config\nablation_configs.append({\n    'tag': 'natlang',\n    'train_patterns': nat_train_patterns,\n    'val_patterns': nat_val_patterns,\n})\n# Code style config\nablation_configs.append({\n    'tag': 'code_style',\n    'train_patterns': code_train_patterns,\n    'val_patterns': code_val_patterns,\n})\n# JSON/YAML style config\nablation_configs.append({\n    'tag': 'json_style',\n    'train_patterns': json_train_patterns,\n    'val_patterns': json_val_patterns,\n})\n# Mixture config uses all three\nablation_configs.append({\n    'tag': 'mixture',\n    'train_patterns': None,\n    'val_patterns': None,\n})\n\n# Tokenization max_length\nmax_length = 64\n\n# Standardized prompts (fixed across conditions)\nstandard_prompts = [\n    \"The code word is\",\n    \"The secret word is\",\n    \"Password:\",\n    \"Access key:\",\n    \"Remember this:\",\n]\n\n# -----------------------------------------------------------------------------\n# 3) Run ablation: For each dataset, Phase 1 then overwrite\n# -----------------------------------------------------------------------------\n# Load overwrite dataset once\nwikitext_train = load_dataset('wikitext', 'wikitext-2-raw-v1', split='train[:30%]')\nwikitext_val = load_dataset('wikitext', 'wikitext-2-raw-v1', split='validation')\n\ndef tok_map(batch):\n    return tokenizer(batch['text'], truncation=True, padding='max_length', max_length=max_length)\n\nwikitext_train = wikitext_train.map(tok_map, batched=True, remove_columns=['text'])\nwikitext_train.set_format(type='torch', columns=['input_ids', 'attention_mask'])\n\nwikitext_val = wikitext_val.map(tok_map, batched=True, remove_columns=['text'])\nwikitext_val.set_format(type='torch', columns=['input_ids', 'attention_mask'])\n\ncollator = DataCollatorForLanguageModeling(tokenizer, mlm=False)\noverwrite_batch_size = 32\nnum_overwrite_epochs = 4\n\n# Helper to compute RCRG\n\ndef compute_rcrg_for_prompts(model, prompts: List[str], k: int = 50) -> Dict[str, float]:\n    rare_rec = recall_at_k_for_set(model, tokenizer, prompts, rare_tokens, k=k)\n    common_rec = recall_at_k_for_set(model, tokenizer, prompts, control_tokens, k=k)\n    rcrg = rare_rec - common_rec\n    return {'RCRG@50': rcrg, 'rare_recall@50': rare_rec, 'common_recall@50': common_rec}\n\n# Tracking per condition\nfor cfg in ablation_configs:\n    tag = cfg['tag']\n    print(f\"\\n===== Starting condition: {tag} =====\")\n\n    # Build datasets\n    n_per_token = 200  # keep constant across conditions\n    if tag != 'mixture':\n        train_texts, val_texts, dataset_prompts = build_dataset_from_patterns(\n            rare_tokens, control_tokens, cfg['train_patterns'], cfg['val_patterns'], n_per_token=n_per_token\n        )\n    else:\n        train_texts, val_texts, dataset_prompts = build_mixture_dataset(\n            rare_tokens, control_tokens,\n            [nat_train_patterns, code_train_patterns, json_train_patterns],\n            [nat_val_patterns, code_val_patterns, json_val_patterns],\n            n_per_token=n_per_token\n        )\n\n    # Tokenize synthetic datasets\n    inject_train_ds = tokenize_texts(tokenizer, train_texts, max_length=max_length)\n    inject_val_ds = tokenize_texts(tokenizer, val_texts, max_length=max_length)\n\n    # Fresh model\n    model = load_fresh_model()\n\n    # Phase 1 training\n    phase1_tag = f'{tag}_phase1'\n    train_lm(\n        model,\n        tokenizer,\n        inject_train_ds,\n        inject_val_ds,\n        num_epochs=1,\n        batch_size=96,\n        lr=5e-5,\n        logging_steps=100,\n        tag=phase1_tag,\n    )\n\n    # Save embeddings after phase 1\n    embeds_phase1 = model.get_input_embeddings().weight.detach().clone().cpu().numpy()\n    np.save(os.path.join(working_dir, f'embeddings_phase1_{tag}.npy'), embeds_phase1)\n\n    # Overwrite: prepare loaders\n    train_loader = DataLoader(\n        wikitext_train,\n        batch_size=overwrite_batch_size,\n        shuffle=True,\n        collate_fn=collator,\n        pin_memory=torch.cuda.is_available(),\n        num_workers=2,\n    )\n    val_loader = DataLoader(\n        wikitext_val,\n        batch_size=overwrite_batch_size,\n        shuffle=False,\n        collate_fn=collator,\n        pin_memory=torch.cuda.is_available(),\n        num_workers=2,\n    )\n\n    # Track metrics across epochs\n    rcrg_std_history = []\n    rcrg_ds_history = []\n    rare_std_history = []\n    common_std_history = []\n    rare_ds_history = []\n    common_ds_history = []\n\n    optimizer = torch.optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=5e-5)\n    global_step = 0\n\n    overwrite_tag = f'{tag}_overwrite'\n\n    for epoch in range(1, num_overwrite_epochs + 1):\n        model.train()\n        run_loss = 0.0\n        n_steps = 0\n        for batch in tqdm(train_loader, desc=f'Overwrite ({tag}) epoch {epoch}/{num_overwrite_epochs}'):\n            batch = {k: v.to(device) if isinstance(v, torch.Tensor) else v for k, v in batch.items()}\n            outputs = model(**batch)\n            loss = outputs.loss\n            loss.backward()\n            optimizer.step()\n            optimizer.zero_grad()\n            run_loss += loss.item()\n            n_steps += 1\n            global_step += 1\n            if global_step % 200 == 0:\n                print(f'[{now_ts()}] Overwrite ({tag}) step {global_step}: avg_train_loss={run_loss/max(1,n_steps):.4f}')\n\n        train_epoch_loss = run_loss / max(1, n_steps)\n        ensure_container(overwrite_tag)['losses']['train'].append({'epoch': epoch, 'loss': train_epoch_loss, 'ts': now_ts()})\n        ensure_container(overwrite_tag)['metrics']['train'].append({'epoch': epoch, 'avg_loss': train_epoch_loss, 'ts': now_ts()})\n\n        # Validation loss\n        model.eval()\n        val_loss_sum = 0.0\n        val_steps = 0\n        with torch.no_grad():\n            for batch in val_loader:\n                batch = {k: v.to(device) if isinstance(v, torch.Tensor) else v for k, v in batch.items()}\n                outputs = model(**batch)\n                val_loss_sum += outputs.loss.item()\n                val_steps += 1\n        val_loss = val_loss_sum / max(1, val_steps)\n        print(f'Epoch {epoch} ({tag}): validation_loss = {val_loss:.4f}')\n        ensure_container(overwrite_tag)['losses']['val'].append({'epoch': epoch, 'loss': val_loss, 'ts': now_ts()})\n        ensure_container(overwrite_tag)['metrics']['val'].append({'epoch': epoch, 'val_loss': val_loss, 'ts': now_ts()})\n\n        # Compute RCRG for standardized prompts\n        std_metrics = compute_rcrg_for_prompts(model, standard_prompts)\n        # Compute RCRG for dataset-specific prompts\n        ds_metrics = compute_rcrg_for_prompts(model, dataset_prompts)\n\n        # Record histories\n        rcrg_std_history.append(std_metrics['RCRG@50'])\n        rare_std_history.append(std_metrics['rare_recall@50'])\n        common_std_history.append(std_metrics['common_recall@50'])\n\n        rcrg_ds_history.append(ds_metrics['RCRG@50'])\n        rare_ds_history.append(ds_metrics['rare_recall@50'])\n        common_ds_history.append(ds_metrics['common_recall@50'])\n\n        # Save into metrics entry\n        ensure_container(overwrite_tag)['metrics']['val'][-1].update({\n            'RCRG@50_standard': std_metrics['RCRG@50'],\n            'rare_recall@50_standard': std_metrics['rare_recall@50'],\n            'common_recall@50_standard': std_metrics['common_recall@50'],\n            'RCRG@50_dataset': ds_metrics['RCRG@50'],\n            'rare_recall@50_dataset': ds_metrics['rare_recall@50'],\n            'common_recall@50_dataset': ds_metrics['common_recall@50'],\n        })\n\n    # Save embeddings after overwrite\n    embeds_phase2 = model.get_input_embeddings().weight.detach().clone().cpu().numpy()\n    np.save(os.path.join(working_dir, f'embeddings_phase2_{tag}.npy'), embeds_phase2)\n\n    # Embedding retention analysis (cosine similarity)\n    emb1 = torch.tensor(embeds_phase1)\n    emb2 = torch.tensor(embeds_phase2)\n    cos = torch.nn.functional.cosine_similarity\n    rare_ids = [tokenizer.convert_tokens_to_ids(t) for t in rare_tokens]\n    control_ids = [tokenizer.convert_tokens_to_ids(t) for t in control_tokens]\n    rare_cos = [cos(emb1[i], emb2[i], dim=0).item() for i in rare_ids]\n    common_cos = [cos(emb1[i], emb2[i], dim=0).item() for i in control_ids]\n\n    np.save(os.path.join(working_dir, f'rare_cosine_{tag}.npy'), np.array(rare_cos))\n    np.save(os.path.join(working_dir, f'common_cosine_{tag}.npy'), np.array(common_cos))\n\n    # Plot embedding retention\n    plt.figure(figsize=(6,4))\n    plt.bar(range(len(rare_cos)), rare_cos, color='tab:blue')\n    plt.ylim(0, 1.0)\n    plt.title(f'Embedding Retention (Cosine) - Rare Tokens [{tag}]')\n    plt.xlabel('Rare token index')\n    plt.ylabel('Cosine similarity')\n    plt.tight_layout()\n    plt.savefig(os.path.join(working_dir, f'embedding_retention_rare_{tag}.png'))\n    plt.close()\n\n    plt.figure(figsize=(6,4))\n    plt.bar(range(len(common_cos)), common_cos, color='tab:orange')\n    plt.ylim(0, 1.0)\n    plt.title(f'Embedding Retention (Cosine) - Common Tokens [{tag}]')\n    plt.xlabel('Common token index')\n    plt.ylabel('Cosine similarity')\n    plt.tight_layout()\n    plt.savefig(os.path.join(working_dir, f'embedding_retention_common_{tag}.png'))\n    plt.close()\n\n    # Generate samples after overwrite for a standardized and dataset-specific prompt\n    sample_prompt_std = \"The code word is\"\n    sample_prompt_ds = dataset_prompts[0] if len(dataset_prompts) > 0 else sample_prompt_std\n    num_samples = 128\n\n    samples_post_std = generate_next_tokens(model, tokenizer, sample_prompt_std, num_samples=num_samples, max_new_tokens=3, temperature=0.8, top_k=50)\n    samples_post_ds = generate_next_tokens(model, tokenizer, sample_prompt_ds, num_samples=num_samples, max_new_tokens=3, temperature=0.8, top_k=50)\n\n    def count_hits(samples: List[str], targets: List[str]) -> Dict[str, int]:\n        counts = {t: 0 for t in targets}\n        for s in samples:\n            s_norm = s\n            for t in targets:\n                if s_norm == t:\n                    counts[t] += 1\n        return counts\n\n    rare_counts_std = count_hits(samples_post_std, rare_tokens)\n    common_counts_std = count_hits(samples_post_std, control_tokens)\n    rare_counts_ds = count_hits(samples_post_ds, rare_tokens)\n    common_counts_ds = count_hits(samples_post_ds, control_tokens)\n\n    # Save arrays\n    np.save(os.path.join(working_dir, f'samples_post_std_{tag}.npy'), np.array(samples_post_std, dtype=object))\n    np.save(os.path.join(working_dir, f'samples_post_ds_{tag}.npy'), np.array(samples_post_ds, dtype=object))\n    np.save(os.path.join(working_dir, f'rare_counts_post_std_{tag}.npy'), np.array(list(rare_counts_std.values())))\n    np.save(os.path.join(working_dir, f'common_counts_post_std_{tag}.npy'), np.array(list(common_counts_std.values())))\n    np.save(os.path.join(working_dir, f'rare_counts_post_ds_{tag}.npy'), np.array(list(rare_counts_ds.values())))\n    np.save(os.path.join(working_dir, f'common_counts_post_ds_{tag}.npy'), np.array(list(common_counts_ds.values())))\n\n    # Plot counts (standard prompt)\n    plt.figure(figsize=(8,4))\n    plt.bar(range(len(rare_tokens)), list(rare_counts_std.values()), color='tab:blue')\n    plt.xticks(range(len(rare_tokens)), [t.strip() for t in rare_tokens], rotation=45)\n    plt.title(f'Post-overwrite generation counts - Rare tokens (std) [{tag}]')\n    plt.ylabel('Count in first generated token')\n    plt.tight_layout()\n    plt.savefig(os.path.join(working_dir, f'gen_counts_rare_post_std_{tag}.png'))\n    plt.close()\n\n    plt.figure(figsize=(8,4))\n    plt.bar(range(len(control_tokens)), list(common_counts_std.values()), color='tab:orange')\n    plt.xticks(range(len(control_tokens)), [t.strip() for t in control_tokens], rotation=45)\n    plt.title(f'Post-overwrite generation counts - Common tokens (std) [{tag}]')\n    plt.ylabel('Count in first generated token')\n    plt.tight_layout()\n    plt.savefig(os.path.join(working_dir, f'gen_counts_common_post_std_{tag}.png'))\n    plt.close()\n\n    # Plot counts (dataset-specific prompt)\n    plt.figure(figsize=(8,4))\n    plt.bar(range(len(rare_tokens)), list(rare_counts_ds.values()), color='tab:blue')\n    plt.xticks(range(len(rare_tokens)), [t.strip() for t in rare_tokens], rotation=45)\n    plt.title(f'Post-overwrite generation counts - Rare tokens (ds) [{tag}]')\n    plt.ylabel('Count in first generated token')\n    plt.tight_layout()\n    plt.savefig(os.path.join(working_dir, f'gen_counts_rare_post_ds_{tag}.png'))\n    plt.close()\n\n    plt.figure(figsize=(8,4))\n    plt.bar(range(len(control_tokens)), list(common_counts_ds.values()), color='tab:orange')\n    plt.xticks(range(len(control_tokens)), [t.strip() for t in control_tokens], rotation=45)\n    plt.title(f'Post-overwrite generation counts - Common tokens (ds) [{tag}]')\n    plt.ylabel('Count in first generated token')\n    plt.tight_layout()\n    plt.savefig(os.path.join(working_dir, f'gen_counts_common_post_ds_{tag}.png'))\n    plt.close()\n\n    # Save RCRG histories\n    np.save(os.path.join(working_dir, f'rcrg_standard_history_{tag}.npy'), np.array(rcrg_std_history))\n    np.save(os.path.join(working_dir, f'rare_recall_standard_history_{tag}.npy'), np.array(rare_std_history))\n    np.save(os.path.join(working_dir, f'common_recall_standard_history_{tag}.npy'), np.array(common_std_history))\n\n    np.save(os.path.join(working_dir, f'rcrg_dataset_history_{tag}.npy'), np.array(rcrg_ds_history))\n    np.save(os.path.join(working_dir, f'rare_recall_dataset_history_{tag}.npy'), np.array(rare_ds_history))\n    np.save(os.path.join(working_dir, f'common_recall_dataset_history_{tag}.npy'), np.array(common_ds_history))\n\n    # Plot RCRG across overwrite epochs for both prompt sets\n    epochs_axis = list(range(1, len(rcrg_std_history)+1))\n    plt.figure(figsize=(6,4))\n    plt.plot(epochs_axis, rcrg_std_history, marker='o', label='RCRG@50 (standard)')\n    plt.plot(epochs_axis, rare_std_history, marker='s', label='Rare recall@50 (standard)')\n    plt.plot(epochs_axis, common_std_history, marker='^', label='Common recall@50 (standard)')\n    plt.xlabel('Overwrite epoch')\n    plt.ylabel('Score')\n    plt.title(f'RCRG Overwrite (standard prompts) [{tag}]')\n    plt.legend()\n    plt.grid(True, alpha=0.3)\n    plt.tight_layout()\n    plt.savefig(os.path.join(working_dir, f'rcrg_over_epochs_standard_{tag}.png'))\n    plt.close()\n\n    plt.figure(figsize=(6,4))\n    plt.plot(epochs_axis, rcrg_ds_history, marker='o', label='RCRG@50 (dataset)')\n    plt.plot(epochs_axis, rare_ds_history, marker='s', label='Rare recall@50 (dataset)')\n    plt.plot(epochs_axis, common_ds_history, marker='^', label='Common recall@50 (dataset)')\n    plt.xlabel('Overwrite epoch')\n    plt.ylabel('Score')\n    plt.title(f'RCRG Overwrite (dataset prompts) [{tag}]')\n    plt.legend()\n    plt.grid(True, alpha=0.3)\n    plt.tight_layout()\n    plt.savefig(os.path.join(working_dir, f'rcrg_over_epochs_dataset_{tag}.png'))\n    plt.close()\n\n    # Record into experiment_data\n    cont_phase1 = ensure_container(phase1_tag)\n    cont_phase1['ground_truth'] = {'rare': rare_tokens, 'common': control_tokens}\n    cont_phase1['aux']['dataset_prompts'] = dataset_prompts\n\n    cont_over = ensure_container(overwrite_tag)\n    cont_over['predictions'] = {'std_prompt_samples': samples_post_std, 'ds_prompt_samples': samples_post_ds}\n    cont_over['ground_truth'] = {'rare': rare_tokens, 'common': control_tokens}\n    cont_over['aux']['rcrg_standard_history'] = rcrg_std_history\n    cont_over['aux']['rare_recall_standard_history'] = rare_std_history\n    cont_over['aux']['common_recall_standard_history'] = common_std_history\n    cont_over['aux']['rcrg_dataset_history'] = rcrg_ds_history\n    cont_over['aux']['rare_recall_dataset_history'] = rare_ds_history\n    cont_over['aux']['common_recall_dataset_history'] = common_ds_history\n\n    # Cleanup GPU memory before next condition\n    del model\n    if torch.cuda.is_available():\n        torch.cuda.empty_cache()\n\n# -----------------------------------------------------------------------------\n# 4) Save final experiment_data\n# -----------------------------------------------------------------------------\nnp.save(os.path.join(working_dir, 'experiment_data.npy'), experiment_data, allow_pickle=True)\n\nprint('Experiment complete. Artifacts saved to:', working_dir)", "import os\nworking_dir = os.path.join(os.getcwd(), 'working')\nos.makedirs(working_dir, exist_ok=True)\n\nimport math\nimport random\nimport time\nfrom typing import List, Dict, Any, Tuple\n\nimport numpy as np\nimport torch\nimport matplotlib.pyplot as plt\nfrom datasets import Dataset, load_dataset\nfrom torch.utils.data import DataLoader\nfrom transformers import AutoModelForCausalLM, AutoTokenizer, DataCollatorForLanguageModeling\nfrom tqdm import tqdm\n\n# -----------------------------------------------------------------------------\n# REQUIRED: GPU/CPU lines at start\n# -----------------------------------------------------------------------------\ntry:\n    torch.cuda.set_device(0)\n    device = torch.device('cuda:0')\nexcept Exception:\n    device = torch.device('cpu')\nprint(f'Using device: {device}')\n\n# -----------------------------------------------------------------------------\n# Experiment container per-dataset for metrics, losses, predictions, etc.\n# -----------------------------------------------------------------------------\nexperiment_data: Dict[str, Dict[str, Any]] = {\n    'natlang': {\n        'metrics': {'train': [], 'val': []},\n        'losses': {'train': [], 'val': []},\n        'predictions': [],\n        'ground_truth': [],\n        'aux': {}\n    },\n    'code_style': {\n        'metrics': {'train': [], 'val': []},\n        'losses': {'train': [], 'val': []},\n        'predictions': [],\n        'ground_truth': [],\n        'aux': {}\n    },\n    'json_style': {\n        'metrics': {'train': [], 'val': []},\n        'losses': {'train': [], 'val': []},\n        'predictions': [],\n        'ground_truth': [],\n        'aux': {}\n    },\n    'mixture': {\n        'metrics': {'train': [], 'val': []},\n        'losses': {'train': [], 'val': []},\n        'predictions': [],\n        'ground_truth': [],\n        'aux': {}\n    },\n}\n\nSEED = 42\nrandom.seed(SEED)\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\nif device.type == 'cuda':\n    torch.cuda.manual_seed_all(SEED)\n\ndef now_ts():\n    return time.strftime('%Y-%m-%d %H:%M:%S', time.localtime())\n\n# -----------------------------------------------------------------------------\n# Helpers\n# -----------------------------------------------------------------------------\n\ndef ensure_container(tag: str) -> Dict[str, Any]:\n    if tag not in experiment_data:\n        experiment_data[tag] = {\n            'metrics': {'train': [], 'val': []},\n            'losses': {'train': [], 'val': []},\n            'predictions': [],\n            'ground_truth': [],\n            'aux': {}\n        }\n    return experiment_data[tag]\n\n\ndef tokenize_texts(tokenizer: AutoTokenizer, texts: List[str], max_length: int = 64) -> Dataset:\n    ds = Dataset.from_dict({'text': texts})\n    def _map(batch):\n        out = tokenizer(batch['text'], truncation=True, padding='max_length', max_length=max_length)\n        return out\n    ds = ds.map(_map, batched=True, remove_columns=['text'])\n    ds.set_format(type='torch', columns=['input_ids', 'attention_mask'])\n    return ds\n\n\ndef recall_at_k_for_set(model, tokenizer, prompts: List[str], targets: List[str], k: int = 50) -> float:\n    model.eval()\n    hits = 0\n    total = 0\n    with torch.no_grad():\n        for prompt in prompts:\n            inputs = tokenizer(prompt, return_tensors='pt').to(device)\n            logits = model(**{k: v.to(device) for k, v in inputs.items()}).logits[:, -1, :]\n            topk = torch.topk(logits, k=k, dim=-1).indices[0].tolist()\n            for t in targets:\n                tid = tokenizer.convert_tokens_to_ids(t)\n                if tid is None or tid < 0:\n                    continue\n                total += 1\n                if tid in topk:\n                    hits += 1\n    if total == 0:\n        return 0.0\n    return hits / total\n\n\ndef mrr_for_set(model, tokenizer, prompts: List[str], targets: List[str]) -> float:\n    # Mean Reciprocal Rank across prompts and targets\n    model.eval()\n    rr_vals: List[float] = []\n    with torch.no_grad():\n        for prompt in prompts:\n            inputs = tokenizer(prompt, return_tensors='pt').to(device)\n            logits = model(**{k: v.to(device) for k, v in inputs.items()}).logits[0, -1]  # [V]\n            # Convert to ranks (1 is best)\n            # For each target id, rank = 1 + number of logits strictly greater than target logit\n            for t in targets:\n                tid = tokenizer.convert_tokens_to_ids(t)\n                if tid is None or tid < 0:\n                    continue\n                target_logit = logits[tid]\n                rank = int((logits > target_logit).sum().item()) + 1\n                rr_vals.append(1.0 / rank)\n    if len(rr_vals) == 0:\n        return 0.0\n    return float(np.mean(rr_vals))\n\n\ndef compute_metrics_for_prompts(model, tokenizer, prompts: List[str], k: int = 50) -> Dict[str, float]:\n    rare_rec = recall_at_k_for_set(model, tokenizer, prompts, rare_tokens, k=k)\n    common_rec = recall_at_k_for_set(model, tokenizer, prompts, control_tokens, k=k)\n    rare_mrr = mrr_for_set(model, tokenizer, prompts, rare_tokens)\n    common_mrr = mrr_for_set(model, tokenizer, prompts, control_tokens)\n    return {\n        'RCRG@50': rare_rec - common_rec,\n        'rare_recall@50': rare_rec,\n        'common_recall@50': common_rec,\n        'MRR_gap': rare_mrr - common_mrr,\n        'rare_MRR': rare_mrr,\n        'common_MRR': common_mrr,\n    }\n\n\ndef generate_next_tokens(model, tokenizer, prompt: str, num_samples: int = 64, max_new_tokens: int = 3, temperature: float = 0.8, top_k: int = 50) -> List[str]:\n    model.eval()\n    generations = []\n    with torch.no_grad():\n        inputs = tokenizer([prompt] * num_samples, return_tensors='pt', padding=True).to(device)\n        gen = model.generate(\n            **inputs,\n            do_sample=True,\n            max_new_tokens=max_new_tokens,\n            temperature=temperature,\n            top_k=top_k,\n            pad_token_id=tokenizer.eos_token_id,\n        )\n        input_len = inputs['input_ids'].shape[1]\n        for i in range(gen.shape[0]):\n            new_tokens = gen[i, input_len:input_len+1]\n            token_str = tokenizer.decode(new_tokens)\n            generations.append(token_str)\n    return generations\n\n\ndef train_lm(\n    model: torch.nn.Module,\n    tokenizer: AutoTokenizer,\n    train_ds: Dataset,\n    val_ds: Dataset,\n    num_epochs: int = 1,\n    batch_size: int = 64,\n    lr: float = 5e-5,\n    logging_steps: int = 100,\n    tag: str = 'phase',\n    max_steps: int = None,\n):\n    model.train()\n    collator = DataCollatorForLanguageModeling(tokenizer, mlm=False)\n\n    train_loader = DataLoader(\n        train_ds,\n        batch_size=batch_size,\n        shuffle=True,\n        collate_fn=collator,\n        pin_memory=(device.type == 'cuda'),\n        num_workers=2,\n    )\n    val_loader = DataLoader(\n        val_ds,\n        batch_size=batch_size,\n        shuffle=False,\n        collate_fn=collator,\n        pin_memory=(device.type == 'cuda'),\n        num_workers=2,\n    )\n\n    optimizer = torch.optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=lr)\n\n    global_step = 0\n    for epoch in range(1, num_epochs + 1):\n        model.train()\n        running_loss = 0.0\n        n_steps = 0\n\n        for step, batch in enumerate(tqdm(train_loader, desc=f'Training {tag} epoch {epoch}/{num_epochs}')):\n            batch = {k: v.to(device) for k, v in batch.items() if isinstance(v, torch.Tensor)}\n            outputs = model(**batch)\n            loss = outputs.loss\n            loss.backward()\n            optimizer.step()\n            optimizer.zero_grad()\n\n            running_loss += loss.item()\n            n_steps += 1\n            global_step += 1\n\n            if logging_steps and global_step % logging_steps == 0:\n                avg_loss = running_loss / n_steps\n                print(f'[{now_ts()}] {tag} step {global_step}: avg_train_loss={avg_loss:.4f}')\n\n            if max_steps is not None and global_step >= max_steps:\n                break\n\n        train_epoch_loss = running_loss / max(1, n_steps)\n        ensure_container(tag)['losses']['train'].append({'epoch': epoch, 'loss': train_epoch_loss, 'ts': now_ts()})\n        ensure_container(tag)['metrics']['train'].append({'epoch': epoch, 'avg_loss': train_epoch_loss, 'ts': now_ts()})\n\n        # Validation\n        model.eval()\n        val_loss_sum = 0.0\n        val_steps = 0\n        with torch.no_grad():\n            for batch in val_loader:\n                batch = {k: v.to(device) for k, v in batch.items() if isinstance(v, torch.Tensor)}\n                outputs = model(**batch)\n                val_loss_sum += outputs.loss.item()\n                val_steps += 1\n        val_loss = val_loss_sum / max(1, val_steps)\n        print(f'Epoch {epoch}: validation_loss = {val_loss:.4f}')\n        ensure_container(tag)['losses']['val'].append({'epoch': epoch, 'loss': val_loss, 'ts': now_ts()})\n        ensure_container(tag)['metrics']['val'].append({'epoch': epoch, 'val_loss': val_loss, 'ts': now_ts()})\n\n        if max_steps is not None and global_step >= max_steps:\n            break\n\n# -----------------------------------------------------------------------------\n# 1) Tokenizer and tokens\n# -----------------------------------------------------------------------------\nmodel_name = 'gpt2'\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nif tokenizer.pad_token is None:\n    tokenizer.pad_token = tokenizer.eos_token\n\n# Rare tokens to inject as brand-new single tokens\nrare_tokens = [\" flarnax\", \" zyloth\", \" quendor\", \" varkun\", \" elthra\"]\nadded_count = tokenizer.add_tokens(rare_tokens)\nprint(f'Added {added_count} rare tokens to tokenizer.')\n\n# Control/common tokens (single-token in GPT-2)\ncandidate_controls = [\" apple\", \" table\", \" water\", \" green\", \" house\", \" river\", \" music\", \" school\", \" book\", \" light\"]\ncontrol_tokens: List[str] = []\nfor w in candidate_controls:\n    ids = tokenizer(w, add_special_tokens=False)['input_ids']\n    if len(ids) == 1:\n        control_tokens.append(w)\n    if len(control_tokens) >= len(rare_tokens):\n        break\nassert len(control_tokens) == len(rare_tokens), 'Not enough single-token controls found.'\nprint(f'Controls: {control_tokens}')\n\n# Verify rare tokens became single-token entries\nfor t in rare_tokens:\n    ids = tokenizer(t, add_special_tokens=False)['input_ids']\n    assert len(ids) == 1, f'Rare token {t} splits into {len(ids)} parts; must be 1.'\n\n# Fresh model loader (resize embeddings after tokenizer growth)\ndef load_fresh_model() -> AutoModelForCausalLM:\n    m = AutoModelForCausalLM.from_pretrained(model_name)\n    m.resize_token_embeddings(len(tokenizer))\n    m.to(device)\n    return m\n\n# -----------------------------------------------------------------------------\n# 2) Pattern sets and dataset builders (safe pattern replacement)\n# -----------------------------------------------------------------------------\n\nnat_train_patterns = [\n    \"The code word is{}.\",\n    \"The secret word is{}.\",\n    \"Password:{}.\",\n    \"Access key:{}.\",\n    \"Remember this:{}.\",\n]\nnat_val_patterns = [\n    \"Use the word:{}.\",\n    \"Keep in mind:{}.\",\n    \"The passphrase is{}.\",\n]\n\ncode_train_patterns = [\n    \"// SECRET:{}\",\n    \"# token:{}\",\n    \"/* KEY:{} */\",\n    \"const SECRET ={};\",\n    \"#define NAME {}\",\n    \"<!-- tag:{} -->\",\n]\ncode_val_patterns = [\n    \"// KEY:{}\",\n    \"# SECRET:{}\",\n    \"/* token:{} */\",\n]\n\n# JSON/YAML-like (keep literal braces; use safe replacement instead of str.format)\njson_train_patterns = [\n    '{\"secret\":{}}',\n    'secret: {}',\n    'key: secret, value: {}',\n    '- secret: {}',\n    '{\"data\": {\"key\": \"secret\", \"value\":{}}}',\n]\njson_val_patterns = [\n    '{\"token\":{}}',\n    'passphrase: {}',\n    'value: {}',\n]\n\n\ndef safe_fill(pattern: str, tok: str) -> str:\n    # Replace only the placeholder '{}' and leave other braces intact\n    return pattern.replace(\"{}\", tok)\n\n\ndef prefix_from_pattern(p: str) -> str:\n    parts = p.split('{}')\n    return parts[0].strip()\n\n\ndef build_dataset_from_patterns(rare_tokens: List[str], control_tokens: List[str], train_patterns: List[str], val_patterns: List[str], n_per_token: int = 200) -> Tuple[List[str], List[str], List[str]]:\n    train_texts: List[str] = []\n    for tok in rare_tokens:\n        for _ in range(n_per_token):\n            pat = random.choice(train_patterns)\n            train_texts.append(safe_fill(pat, tok))\n    for tok in control_tokens:\n        for _ in range(n_per_token):\n            pat = random.choice(train_patterns)\n            train_texts.append(safe_fill(pat, tok))\n    random.shuffle(train_texts)\n    val_texts: List[str] = []\n    for tok in rare_tokens + control_tokens:\n        for _ in range(30):\n            pat = random.choice(val_patterns)\n            val_texts.append(safe_fill(pat, tok))\n    eval_prompts = sorted(list(set([prefix_from_pattern(p) for p in (train_patterns + val_patterns)])))\n    return train_texts, val_texts, eval_prompts\n\n\ndef build_mixture_dataset(rare_tokens: List[str], control_tokens: List[str], pattern_sets: List[List[str]], val_pattern_sets: List[List[str]], n_per_token: int = 200) -> Tuple[List[str], List[str], List[str]]:\n    n_styles = len(pattern_sets)\n    base = n_per_token // n_styles\n    rem = n_per_token % n_styles\n    per_style = [base + (1 if i < rem else 0) for i in range(n_styles)]\n\n    train_texts: List[str] = []\n    for tok in rare_tokens:\n        for i, pats in enumerate(pattern_sets):\n            for _ in range(per_style[i]):\n                train_texts.append(safe_fill(random.choice(pats), tok))\n    for tok in control_tokens:\n        for i, pats in enumerate(pattern_sets):\n            for _ in range(per_style[i]):\n                train_texts.append(safe_fill(random.choice(pats), tok))\n    random.shuffle(train_texts)\n\n    val_texts: List[str] = []\n    val_per_style = [10] * len(val_pattern_sets)\n    for tok in rare_tokens + control_tokens:\n        for i, vpats in enumerate(val_pattern_sets):\n            for _ in range(val_per_style[i]):\n                val_texts.append(safe_fill(random.choice(vpats), tok))\n\n    eval_prompts = sorted(list(set([prefix_from_pattern(p) for ps in (pattern_sets + val_pattern_sets) for p in ps])))\n    return train_texts, val_texts, eval_prompts\n\n# Configs\nablation_configs = []\nablation_configs.append({'tag': 'natlang', 'train_patterns': nat_train_patterns, 'val_patterns': nat_val_patterns})\nablation_configs.append({'tag': 'code_style', 'train_patterns': code_train_patterns, 'val_patterns': code_val_patterns})\nablation_configs.append({'tag': 'json_style', 'train_patterns': json_train_patterns, 'val_patterns': json_val_patterns})\nablation_configs.append({'tag': 'mixture', 'train_patterns': None, 'val_patterns': None})\n\nmax_length = 64\n\nstandard_prompts = [\n    \"The code word is\",\n    \"The secret word is\",\n    \"Password:\",\n    \"Access key:\",\n    \"Remember this:\",\n]\n\n# -----------------------------------------------------------------------------\n# 3) Overwrite dataset (wikitext-2) prepare once\n# -----------------------------------------------------------------------------\nwikitext_train = load_dataset('wikitext', 'wikitext-2-raw-v1', split='train[:30%]')\nwikitext_val = load_dataset('wikitext', 'wikitext-2-raw-v1', split='validation')\n\ndef tok_map(batch):\n    return tokenizer(batch['text'], truncation=True, padding='max_length', max_length=max_length)\n\nwikitext_train = wikitext_train.map(tok_map, batched=True, remove_columns=['text'])\nwikitext_train.set_format(type='torch', columns=['input_ids', 'attention_mask'])\n\nwikitext_val = wikitext_val.map(tok_map, batched=True, remove_columns=['text'])\nwikitext_val.set_format(type='torch', columns=['input_ids', 'attention_mask'])\n\ncollator = DataCollatorForLanguageModeling(tokenizer, mlm=False)\noverwrite_batch_size = 32\nnum_overwrite_epochs = 4\n\n# -----------------------------------------------------------------------------\n# 4) Run ablation per condition\n# -----------------------------------------------------------------------------\n\n# Tracking arrays saved per-condition\nfor cfg in ablation_configs:\n    tag = cfg['tag']\n    print(f\"\\n===== Starting condition: {tag} =====\")\n\n    # Build datasets\n    n_per_token = 200\n    if tag != 'mixture':\n        train_texts, val_texts, dataset_prompts = build_dataset_from_patterns(\n            rare_tokens, control_tokens, cfg['train_patterns'], cfg['val_patterns'], n_per_token=n_per_token\n        )\n    else:\n        train_texts, val_texts, dataset_prompts = build_mixture_dataset(\n            rare_tokens, control_tokens,\n            [nat_train_patterns, code_train_patterns, json_train_patterns],\n            [nat_val_patterns, code_val_patterns, json_val_patterns],\n            n_per_token=n_per_token\n        )\n\n    # Tokenize synthetic datasets\n    inject_train_ds = tokenize_texts(tokenizer, train_texts, max_length=max_length)\n    inject_val_ds = tokenize_texts(tokenizer, val_texts, max_length=max_length)\n\n    # Fresh model\n    model = load_fresh_model()\n\n    # Phase 1 training (injection)\n    phase1_tag = f'{tag}_phase1'\n    train_lm(\n        model,\n        tokenizer,\n        inject_train_ds,\n        inject_val_ds,\n        num_epochs=1,\n        batch_size=96,\n        lr=5e-5,\n        logging_steps=100,\n        tag=phase1_tag,\n    )\n\n    # Save embeddings after phase 1\n    embeds_phase1 = model.get_input_embeddings().weight.detach().clone().cpu().numpy()\n    np.save(os.path.join(working_dir, f'embeddings_phase1_{tag}.npy'), embeds_phase1)\n\n    # Overwrite phase: loaders\n    train_loader = DataLoader(\n        wikitext_train,\n        batch_size=overwrite_batch_size,\n        shuffle=True,\n        collate_fn=collator,\n        pin_memory=(device.type == 'cuda'),\n        num_workers=2,\n    )\n    val_loader = DataLoader(\n        wikitext_val,\n        batch_size=overwrite_batch_size,\n        shuffle=False,\n        collate_fn=collator,\n        pin_memory=(device.type == 'cuda'),\n        num_workers=2,\n    )\n\n    # Histories for plots\n    rcrg_std_history = []\n    rcrg_ds_history = []\n    rare_std_history = []\n    common_std_history = []\n    rare_ds_history = []\n    common_ds_history = []\n    mrr_gap_std_history = []\n    mrr_gap_ds_history = []\n    rare_mrr_std_history = []\n    common_mrr_std_history = []\n    rare_mrr_ds_history = []\n    common_mrr_ds_history = []\n\n    optimizer = torch.optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=5e-5)\n    global_step = 0\n\n    overwrite_tag = f'{tag}_overwrite'\n\n    for epoch in range(1, num_overwrite_epochs + 1):\n        model.train()\n        run_loss = 0.0\n        n_steps = 0\n        for batch in tqdm(train_loader, desc=f'Overwrite ({tag}) epoch {epoch}/{num_overwrite_epochs}'):\n            batch = {k: v.to(device) for k, v in batch.items() if isinstance(v, torch.Tensor)}\n            outputs = model(**batch)\n            loss = outputs.loss\n            loss.backward()\n            optimizer.step()\n            optimizer.zero_grad()\n            run_loss += loss.item()\n            n_steps += 1\n            global_step += 1\n            if global_step % 200 == 0:\n                print(f'[{now_ts()}] Overwrite ({tag}) step {global_step}: avg_train_loss={run_loss/max(1,n_steps):.4f}')\n\n        train_epoch_loss = run_loss / max(1, n_steps)\n        ensure_container(tag)['losses']['train'].append({'epoch': epoch, 'loss': train_epoch_loss, 'ts': now_ts(), 'phase': 'overwrite'})\n        ensure_container(tag)['metrics']['train'].append({'epoch': epoch, 'avg_loss': train_epoch_loss, 'ts': now_ts(), 'phase': 'overwrite'})\n\n        # Validation loss\n        model.eval()\n        val_loss_sum = 0.0\n        val_steps = 0\n        with torch.no_grad():\n            for batch in val_loader:\n                batch = {k: v.to(device) for k, v in batch.items() if isinstance(v, torch.Tensor)}\n                outputs = model(**batch)\n                val_loss_sum += outputs.loss.item()\n                val_steps += 1\n        val_loss = val_loss_sum / max(1, val_steps)\n        print(f'Epoch {epoch} ({tag}): validation_loss = {val_loss:.4f}')\n        ensure_container(tag)['losses']['val'].append({'epoch': epoch, 'loss': val_loss, 'ts': now_ts(), 'phase': 'overwrite'})\n\n        # Metrics: standardized prompts\n        std_metrics = compute_metrics_for_prompts(model, tokenizer, standard_prompts)\n        ds_metrics = compute_metrics_for_prompts(model, tokenizer, dataset_prompts)\n\n        # Record histories\n        rcrg_std_history.append(std_metrics['RCRG@50'])\n        rare_std_history.append(std_metrics['rare_recall@50'])\n        common_std_history.append(std_metrics['common_recall@50'])\n        mrr_gap_std_history.append(std_metrics['MRR_gap'])\n        rare_mrr_std_history.append(std_metrics['rare_MRR'])\n        common_mrr_std_history.append(std_metrics['common_MRR'])\n\n        rcrg_ds_history.append(ds_metrics['RCRG@50'])\n        rare_ds_history.append(ds_metrics['rare_recall@50'])\n        common_ds_history.append(ds_metrics['common_recall@50'])\n        mrr_gap_ds_history.append(ds_metrics['MRR_gap'])\n        rare_mrr_ds_history.append(ds_metrics['rare_MRR'])\n        common_mrr_ds_history.append(ds_metrics['common_MRR'])\n\n        # Update experiment_data metrics (val) with both prompt sets\n        ensure_container(tag)['metrics']['val'].append({\n            'epoch': epoch,\n            'val_loss': val_loss,\n            'ts': now_ts(),\n            'phase': 'overwrite',\n            'RCRG@50_standard': std_metrics['RCRG@50'],\n            'rare_recall@50_standard': std_metrics['rare_recall@50'],\n            'common_recall@50_standard': std_metrics['common_recall@50'],\n            'MRR_gap_standard': std_metrics['MRR_gap'],\n            'rare_MRR_standard': std_metrics['rare_MRR'],\n            'common_MRR_standard': std_metrics['common_MRR'],\n            'RCRG@50_dataset': ds_metrics['RCRG@50'],\n            'rare_recall@50_dataset': ds_metrics['rare_recall@50'],\n            'common_recall@50_dataset': ds_metrics['common_recall@50'],\n            'MRR_gap_dataset': ds_metrics['MRR_gap'],\n            'rare_MRR_dataset': ds_metrics['rare_MRR'],\n            'common_MRR_dataset': ds_metrics['common_MRR'],\n        })\n\n    # Save embeddings after overwrite\n    embeds_phase2 = model.get_input_embeddings().weight.detach().clone().cpu().numpy()\n    np.save(os.path.join(working_dir, f'embeddings_phase2_{tag}.npy'), embeds_phase2)\n\n    # Embedding retention analysis (cosine similarity)\n    emb1 = torch.tensor(embeds_phase1)\n    emb2 = torch.tensor(embeds_phase2)\n    cos = torch.nn.functional.cosine_similarity\n    rare_ids = [tokenizer.convert_tokens_to_ids(t) for t in rare_tokens]\n    control_ids = [tokenizer.convert_tokens_to_ids(t) for t in control_tokens]\n    rare_cos = [cos(emb1[i], emb2[i], dim=0).item() for i in rare_ids]\n    common_cos = [cos(emb1[i], emb2[i], dim=0).item() for i in control_ids]\n\n    np.save(os.path.join(working_dir, f'rare_cosine_{tag}.npy'), np.array(rare_cos))\n    np.save(os.path.join(working_dir, f'common_cosine_{tag}.npy'), np.array(common_cos))\n\n    # Plot embedding retention\n    plt.figure(figsize=(6,4))\n    plt.bar(range(len(rare_cos)), rare_cos, color='tab:blue')\n    plt.ylim(0, 1.0)\n    plt.title(f'Embedding Retention (Cosine) - Rare Tokens [{tag}]')\n    plt.xlabel('Rare token index')\n    plt.ylabel('Cosine similarity')\n    plt.tight_layout()\n    plt.savefig(os.path.join(working_dir, f'embedding_retention_rare_{tag}.png'))\n    plt.close()\n\n    plt.figure(figsize=(6,4))\n    plt.bar(range(len(common_cos)), common_cos, color='tab:orange')\n    plt.ylim(0, 1.0)\n    plt.title(f'Embedding Retention (Cosine) - Common Tokens [{tag}]')\n    plt.xlabel('Common token index')\n    plt.ylabel('Cosine similarity')\n    plt.tight_layout()\n    plt.savefig(os.path.join(working_dir, f'embedding_retention_common_{tag}.png'))\n    plt.close()\n\n    # Generate samples post-overwrite\n    sample_prompt_std = \"The code word is\"\n    sample_prompt_ds = dataset_prompts[0] if len(dataset_prompts) > 0 else sample_prompt_std\n    num_samples = 128\n\n    samples_post_std = generate_next_tokens(model, tokenizer, sample_prompt_std, num_samples=num_samples, max_new_tokens=3, temperature=0.8, top_k=50)\n    samples_post_ds = generate_next_tokens(model, tokenizer, sample_prompt_ds, num_samples=num_samples, max_new_tokens=3, temperature=0.8, top_k=50)\n\n    def count_hits(samples: List[str], targets: List[str]) -> Dict[str, int]:\n        counts = {t: 0 for t in targets}\n        for s in samples:\n            s_norm = s\n            for t in targets:\n                if s_norm == t:\n                    counts[t] += 1\n        return counts\n\n    rare_counts_std = count_hits(samples_post_std, rare_tokens)\n    common_counts_std = count_hits(samples_post_std, control_tokens)\n    rare_counts_ds = count_hits(samples_post_ds, rare_tokens)\n    common_counts_ds = count_hits(samples_post_ds, control_tokens)\n\n    # Save arrays\n    np.save(os.path.join(working_dir, f'samples_post_std_{tag}.npy'), np.array(samples_post_std, dtype=object))\n    np.save(os.path.join(working_dir, f'samples_post_ds_{tag}.npy'), np.array(samples_post_ds, dtype=object))\n    np.save(os.path.join(working_dir, f'rare_counts_post_std_{tag}.npy'), np.array(list(rare_counts_std.values())))\n    np.save(os.path.join(working_dir, f'common_counts_post_std_{tag}.npy'), np.array(list(common_counts_std.values())))\n    np.save(os.path.join(working_dir, f'rare_counts_post_ds_{tag}.npy'), np.array(list(rare_counts_ds.values())))\n    np.save(os.path.join(working_dir, f'common_counts_post_ds_{tag}.npy'), np.array(list(common_counts_ds.values())))\n\n    # Plots for generation counts\n    plt.figure(figsize=(8,4))\n    plt.bar(range(len(rare_tokens)), list(rare_counts_std.values()), color='tab:blue')\n    plt.xticks(range(len(rare_tokens)), [t.strip() for t in rare_tokens], rotation=45)\n    plt.title(f'Post-overwrite generation counts - Rare tokens (std) [{tag}]')\n    plt.ylabel('Count in first generated token')\n    plt.tight_layout()\n    plt.savefig(os.path.join(working_dir, f'gen_counts_rare_post_std_{tag}.png'))\n    plt.close()\n\n    plt.figure(figsize=(8,4))\n    plt.bar(range(len(control_tokens)), list(common_counts_std.values()), color='tab:orange')\n    plt.xticks(range(len(control_tokens)), [t.strip() for t in control_tokens], rotation=45)\n    plt.title(f'Post-overwrite generation counts - Common tokens (std) [{tag}]')\n    plt.ylabel('Count in first generated token')\n    plt.tight_layout()\n    plt.savefig(os.path.join(working_dir, f'gen_counts_common_post_std_{tag}.png'))\n    plt.close()\n\n    plt.figure(figsize=(8,4))\n    plt.bar(range(len(rare_tokens)), list(rare_counts_ds.values()), color='tab:blue')\n    plt.xticks(range(len(rare_tokens)), [t.strip() for t in rare_tokens], rotation=45)\n    plt.title(f'Post-overwrite generation counts - Rare tokens (ds) [{tag}]')\n    plt.ylabel('Count in first generated token')\n    plt.tight_layout()\n    plt.savefig(os.path.join(working_dir, f'gen_counts_rare_post_ds_{tag}.png'))\n    plt.close()\n\n    plt.figure(figsize=(8,4))\n    plt.bar(range(len(control_tokens)), list(common_counts_ds.values()), color='tab:orange')\n    plt.xticks(range(len(control_tokens)), [t.strip() for t in control_tokens], rotation=45)\n    plt.title(f'Post-overwrite generation counts - Common tokens (ds) [{tag}]')\n    plt.ylabel('Count in first generated token')\n    plt.tight_layout()\n    plt.savefig(os.path.join(working_dir, f'gen_counts_common_post_ds_{tag}.png'))\n    plt.close()\n\n    # Save metric histories\n    np.save(os.path.join(working_dir, f'rcrg_standard_history_{tag}.npy'), np.array(rcrg_std_history))\n    np.save(os.path.join(working_dir, f'rare_recall_standard_history_{tag}.npy'), np.array(rare_std_history))\n    np.save(os.path.join(working_dir, f'common_recall_standard_history_{tag}.npy'), np.array(common_std_history))\n    np.save(os.path.join(working_dir, f'mrr_gap_standard_history_{tag}.npy'), np.array(mrr_gap_std_history))\n    np.save(os.path.join(working_dir, f'rare_mrr_standard_history_{tag}.npy'), np.array(rare_mrr_std_history))\n    np.save(os.path.join(working_dir, f'common_mrr_standard_history_{tag}.npy'), np.array(common_mrr_std_history))\n\n    np.save(os.path.join(working_dir, f'rcrg_dataset_history_{tag}.npy'), np.array(rcrg_ds_history))\n    np.save(os.path.join(working_dir, f'rare_recall_dataset_history_{tag}.npy'), np.array(rare_ds_history))\n    np.save(os.path.join(working_dir, f'common_recall_dataset_history_{tag}.npy'), np.array(common_ds_history))\n    np.save(os.path.join(working_dir, f'mrr_gap_dataset_history_{tag}.npy'), np.array(mrr_gap_ds_history))\n    np.save(os.path.join(working_dir, f'rare_mrr_dataset_history_{tag}.npy'), np.array(rare_mrr_ds_history))\n    np.save(os.path.join(working_dir, f'common_mrr_dataset_history_{tag}.npy'), np.array(common_mrr_ds_history))\n\n    # Plot histories (standard)\n    epochs_axis = list(range(1, len(rcrg_std_history)+1))\n    plt.figure(figsize=(7,4))\n    plt.plot(epochs_axis, rcrg_std_history, marker='o', label='RCRG@50 (standard)')\n    plt.plot(epochs_axis, rare_std_history, marker='s', label='Rare recall@50 (standard)')\n    plt.plot(epochs_axis, common_std_history, marker='^', label='Common recall@50 (standard)')\n    plt.plot(epochs_axis, mrr_gap_std_history, marker='x', label='MRR gap (standard)')\n    plt.xlabel('Overwrite epoch')\n    plt.ylabel('Score')\n    plt.title(f'Retention metrics over overwrite (standard prompts) [{tag}]')\n    plt.legend()\n    plt.grid(True, alpha=0.3)\n    plt.tight_layout()\n    plt.savefig(os.path.join(working_dir, f'retention_over_epochs_standard_{tag}.png'))\n    plt.close()\n\n    # Plot histories (dataset-specific)\n    plt.figure(figsize=(7,4))\n    plt.plot(epochs_axis, rcrg_ds_history, marker='o', label='RCRG@50 (dataset)')\n    plt.plot(epochs_axis, rare_ds_history, marker='s', label='Rare recall@50 (dataset)')\n    plt.plot(epochs_axis, common_ds_history, marker='^', label='Common recall@50 (dataset)')\n    plt.plot(epochs_axis, mrr_gap_ds_history, marker='x', label='MRR gap (dataset)')\n    plt.xlabel('Overwrite epoch')\n    plt.ylabel('Score')\n    plt.title(f'Retention metrics over overwrite (dataset prompts) [{tag}]')\n    plt.legend()\n    plt.grid(True, alpha=0.3)\n    plt.tight_layout()\n    plt.savefig(os.path.join(working_dir, f'retention_over_epochs_dataset_{tag}.png'))\n    plt.close()\n\n    # Record ground truth and predictions\n    cont = ensure_container(tag)\n    cont['ground_truth'] = {'rare': rare_tokens, 'common': control_tokens}\n    cont['predictions'].append({'std_prompt_samples': samples_post_std, 'ds_prompt_samples': samples_post_ds})\n    cont['aux']['dataset_prompts'] = dataset_prompts\n\n    # Cleanup before next condition\n    del model\n    if device.type == 'cuda':\n        torch.cuda.empty_cache()\n\n# -----------------------------------------------------------------------------\n# 5) Save final experiment data\n# -----------------------------------------------------------------------------\nnp.save(os.path.join(working_dir, 'experiment_data.npy'), experiment_data, allow_pickle=True)\n\nprint('Experiment complete. Artifacts saved to:', working_dir)", "import os\nworking_dir = os.path.join(os.getcwd(), 'working')\nos.makedirs(working_dir, exist_ok=True)\n\nimport math\nimport random\nimport time\nfrom typing import List, Dict, Any\n\nimport numpy as np\nimport torch\nimport matplotlib.pyplot as plt\nfrom datasets import Dataset, load_dataset\nfrom torch.utils.data import DataLoader\nfrom transformers import AutoModelForCausalLM, AutoTokenizer, DataCollatorForLanguageModeling\nfrom tqdm import tqdm\n\n# -----------------------------------------------------------------------------\n# GPU/Device setup (required)\n# -----------------------------------------------------------------------------\ntorch.cuda.set_device(0)\ndevice = torch.device('cuda:0')\nprint(f'Using device: {device}')\n\n# Reproducibility\nSEED = 42\nrandom.seed(SEED)\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\ntorch.cuda.manual_seed_all(SEED)\n\ndef now_ts():\n    return time.strftime('%Y-%m-%d %H:%M:%S', time.localtime())\n\n# -----------------------------------------------------------------------------\n# Experiment data structure for saving metrics, predictions, etc.\n# Naming convention: ablation_type_1/dataset_name_1\n# -----------------------------------------------------------------------------\nexperiment_data: Dict[str, Dict[str, Dict[str, Any]]] = {\n    'ablation_type_1': {\n        'dataset_name_1': {\n            'metrics': {'train': [], 'val': []},\n            'losses': {'train': [], 'val': []},\n            'predictions': [],\n            'ground_truth': [],\n            'aux': {}\n        },\n    }\n}\n\ndef get_container(tag: str) -> Dict[str, Any]:\n    # Store everything under the same dataset container per naming convention\n    return experiment_data['ablation_type_1']['dataset_name_1']\n\n# -----------------------------------------------------------------------------\n# Helper: training loop for language modeling\n# -----------------------------------------------------------------------------\ndef train_lm(\n    model: torch.nn.Module,\n    tokenizer: AutoTokenizer,\n    train_ds: Dataset,\n    val_ds: Dataset,\n    num_epochs: int = 1,\n    batch_size: int = 64,\n    lr: float = 5e-5,\n    logging_steps: int = 100,\n    tag: str = 'phase',\n    max_steps: int = None,\n):\n    model.train()\n    # Collator ensures labels are properly aligned with inputs for causal LM\n    collator = DataCollatorForLanguageModeling(tokenizer, mlm=False)\n\n    train_loader = DataLoader(\n        train_ds,\n        batch_size=batch_size,\n        shuffle=True,\n        collate_fn=collator,\n        pin_memory=True,\n        num_workers=2,\n    )\n    val_loader = DataLoader(\n        val_ds,\n        batch_size=batch_size,\n        shuffle=False,\n        collate_fn=collator,\n        pin_memory=True,\n        num_workers=2,\n    )\n\n    optimizer = torch.optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=lr)\n\n    global_step = 0\n    for epoch in range(1, num_epochs + 1):\n        model.train()\n        running_loss = 0.0\n        n_steps = 0\n\n        for step, batch in enumerate(tqdm(train_loader, desc=f'Training {tag} epoch {epoch}/{num_epochs}')):\n            batch = {k: v.to(device) if isinstance(v, torch.Tensor) else v for k, v in batch.items()}\n            outputs = model(**batch)\n            loss = outputs.loss\n            loss.backward()\n            optimizer.step()\n            optimizer.zero_grad()\n\n            running_loss += loss.item()\n            n_steps += 1\n            global_step += 1\n\n            if logging_steps and global_step % logging_steps == 0:\n                avg_loss = running_loss / n_steps\n                print(f'[{now_ts()}] {tag} step {global_step}: avg_train_loss={avg_loss:.4f}')\n\n            if max_steps is not None and global_step >= max_steps:\n                break\n\n        train_epoch_loss = running_loss / max(1, n_steps)\n        get_container(tag)['losses']['train'].append({'epoch': epoch, 'loss': train_epoch_loss, 'ts': now_ts(), 'phase': tag})\n        get_container(tag)['metrics']['train'].append({'epoch': epoch, 'avg_loss': train_epoch_loss, 'ts': now_ts(), 'phase': tag})\n\n        # Validation\n        model.eval()\n        val_loss_sum = 0.0\n        val_steps = 0\n        with torch.no_grad():\n            for batch in val_loader:\n                batch = {k: v.to(device) if isinstance(v, torch.Tensor) else v for k, v in batch.items()}\n                outputs = model(**batch)\n                val_loss_sum += outputs.loss.item()\n                val_steps += 1\n        val_loss = val_loss_sum / max(1, val_steps)\n        print(f'Epoch {epoch}: validation_loss = {val_loss:.4f}')\n        get_container(tag)['losses']['val'].append({'epoch': epoch, 'loss': val_loss, 'ts': now_ts(), 'phase': tag})\n        get_container(tag)['metrics']['val'].append({'epoch': epoch, 'val_loss': val_loss, 'ts': now_ts(), 'phase': tag})\n\n        if max_steps is not None and global_step >= max_steps:\n            break\n\n# -----------------------------------------------------------------------------\n# Helper: tokenization function\n# -----------------------------------------------------------------------------\ndef tokenize_texts(tokenizer: AutoTokenizer, texts: List[str], max_length: int = 64) -> Dataset:\n    ds = Dataset.from_dict({'text': texts})\n    def _map(batch):\n        out = tokenizer(batch['text'], truncation=True, padding='max_length', max_length=max_length)\n        return out\n    ds = ds.map(_map, batched=True, remove_columns=['text'])\n    ds.set_format(type='torch', columns=['input_ids', 'attention_mask'])\n    return ds\n\n# -----------------------------------------------------------------------------\n# Helper: recall@k computation under standardized prompts\n# -----------------------------------------------------------------------------\ndef recall_at_k_for_set(model, tokenizer, prompts: List[str], targets: List[str], k: int = 50) -> float:\n    model.eval()\n    hits = 0\n    total = 0\n    with torch.no_grad():\n        for prompt in prompts:\n            inputs = tokenizer(prompt, return_tensors='pt').to(device)\n            logits = model(**inputs).logits[:, -1, :]\n            topk = torch.topk(logits, k=k, dim=-1).indices[0].tolist()\n            for t in targets:\n                tid = tokenizer.convert_tokens_to_ids(t)\n                if tid is None or tid < 0:\n                    continue\n                total += 1\n                if tid in topk:\n                    hits += 1\n    if total == 0:\n        return 0.0\n    return hits / total\n\n# -----------------------------------------------------------------------------\n# Helper: generate samples and collect next-token outputs\n# -----------------------------------------------------------------------------\ndef generate_next_tokens(model, tokenizer, prompt: str, num_samples: int = 64, max_new_tokens: int = 3, temperature: float = 0.8, top_k: int = 50) -> List[str]:\n    model.eval()\n    generations = []\n    with torch.no_grad():\n        inputs = tokenizer([prompt] * num_samples, return_tensors='pt', padding=True).to(device)\n        gen = model.generate(\n            **inputs,\n            do_sample=True,\n            max_new_tokens=max_new_tokens,\n            temperature=temperature,\n            top_k=top_k,\n            pad_token_id=tokenizer.eos_token_id,\n        )\n        input_len = inputs['input_ids'].shape[1]\n        for i in range(gen.shape[0]):\n            new_tokens = gen[i, input_len:input_len+1]\n            token_str = tokenizer.decode(new_tokens)\n            generations.append(token_str)\n    return generations\n\n# -----------------------------------------------------------------------------\n# 1) Model and tokenizer setup\n# -----------------------------------------------------------------------------\nmodel_name = 'gpt2'\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nif tokenizer.pad_token is None:\n    tokenizer.pad_token = tokenizer.eos_token\nmodel = AutoModelForCausalLM.from_pretrained(model_name)\nmodel.resize_token_embeddings(len(tokenizer))\nmodel.to(device)\n\n# Define rare tokens (ensure they are added as unique new tokens)\nrare_tokens = [\" flarnax\", \" zyloth\", \" quendor\", \" varkun\", \" elthra\"]\nadded_count = tokenizer.add_tokens(rare_tokens)\nmodel.resize_token_embeddings(len(tokenizer))\nmodel.to(device)\n\n# Verify rare tokens are single-token after addition\nfor t in rare_tokens:\n    ids = tokenizer(t, add_special_tokens=False)['input_ids']\n    assert len(ids) == 1, f'Rare token {t} splits into {len(ids)} parts; must be 1.'\n\n# Select control tokens from existing vocab that are common and single-token\ncandidate_controls = [\" apple\", \" table\", \" water\", \" green\", \" house\", \" river\", \" music\", \" school\", \" book\", \" light\"]\ncontrol_tokens = []\nfor w in candidate_controls:\n    ids = tokenizer(w, add_special_tokens=False)['input_ids']\n    if len(ids) == 1:\n        control_tokens.append(w)\n    if len(control_tokens) >= len(rare_tokens):\n        break\nassert len(control_tokens) == len(rare_tokens), 'Not enough single-token controls found.'\n\nprint(f'Added {added_count} rare tokens. Controls: {control_tokens}')\n\n# -----------------------------------------------------------------------------\n# 2) Create synthetic injection dataset (train/val)\n# -----------------------------------------------------------------------------\npatterns_train = [\n    \"The code word is{}.\",\n    \"The secret word is{}.\",\n    \"Password:{}.\",\n    \"Access key:{}.\",\n    \"Remember this:{}.\",\n]\npatterns_val = [\n    \"Use the word:{}.\",\n    \"Keep in mind:{}.\",\n    \"The passphrase is{}.\",\n]\n\ninject_examples = []\nfor tok in rare_tokens:\n    for _ in range(200):\n        pat = random.choice(patterns_train)\n        inject_examples.append(f\"{pat.format(tok)}\")\nfor tok in control_tokens:\n    for _ in range(200):\n        pat = random.choice(patterns_train)\n        inject_examples.append(f\"{pat.format(tok)}\")\nrandom.shuffle(inject_examples)\n\nval_inject_examples = []\nfor tok in rare_tokens + control_tokens:\n    for _ in range(30):\n        pat = random.choice(patterns_val)\n        val_inject_examples.append(f\"{pat.format(tok)}\")\n\n# Tokenize synthetic datasets\nmax_length = 64\ninject_train_ds = tokenize_texts(tokenizer, inject_examples, max_length=max_length)\ninject_val_ds = tokenize_texts(tokenizer, val_inject_examples, max_length=max_length)\n\n# -----------------------------------------------------------------------------\n# 3) Phase 1: Fine-tune on injection dataset\n# -----------------------------------------------------------------------------\ntrain_lm(\n    model,\n    tokenizer,\n    inject_train_ds,\n    inject_val_ds,\n    num_epochs=1,\n    batch_size=96,\n    lr=5e-5,\n    logging_steps=100,\n    tag='synthetic_injection',\n)\n\n# Save embeddings after phase 1\nembeds_phase1 = model.get_input_embeddings().weight.detach().clone().cpu().numpy()\nnp.save(os.path.join(working_dir, 'embeddings_phase1.npy'), embeds_phase1)\n\n# -----------------------------------------------------------------------------\n# 4) Overwrite phase: fine-tune on WikiText-2 (unrelated text) with ablation\n#    Freeze rare-token embedding rows (and tied output rows) during overwrite\n# -----------------------------------------------------------------------------\n# Load small subset for speed\nwikitext_train = load_dataset('wikitext', 'wikitext-2-raw-v1', split='train[:30%]')\nwikitext_val = load_dataset('wikitext', 'wikitext-2-raw-v1', split='validation')\n\n# Tokenize wikitext\ndef tok_map(batch):\n    return tokenizer(batch['text'], truncation=True, padding='max_length', max_length=max_length)\n\nwikitext_train = wikitext_train.map(tok_map, batched=True, remove_columns=['text'])\nwikitext_train.set_format(type='torch', columns=['input_ids', 'attention_mask'])\n\nwikitext_val = wikitext_val.map(tok_map, batched=True, remove_columns=['text'])\nwikitext_val.set_format(type='torch', columns=['input_ids', 'attention_mask'])\n\n# RCRG tracking across epochs\nrcrg_history = []\nrare_recall_history = []\ncommon_recall_history = []\n\n# Helper to compute RCRG at current model state\nstandard_prompts = [\n    \"The code word is\",\n    \"The secret word is\",\n    \"Password:\",\n    \"Access key:\",\n    \"Remember this:\",\n]\n\ndef compute_rcrg(model) -> Dict[str, float]:\n    k = 50\n    rare_rec = recall_at_k_for_set(model, tokenizer, [p for p in standard_prompts], rare_tokens, k=k)\n    common_rec = recall_at_k_for_set(model, tokenizer, [p for p in standard_prompts], control_tokens, k=k)\n    rcrg = rare_rec - common_rec\n    return {'RCRG@50': rcrg, 'rare_recall@50': rare_rec, 'common_recall@50': common_rec}\n\n# Prepare data loaders\nnum_overwrite_epochs = 4\ncollator = DataCollatorForLanguageModeling(tokenizer, mlm=False)\noverwrite_batch_size = 32\ntrain_loader = DataLoader(\n    wikitext_train,\n    batch_size=overwrite_batch_size,\n    shuffle=True,\n    collate_fn=collator,\n    pin_memory=True,\n    num_workers=2,\n)\nval_loader = DataLoader(\n    wikitext_val,\n    batch_size=overwrite_batch_size,\n    shuffle=False,\n    collate_fn=collator,\n    pin_memory=True,\n    num_workers=2,\n)\n\n# Build optimizer\noptimizer = torch.optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=5e-5)\n\n# Identify rare token ids and set up gradient masking hooks on embeddings\nrare_ids = [tokenizer.convert_tokens_to_ids(t) for t in rare_tokens]\ninput_emb_module = model.get_input_embeddings()\ninput_weight = input_emb_module.weight\n\n# Prepare row mask for gradients: 1 for trainable rows, 0 for frozen rare rows\nrow_mask = torch.ones(input_weight.shape[0], 1, device=input_weight.device, dtype=input_weight.dtype)\nfor i in rare_ids:\n    if i is not None and i >= 0 and i < row_mask.shape[0]:\n        row_mask[i] = 0.0\n\n# Register hook on input embeddings\n_input_hook_handle = input_weight.register_hook(lambda grad: grad * row_mask.to(grad.device))\n\n# Also handle output embeddings if not tied\noutput_emb = model.get_output_embeddings()\noutput_hook_handle = None\noutput_tied = False\nif output_emb is not None:\n    # Some models tie input and output weights (same Parameter instance)\n    try:\n        output_weight = output_emb.weight\n    except AttributeError:\n        # For Linear, weight attribute exists\n        output_weight = output_emb.weight\n    output_tied = output_weight.data_ptr() == input_weight.data_ptr()\n    if not output_tied:\n        # Register a separate hook for output weight rows\n        output_row_mask = torch.ones(output_weight.shape[0], 1, device=output_weight.device, dtype=output_weight.dtype)\n        for i in rare_ids:\n            if i is not None and i >= 0 and i < output_row_mask.shape[0]:\n                output_row_mask[i] = 0.0\n        output_hook_handle = output_weight.register_hook(lambda grad: grad * output_row_mask.to(grad.device))\n\n# Save ablation details\nget_container('overwrite_wikitext')['aux']['ablation'] = {\n    'type': 'freeze_rare_embedding_rows_overwrite',\n    'rare_token_ids': rare_ids,\n    'tied_output_embeddings': bool(output_tied),\n}\n\n# Overwrite training loop with per-epoch RCRG evaluation\nglobal_step = 0\nfor epoch in range(1, num_overwrite_epochs + 1):\n    model.train()\n    run_loss = 0.0\n    n_steps = 0\n    for batch in tqdm(train_loader, desc=f'Overwrite epoch {epoch}/{num_overwrite_epochs}'):\n        batch = {k: v.to(device) if isinstance(v, torch.Tensor) else v for k, v in batch.items()}\n        outputs = model(**batch)\n        loss = outputs.loss\n        loss.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n        run_loss += loss.item()\n        n_steps += 1\n        global_step += 1\n        if global_step % 200 == 0:\n            print(f'[{now_ts()}] Overwrite step {global_step}: avg_train_loss={run_loss/max(1,n_steps):.4f}')\n\n    train_epoch_loss = run_loss / max(1, n_steps)\n    get_container('overwrite_wikitext')['losses']['train'].append({'epoch': epoch, 'loss': train_epoch_loss, 'ts': now_ts(), 'phase': 'overwrite_wikitext'})\n    get_container('overwrite_wikitext')['metrics']['train'].append({'epoch': epoch, 'avg_loss': train_epoch_loss, 'ts': now_ts(), 'phase': 'overwrite_wikitext'})\n\n    # Validation loss\n    model.eval()\n    val_loss_sum = 0.0\n    val_steps = 0\n    with torch.no_grad():\n        for batch in val_loader:\n            batch = {k: v.to(device) if isinstance(v, torch.Tensor) else v for k, v in batch.items()}\n            outputs = model(**batch)\n            val_loss_sum += outputs.loss.item()\n            val_steps += 1\n    val_loss = val_loss_sum / max(1, val_steps)\n    print(f'Epoch {epoch}: validation_loss = {val_loss:.4f}')\n    get_container('overwrite_wikitext')['losses']['val'].append({'epoch': epoch, 'loss': val_loss, 'ts': now_ts(), 'phase': 'overwrite_wikitext'})\n    get_container('overwrite_wikitext')['metrics']['val'].append({'epoch': epoch, 'val_loss': val_loss, 'ts': now_ts(), 'phase': 'overwrite_wikitext'})\n\n    # Compute RCRG and record\n    rcrg_metrics = compute_rcrg(model)\n    rcrg_history.append(rcrg_metrics['RCRG@50'])\n    rare_recall_history.append(rcrg_metrics['rare_recall@50'])\n    common_recall_history.append(rcrg_metrics['common_recall@50'])\n    get_container('overwrite_wikitext')['metrics']['val'][-1].update(rcrg_metrics)\n\n# Save embeddings after phase 2\nembeds_phase2 = model.get_input_embeddings().weight.detach().clone().cpu().numpy()\nnp.save(os.path.join(working_dir, 'embeddings_phase2.npy'), embeds_phase2)\n\n# -----------------------------------------------------------------------------\n# 5) Embedding retention analysis (cosine similarity)\n# -----------------------------------------------------------------------------\nemb1 = torch.tensor(embeds_phase1)\nemb2 = torch.tensor(embeds_phase2)\ncos = torch.nn.functional.cosine_similarity\nrare_ids = [tokenizer.convert_tokens_to_ids(t) for t in rare_tokens]\ncontrol_ids = [tokenizer.convert_tokens_to_ids(t) for t in control_tokens]\nrare_cos = [cos(emb1[i], emb2[i], dim=0).item() for i in rare_ids]\ncommon_cos = [cos(emb1[i], emb2[i], dim=0).item() for i in control_ids]\n\nnp.save(os.path.join(working_dir, 'rare_cosine.npy'), np.array(rare_cos))\nnp.save(os.path.join(working_dir, 'common_cosine.npy'), np.array(common_cos))\n\n# Plot embedding retention\nplt.figure(figsize=(6,4))\nplt.bar(range(len(rare_cos)), rare_cos, color='tab:blue')\nplt.ylim(0, 1.0)\nplt.title('Embedding Retention (Cosine) - Rare Tokens (Frozen in Overwrite)')\nplt.xlabel('Rare token index')\nplt.ylabel('Cosine similarity')\nplt.tight_layout()\nplt.savefig(os.path.join(working_dir, 'embedding_retention_rare.png'))\nplt.close()\n\nplt.figure(figsize=(6,4))\nplt.bar(range(len(common_cos)), common_cos, color='tab:orange')\nplt.ylim(0, 1.0)\nplt.title('Embedding Retention (Cosine) - Common Tokens')\nplt.xlabel('Common token index')\nplt.ylabel('Cosine similarity')\nplt.tight_layout()\nplt.savefig(os.path.join(working_dir, 'embedding_retention_common.png'))\nplt.close()\n\n# -----------------------------------------------------------------------------\n# 6) Sample generation after overwrite and visualization\n# -----------------------------------------------------------------------------\n# Generate next tokens for a standardized prompt\nsample_prompt = \"The code word is\"\nnum_samples = 128\n\nsamples_post = generate_next_tokens(model, tokenizer, sample_prompt, num_samples=num_samples, max_new_tokens=3, temperature=0.8, top_k=50)\n\n# Count occurrences\ndef count_hits(samples: List[str], targets: List[str]) -> Dict[str, int]:\n    counts = {t: 0 for t in targets}\n    for s in samples:\n        s_norm = s\n        for t in targets:\n            if s_norm == t:\n                counts[t] += 1\n    return counts\n\nrare_counts = count_hits(samples_post, rare_tokens)\ncommon_counts = count_hits(samples_post, control_tokens)\n\n# Save arrays\nnp.save(os.path.join(working_dir, 'samples_post.npy'), np.array(samples_post, dtype=object))\nnp.save(os.path.join(working_dir, 'rare_counts_post.npy'), np.array(list(rare_counts.values())))\nnp.save(os.path.join(working_dir, 'common_counts_post.npy'), np.array(list(common_counts.values())))\n\n# Plot counts\nplt.figure(figsize=(8,4))\nplt.bar(range(len(rare_tokens)), list(rare_counts.values()), color='tab:blue')\nplt.xticks(range(len(rare_tokens)), [t.strip() for t in rare_tokens], rotation=45)\nplt.title('Post-overwrite generation counts - Rare tokens (Embeddings Frozen)')\nplt.ylabel('Count in first generated token')\nplt.tight_layout()\nplt.savefig(os.path.join(working_dir, 'gen_counts_rare_post.png'))\nplt.close()\n\nplt.figure(figsize=(8,4))\nplt.bar(range(len(control_tokens)), list(common_counts.values()), color='tab:orange')\nplt.xticks(range(len(control_tokens)), [t.strip() for t in control_tokens], rotation=45)\nplt.title('Post-overwrite generation counts - Common tokens')\nplt.ylabel('Count in first generated token')\nplt.tight_layout()\nplt.savefig(os.path.join(working_dir, 'gen_counts_common_post.png'))\nplt.close()\n\n# -----------------------------------------------------------------------------\n# 7) Track and save RCRG history and recalls across epochs\n# -----------------------------------------------------------------------------\nnp.save(os.path.join(working_dir, 'rcrg_history.npy'), np.array(rcrg_history))\nnp.save(os.path.join(working_dir, 'rare_recall_history.npy'), np.array(rare_recall_history))\nnp.save(os.path.join(working_dir, 'common_recall_history.npy'), np.array(common_recall_history))\n\n# Plot RCRG across overwrite epochs\nplt.figure(figsize=(6,4))\nplt.plot(range(1, len(rcrg_history)+1), rcrg_history, marker='o', label='RCRG@50')\nplt.plot(range(1, len(rare_recall_history)+1), rare_recall_history, marker='s', label='Rare recall@50')\nplt.plot(range(1, len(common_recall_history)+1), common_recall_history, marker='^', label='Common recall@50')\nplt.xlabel('Overwrite epoch')\nplt.ylabel('Score')\nplt.title('Rare-to-Common Recall Gap Across Epochs (Embedding Freeze Ablation)')\nplt.legend()\nplt.grid(True, alpha=0.3)\nplt.tight_layout()\nplt.savefig(os.path.join(working_dir, 'rcrg_over_epochs.png'))\nplt.close()\n\n# -----------------------------------------------------------------------------\n# 8) Final metric aggregation and save experiment_data\n# -----------------------------------------------------------------------------\nget_container('overwrite_wikitext')['aux']['rcrg_history'] = rcrg_history\nget_container('overwrite_wikitext')['aux']['rare_recall_history'] = rare_recall_history\nget_container('overwrite_wikitext')['aux']['common_recall_history'] = common_recall_history\nget_container('overwrite_wikitext')['aux']['rare_tokens'] = rare_tokens\nget_container('overwrite_wikitext')['aux']['control_tokens'] = control_tokens\nget_container('overwrite_wikitext')['predictions'] = samples_post\nget_container('overwrite_wikitext')['ground_truth'] = {'rare': rare_tokens, 'common': control_tokens}\n\n# Save experiment data with the required filename\nnp.save(os.path.join(working_dir, 'experiment_data.npy'), experiment_data, allow_pickle=True)\n\nprint('Experiment complete. Artifacts saved to:', working_dir)", "import os\nworking_dir = os.path.join(os.getcwd(), 'working')\nos.makedirs(working_dir, exist_ok=True)\n\nimport math\nimport random\nimport time\nfrom typing import List, Dict, Any\n\nimport numpy as np\nimport torch\nimport matplotlib.pyplot as plt\nfrom datasets import Dataset, load_dataset\nfrom torch.utils.data import DataLoader\nfrom transformers import AutoModelForCausalLM, AutoTokenizer, DataCollatorForLanguageModeling\nfrom tqdm import tqdm\n\n# -----------------------------------------------------------------------------\n# GPU/Device setup (required)\n# -----------------------------------------------------------------------------\ntorch.cuda.set_device(0)\ndevice = torch.device('cuda:0')\nprint(f'Using device: {device}')\n\n# Reproducibility\nSEED = 42\nrandom.seed(SEED)\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\ntorch.cuda.manual_seed_all(SEED)\n\ndef now_ts():\n    return time.strftime('%Y-%m-%d %H:%M:%S', time.localtime())\n\n# -----------------------------------------------------------------------------\n# Experiment data structure for saving metrics, predictions, etc. (flat schema)\n# -----------------------------------------------------------------------------\nexperiment_data: Dict[str, Dict[str, Any]] = {\n    'dataset_synthetic_injection': {\n        'metrics': {'train': [], 'val': []},\n        'losses': {'train': [], 'val': []},\n        'predictions': [],\n        'ground_truth': [],\n        'aux': {}\n    },\n    'dataset_wikitext_overwrite': {\n        'metrics': {'train': [], 'val': []},\n        'losses': {'train': [], 'val': []},\n        'predictions': [],\n        'ground_truth': [],\n        'aux': {}\n    },\n}\n\n# -----------------------------------------------------------------------------\n# Helper: tokenization function\n# -----------------------------------------------------------------------------\ndef tokenize_texts(tokenizer: AutoTokenizer, texts: List[str], max_length: int = 64) -> Dataset:\n    ds = Dataset.from_dict({'text': texts})\n    def _map(batch):\n        out = tokenizer(batch['text'], truncation=True, padding='max_length', max_length=max_length)\n        return out\n    ds = ds.map(_map, batched=True, remove_columns=['text'])\n    ds.set_format(type='torch', columns=['input_ids', 'attention_mask'])\n    return ds\n\n# -----------------------------------------------------------------------------\n# Helper: training loop for language modeling\n# -----------------------------------------------------------------------------\ndef train_lm(\n    model: torch.nn.Module,\n    tokenizer: AutoTokenizer,\n    train_ds: Dataset,\n    val_ds: Dataset,\n    dataset_key: str,\n    num_epochs: int = 1,\n    batch_size: int = 64,\n    lr: float = 5e-5,\n    logging_steps: int = 100,\n    max_steps: int = None,\n):\n    model.train()\n    collator = DataCollatorForLanguageModeling(tokenizer, mlm=False)\n\n    train_loader = DataLoader(\n        train_ds,\n        batch_size=batch_size,\n        shuffle=True,\n        collate_fn=collator,\n        pin_memory=True,\n        num_workers=2,\n    )\n    val_loader = DataLoader(\n        val_ds,\n        batch_size=batch_size,\n        shuffle=False,\n        collate_fn=collator,\n        pin_memory=True,\n        num_workers=2,\n    )\n\n    optimizer = torch.optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=lr)\n\n    global_step = 0\n    for epoch in range(1, num_epochs + 1):\n        model.train()\n        running_loss = 0.0\n        n_steps = 0\n\n        for step, batch in enumerate(tqdm(train_loader, desc=f'Training {dataset_key} epoch {epoch}/{num_epochs}')):\n            batch = {k: v.to(device) for k, v in batch.items() if isinstance(v, torch.Tensor)}\n            outputs = model(**batch)\n            loss = outputs.loss\n            loss.backward()\n            optimizer.step()\n            optimizer.zero_grad()\n\n            running_loss += loss.item()\n            n_steps += 1\n            global_step += 1\n\n            if logging_steps and global_step % logging_steps == 0:\n                avg_loss = running_loss / max(1, n_steps)\n                print(f'[{now_ts()}] {dataset_key} step {global_step}: avg_train_loss={avg_loss:.4f}')\n\n            if max_steps is not None and global_step >= max_steps:\n                break\n\n        train_epoch_loss = running_loss / max(1, n_steps)\n        experiment_data[dataset_key]['losses']['train'].append({'epoch': epoch, 'loss': train_epoch_loss, 'ts': now_ts(), 'phase': dataset_key})\n        experiment_data[dataset_key]['metrics']['train'].append({'epoch': epoch, 'avg_loss': train_epoch_loss, 'ts': now_ts(), 'phase': dataset_key})\n\n        # Validation\n        model.eval()\n        val_loss_sum = 0.0\n        val_steps = 0\n        with torch.no_grad():\n            for batch in val_loader:\n                batch = {k: v.to(device) for k, v in batch.items() if isinstance(v, torch.Tensor)}\n                outputs = model(**batch)\n                val_loss_sum += outputs.loss.item()\n                val_steps += 1\n        val_loss = val_loss_sum / max(1, val_steps)\n        print(f'Epoch {epoch}: validation_loss = {val_loss:.4f}')\n        experiment_data[dataset_key]['losses']['val'].append({'epoch': epoch, 'loss': val_loss, 'ts': now_ts(), 'phase': dataset_key})\n        experiment_data[dataset_key]['metrics']['val'].append({'epoch': epoch, 'val_loss': val_loss, 'ts': now_ts(), 'phase': dataset_key})\n\n        if max_steps is not None and global_step >= max_steps:\n            break\n\n# -----------------------------------------------------------------------------\n# Helpers: evaluation metrics (Recall@k and MRR)\n# -----------------------------------------------------------------------------\ndef recall_at_k_for_set(model, tokenizer, prompts: List[str], targets: List[str], k: int = 50) -> float:\n    model.eval()\n    hits = 0\n    total = 0\n    with torch.no_grad():\n        for prompt in prompts:\n            inputs = tokenizer(prompt, return_tensors='pt').to(device)\n            logits = model(**inputs).logits[:, -1, :]\n            topk = torch.topk(logits, k=k, dim=-1).indices[0].tolist()\n            for t in targets:\n                tid = tokenizer.convert_tokens_to_ids(t)\n                if tid is None or tid < 0:\n                    continue\n                total += 1\n                if tid in topk:\n                    hits += 1\n    if total == 0:\n        return 0.0\n    return hits / total\n\n\ndef mrr_for_set(model, tokenizer, prompts: List[str], targets: List[str]) -> float:\n    # MRR over next-token ranks for each (prompt, target)\n    model.eval()\n    rr_values = []\n    with torch.no_grad():\n        for prompt in prompts:\n            inputs = tokenizer(prompt, return_tensors='pt').to(device)\n            logits = model(**inputs).logits[0, -1, :]\n            for t in targets:\n                tid = tokenizer.convert_tokens_to_ids(t)\n                if tid is None or tid < 0:\n                    continue\n                target_logit = logits[tid]\n                # rank = 1 + count of logits strictly greater than target_logit\n                rank = 1 + torch.sum((logits > target_logit).to(torch.int32)).item()\n                rr_values.append(1.0 / float(rank))\n    if len(rr_values) == 0:\n        return 0.0\n    return float(np.mean(rr_values))\n\n# -----------------------------------------------------------------------------\n# 1) Model and tokenizer setup\n# -----------------------------------------------------------------------------\nmodel_name = 'gpt2'\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nif tokenizer.pad_token is None:\n    tokenizer.pad_token = tokenizer.eos_token\nmodel = AutoModelForCausalLM.from_pretrained(model_name)\nmodel.resize_token_embeddings(len(tokenizer))\nmodel.to(device)\n\n# Define rare tokens (ensure they are added as unique new tokens)\nrare_tokens = [\" flarnax\", \" zyloth\", \" quendor\", \" varkun\", \" elthra\"]\nadded_count = tokenizer.add_tokens(rare_tokens)\nmodel.resize_token_embeddings(len(tokenizer))\nmodel.to(device)\n\n# Verify rare tokens are single-token after addition\nfor t in rare_tokens:\n    ids = tokenizer(t, add_special_tokens=False)['input_ids']\n    assert len(ids) == 1, f'Rare token {t} splits into {len(ids)} parts; must be 1.'\n\n# Select control tokens from existing vocab that are common and single-token\ncandidate_controls = [\" apple\", \" table\", \" water\", \" green\", \" house\", \" river\", \" music\", \" school\", \" book\", \" light\"]\ncontrol_tokens = []\nfor w in candidate_controls:\n    ids = tokenizer(w, add_special_tokens=False)['input_ids']\n    if len(ids) == 1:\n        control_tokens.append(w)\n    if len(control_tokens) >= len(rare_tokens):\n        break\nassert len(control_tokens) == len(rare_tokens), 'Not enough single-token controls found.'\n\nprint(f'Added {added_count} rare tokens. Controls: {control_tokens}')\n\n# -----------------------------------------------------------------------------\n# 2) Create synthetic injection dataset (train/val)\n# -----------------------------------------------------------------------------\npatterns_train = [\n    \"The code word is{}.\",\n    \"The secret word is{}.\",\n    \"Password:{}.\",\n    \"Access key:{}.\",\n    \"Remember this:{}.\",\n]\npatterns_val = [\n    \"Use the word:{}.\",\n    \"Keep in mind:{}.\",\n    \"The passphrase is{}.\",\n]\n\ninject_examples = []\nfor tok in rare_tokens:\n    for _ in range(200):\n        pat = random.choice(patterns_train)\n        inject_examples.append(f\"{pat.format(tok)}\")\nfor tok in control_tokens:\n    for _ in range(200):\n        pat = random.choice(patterns_train)\n        inject_examples.append(f\"{pat.format(tok)}\")\nrandom.shuffle(inject_examples)\n\nval_inject_examples = []\nfor tok in rare_tokens + control_tokens:\n    for _ in range(30):\n        pat = random.choice(patterns_val)\n        val_inject_examples.append(f\"{pat.format(tok)}\")\n\n# Tokenize synthetic datasets\nmax_length = 64\ninject_train_ds = tokenize_texts(tokenizer, inject_examples, max_length=max_length)\ninject_val_ds = tokenize_texts(tokenizer, val_inject_examples, max_length=max_length)\n\n# -----------------------------------------------------------------------------\n# 3) Phase 1: Fine-tune on injection dataset\n# -----------------------------------------------------------------------------\ntrain_lm(\n    model,\n    tokenizer,\n    inject_train_ds,\n    inject_val_ds,\n    dataset_key='dataset_synthetic_injection',\n    num_epochs=1,\n    batch_size=96,\n    lr=5e-5,\n    logging_steps=100,\n)\n\n# Save embeddings after phase 1\nembeds_phase1 = model.get_input_embeddings().weight.detach().clone().cpu().numpy()\nnp.save(os.path.join(working_dir, 'embeddings_phase1.npy'), embeds_phase1)\n\n# Evaluate recall@50 and MRR on standardized prompts after phase 1\nstandard_prompts = [\n    \"The code word is\",\n    \"The secret word is\",\n    \"Password:\",\n    \"Access key:\",\n    \"Remember this:\",\n]\nrare_recall_phase1 = recall_at_k_for_set(model, tokenizer, standard_prompts, rare_tokens, k=50)\ncommon_recall_phase1 = recall_at_k_for_set(model, tokenizer, standard_prompts, control_tokens, k=50)\nrare_mrr_phase1 = mrr_for_set(model, tokenizer, standard_prompts, rare_tokens)\ncommon_mrr_phase1 = mrr_for_set(model, tokenizer, standard_prompts, control_tokens)\nmrr_gap_phase1 = rare_mrr_phase1 - common_mrr_phase1\n\nexperiment_data['dataset_synthetic_injection']['metrics']['val'].append({\n    'epoch': 1,\n    'val_loss': experiment_data['dataset_synthetic_injection']['losses']['val'][-1]['loss'] if experiment_data['dataset_synthetic_injection']['losses']['val'] else None,\n    'rare_recall@50': rare_recall_phase1,\n    'common_recall@50': common_recall_phase1,\n    'MRR_rare': rare_mrr_phase1,\n    'MRR_common': common_mrr_phase1,\n    'MRR_Retention_Gap': mrr_gap_phase1,\n    'ts': now_ts(),\n    'phase': 'post_injection_eval'\n})\n\n# -----------------------------------------------------------------------------\n# 4) Overwrite phase: fine-tune on WikiText-2 (unrelated text) with ablation\n#    Freeze rare-token embedding rows (and tied output rows) during overwrite\n# -----------------------------------------------------------------------------\n# Load small subset for speed\nwikitext_train = load_dataset('wikitext', 'wikitext-2-raw-v1', split='train[:30%]')\nwikitext_val = load_dataset('wikitext', 'wikitext-2-raw-v1', split='validation')\n\n# Tokenize wikitext\n\ndef tok_map(batch):\n    return tokenizer(batch['text'], truncation=True, padding='max_length', max_length=max_length)\n\nwikitext_train = wikitext_train.map(tok_map, batched=True, remove_columns=['text'])\nwikitext_train.set_format(type='torch', columns=['input_ids', 'attention_mask'])\n\nwikitext_val = wikitext_val.map(tok_map, batched=True, remove_columns=['text'])\nwikitext_val.set_format(type='torch', columns=['input_ids', 'attention_mask'])\n\n# Prepare data loaders\nnum_overwrite_epochs = 4\ncollator = DataCollatorForLanguageModeling(tokenizer, mlm=False)\noverwrite_batch_size = 32\ntrain_loader = DataLoader(\n    wikitext_train,\n    batch_size=overwrite_batch_size,\n    shuffle=True,\n    collate_fn=collator,\n    pin_memory=True,\n    num_workers=2,\n)\nval_loader = DataLoader(\n    wikitext_val,\n    batch_size=overwrite_batch_size,\n    shuffle=False,\n    collate_fn=collator,\n    pin_memory=True,\n    num_workers=2,\n)\n\n# Build optimizer\noptimizer = torch.optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=5e-5)\n\n# Identify rare token ids and set up gradient masking hooks on embeddings\nrare_ids = [tokenizer.convert_tokens_to_ids(t) for t in rare_tokens]\ninput_emb_module = model.get_input_embeddings()\ninput_weight = input_emb_module.weight\n\n# Prepare row mask for gradients: 1 for trainable rows, 0 for frozen rare rows\nrow_mask = torch.ones(input_weight.shape[0], 1, device=input_weight.device, dtype=input_weight.dtype)\nfor i in rare_ids:\n    if i is not None and 0 <= i < row_mask.shape[0]:\n        row_mask[i] = 0.0\n\n# Register hook on input embeddings\n_input_hook_handle = input_weight.register_hook(lambda grad: grad * row_mask.to(grad.device))\n\n# Also handle output embeddings if not tied\noutput_emb = model.get_output_embeddings()\noutput_hook_handle = None\noutput_tied = False\nif output_emb is not None:\n    output_weight = output_emb.weight\n    output_tied = output_weight.data_ptr() == input_weight.data_ptr()\n    if not output_tied:\n        output_row_mask = torch.ones(output_weight.shape[0], 1, device=output_weight.device, dtype=output_weight.dtype)\n        for i in rare_ids:\n            if i is not None and 0 <= i < output_row_mask.shape[0]:\n                output_row_mask[i] = 0.0\n        output_hook_handle = output_weight.register_hook(lambda grad: grad * output_row_mask.to(grad.device))\n\n# Save ablation details\nexperiment_data['dataset_wikitext_overwrite']['aux']['ablation'] = {\n    'type': 'freeze_rare_embedding_rows_overwrite',\n    'rare_token_ids': rare_ids,\n    'tied_output_embeddings': bool(output_tied),\n}\n\n# Overwrite training loop with per-epoch metrics (val loss, recall@50, MRR gap)\nrare_recall_history = []\ncommon_recall_history = []\nmrr_gap_history = []\n\nfor epoch in range(1, num_overwrite_epochs + 1):\n    model.train()\n    run_loss = 0.0\n    n_steps = 0\n    for batch in tqdm(train_loader, desc=f'Overwrite epoch {epoch}/{num_overwrite_epochs}'):\n        batch = {k: v.to(device) for k, v in batch.items() if isinstance(v, torch.Tensor)}\n        outputs = model(**batch)\n        loss = outputs.loss\n        loss.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n        run_loss += loss.item()\n        n_steps += 1\n\n    train_epoch_loss = run_loss / max(1, n_steps)\n    experiment_data['dataset_wikitext_overwrite']['losses']['train'].append({'epoch': epoch, 'loss': train_epoch_loss, 'ts': now_ts(), 'phase': 'wikitext_overwrite'})\n    experiment_data['dataset_wikitext_overwrite']['metrics']['train'].append({'epoch': epoch, 'avg_loss': train_epoch_loss, 'ts': now_ts(), 'phase': 'wikitext_overwrite'})\n\n    # Validation loss\n    model.eval()\n    val_loss_sum = 0.0\n    val_steps = 0\n    with torch.no_grad():\n        for batch in val_loader:\n            batch = {k: v.to(device) for k, v in batch.items() if isinstance(v, torch.Tensor)}\n            outputs = model(**batch)\n            val_loss_sum += outputs.loss.item()\n            val_steps += 1\n    val_loss = val_loss_sum / max(1, val_steps)\n    print(f'Epoch {epoch}: validation_loss = {val_loss:.4f}')\n    experiment_data['dataset_wikitext_overwrite']['losses']['val'].append({'epoch': epoch, 'loss': val_loss, 'ts': now_ts(), 'phase': 'wikitext_overwrite'})\n\n    # Compute recall@50 and MRR gap on standardized prompts\n    rare_rec = recall_at_k_for_set(model, tokenizer, [p for p in standard_prompts], rare_tokens, k=50)\n    common_rec = recall_at_k_for_set(model, tokenizer, [p for p in standard_prompts], control_tokens, k=50)\n    rare_mrr = mrr_for_set(model, tokenizer, [p for p in standard_prompts], rare_tokens)\n    common_mrr = mrr_for_set(model, tokenizer, [p for p in standard_prompts], control_tokens)\n    mrr_gap = rare_mrr - common_mrr\n\n    rare_recall_history.append(rare_rec)\n    common_recall_history.append(common_rec)\n    mrr_gap_history.append(mrr_gap)\n\n    experiment_data['dataset_wikitext_overwrite']['metrics']['val'].append({\n        'epoch': epoch,\n        'val_loss': val_loss,\n        'rare_recall@50': rare_rec,\n        'common_recall@50': common_rec,\n        'MRR_rare': rare_mrr,\n        'MRR_common': common_mrr,\n        'MRR_Retention_Gap': mrr_gap,\n        'ts': now_ts(),\n        'phase': 'wikitext_overwrite_eval'\n    })\n\n# Save embeddings after phase 2\nembeds_phase2 = model.get_input_embeddings().weight.detach().clone().cpu().numpy()\nnp.save(os.path.join(working_dir, 'embeddings_phase2.npy'), embeds_phase2)\n\n# -----------------------------------------------------------------------------\n# 5) Embedding retention analysis (cosine similarity)\n# -----------------------------------------------------------------------------\nemb1 = torch.tensor(embeds_phase1)\nemb2 = torch.tensor(embeds_phase2)\ncos = torch.nn.functional.cosine_similarity\nrare_ids = [tokenizer.convert_tokens_to_ids(t) for t in rare_tokens]\ncontrol_ids = [tokenizer.convert_tokens_to_ids(t) for t in control_tokens]\nrare_cos = [cos(emb1[i], emb2[i], dim=0).item() for i in rare_ids]\ncommon_cos = [cos(emb1[i], emb2[i], dim=0).item() for i in control_ids]\n\nnp.save(os.path.join(working_dir, 'rare_cosine.npy'), np.array(rare_cos))\nnp.save(os.path.join(working_dir, 'common_cosine.npy'), np.array(common_cos))\n\n# Plot embedding retention\nplt.figure(figsize=(6,4))\nplt.bar(range(len(rare_cos)), rare_cos, color='tab:blue')\nplt.ylim(0, 1.0)\nplt.title('Embedding Retention (Cosine) - Rare Tokens (Frozen in Overwrite)')\nplt.xlabel('Rare token index')\nplt.ylabel('Cosine similarity')\nplt.tight_layout()\nplt.savefig(os.path.join(working_dir, 'embedding_retention_rare_tokens.png'))\nplt.close()\n\nplt.figure(figsize=(6,4))\nplt.bar(range(len(common_cos)), common_cos, color='tab:orange')\nplt.ylim(0, 1.0)\nplt.title('Embedding Retention (Cosine) - Common Tokens')\nplt.xlabel('Common token index')\nplt.ylabel('Cosine similarity')\nplt.tight_layout()\nplt.savefig(os.path.join(working_dir, 'embedding_retention_common_tokens.png'))\nplt.close()\n\n# -----------------------------------------------------------------------------\n# 6) Sample generation after overwrite and visualization\n# -----------------------------------------------------------------------------\n# Generate next tokens for a standardized prompt\nsample_prompt = \"The code word is\"\nnum_samples = 128\n\ndef generate_next_tokens(model, tokenizer, prompt: str, num_samples: int = 64, max_new_tokens: int = 3, temperature: float = 0.8, top_k: int = 50) -> List[str]:\n    model.eval()\n    generations = []\n    with torch.no_grad():\n        inputs = tokenizer([prompt] * num_samples, return_tensors='pt', padding=True).to(device)\n        gen = model.generate(\n            **inputs,\n            do_sample=True,\n            max_new_tokens=max_new_tokens,\n            temperature=temperature,\n            top_k=top_k,\n            pad_token_id=tokenizer.eos_token_id,\n        )\n        input_len = inputs['input_ids'].shape[1]\n        for i in range(gen.shape[0]):\n            new_tokens = gen[i, input_len:input_len+1]\n            token_str = tokenizer.decode(new_tokens)\n            generations.append(token_str)\n    return generations\n\nsamples_post = generate_next_tokens(model, tokenizer, sample_prompt, num_samples=num_samples, max_new_tokens=3, temperature=0.8, top_k=50)\n\n# Count occurrences\n\ndef count_hits(samples: List[str], targets: List[str]) -> Dict[str, int]:\n    counts = {t: 0 for t in targets}\n    for s in samples:\n        for t in targets:\n            if s == t:\n                counts[t] += 1\n    return counts\n\nrare_counts = count_hits(samples_post, rare_tokens)\ncommon_counts = count_hits(samples_post, control_tokens)\n\n# Save arrays\nnp.save(os.path.join(working_dir, 'samples_post.npy'), np.array(samples_post, dtype=object))\nnp.save(os.path.join(working_dir, 'rare_counts_post.npy'), np.array(list(rare_counts.values())))\nnp.save(os.path.join(working_dir, 'common_counts_post.npy'), np.array(list(common_counts.values())))\n\n# Plot counts\nplt.figure(figsize=(8,4))\nplt.bar(range(len(rare_tokens)), list(rare_counts.values()), color='tab:blue')\nplt.xticks(range(len(rare_tokens)), [t.strip() for t in rare_tokens], rotation=45)\nplt.title('Post-overwrite generation counts - Rare tokens (Embeddings Frozen)')\nplt.ylabel('Count in first generated token')\nplt.tight_layout()\nplt.savefig(os.path.join(working_dir, 'gen_counts_rare_post_wikitext.png'))\nplt.close()\n\nplt.figure(figsize=(8,4))\nplt.bar(range(len(control_tokens)), list(common_counts.values()), color='tab:orange')\nplt.xticks(range(len(control_tokens)), [t.strip() for t in control_tokens], rotation=45)\nplt.title('Post-overwrite generation counts - Common tokens')\nplt.ylabel('Count in first generated token')\nplt.tight_layout()\nplt.savefig(os.path.join(working_dir, 'gen_counts_common_post_wikitext.png'))\nplt.close()\n\n# -----------------------------------------------------------------------------\n# 7) Track and save histories (RCRG and MRR gap) across overwrite epochs\n# -----------------------------------------------------------------------------\n# Recompute RCRG history from saved evals for completeness\nrcrg_history = []\nfor i in range(len(rare_recall_history)):\n    rcrg_history.append(rare_recall_history[i] - common_recall_history[i])\n\nnp.save(os.path.join(working_dir, 'rcrg_history.npy'), np.array(rcrg_history))\nnp.save(os.path.join(working_dir, 'rare_recall_history.npy'), np.array(rare_recall_history))\nnp.save(os.path.join(working_dir, 'common_recall_history.npy'), np.array(common_recall_history))\nnp.save(os.path.join(working_dir, 'mrr_gap_history.npy'), np.array(mrr_gap_history))\n\n# Plot RCRG and MRR gap across overwrite epochs\nplt.figure(figsize=(6,4))\nplt.plot(range(1, len(rcrg_history)+1), rcrg_history, marker='o', label='RCRG@50')\nplt.plot(range(1, len(rare_recall_history)+1), rare_recall_history, marker='s', label='Rare recall@50')\nplt.plot(range(1, len(common_recall_history)+1), common_recall_history, marker='^', label='Common recall@50')\nplt.xlabel('Overwrite epoch')\nplt.ylabel('Score')\nplt.title('Recall Metrics Across Overwrite Epochs (Freeze Rare Embeddings)')\nplt.legend()\nplt.grid(True, alpha=0.3)\nplt.tight_layout()\nplt.savefig(os.path.join(working_dir, 'rcrg_over_epochs_wikitext.png'))\nplt.close()\n\nplt.figure(figsize=(6,4))\nplt.plot(range(1, len(mrr_gap_history)+1), mrr_gap_history, marker='o', color='tab:green', label='MRR Retention Gap')\nplt.xlabel('Overwrite epoch')\nplt.ylabel('MRR gap (rare - common)')\nplt.title('MRR Retention Gap Across Overwrite Epochs')\nplt.legend()\nplt.grid(True, alpha=0.3)\nplt.tight_layout()\nplt.savefig(os.path.join(working_dir, 'mrr_gap_over_epochs_wikitext.png'))\nplt.close()\n\n# -----------------------------------------------------------------------------\n# 8) Final metric aggregation and save experiment_data\n# -----------------------------------------------------------------------------\nexperiment_data['dataset_wikitext_overwrite']['aux']['rcrg_history'] = rcrg_history\nexperiment_data['dataset_wikitext_overwrite']['aux']['rare_recall_history'] = rare_recall_history\nexperiment_data['dataset_wikitext_overwrite']['aux']['common_recall_history'] = common_recall_history\nexperiment_data['dataset_wikitext_overwrite']['aux']['mrr_gap_history'] = mrr_gap_history\nexperiment_data['dataset_wikitext_overwrite']['aux']['rare_tokens'] = rare_tokens\nexperiment_data['dataset_wikitext_overwrite']['aux']['control_tokens'] = control_tokens\nexperiment_data['dataset_wikitext_overwrite']['predictions'] = samples_post\nexperiment_data['dataset_wikitext_overwrite']['ground_truth'] = {'rare': rare_tokens, 'common': control_tokens}\n\nnp.save(os.path.join(working_dir, 'experiment_data.npy'), experiment_data)\n\nprint('Experiment complete. Artifacts saved to:', working_dir)", "# Set random seed\nimport random\nimport numpy as np\nimport torch\n\nseed = 0\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed(seed)\n\nimport os\nworking_dir = os.path.join(os.getcwd(), 'working')\nos.makedirs(working_dir, exist_ok=True)\n\nimport math\nimport random\nimport time\nfrom typing import List, Dict, Any, Tuple\n\nimport numpy as np\nimport torch\nimport matplotlib.pyplot as plt\nfrom datasets import Dataset, load_dataset\nfrom torch.utils.data import DataLoader\nfrom transformers import AutoModelForCausalLM, AutoTokenizer, DataCollatorForLanguageModeling\nfrom tqdm import tqdm\n\n# -----------------------------------------------------------------------------\n# REQUIRED: GPU/CPU lines at start\n# -----------------------------------------------------------------------------\ntry:\n    torch.cuda.set_device(0)\n    device = torch.device('cuda:0')\nexcept Exception:\n    device = torch.device('cpu')\nprint(f'Using device: {device}')\n\n# -----------------------------------------------------------------------------\n# Experiment container per-dataset for metrics, losses, predictions, etc.\n# -----------------------------------------------------------------------------\nexperiment_data: Dict[str, Dict[str, Any]] = {\n    'natlang': {\n        'metrics': {'train': [], 'val': []},\n        'losses': {'train': [], 'val': []},\n        'predictions': [],\n        'ground_truth': [],\n        'aux': {}\n    },\n    'code_style': {\n        'metrics': {'train': [], 'val': []},\n        'losses': {'train': [], 'val': []},\n        'predictions': [],\n        'ground_truth': [],\n        'aux': {}\n    },\n    'json_style': {\n        'metrics': {'train': [], 'val': []},\n        'losses': {'train': [], 'val': []},\n        'predictions': [],\n        'ground_truth': [],\n        'aux': {}\n    },\n    'mixture': {\n        'metrics': {'train': [], 'val': []},\n        'losses': {'train': [], 'val': []},\n        'predictions': [],\n        'ground_truth': [],\n        'aux': {}\n    },\n}\n\nSEED = 42\nrandom.seed(SEED)\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\nif device.type == 'cuda':\n    torch.cuda.manual_seed_all(SEED)\n\ndef now_ts():\n    return time.strftime('%Y-%m-%d %H:%M:%S', time.localtime())\n\n# -----------------------------------------------------------------------------\n# Helpers\n# -----------------------------------------------------------------------------\n\ndef ensure_container(tag: str) -> Dict[str, Any]:\n    if tag not in experiment_data:\n        experiment_data[tag] = {\n            'metrics': {'train': [], 'val': []},\n            'losses': {'train': [], 'val': []},\n            'predictions': [],\n            'ground_truth': [],\n            'aux': {}\n        }\n    return experiment_data[tag]\n\n\ndef tokenize_texts(tokenizer: AutoTokenizer, texts: List[str], max_length: int = 64) -> Dataset:\n    ds = Dataset.from_dict({'text': texts})\n    def _map(batch):\n        out = tokenizer(batch['text'], truncation=True, padding='max_length', max_length=max_length)\n        return out\n    ds = ds.map(_map, batched=True, remove_columns=['text'])\n    ds.set_format(type='torch', columns=['input_ids', 'attention_mask'])\n    return ds\n\n\ndef recall_at_k_for_set(model, tokenizer, prompts: List[str], targets: List[str], k: int = 50) -> float:\n    model.eval()\n    hits = 0\n    total = 0\n    with torch.no_grad():\n        for prompt in prompts:\n            inputs = tokenizer(prompt, return_tensors='pt').to(device)\n            logits = model(**{k: v.to(device) for k, v in inputs.items()}).logits[:, -1, :]\n            topk = torch.topk(logits, k=k, dim=-1).indices[0].tolist()\n            for t in targets:\n                tid = tokenizer.convert_tokens_to_ids(t)\n                if tid is None or tid < 0:\n                    continue\n                total += 1\n                if tid in topk:\n                    hits += 1\n    if total == 0:\n        return 0.0\n    return hits / total\n\n\ndef mrr_for_set(model, tokenizer, prompts: List[str], targets: List[str]) -> float:\n    # Mean Reciprocal Rank across prompts and targets\n    model.eval()\n    rr_vals: List[float] = []\n    with torch.no_grad():\n        for prompt in prompts:\n            inputs = tokenizer(prompt, return_tensors='pt').to(device)\n            logits = model(**{k: v.to(device) for k, v in inputs.items()}).logits[0, -1]  # [V]\n            # Convert to ranks (1 is best)\n            # For each target id, rank = 1 + number of logits strictly greater than target logit\n            for t in targets:\n                tid = tokenizer.convert_tokens_to_ids(t)\n                if tid is None or tid < 0:\n                    continue\n                target_logit = logits[tid]\n                rank = int((logits > target_logit).sum().item()) + 1\n                rr_vals.append(1.0 / rank)\n    if len(rr_vals) == 0:\n        return 0.0\n    return float(np.mean(rr_vals))\n\n\ndef compute_metrics_for_prompts(model, tokenizer, prompts: List[str], k: int = 50) -> Dict[str, float]:\n    rare_rec = recall_at_k_for_set(model, tokenizer, prompts, rare_tokens, k=k)\n    common_rec = recall_at_k_for_set(model, tokenizer, prompts, control_tokens, k=k)\n    rare_mrr = mrr_for_set(model, tokenizer, prompts, rare_tokens)\n    common_mrr = mrr_for_set(model, tokenizer, prompts, control_tokens)\n    return {\n        'RCRG@50': rare_rec - common_rec,\n        'rare_recall@50': rare_rec,\n        'common_recall@50': common_rec,\n        'MRR_gap': rare_mrr - common_mrr,\n        'rare_MRR': rare_mrr,\n        'common_MRR': common_mrr,\n    }\n\n\ndef generate_next_tokens(model, tokenizer, prompt: str, num_samples: int = 64, max_new_tokens: int = 3, temperature: float = 0.8, top_k: int = 50) -> List[str]:\n    model.eval()\n    generations = []\n    with torch.no_grad():\n        inputs = tokenizer([prompt] * num_samples, return_tensors='pt', padding=True).to(device)\n        gen = model.generate(\n            **inputs,\n            do_sample=True,\n            max_new_tokens=max_new_tokens,\n            temperature=temperature,\n            top_k=top_k,\n            pad_token_id=tokenizer.eos_token_id,\n        )\n        input_len = inputs['input_ids'].shape[1]\n        for i in range(gen.shape[0]):\n            new_tokens = gen[i, input_len:input_len+1]\n            token_str = tokenizer.decode(new_tokens)\n            generations.append(token_str)\n    return generations\n\n\ndef train_lm(\n    model: torch.nn.Module,\n    tokenizer: AutoTokenizer,\n    train_ds: Dataset,\n    val_ds: Dataset,\n    num_epochs: int = 1,\n    batch_size: int = 64,\n    lr: float = 5e-5,\n    logging_steps: int = 100,\n    tag: str = 'phase',\n    max_steps: int = None,\n):\n    model.train()\n    collator = DataCollatorForLanguageModeling(tokenizer, mlm=False)\n\n    train_loader = DataLoader(\n        train_ds,\n        batch_size=batch_size,\n        shuffle=True,\n        collate_fn=collator,\n        pin_memory=(device.type == 'cuda'),\n        num_workers=2,\n    )\n    val_loader = DataLoader(\n        val_ds,\n        batch_size=batch_size,\n        shuffle=False,\n        collate_fn=collator,\n        pin_memory=(device.type == 'cuda'),\n        num_workers=2,\n    )\n\n    optimizer = torch.optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=lr)\n\n    global_step = 0\n    for epoch in range(1, num_epochs + 1):\n        model.train()\n        running_loss = 0.0\n        n_steps = 0\n\n        for step, batch in enumerate(tqdm(train_loader, desc=f'Training {tag} epoch {epoch}/{num_epochs}')):\n            batch = {k: v.to(device) for k, v in batch.items() if isinstance(v, torch.Tensor)}\n            outputs = model(**batch)\n            loss = outputs.loss\n            loss.backward()\n            optimizer.step()\n            optimizer.zero_grad()\n\n            running_loss += loss.item()\n            n_steps += 1\n            global_step += 1\n\n            if logging_steps and global_step % logging_steps == 0:\n                avg_loss = running_loss / n_steps\n                print(f'[{now_ts()}] {tag} step {global_step}: avg_train_loss={avg_loss:.4f}')\n\n            if max_steps is not None and global_step >= max_steps:\n                break\n\n        train_epoch_loss = running_loss / max(1, n_steps)\n        ensure_container(tag)['losses']['train'].append({'epoch': epoch, 'loss': train_epoch_loss, 'ts': now_ts()})\n        ensure_container(tag)['metrics']['train'].append({'epoch': epoch, 'avg_loss': train_epoch_loss, 'ts': now_ts()})\n\n        # Validation\n        model.eval()\n        val_loss_sum = 0.0\n        val_steps = 0\n        with torch.no_grad():\n            for batch in val_loader:\n                batch = {k: v.to(device) for k, v in batch.items() if isinstance(v, torch.Tensor)}\n                outputs = model(**batch)\n                val_loss_sum += outputs.loss.item()\n                val_steps += 1\n        val_loss = val_loss_sum / max(1, val_steps)\n        print(f'Epoch {epoch}: validation_loss = {val_loss:.4f}')\n        ensure_container(tag)['losses']['val'].append({'epoch': epoch, 'loss': val_loss, 'ts': now_ts()})\n        ensure_container(tag)['metrics']['val'].append({'epoch': epoch, 'val_loss': val_loss, 'ts': now_ts()})\n\n        if max_steps is not None and global_step >= max_steps:\n            break\n\n# -----------------------------------------------------------------------------\n# 1) Tokenizer and tokens\n# -----------------------------------------------------------------------------\nmodel_name = 'gpt2'\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nif tokenizer.pad_token is None:\n    tokenizer.pad_token = tokenizer.eos_token\n\n# Rare tokens to inject as brand-new single tokens\nrare_tokens = [\" flarnax\", \" zyloth\", \" quendor\", \" varkun\", \" elthra\"]\nadded_count = tokenizer.add_tokens(rare_tokens)\nprint(f'Added {added_count} rare tokens to tokenizer.')\n\n# Control/common tokens (single-token in GPT-2)\ncandidate_controls = [\" apple\", \" table\", \" water\", \" green\", \" house\", \" river\", \" music\", \" school\", \" book\", \" light\"]\ncontrol_tokens: List[str] = []\nfor w in candidate_controls:\n    ids = tokenizer(w, add_special_tokens=False)['input_ids']\n    if len(ids) == 1:\n        control_tokens.append(w)\n    if len(control_tokens) >= len(rare_tokens):\n        break\nassert len(control_tokens) == len(rare_tokens), 'Not enough single-token controls found.'\nprint(f'Controls: {control_tokens}')\n\n# Verify rare tokens became single-token entries\nfor t in rare_tokens:\n    ids = tokenizer(t, add_special_tokens=False)['input_ids']\n    assert len(ids) == 1, f'Rare token {t} splits into {len(ids)} parts; must be 1.'\n\n# Fresh model loader (resize embeddings after tokenizer growth)\ndef load_fresh_model() -> AutoModelForCausalLM:\n    m = AutoModelForCausalLM.from_pretrained(model_name)\n    m.resize_token_embeddings(len(tokenizer))\n    m.to(device)\n    return m\n\n# -----------------------------------------------------------------------------\n# 2) Pattern sets and dataset builders (safe pattern replacement)\n# -----------------------------------------------------------------------------\n\nnat_train_patterns = [\n    \"The code word is{}.\",\n    \"The secret word is{}.\",\n    \"Password:{}.\",\n    \"Access key:{}.\",\n    \"Remember this:{}.\",\n]\nnat_val_patterns = [\n    \"Use the word:{}.\",\n    \"Keep in mind:{}.\",\n    \"The passphrase is{}.\",\n]\n\ncode_train_patterns = [\n    \"// SECRET:{}\",\n    \"# token:{}\",\n    \"/* KEY:{} */\",\n    \"const SECRET ={};\",\n    \"#define NAME {}\",\n    \"<!-- tag:{} -->\",\n]\ncode_val_patterns = [\n    \"// KEY:{}\",\n    \"# SECRET:{}\",\n    \"/* token:{} */\",\n]\n\n# JSON/YAML-like (keep literal braces; use safe replacement instead of str.format)\njson_train_patterns = [\n    '{\"secret\":{}}',\n    'secret: {}',\n    'key: secret, value: {}',\n    '- secret: {}',\n    '{\"data\": {\"key\": \"secret\", \"value\":{}}}',\n]\njson_val_patterns = [\n    '{\"token\":{}}',\n    'passphrase: {}',\n    'value: {}',\n]\n\n\ndef safe_fill(pattern: str, tok: str) -> str:\n    # Replace only the placeholder '{}' and leave other braces intact\n    return pattern.replace(\"{}\", tok)\n\n\ndef prefix_from_pattern(p: str) -> str:\n    parts = p.split('{}')\n    return parts[0].strip()\n\n\ndef build_dataset_from_patterns(rare_tokens: List[str], control_tokens: List[str], train_patterns: List[str], val_patterns: List[str], n_per_token: int = 200) -> Tuple[List[str], List[str], List[str]]:\n    train_texts: List[str] = []\n    for tok in rare_tokens:\n        for _ in range(n_per_token):\n            pat = random.choice(train_patterns)\n            train_texts.append(safe_fill(pat, tok))\n    for tok in control_tokens:\n        for _ in range(n_per_token):\n            pat = random.choice(train_patterns)\n            train_texts.append(safe_fill(pat, tok))\n    random.shuffle(train_texts)\n    val_texts: List[str] = []\n    for tok in rare_tokens + control_tokens:\n        for _ in range(30):\n            pat = random.choice(val_patterns)\n            val_texts.append(safe_fill(pat, tok))\n    eval_prompts = sorted(list(set([prefix_from_pattern(p) for p in (train_patterns + val_patterns)])))\n    return train_texts, val_texts, eval_prompts\n\n\ndef build_mixture_dataset(rare_tokens: List[str], control_tokens: List[str], pattern_sets: List[List[str]], val_pattern_sets: List[List[str]], n_per_token: int = 200) -> Tuple[List[str], List[str], List[str]]:\n    n_styles = len(pattern_sets)\n    base = n_per_token // n_styles\n    rem = n_per_token % n_styles\n    per_style = [base + (1 if i < rem else 0) for i in range(n_styles)]\n\n    train_texts: List[str] = []\n    for tok in rare_tokens:\n        for i, pats in enumerate(pattern_sets):\n            for _ in range(per_style[i]):\n                train_texts.append(safe_fill(random.choice(pats), tok))\n    for tok in control_tokens:\n        for i, pats in enumerate(pattern_sets):\n            for _ in range(per_style[i]):\n                train_texts.append(safe_fill(random.choice(pats), tok))\n    random.shuffle(train_texts)\n\n    val_texts: List[str] = []\n    val_per_style = [10] * len(val_pattern_sets)\n    for tok in rare_tokens + control_tokens:\n        for i, vpats in enumerate(val_pattern_sets):\n            for _ in range(val_per_style[i]):\n                val_texts.append(safe_fill(random.choice(vpats), tok))\n\n    eval_prompts = sorted(list(set([prefix_from_pattern(p) for ps in (pattern_sets + val_pattern_sets) for p in ps])))\n    return train_texts, val_texts, eval_prompts\n\n# Configs\nablation_configs = []\nablation_configs.append({'tag': 'natlang', 'train_patterns': nat_train_patterns, 'val_patterns': nat_val_patterns})\nablation_configs.append({'tag': 'code_style', 'train_patterns': code_train_patterns, 'val_patterns': code_val_patterns})\nablation_configs.append({'tag': 'json_style', 'train_patterns': json_train_patterns, 'val_patterns': json_val_patterns})\nablation_configs.append({'tag': 'mixture', 'train_patterns': None, 'val_patterns': None})\n\nmax_length = 64\n\nstandard_prompts = [\n    \"The code word is\",\n    \"The secret word is\",\n    \"Password:\",\n    \"Access key:\",\n    \"Remember this:\",\n]\n\n# -----------------------------------------------------------------------------\n# 3) Overwrite dataset (wikitext-2) prepare once\n# -----------------------------------------------------------------------------\nwikitext_train = load_dataset('wikitext', 'wikitext-2-raw-v1', split='train[:30%]')\nwikitext_val = load_dataset('wikitext', 'wikitext-2-raw-v1', split='validation')\n\ndef tok_map(batch):\n    return tokenizer(batch['text'], truncation=True, padding='max_length', max_length=max_length)\n\nwikitext_train = wikitext_train.map(tok_map, batched=True, remove_columns=['text'])\nwikitext_train.set_format(type='torch', columns=['input_ids', 'attention_mask'])\n\nwikitext_val = wikitext_val.map(tok_map, batched=True, remove_columns=['text'])\nwikitext_val.set_format(type='torch', columns=['input_ids', 'attention_mask'])\n\ncollator = DataCollatorForLanguageModeling(tokenizer, mlm=False)\noverwrite_batch_size = 32\nnum_overwrite_epochs = 4\n\n# -----------------------------------------------------------------------------\n# 4) Run ablation per condition\n# -----------------------------------------------------------------------------\n\n# Tracking arrays saved per-condition\nfor cfg in ablation_configs:\n    tag = cfg['tag']\n    print(f\"\\n===== Starting condition: {tag} =====\")\n\n    # Build datasets\n    n_per_token = 200\n    if tag != 'mixture':\n        train_texts, val_texts, dataset_prompts = build_dataset_from_patterns(\n            rare_tokens, control_tokens, cfg['train_patterns'], cfg['val_patterns'], n_per_token=n_per_token\n        )\n    else:\n        train_texts, val_texts, dataset_prompts = build_mixture_dataset(\n            rare_tokens, control_tokens,\n            [nat_train_patterns, code_train_patterns, json_train_patterns],\n            [nat_val_patterns, code_val_patterns, json_val_patterns],\n            n_per_token=n_per_token\n        )\n\n    # Tokenize synthetic datasets\n    inject_train_ds = tokenize_texts(tokenizer, train_texts, max_length=max_length)\n    inject_val_ds = tokenize_texts(tokenizer, val_texts, max_length=max_length)\n\n    # Fresh model\n    model = load_fresh_model()\n\n    # Phase 1 training (injection)\n    phase1_tag = f'{tag}_phase1'\n    train_lm(\n        model,\n        tokenizer,\n        inject_train_ds,\n        inject_val_ds,\n        num_epochs=1,\n        batch_size=96,\n        lr=5e-5,\n        logging_steps=100,\n        tag=phase1_tag,\n    )\n\n    # Save embeddings after phase 1\n    embeds_phase1 = model.get_input_embeddings().weight.detach().clone().cpu().numpy()\n    np.save(os.path.join(working_dir, f'embeddings_phase1_{tag}.npy'), embeds_phase1)\n\n    # Overwrite phase: loaders\n    train_loader = DataLoader(\n        wikitext_train,\n        batch_size=overwrite_batch_size,\n        shuffle=True,\n        collate_fn=collator,\n        pin_memory=(device.type == 'cuda'),\n        num_workers=2,\n    )\n    val_loader = DataLoader(\n        wikitext_val,\n        batch_size=overwrite_batch_size,\n        shuffle=False,\n        collate_fn=collator,\n        pin_memory=(device.type == 'cuda'),\n        num_workers=2,\n    )\n\n    # Histories for plots\n    rcrg_std_history = []\n    rcrg_ds_history = []\n    rare_std_history = []\n    common_std_history = []\n    rare_ds_history = []\n    common_ds_history = []\n    mrr_gap_std_history = []\n    mrr_gap_ds_history = []\n    rare_mrr_std_history = []\n    common_mrr_std_history = []\n    rare_mrr_ds_history = []\n    common_mrr_ds_history = []\n\n    optimizer = torch.optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=5e-5)\n    global_step = 0\n\n    overwrite_tag = f'{tag}_overwrite'\n\n    for epoch in range(1, num_overwrite_epochs + 1):\n        model.train()\n        run_loss = 0.0\n        n_steps = 0\n        for batch in tqdm(train_loader, desc=f'Overwrite ({tag}) epoch {epoch}/{num_overwrite_epochs}'):\n            batch = {k: v.to(device) for k, v in batch.items() if isinstance(v, torch.Tensor)}\n            outputs = model(**batch)\n            loss = outputs.loss\n            loss.backward()\n            optimizer.step()\n            optimizer.zero_grad()\n            run_loss += loss.item()\n            n_steps += 1\n            global_step += 1\n            if global_step % 200 == 0:\n                print(f'[{now_ts()}] Overwrite ({tag}) step {global_step}: avg_train_loss={run_loss/max(1,n_steps):.4f}')\n\n        train_epoch_loss = run_loss / max(1, n_steps)\n        ensure_container(tag)['losses']['train'].append({'epoch': epoch, 'loss': train_epoch_loss, 'ts': now_ts(), 'phase': 'overwrite'})\n        ensure_container(tag)['metrics']['train'].append({'epoch': epoch, 'avg_loss': train_epoch_loss, 'ts': now_ts(), 'phase': 'overwrite'})\n\n        # Validation loss\n        model.eval()\n        val_loss_sum = 0.0\n        val_steps = 0\n        with torch.no_grad():\n            for batch in val_loader:\n                batch = {k: v.to(device) for k, v in batch.items() if isinstance(v, torch.Tensor)}\n                outputs = model(**batch)\n                val_loss_sum += outputs.loss.item()\n                val_steps += 1\n        val_loss = val_loss_sum / max(1, val_steps)\n        print(f'Epoch {epoch} ({tag}): validation_loss = {val_loss:.4f}')\n        ensure_container(tag)['losses']['val'].append({'epoch': epoch, 'loss': val_loss, 'ts': now_ts(), 'phase': 'overwrite'})\n\n        # Metrics: standardized prompts\n        std_metrics = compute_metrics_for_prompts(model, tokenizer, standard_prompts)\n        ds_metrics = compute_metrics_for_prompts(model, tokenizer, dataset_prompts)\n\n        # Record histories\n        rcrg_std_history.append(std_metrics['RCRG@50'])\n        rare_std_history.append(std_metrics['rare_recall@50'])\n        common_std_history.append(std_metrics['common_recall@50'])\n        mrr_gap_std_history.append(std_metrics['MRR_gap'])\n        rare_mrr_std_history.append(std_metrics['rare_MRR'])\n        common_mrr_std_history.append(std_metrics['common_MRR'])\n\n        rcrg_ds_history.append(ds_metrics['RCRG@50'])\n        rare_ds_history.append(ds_metrics['rare_recall@50'])\n        common_ds_history.append(ds_metrics['common_recall@50'])\n        mrr_gap_ds_history.append(ds_metrics['MRR_gap'])\n        rare_mrr_ds_history.append(ds_metrics['rare_MRR'])\n        common_mrr_ds_history.append(ds_metrics['common_MRR'])\n\n        # Update experiment_data metrics (val) with both prompt sets\n        ensure_container(tag)['metrics']['val'].append({\n            'epoch': epoch,\n            'val_loss': val_loss,\n            'ts': now_ts(),\n            'phase': 'overwrite',\n            'RCRG@50_standard': std_metrics['RCRG@50'],\n            'rare_recall@50_standard': std_metrics['rare_recall@50'],\n            'common_recall@50_standard': std_metrics['common_recall@50'],\n            'MRR_gap_standard': std_metrics['MRR_gap'],\n            'rare_MRR_standard': std_metrics['rare_MRR'],\n            'common_MRR_standard': std_metrics['common_MRR'],\n            'RCRG@50_dataset': ds_metrics['RCRG@50'],\n            'rare_recall@50_dataset': ds_metrics['rare_recall@50'],\n            'common_recall@50_dataset': ds_metrics['common_recall@50'],\n            'MRR_gap_dataset': ds_metrics['MRR_gap'],\n            'rare_MRR_dataset': ds_metrics['rare_MRR'],\n            'common_MRR_dataset': ds_metrics['common_MRR'],\n        })\n\n    # Save embeddings after overwrite\n    embeds_phase2 = model.get_input_embeddings().weight.detach().clone().cpu().numpy()\n    np.save(os.path.join(working_dir, f'embeddings_phase2_{tag}.npy'), embeds_phase2)\n\n    # Embedding retention analysis (cosine similarity)\n    emb1 = torch.tensor(embeds_phase1)\n    emb2 = torch.tensor(embeds_phase2)\n    cos = torch.nn.functional.cosine_similarity\n    rare_ids = [tokenizer.convert_tokens_to_ids(t) for t in rare_tokens]\n    control_ids = [tokenizer.convert_tokens_to_ids(t) for t in control_tokens]\n    rare_cos = [cos(emb1[i], emb2[i], dim=0).item() for i in rare_ids]\n    common_cos = [cos(emb1[i], emb2[i], dim=0).item() for i in control_ids]\n\n    np.save(os.path.join(working_dir, f'rare_cosine_{tag}.npy'), np.array(rare_cos))\n    np.save(os.path.join(working_dir, f'common_cosine_{tag}.npy'), np.array(common_cos))\n\n    # Plot embedding retention\n    plt.figure(figsize=(6,4))\n    plt.bar(range(len(rare_cos)), rare_cos, color='tab:blue')\n    plt.ylim(0, 1.0)\n    plt.title(f'Embedding Retention (Cosine) - Rare Tokens [{tag}]')\n    plt.xlabel('Rare token index')\n    plt.ylabel('Cosine similarity')\n    plt.tight_layout()\n    plt.savefig(os.path.join(working_dir, f'embedding_retention_rare_{tag}.png'))\n    plt.close()\n\n    plt.figure(figsize=(6,4))\n    plt.bar(range(len(common_cos)), common_cos, color='tab:orange')\n    plt.ylim(0, 1.0)\n    plt.title(f'Embedding Retention (Cosine) - Common Tokens [{tag}]')\n    plt.xlabel('Common token index')\n    plt.ylabel('Cosine similarity')\n    plt.tight_layout()\n    plt.savefig(os.path.join(working_dir, f'embedding_retention_common_{tag}.png'))\n    plt.close()\n\n    # Generate samples post-overwrite\n    sample_prompt_std = \"The code word is\"\n    sample_prompt_ds = dataset_prompts[0] if len(dataset_prompts) > 0 else sample_prompt_std\n    num_samples = 128\n\n    samples_post_std = generate_next_tokens(model, tokenizer, sample_prompt_std, num_samples=num_samples, max_new_tokens=3, temperature=0.8, top_k=50)\n    samples_post_ds = generate_next_tokens(model, tokenizer, sample_prompt_ds, num_samples=num_samples, max_new_tokens=3, temperature=0.8, top_k=50)\n\n    def count_hits(samples: List[str], targets: List[str]) -> Dict[str, int]:\n        counts = {t: 0 for t in targets}\n        for s in samples:\n            s_norm = s\n            for t in targets:\n                if s_norm == t:\n                    counts[t] += 1\n        return counts\n\n    rare_counts_std = count_hits(samples_post_std, rare_tokens)\n    common_counts_std = count_hits(samples_post_std, control_tokens)\n    rare_counts_ds = count_hits(samples_post_ds, rare_tokens)\n    common_counts_ds = count_hits(samples_post_ds, control_tokens)\n\n    # Save arrays\n    np.save(os.path.join(working_dir, f'samples_post_std_{tag}.npy'), np.array(samples_post_std, dtype=object))\n    np.save(os.path.join(working_dir, f'samples_post_ds_{tag}.npy'), np.array(samples_post_ds, dtype=object))\n    np.save(os.path.join(working_dir, f'rare_counts_post_std_{tag}.npy'), np.array(list(rare_counts_std.values())))\n    np.save(os.path.join(working_dir, f'common_counts_post_std_{tag}.npy'), np.array(list(common_counts_std.values())))\n    np.save(os.path.join(working_dir, f'rare_counts_post_ds_{tag}.npy'), np.array(list(rare_counts_ds.values())))\n    np.save(os.path.join(working_dir, f'common_counts_post_ds_{tag}.npy'), np.array(list(common_counts_ds.values())))\n\n    # Plots for generation counts\n    plt.figure(figsize=(8,4))\n    plt.bar(range(len(rare_tokens)), list(rare_counts_std.values()), color='tab:blue')\n    plt.xticks(range(len(rare_tokens)), [t.strip() for t in rare_tokens], rotation=45)\n    plt.title(f'Post-overwrite generation counts - Rare tokens (std) [{tag}]')\n    plt.ylabel('Count in first generated token')\n    plt.tight_layout()\n    plt.savefig(os.path.join(working_dir, f'gen_counts_rare_post_std_{tag}.png'))\n    plt.close()\n\n    plt.figure(figsize=(8,4))\n    plt.bar(range(len(control_tokens)), list(common_counts_std.values()), color='tab:orange')\n    plt.xticks(range(len(control_tokens)), [t.strip() for t in control_tokens], rotation=45)\n    plt.title(f'Post-overwrite generation counts - Common tokens (std) [{tag}]')\n    plt.ylabel('Count in first generated token')\n    plt.tight_layout()\n    plt.savefig(os.path.join(working_dir, f'gen_counts_common_post_std_{tag}.png'))\n    plt.close()\n\n    plt.figure(figsize=(8,4))\n    plt.bar(range(len(rare_tokens)), list(rare_counts_ds.values()), color='tab:blue')\n    plt.xticks(range(len(rare_tokens)), [t.strip() for t in rare_tokens], rotation=45)\n    plt.title(f'Post-overwrite generation counts - Rare tokens (ds) [{tag}]')\n    plt.ylabel('Count in first generated token')\n    plt.tight_layout()\n    plt.savefig(os.path.join(working_dir, f'gen_counts_rare_post_ds_{tag}.png'))\n    plt.close()\n\n    plt.figure(figsize=(8,4))\n    plt.bar(range(len(control_tokens)), list(common_counts_ds.values()), color='tab:orange')\n    plt.xticks(range(len(control_tokens)), [t.strip() for t in control_tokens], rotation=45)\n    plt.title(f'Post-overwrite generation counts - Common tokens (ds) [{tag}]')\n    plt.ylabel('Count in first generated token')\n    plt.tight_layout()\n    plt.savefig(os.path.join(working_dir, f'gen_counts_common_post_ds_{tag}.png'))\n    plt.close()\n\n    # Save metric histories\n    np.save(os.path.join(working_dir, f'rcrg_standard_history_{tag}.npy'), np.array(rcrg_std_history))\n    np.save(os.path.join(working_dir, f'rare_recall_standard_history_{tag}.npy'), np.array(rare_std_history))\n    np.save(os.path.join(working_dir, f'common_recall_standard_history_{tag}.npy'), np.array(common_std_history))\n    np.save(os.path.join(working_dir, f'mrr_gap_standard_history_{tag}.npy'), np.array(mrr_gap_std_history))\n    np.save(os.path.join(working_dir, f'rare_mrr_standard_history_{tag}.npy'), np.array(rare_mrr_std_history))\n    np.save(os.path.join(working_dir, f'common_mrr_standard_history_{tag}.npy'), np.array(common_mrr_std_history))\n\n    np.save(os.path.join(working_dir, f'rcrg_dataset_history_{tag}.npy'), np.array(rcrg_ds_history))\n    np.save(os.path.join(working_dir, f'rare_recall_dataset_history_{tag}.npy'), np.array(rare_ds_history))\n    np.save(os.path.join(working_dir, f'common_recall_dataset_history_{tag}.npy'), np.array(common_ds_history))\n    np.save(os.path.join(working_dir, f'mrr_gap_dataset_history_{tag}.npy'), np.array(mrr_gap_ds_history))\n    np.save(os.path.join(working_dir, f'rare_mrr_dataset_history_{tag}.npy'), np.array(rare_mrr_ds_history))\n    np.save(os.path.join(working_dir, f'common_mrr_dataset_history_{tag}.npy'), np.array(common_mrr_ds_history))\n\n    # Plot histories (standard)\n    epochs_axis = list(range(1, len(rcrg_std_history)+1))\n    plt.figure(figsize=(7,4))\n    plt.plot(epochs_axis, rcrg_std_history, marker='o', label='RCRG@50 (standard)')\n    plt.plot(epochs_axis, rare_std_history, marker='s', label='Rare recall@50 (standard)')\n    plt.plot(epochs_axis, common_std_history, marker='^', label='Common recall@50 (standard)')\n    plt.plot(epochs_axis, mrr_gap_std_history, marker='x', label='MRR gap (standard)')\n    plt.xlabel('Overwrite epoch')\n    plt.ylabel('Score')\n    plt.title(f'Retention metrics over overwrite (standard prompts) [{tag}]')\n    plt.legend()\n    plt.grid(True, alpha=0.3)\n    plt.tight_layout()\n    plt.savefig(os.path.join(working_dir, f'retention_over_epochs_standard_{tag}.png'))\n    plt.close()\n\n    # Plot histories (dataset-specific)\n    plt.figure(figsize=(7,4))\n    plt.plot(epochs_axis, rcrg_ds_history, marker='o', label='RCRG@50 (dataset)')\n    plt.plot(epochs_axis, rare_ds_history, marker='s', label='Rare recall@50 (dataset)')\n    plt.plot(epochs_axis, common_ds_history, marker='^', label='Common recall@50 (dataset)')\n    plt.plot(epochs_axis, mrr_gap_ds_history, marker='x', label='MRR gap (dataset)')\n    plt.xlabel('Overwrite epoch')\n    plt.ylabel('Score')\n    plt.title(f'Retention metrics over overwrite (dataset prompts) [{tag}]')\n    plt.legend()\n    plt.grid(True, alpha=0.3)\n    plt.tight_layout()\n    plt.savefig(os.path.join(working_dir, f'retention_over_epochs_dataset_{tag}.png'))\n    plt.close()\n\n    # Record ground truth and predictions\n    cont = ensure_container(tag)\n    cont['ground_truth'] = {'rare': rare_tokens, 'common': control_tokens}\n    cont['predictions'].append({'std_prompt_samples': samples_post_std, 'ds_prompt_samples': samples_post_ds})\n    cont['aux']['dataset_prompts'] = dataset_prompts\n\n    # Cleanup before next condition\n    del model\n    if device.type == 'cuda':\n        torch.cuda.empty_cache()\n\n# -----------------------------------------------------------------------------\n# 5) Save final experiment data\n# -----------------------------------------------------------------------------\nnp.save(os.path.join(working_dir, 'experiment_data.npy'), experiment_data, allow_pickle=True)\n\nprint('Experiment complete. Artifacts saved to:', working_dir)"], "term_out": ["['Using device: cuda:0', '\\n', \"Added 5 rare tokens. Controls: [' apple', '\ntable', ' water', ' green', ' house']\", '\\n', '\\rMap:   0%|          | 0/2000\n[00:00<?, ? examples/s]', '', '\\rMap: 100%|##########| 2000/2000 [00:00<00:00,\n23617.64 examples/s]', '\\n', '\\rMap:   0%|          | 0/300 [00:00<?, ?\nexamples/s]', '', '\\rMap: 100%|##########| 300/300 [00:00<00:00, 32215.97\nexamples/s]', '\\n', '\\rTraining synthetic_injection epoch 1/1:   0%|          |\n0/21 [00:00<?, ?it/s]', '\\rTraining synthetic_injection epoch 1/1:   5%|4\n| 1/21 [00:54<18:08, 54.42s/it]', '\\rTraining synthetic_injection epoch 1/1:\n10%|9         | 2/21 [00:54<07:07, 22.48s/it]', '\\rTraining synthetic_injection\nepoch 1/1:  14%|#4        | 3/21 [00:54<03:40, 12.27s/it]', '\\rTraining\nsynthetic_injection epoch 1/1:  19%|#9        | 4/21 [00:54<02:06,  7.47s/it]',\n'\\rTraining synthetic_injection epoch 1/1:  24%|##3       | 5/21 [00:54<01:17,\n4.82s/it]', '\\rTraining synthetic_injection epoch 1/1:  29%|##8       | 6/21\n[00:54<00:48,  3.22s/it]', '\\rTraining synthetic_injection epoch 1/1:  33%|###3\n| 7/21 [00:55<00:30,  2.20s/it]', '\\rTraining synthetic_injection epoch 1/1:\n38%|###8      | 8/21 [00:55<00:20,  1.54s/it]', '\\rTraining synthetic_injection\nepoch 1/1:  43%|####2     | 9/21 [00:55<00:13,  1.09s/it]', '\\rTraining\nsynthetic_injection epoch 1/1:  48%|####7     | 10/21 [00:55<00:08,  1.26it/s]',\n'\\rTraining synthetic_injection epoch 1/1:  52%|#####2    | 11/21 [00:55<00:05,\n1.71it/s]', '\\rTraining synthetic_injection epoch 1/1:  57%|#####7    | 12/21\n[00:55<00:03,  2.26it/s]', '\\rTraining synthetic_injection epoch 1/1:\n62%|######1   | 13/21 [00:55<00:02,  2.92it/s]', '\\rTraining synthetic_injection\nepoch 1/1:  67%|######6   | 14/21 [00:55<00:01,  3.65it/s]', '\\rTraining\nsynthetic_injection epoch 1/1:  71%|#######1  | 15/21 [00:56<00:01,  4.43it/s]',\n'\\rTraining synthetic_injection epoch 1/1:  76%|#######6  | 16/21 [00:56<00:00,\n5.20it/s]', '\\rTraining synthetic_injection epoch 1/1:  81%|########  | 17/21\n[00:56<00:00,  5.91it/s]', '\\rTraining synthetic_injection epoch 1/1:\n86%|########5 | 18/21 [00:56<00:00,  6.54it/s]', '\\rTraining synthetic_injection\nepoch 1/1:  90%|######### | 19/21 [00:56<00:00,  7.07it/s]', '\\rTraining\nsynthetic_injection epoch 1/1:  95%|#########5| 20/21 [00:56<00:00,  7.49it/s]',\n'', '\\rTraining synthetic_injection epoch 1/1: 100%|##########| 21/21\n[00:57<00:00,  2.75s/it]', '\\n', 'Epoch 1: validation_loss = 3.2268', '\\n',\n'\\rOverwrite epoch 1/4:   0%|          | 0/345 [00:00<?, ?it/s]', '\\rOverwrite\nepoch 1/4:   0%|          | 1/345 [00:53<5:04:01, 53.03s/it]', '\\rOverwrite\nepoch 1/4:   1%|          | 3/345 [00:53<1:18:35, 13.79s/it]', '\\rOverwrite\nepoch 1/4:   2%|1         | 6/345 [00:53<30:16,  5.36s/it]  ', '\\rOverwrite\nepoch 1/4:   3%|2         | 9/345 [00:53<16:06,  2.88s/it]', '\\rOverwrite epoch\n1/4:   3%|3         | 12/345 [00:53<09:40,  1.74s/it]', '\\rOverwrite epoch 1/4:\n4%|4         | 15/345 [00:53<06:11,  1.13s/it]', '\\rOverwrite epoch 1/4:   5%|5\n| 18/345 [00:53<04:07,  1.32it/s]', '\\rOverwrite epoch 1/4:   6%|6         |\n21/345 [00:53<02:49,  1.91it/s]', '\\rOverwrite epoch 1/4:   7%|6         |\n24/345 [00:54<01:59,  2.70it/s]', '\\rOverwrite epoch 1/4:   8%|7         |\n27/345 [00:54<01:25,  3.72it/s]', '\\rOverwrite epoch 1/4:   9%|8         |\n30/345 [00:54<01:03,  4.98it/s]', '\\rOverwrite epoch 1/4:  10%|9         |\n33/345 [00:54<00:47,  6.53it/s]', '\\rOverwrite epoch 1/4:  10%|#         |\n36/345 [00:54<00:37,  8.30it/s]', '\\rOverwrite epoch 1/4:  11%|#1        |\n39/345 [00:54<00:29, 10.23it/s]', '\\rOverwrite epoch 1/4:  12%|#2        |\n42/345 [00:54<00:25, 12.10it/s]', '\\rOverwrite epoch 1/4:  13%|#3        |\n45/345 [00:55<00:21, 13.98it/s]', '\\rOverwrite epoch 1/4:  14%|#3        |\n48/345 [00:55<00:18, 15.69it/s]', '\\rOverwrite epoch 1/4:  15%|#4        |\n51/345 [00:55<00:17, 17.12it/s]', '\\rOverwrite epoch 1/4:  16%|#5        |\n54/345 [00:55<00:15, 18.27it/s]', '\\rOverwrite epoch 1/4:  17%|#6        |\n57/345 [00:55<00:15, 19.19it/s]', '\\rOverwrite epoch 1/4:  17%|#7        |\n60/345 [00:55<00:14, 19.92it/s]', '\\rOverwrite epoch 1/4:  18%|#8        |\n63/345 [00:55<00:13, 20.43it/s]', '\\rOverwrite epoch 1/4:  19%|#9        |\n66/345 [00:56<00:13, 20.83it/s]', '\\rOverwrite epoch 1/4:  20%|##        |\n69/345 [00:56<00:13, 21.12it/s]', '\\rOverwrite epoch 1/4:  21%|##        |\n72/345 [00:56<00:12, 21.33it/s]', '\\rOverwrite epoch 1/4:  22%|##1       |\n75/345 [00:56<00:12, 21.50it/s]', '\\rOverwrite epoch 1/4:  23%|##2       |\n78/345 [00:56<00:12, 21.63it/s]', '\\rOverwrite epoch 1/4:  23%|##3       |\n81/345 [00:56<00:12, 21.68it/s]', '\\rOverwrite epoch 1/4:  24%|##4       |\n84/345 [00:56<00:12, 21.65it/s]', '\\rOverwrite epoch 1/4:  25%|##5       |\n87/345 [00:56<00:11, 21.73it/s]', '\\rOverwrite epoch 1/4:  26%|##6       |\n90/345 [00:57<00:11, 21.77it/s]', '\\rOverwrite epoch 1/4:  27%|##6       |\n93/345 [00:57<00:11, 21.80it/s]', '\\rOverwrite epoch 1/4:  28%|##7       |\n96/345 [00:57<00:11, 21.83it/s]', '\\rOverwrite epoch 1/4:  29%|##8       |\n99/345 [00:57<00:11, 21.71it/s]', '\\rOverwrite epoch 1/4:  30%|##9       |\n102/345 [00:57<00:11, 21.72it/s]', '\\rOverwrite epoch 1/4:  30%|###       |\n105/345 [00:57<00:11, 21.63it/s]', '\\rOverwrite epoch 1/4:  31%|###1      |\n108/345 [00:57<00:10, 21.63it/s]', '\\rOverwrite epoch 1/4:  32%|###2      |\n111/345 [00:58<00:10, 21.69it/s]', '\\rOverwrite epoch 1/4:  33%|###3      |\n114/345 [00:58<00:10, 21.66it/s]', '\\rOverwrite epoch 1/4:  34%|###3      |\n117/345 [00:58<00:10, 21.72it/s]', '\\rOverwrite epoch 1/4:  35%|###4      |\n120/345 [00:58<00:10, 21.74it/s]', '\\rOverwrite epoch 1/4:  36%|###5      |\n123/345 [00:58<00:10, 21.76it/s]', '\\rOverwrite epoch 1/4:  37%|###6      |\n126/345 [00:58<00:10, 21.72it/s]', '\\rOverwrite epoch 1/4:  37%|###7      |\n129/345 [00:58<00:09, 21.72it/s]', '\\rOverwrite epoch 1/4:  38%|###8      |\n132/345 [00:59<00:09, 21.76it/s]', '\\rOverwrite epoch 1/4:  39%|###9      |\n135/345 [00:59<00:09, 21.77it/s]', '\\rOverwrite epoch 1/4:  40%|####      |\n138/345 [00:59<00:09, 21.78it/s]', '\\rOverwrite epoch 1/4:  41%|####      |\n141/345 [00:59<00:09, 21.80it/s]', '\\rOverwrite epoch 1/4:  42%|####1     |\n144/345 [00:59<00:09, 21.80it/s]', '\\rOverwrite epoch 1/4:  43%|####2     |\n147/345 [00:59<00:09, 21.69it/s]', '\\rOverwrite epoch 1/4:  43%|####3     |\n150/345 [00:59<00:08, 21.73it/s]', '\\rOverwrite epoch 1/4:  44%|####4     |\n153/345 [01:00<00:08, 21.73it/s]', '\\rOverwrite epoch 1/4:  45%|####5     |\n156/345 [01:00<00:08, 21.72it/s]', '\\rOverwrite epoch 1/4:  46%|####6     |\n159/345 [01:00<00:08, 21.69it/s]', '\\rOverwrite epoch 1/4:  47%|####6     |\n162/345 [01:00<00:08, 21.69it/s]', '\\rOverwrite epoch 1/4:  48%|####7     |\n165/345 [01:00<00:08, 21.65it/s]', '\\rOverwrite epoch 1/4:  49%|####8     |\n168/345 [01:00<00:08, 21.70it/s]', '\\rOverwrite epoch 1/4:  50%|####9     |\n171/345 [01:00<00:08, 21.60it/s]', '\\rOverwrite epoch 1/4:  50%|#####     |\n174/345 [01:01<00:07, 21.72it/s]', '\\rOverwrite epoch 1/4:  51%|#####1    |\n177/345 [01:01<00:07, 21.64it/s]', '\\rOverwrite epoch 1/4:  52%|#####2    |\n180/345 [01:01<00:07, 21.68it/s]', '\\rOverwrite epoch 1/4:  53%|#####3    |\n183/345 [01:01<00:07, 21.64it/s]', '\\rOverwrite epoch 1/4:  54%|#####3    |\n186/345 [01:01<00:07, 21.61it/s]', '\\rOverwrite epoch 1/4:  55%|#####4    |\n189/345 [01:01<00:07, 21.49it/s]', '\\rOverwrite epoch 1/4:  56%|#####5    |\n192/345 [01:01<00:07, 21.54it/s]', '\\rOverwrite epoch 1/4:  57%|#####6    |\n195/345 [01:01<00:06, 21.49it/s]', '\\rOverwrite epoch 1/4:  57%|#####7    |\n198/345 [01:02<00:06, 21.52it/s]', '[2025-12-03 19:04:18] Overwrite step 200:\navg_train_loss=3.8327', '\\n', '\\rOverwrite epoch 1/4:  58%|#####8    | 201/345\n[01:02<00:06, 21.44it/s]', '\\rOverwrite epoch 1/4:  59%|#####9    | 204/345\n[01:02<00:06, 21.55it/s]', '\\rOverwrite epoch 1/4:  60%|######    | 207/345\n[01:02<00:06, 21.64it/s]', '\\rOverwrite epoch 1/4:  61%|######    | 210/345\n[01:02<00:06, 21.70it/s]', '\\rOverwrite epoch 1/4:  62%|######1   | 213/345\n[01:02<00:06, 21.73it/s]', '\\rOverwrite epoch 1/4:  63%|######2   | 216/345\n[01:02<00:05, 21.77it/s]', '\\rOverwrite epoch 1/4:  63%|######3   | 219/345\n[01:03<00:05, 21.81it/s]', '\\rOverwrite epoch 1/4:  64%|######4   | 222/345\n[01:03<00:05, 21.82it/s]', '\\rOverwrite epoch 1/4:  65%|######5   | 225/345\n[01:03<00:05, 21.82it/s]', '\\rOverwrite epoch 1/4:  66%|######6   | 228/345\n[01:03<00:05, 21.85it/s]', '\\rOverwrite epoch 1/4:  67%|######6   | 231/345\n[01:03<00:05, 21.84it/s]', '\\rOverwrite epoch 1/4:  68%|######7   | 234/345\n[01:03<00:05, 21.76it/s]', '\\rOverwrite epoch 1/4:  69%|######8   | 237/345\n[01:03<00:04, 21.78it/s]', '\\rOverwrite epoch 1/4:  70%|######9   | 240/345\n[01:04<00:04, 21.77it/s]', '\\rOverwrite epoch 1/4:  70%|#######   | 243/345\n[01:04<00:04, 21.80it/s]', '\\rOverwrite epoch 1/4:  71%|#######1  | 246/345\n[01:04<00:04, 21.81it/s]', '\\rOverwrite epoch 1/4:  72%|#######2  | 249/345\n[01:04<00:04, 21.84it/s]', '\\rOverwrite epoch 1/4:  73%|#######3  | 252/345\n[01:04<00:04, 21.87it/s]', '\\rOverwrite epoch 1/4:  74%|#######3  | 255/345\n[01:04<00:04, 21.88it/s]', '\\rOverwrite epoch 1/4:  75%|#######4  | 258/345\n[01:04<00:03, 21.86it/s]', '\\rOverwrite epoch 1/4:  76%|#######5  | 261/345\n[01:05<00:03, 21.85it/s]', '\\rOverwrite epoch 1/4:  77%|#######6  | 264/345\n[01:05<00:03, 21.84it/s]', '\\rOverwrite epoch 1/4:  77%|#######7  | 267/345\n[01:05<00:03, 21.84it/s]', '\\rOverwrite epoch 1/4:  78%|#######8  | 270/345\n[01:05<00:03, 21.81it/s]', '\\rOverwrite epoch 1/4:  79%|#######9  | 273/345\n[01:05<00:03, 21.82it/s]', '\\rOverwrite epoch 1/4:  80%|########  | 276/345\n[01:05<00:03, 21.78it/s]', '\\rOverwrite epoch 1/4:  81%|########  | 279/345\n[01:05<00:03, 21.80it/s]', '\\rOverwrite epoch 1/4:  82%|########1 | 282/345\n[01:05<00:02, 21.68it/s]', '\\rOverwrite epoch 1/4:  83%|########2 | 285/345\n[01:06<00:02, 21.73it/s]', '\\rOverwrite epoch 1/4:  83%|########3 | 288/345\n[01:06<00:02, 21.77it/s]', '\\rOverwrite epoch 1/4:  84%|########4 | 291/345\n[01:06<00:02, 21.82it/s]', '\\rOverwrite epoch 1/4:  85%|########5 | 294/345\n[01:06<00:02, 21.85it/s]', '\\rOverwrite epoch 1/4:  86%|########6 | 297/345\n[01:06<00:02, 21.79it/s]', '\\rOverwrite epoch 1/4:  87%|########6 | 300/345\n[01:06<00:02, 21.62it/s]', '\\rOverwrite epoch 1/4:  88%|########7 | 303/345\n[01:06<00:01, 21.46it/s]', '\\rOverwrite epoch 1/4:  89%|########8 | 306/345\n[01:07<00:01, 21.52it/s]', '\\rOverwrite epoch 1/4:  90%|########9 | 309/345\n[01:07<00:01, 21.53it/s]', '\\rOverwrite epoch 1/4:  90%|######### | 312/345\n[01:07<00:01, 21.56it/s]', '\\rOverwrite epoch 1/4:  91%|#########1| 315/345\n[01:07<00:01, 21.59it/s]', '\\rOverwrite epoch 1/4:  92%|#########2| 318/345\n[01:07<00:01, 21.65it/s]', '\\rOverwrite epoch 1/4:  93%|#########3| 321/345\n[01:07<00:01, 21.66it/s]', '\\rOverwrite epoch 1/4:  94%|#########3| 324/345\n[01:07<00:00, 21.49it/s]', '\\rOverwrite epoch 1/4:  95%|#########4| 327/345\n[01:08<00:00, 21.47it/s]', '\\rOverwrite epoch 1/4:  96%|#########5| 330/345\n[01:08<00:00, 21.55it/s]', '\\rOverwrite epoch 1/4:  97%|#########6| 333/345\n[01:08<00:00, 21.62it/s]', '\\rOverwrite epoch 1/4:  97%|#########7| 336/345\n[01:08<00:00, 21.63it/s]', '\\rOverwrite epoch 1/4:  98%|#########8| 339/345\n[01:08<00:00, 21.52it/s]', '\\rOverwrite epoch 1/4:  99%|#########9| 342/345\n[01:08<00:00, 21.50it/s]', '\\rOverwrite epoch 1/4: 100%|##########| 345/345\n[01:08<00:00, 22.49it/s]', '', '\\rOverwrite epoch 1/4: 100%|##########| 345/345\n[01:09<00:00,  4.94it/s]', '\\n', 'Epoch 1: validation_loss = 3.6236', '\\n',\n'\\rOverwrite epoch 2/4:   0%|          | 0/345 [00:00<?, ?it/s]', '\\rOverwrite\nepoch 2/4:   0%|          | 1/345 [00:54<5:10:31, 54.16s/it]', '\\rOverwrite\nepoch 2/4:   1%|          | 3/345 [00:54<1:20:20, 14.10s/it]', '\\rOverwrite\nepoch 2/4:   2%|1         | 6/345 [00:54<30:56,  5.48s/it]  ', '\\rOverwrite\nepoch 2/4:   3%|2         | 9/345 [00:54<16:27,  2.94s/it]', '\\rOverwrite epoch\n2/4:   3%|3         | 12/345 [00:54<09:53,  1.78s/it]', '\\rOverwrite epoch 2/4:\n4%|4         | 15/345 [00:54<06:19,  1.15s/it]', '\\rOverwrite epoch 2/4:   5%|5\n| 18/345 [00:54<04:12,  1.29it/s]', '\\rOverwrite epoch 2/4:   6%|6         |\n21/345 [00:55<02:52,  1.87it/s]', '\\rOverwrite epoch 2/4:   7%|6         |\n24/345 [00:55<02:01,  2.65it/s]', '\\rOverwrite epoch 2/4:   8%|7         |\n27/345 [00:55<01:27,  3.65it/s]', '\\rOverwrite epoch 2/4:   9%|8         |\n30/345 [00:55<01:04,  4.92it/s]', '\\rOverwrite epoch 2/4:  10%|9         |\n33/345 [00:55<00:48,  6.45it/s]', '\\rOverwrite epoch 2/4:  10%|#         |\n36/345 [00:55<00:37,  8.21it/s]', '\\rOverwrite epoch 2/4:  11%|#1        |\n39/345 [00:55<00:30, 10.12it/s]', '\\rOverwrite epoch 2/4:  12%|#2        |\n42/345 [00:56<00:25, 12.07it/s]', '\\rOverwrite epoch 2/4:  13%|#3        |\n45/345 [00:56<00:21, 13.95it/s]', '\\rOverwrite epoch 2/4:  14%|#3        |\n48/345 [00:56<00:18, 15.64it/s]', '\\rOverwrite epoch 2/4:  15%|#4        |\n51/345 [00:56<00:17, 17.09it/s]', '\\rOverwrite epoch 2/4:  16%|#5        |\n54/345 [00:56<00:16, 18.07it/s]', '[2025-12-03 19:06:20] Overwrite step 400:\navg_train_loss=3.3332', '\\n', '\\rOverwrite epoch 2/4:  17%|#6        | 57/345\n[00:56<00:15, 18.82it/s]', '\\rOverwrite epoch 2/4:  17%|#7        | 60/345\n[00:56<00:14, 19.59it/s]', '\\rOverwrite epoch 2/4:  18%|#8        | 63/345\n[00:57<00:13, 20.15it/s]', '\\rOverwrite epoch 2/4:  19%|#9        | 66/345\n[00:57<00:13, 20.60it/s]', '\\rOverwrite epoch 2/4:  20%|##        | 69/345\n[00:57<00:13, 20.76it/s]', '\\rOverwrite epoch 2/4:  21%|##        | 72/345\n[00:57<00:13, 20.82it/s]', '\\rOverwrite epoch 2/4:  22%|##1       | 75/345\n[00:57<00:13, 20.67it/s]', '\\rOverwrite epoch 2/4:  23%|##2       | 78/345\n[00:57<00:12, 20.95it/s]', '\\rOverwrite epoch 2/4:  23%|##3       | 81/345\n[00:57<00:12, 21.21it/s]', '\\rOverwrite epoch 2/4:  24%|##4       | 84/345\n[00:58<00:12, 21.41it/s]', '\\rOverwrite epoch 2/4:  25%|##5       | 87/345\n[00:58<00:11, 21.56it/s]', '\\rOverwrite epoch 2/4:  26%|##6       | 90/345\n[00:58<00:11, 21.52it/s]', '\\rOverwrite epoch 2/4:  27%|##6       | 93/345\n[00:58<00:11, 21.63it/s]', '\\rOverwrite epoch 2/4:  28%|##7       | 96/345\n[00:58<00:11, 21.69it/s]', '\\rOverwrite epoch 2/4:  29%|##8       | 99/345\n[00:58<00:11, 21.76it/s]', '\\rOverwrite epoch 2/4:  30%|##9       | 102/345\n[00:58<00:11, 21.79it/s]', '\\rOverwrite epoch 2/4:  30%|###       | 105/345\n[00:59<00:10, 21.82it/s]', '\\rOverwrite epoch 2/4:  31%|###1      | 108/345\n[00:59<00:10, 21.84it/s]', '\\rOverwrite epoch 2/4:  32%|###2      | 111/345\n[00:59<00:10, 21.85it/s]', '\\rOverwrite epoch 2/4:  33%|###3      | 114/345\n[00:59<00:10, 21.86it/s]', '\\rOverwrite epoch 2/4:  34%|###3      | 117/345\n[00:59<00:10, 21.28it/s]', '\\rOverwrite epoch 2/4:  35%|###4      | 120/345\n[00:59<00:10, 20.57it/s]', '\\rOverwrite epoch 2/4:  36%|###5      | 123/345\n[00:59<00:11, 20.09it/s]', '\\rOverwrite epoch 2/4:  37%|###6      | 126/345\n[01:00<00:11, 19.72it/s]', '\\rOverwrite epoch 2/4:  37%|###7      | 129/345\n[01:00<00:10, 20.30it/s]', '\\rOverwrite epoch 2/4:  38%|###8      | 132/345\n[01:00<00:10, 20.72it/s]', '\\rOverwrite epoch 2/4:  39%|###9      | 135/345\n[01:00<00:10, 20.98it/s]', '\\rOverwrite epoch 2/4:  40%|####      | 138/345\n[01:00<00:09, 20.87it/s]', '\\rOverwrite epoch 2/4:  41%|####      | 141/345\n[01:00<00:09, 21.08it/s]', '\\rOverwrite epoch 2/4:  42%|####1     | 144/345\n[01:00<00:09, 21.31it/s]', '\\rOverwrite epoch 2/4:  43%|####2     | 147/345\n[01:01<00:09, 21.48it/s]', '\\rOverwrite epoch 2/4:  43%|####3     | 150/345\n[01:01<00:09, 21.60it/s]', '\\rOverwrite epoch 2/4:  44%|####4     | 153/345\n[01:01<00:08, 21.70it/s]', '\\rOverwrite epoch 2/4:  45%|####5     | 156/345\n[01:01<00:08, 21.74it/s]', '\\rOverwrite epoch 2/4:  46%|####6     | 159/345\n[01:01<00:08, 21.73it/s]', '\\rOverwrite epoch 2/4:  47%|####6     | 162/345\n[01:01<00:08, 21.65it/s]', '\\rOverwrite epoch 2/4:  48%|####7     | 165/345\n[01:01<00:08, 21.57it/s]', '\\rOverwrite epoch 2/4:  49%|####8     | 168/345\n[01:01<00:08, 21.68it/s]', '\\rOverwrite epoch 2/4:  50%|####9     | 171/345\n[01:02<00:08, 21.74it/s]', '\\rOverwrite epoch 2/4:  50%|#####     | 174/345\n[01:02<00:07, 21.78it/s]', '\\rOverwrite epoch 2/4:  51%|#####1    | 177/345\n[01:02<00:07, 21.74it/s]', '\\rOverwrite epoch 2/4:  52%|#####2    | 180/345\n[01:02<00:07, 21.67it/s]', '\\rOverwrite epoch 2/4:  53%|#####3    | 183/345\n[01:02<00:07, 21.56it/s]', '\\rOverwrite epoch 2/4:  54%|#####3    | 186/345\n[01:02<00:07, 21.56it/s]', '\\rOverwrite epoch 2/4:  55%|#####4    | 189/345\n[01:02<00:07, 21.60it/s]', '\\rOverwrite epoch 2/4:  56%|#####5    | 192/345\n[01:03<00:07, 21.67it/s]', '\\rOverwrite epoch 2/4:  57%|#####6    | 195/345\n[01:03<00:06, 21.72it/s]', '\\rOverwrite epoch 2/4:  57%|#####7    | 198/345\n[01:03<00:06, 21.76it/s]', '\\rOverwrite epoch 2/4:  58%|#####8    | 201/345\n[01:03<00:06, 21.80it/s]', '\\rOverwrite epoch 2/4:  59%|#####9    | 204/345\n[01:03<00:06, 21.84it/s]', '\\rOverwrite epoch 2/4:  60%|######    | 207/345\n[01:03<00:06, 21.86it/s]', '\\rOverwrite epoch 2/4:  61%|######    | 210/345\n[01:03<00:06, 21.87it/s]', '\\rOverwrite epoch 2/4:  62%|######1   | 213/345\n[01:04<00:06, 21.65it/s]', '\\rOverwrite epoch 2/4:  63%|######2   | 216/345\n[01:04<00:06, 21.49it/s]', '\\rOverwrite epoch 2/4:  63%|######3   | 219/345\n[01:04<00:05, 21.50it/s]', '\\rOverwrite epoch 2/4:  64%|######4   | 222/345\n[01:04<00:05, 21.54it/s]', '\\rOverwrite epoch 2/4:  65%|######5   | 225/345\n[01:04<00:05, 21.53it/s]', '\\rOverwrite epoch 2/4:  66%|######6   | 228/345\n[01:04<00:05, 21.58it/s]', '\\rOverwrite epoch 2/4:  67%|######6   | 231/345\n[01:04<00:05, 21.62it/s]', '\\rOverwrite epoch 2/4:  68%|######7   | 234/345\n[01:05<00:05, 21.60it/s]', '\\rOverwrite epoch 2/4:  69%|######8   | 237/345\n[01:05<00:05, 21.57it/s]', '\\rOverwrite epoch 2/4:  70%|######9   | 240/345\n[01:05<00:04, 21.57it/s]', '\\rOverwrite epoch 2/4:  70%|#######   | 243/345\n[01:05<00:04, 21.63it/s]', '\\rOverwrite epoch 2/4:  71%|#######1  | 246/345\n[01:05<00:04, 21.61it/s]', '\\rOverwrite epoch 2/4:  72%|#######2  | 249/345\n[01:05<00:04, 21.59it/s]', '\\rOverwrite epoch 2/4:  73%|#######3  | 252/345\n[01:05<00:04, 21.62it/s]', '[2025-12-03 19:06:30] Overwrite step 600:\navg_train_loss=3.3203', '\\n', '\\rOverwrite epoch 2/4:  74%|#######3  | 255/345\n[01:06<00:04, 21.65it/s]', '\\rOverwrite epoch 2/4:  75%|#######4  | 258/345\n[01:06<00:04, 21.59it/s]', '\\rOverwrite epoch 2/4:  76%|#######5  | 261/345\n[01:06<00:03, 21.60it/s]', '\\rOverwrite epoch 2/4:  77%|#######6  | 264/345\n[01:06<00:03, 21.47it/s]', '\\rOverwrite epoch 2/4:  77%|#######7  | 267/345\n[01:06<00:03, 21.49it/s]', '\\rOverwrite epoch 2/4:  78%|#######8  | 270/345\n[01:06<00:03, 21.61it/s]', '\\rOverwrite epoch 2/4:  79%|#######9  | 273/345\n[01:06<00:03, 21.72it/s]', '\\rOverwrite epoch 2/4:  80%|########  | 276/345\n[01:06<00:03, 21.77it/s]', '\\rOverwrite epoch 2/4:  81%|########  | 279/345\n[01:07<00:03, 21.63it/s]', '\\rOverwrite epoch 2/4:  82%|########1 | 282/345\n[01:07<00:02, 21.37it/s]', '\\rOverwrite epoch 2/4:  83%|########2 | 285/345\n[01:07<00:02, 20.88it/s]', '\\rOverwrite epoch 2/4:  83%|########3 | 288/345\n[01:07<00:02, 20.62it/s]', '\\rOverwrite epoch 2/4:  84%|########4 | 291/345\n[01:07<00:02, 20.64it/s]', '\\rOverwrite epoch 2/4:  85%|########5 | 294/345\n[01:07<00:02, 20.87it/s]', '\\rOverwrite epoch 2/4:  86%|########6 | 297/345\n[01:07<00:02, 21.07it/s]', '\\rOverwrite epoch 2/4:  87%|########6 | 300/345\n[01:08<00:02, 21.23it/s]', '\\rOverwrite epoch 2/4:  88%|########7 | 303/345\n[01:08<00:01, 21.33it/s]', '\\rOverwrite epoch 2/4:  89%|########8 | 306/345\n[01:08<00:01, 21.42it/s]', '\\rOverwrite epoch 2/4:  90%|########9 | 309/345\n[01:08<00:01, 21.47it/s]', '\\rOverwrite epoch 2/4:  90%|######### | 312/345\n[01:08<00:01, 21.49it/s]', '\\rOverwrite epoch 2/4:  91%|#########1| 315/345\n[01:08<00:01, 21.48it/s]', '\\rOverwrite epoch 2/4:  92%|#########2| 318/345\n[01:08<00:01, 21.49it/s]', '\\rOverwrite epoch 2/4:  93%|#########3| 321/345\n[01:09<00:01, 21.25it/s]', '\\rOverwrite epoch 2/4:  94%|#########3| 324/345\n[01:09<00:00, 21.31it/s]', '\\rOverwrite epoch 2/4:  95%|#########4| 327/345\n[01:09<00:00, 21.35it/s]', '\\rOverwrite epoch 2/4:  96%|#########5| 330/345\n[01:09<00:00, 21.45it/s]', '\\rOverwrite epoch 2/4:  97%|#########6| 333/345\n[01:09<00:00, 21.54it/s]', '\\rOverwrite epoch 2/4:  97%|#########7| 336/345\n[01:09<00:00, 21.59it/s]', '\\rOverwrite epoch 2/4:  98%|#########8| 339/345\n[01:09<00:00, 21.62it/s]', '\\rOverwrite epoch 2/4:  99%|#########9| 342/345\n[01:10<00:00, 21.59it/s]', '\\rOverwrite epoch 2/4: 100%|##########| 345/345\n[01:10<00:00, 22.64it/s]', '', '\\rOverwrite epoch 2/4: 100%|##########| 345/345\n[01:11<00:00,  4.84it/s]', '\\n', 'Epoch 2: validation_loss = 3.6392', '\\n',\n'\\rOverwrite epoch 3/4:   0%|          | 0/345 [00:00<?, ?it/s]', '\\rOverwrite\nepoch 3/4:   0%|          | 1/345 [00:56<5:25:53, 56.84s/it]', '\\rOverwrite\nepoch 3/4:   1%|          | 3/345 [00:56<1:24:16, 14.79s/it]', '\\rOverwrite\nepoch 3/4:   2%|1         | 6/345 [00:57<32:26,  5.74s/it]  ', '\\rOverwrite\nepoch 3/4:   3%|2         | 9/345 [00:57<17:15,  3.08s/it]', '\\rOverwrite epoch\n3/4:   3%|3         | 12/345 [00:57<10:21,  1.87s/it]', '\\rOverwrite epoch 3/4:\n4%|4         | 15/345 [00:57<06:37,  1.20s/it]', '\\rOverwrite epoch 3/4:   5%|5\n| 18/345 [00:57<04:24,  1.24it/s]', '\\rOverwrite epoch 3/4:   6%|6         |\n21/345 [00:57<03:00,  1.79it/s]', '\\rOverwrite epoch 3/4:   7%|6         |\n24/345 [00:57<02:06,  2.53it/s]', '\\rOverwrite epoch 3/4:   8%|7         |\n27/345 [00:58<01:30,  3.50it/s]', '\\rOverwrite epoch 3/4:   9%|8         |\n30/345 [00:58<01:06,  4.73it/s]', '\\rOverwrite epoch 3/4:  10%|9         |\n33/345 [00:58<00:50,  6.21it/s]', '\\rOverwrite epoch 3/4:  10%|#         |\n36/345 [00:58<00:39,  7.85it/s]', '\\rOverwrite epoch 3/4:  11%|#1        |\n39/345 [00:58<00:31,  9.71it/s]', '\\rOverwrite epoch 3/4:  12%|#2        |\n42/345 [00:58<00:25, 11.66it/s]', '\\rOverwrite epoch 3/4:  13%|#3        |\n45/345 [00:58<00:22, 13.53it/s]', '\\rOverwrite epoch 3/4:  14%|#3        |\n48/345 [00:59<00:19, 15.27it/s]', '\\rOverwrite epoch 3/4:  15%|#4        |\n51/345 [00:59<00:17, 16.80it/s]', '\\rOverwrite epoch 3/4:  16%|#5        |\n54/345 [00:59<00:16, 17.99it/s]', '\\rOverwrite epoch 3/4:  17%|#6        |\n57/345 [00:59<00:15, 18.99it/s]', '\\rOverwrite epoch 3/4:  17%|#7        |\n60/345 [00:59<00:14, 19.64it/s]', '\\rOverwrite epoch 3/4:  18%|#8        |\n63/345 [00:59<00:14, 19.81it/s]', '\\rOverwrite epoch 3/4:  19%|#9        |\n66/345 [00:59<00:13, 20.02it/s]', '\\rOverwrite epoch 3/4:  20%|##        |\n69/345 [01:00<00:13, 20.10it/s]', '\\rOverwrite epoch 3/4:  21%|##        |\n72/345 [01:00<00:13, 20.28it/s]', '\\rOverwrite epoch 3/4:  22%|##1       |\n75/345 [01:00<00:13, 20.68it/s]', '\\rOverwrite epoch 3/4:  23%|##2       |\n78/345 [01:00<00:12, 21.03it/s]', '\\rOverwrite epoch 3/4:  23%|##3       |\n81/345 [01:00<00:12, 21.29it/s]', '\\rOverwrite epoch 3/4:  24%|##4       |\n84/345 [01:00<00:12, 21.47it/s]', '\\rOverwrite epoch 3/4:  25%|##5       |\n87/345 [01:00<00:12, 21.48it/s]', '\\rOverwrite epoch 3/4:  26%|##6       |\n90/345 [01:01<00:11, 21.47it/s]', '\\rOverwrite epoch 3/4:  27%|##6       |\n93/345 [01:01<00:11, 21.53it/s]', '\\rOverwrite epoch 3/4:  28%|##7       |\n96/345 [01:01<00:11, 21.53it/s]', '\\rOverwrite epoch 3/4:  29%|##8       |\n99/345 [01:01<00:11, 21.54it/s]', '\\rOverwrite epoch 3/4:  30%|##9       |\n102/345 [01:01<00:11, 21.51it/s]', '\\rOverwrite epoch 3/4:  30%|###       |\n105/345 [01:01<00:11, 21.50it/s]', '\\rOverwrite epoch 3/4:  31%|###1      |\n108/345 [01:01<00:11, 21.34it/s]', '[2025-12-03 19:08:36] Overwrite step 800:\navg_train_loss=3.0696', '\\n', '\\rOverwrite epoch 3/4:  32%|###2      | 111/345\n[01:02<00:11, 21.26it/s]', '\\rOverwrite epoch 3/4:  33%|###3      | 114/345\n[01:02<00:10, 21.02it/s]', '\\rOverwrite epoch 3/4:  34%|###3      | 117/345\n[01:02<00:10, 21.19it/s]', '\\rOverwrite epoch 3/4:  35%|###4      | 120/345\n[01:02<00:10, 21.39it/s]', '\\rOverwrite epoch 3/4:  36%|###5      | 123/345\n[01:02<00:10, 21.52it/s]', '\\rOverwrite epoch 3/4:  37%|###6      | 126/345\n[01:02<00:10, 21.59it/s]', '\\rOverwrite epoch 3/4:  37%|###7      | 129/345\n[01:02<00:10, 21.27it/s]', '\\rOverwrite epoch 3/4:  38%|###8      | 132/345\n[01:02<00:09, 21.45it/s]', '\\rOverwrite epoch 3/4:  39%|###9      | 135/345\n[01:03<00:09, 21.57it/s]', '\\rOverwrite epoch 3/4:  40%|####      | 138/345\n[01:03<00:09, 21.64it/s]', '\\rOverwrite epoch 3/4:  41%|####      | 141/345\n[01:03<00:09, 21.71it/s]', '\\rOverwrite epoch 3/4:  42%|####1     | 144/345\n[01:03<00:09, 21.72it/s]', '\\rOverwrite epoch 3/4:  43%|####2     | 147/345\n[01:03<00:09, 21.75it/s]', '\\rOverwrite epoch 3/4:  43%|####3     | 150/345\n[01:03<00:08, 21.80it/s]', '\\rOverwrite epoch 3/4:  44%|####4     | 153/345\n[01:03<00:08, 21.81it/s]', '\\rOverwrite epoch 3/4:  45%|####5     | 156/345\n[01:04<00:08, 21.79it/s]', '\\rOverwrite epoch 3/4:  46%|####6     | 159/345\n[01:04<00:08, 21.72it/s]', '\\rOverwrite epoch 3/4:  47%|####6     | 162/345\n[01:04<00:08, 21.76it/s]', '\\rOverwrite epoch 3/4:  48%|####7     | 165/345\n[01:04<00:08, 21.81it/s]', '\\rOverwrite epoch 3/4:  49%|####8     | 168/345\n[01:04<00:08, 21.85it/s]', '\\rOverwrite epoch 3/4:  50%|####9     | 171/345\n[01:04<00:07, 21.84it/s]', '\\rOverwrite epoch 3/4:  50%|#####     | 174/345\n[01:04<00:07, 21.84it/s]', '\\rOverwrite epoch 3/4:  51%|#####1    | 177/345\n[01:05<00:07, 21.81it/s]', '\\rOverwrite epoch 3/4:  52%|#####2    | 180/345\n[01:05<00:07, 21.78it/s]', '\\rOverwrite epoch 3/4:  53%|#####3    | 183/345\n[01:05<00:07, 21.78it/s]', '\\rOverwrite epoch 3/4:  54%|#####3    | 186/345\n[01:05<00:07, 21.80it/s]', '\\rOverwrite epoch 3/4:  55%|#####4    | 189/345\n[01:05<00:07, 21.82it/s]', '\\rOverwrite epoch 3/4:  56%|#####5    | 192/345\n[01:05<00:06, 21.89it/s]', '\\rOverwrite epoch 3/4:  57%|#####6    | 195/345\n[01:05<00:06, 21.91it/s]', '\\rOverwrite epoch 3/4:  57%|#####7    | 198/345\n[01:06<00:06, 21.94it/s]', '\\rOverwrite epoch 3/4:  58%|#####8    | 201/345\n[01:06<00:06, 21.82it/s]', '\\rOverwrite epoch 3/4:  59%|#####9    | 204/345\n[01:06<00:06, 21.67it/s]', '\\rOverwrite epoch 3/4:  60%|######    | 207/345\n[01:06<00:06, 21.70it/s]', '\\rOverwrite epoch 3/4:  61%|######    | 210/345\n[01:06<00:06, 21.74it/s]', '\\rOverwrite epoch 3/4:  62%|######1   | 213/345\n[01:06<00:06, 21.79it/s]', '\\rOverwrite epoch 3/4:  63%|######2   | 216/345\n[01:06<00:05, 21.83it/s]', '\\rOverwrite epoch 3/4:  63%|######3   | 219/345\n[01:06<00:05, 21.73it/s]', '\\rOverwrite epoch 3/4:  64%|######4   | 222/345\n[01:07<00:05, 21.76it/s]', '\\rOverwrite epoch 3/4:  65%|######5   | 225/345\n[01:07<00:05, 21.79it/s]', '\\rOverwrite epoch 3/4:  66%|######6   | 228/345\n[01:07<00:05, 21.77it/s]', '\\rOverwrite epoch 3/4:  67%|######6   | 231/345\n[01:07<00:05, 21.82it/s]', '\\rOverwrite epoch 3/4:  68%|######7   | 234/345\n[01:07<00:05, 21.83it/s]', '\\rOverwrite epoch 3/4:  69%|######8   | 237/345\n[01:07<00:04, 21.85it/s]', '\\rOverwrite epoch 3/4:  70%|######9   | 240/345\n[01:07<00:04, 21.88it/s]', '\\rOverwrite epoch 3/4:  70%|#######   | 243/345\n[01:08<00:04, 21.67it/s]', '\\rOverwrite epoch 3/4:  71%|#######1  | 246/345\n[01:08<00:04, 21.62it/s]', '\\rOverwrite epoch 3/4:  72%|#######2  | 249/345\n[01:08<00:04, 21.64it/s]', '\\rOverwrite epoch 3/4:  73%|#######3  | 252/345\n[01:08<00:04, 21.68it/s]', '\\rOverwrite epoch 3/4:  74%|#######3  | 255/345\n[01:08<00:04, 21.71it/s]', '\\rOverwrite epoch 3/4:  75%|#######4  | 258/345\n[01:08<00:04, 21.74it/s]', '\\rOverwrite epoch 3/4:  76%|#######5  | 261/345\n[01:08<00:03, 21.72it/s]', '\\rOverwrite epoch 3/4:  77%|#######6  | 264/345\n[01:09<00:03, 21.70it/s]', '\\rOverwrite epoch 3/4:  77%|#######7  | 267/345\n[01:09<00:03, 21.60it/s]', '\\rOverwrite epoch 3/4:  78%|#######8  | 270/345\n[01:09<00:03, 21.64it/s]', '\\rOverwrite epoch 3/4:  79%|#######9  | 273/345\n[01:09<00:03, 21.65it/s]', '\\rOverwrite epoch 3/4:  80%|########  | 276/345\n[01:09<00:03, 21.68it/s]', '\\rOverwrite epoch 3/4:  81%|########  | 279/345\n[01:09<00:03, 21.70it/s]', '\\rOverwrite epoch 3/4:  82%|########1 | 282/345\n[01:09<00:02, 21.73it/s]', '\\rOverwrite epoch 3/4:  83%|########2 | 285/345\n[01:10<00:02, 21.73it/s]', '\\rOverwrite epoch 3/4:  83%|########3 | 288/345\n[01:10<00:02, 21.48it/s]', '\\rOverwrite epoch 3/4:  84%|########4 | 291/345\n[01:10<00:02, 21.49it/s]', '\\rOverwrite epoch 3/4:  85%|########5 | 294/345\n[01:10<00:02, 21.52it/s]', '\\rOverwrite epoch 3/4:  86%|########6 | 297/345\n[01:10<00:02, 21.63it/s]', '\\rOverwrite epoch 3/4:  87%|########6 | 300/345\n[01:10<00:02, 21.68it/s]', '\\rOverwrite epoch 3/4:  88%|########7 | 303/345\n[01:10<00:01, 21.73it/s]', '\\rOverwrite epoch 3/4:  89%|########8 | 306/345\n[01:10<00:01, 21.77it/s]', '\\rOverwrite epoch 3/4:  90%|########9 | 309/345\n[01:11<00:01, 21.82it/s]', '[2025-12-03 19:08:45] Overwrite step 1000:\navg_train_loss=3.0832', '\\n', '\\rOverwrite epoch 3/4:  90%|######### | 312/345\n[01:11<00:01, 21.71it/s]', '\\rOverwrite epoch 3/4:  91%|#########1| 315/345\n[01:11<00:01, 21.74it/s]', '\\rOverwrite epoch 3/4:  92%|#########2| 318/345\n[01:11<00:01, 21.78it/s]', '\\rOverwrite epoch 3/4:  93%|#########3| 321/345\n[01:11<00:01, 21.73it/s]', '\\rOverwrite epoch 3/4:  94%|#########3| 324/345\n[01:11<00:00, 21.78it/s]', '\\rOverwrite epoch 3/4:  95%|#########4| 327/345\n[01:11<00:00, 21.77it/s]', '\\rOverwrite epoch 3/4:  96%|#########5| 330/345\n[01:12<00:00, 21.76it/s]', '\\rOverwrite epoch 3/4:  97%|#########6| 333/345\n[01:12<00:00, 21.80it/s]', '\\rOverwrite epoch 3/4:  97%|#########7| 336/345\n[01:12<00:00, 21.79it/s]', '\\rOverwrite epoch 3/4:  98%|#########8| 339/345\n[01:12<00:00, 21.81it/s]', '\\rOverwrite epoch 3/4:  99%|#########9| 342/345\n[01:12<00:00, 21.81it/s]', '\\rOverwrite epoch 3/4: 100%|##########| 345/345\n[01:12<00:00, 22.81it/s]', '', '\\rOverwrite epoch 3/4: 100%|##########| 345/345\n[01:13<00:00,  4.68it/s]', '\\n', 'Epoch 3: validation_loss = 3.6716', '\\n',\n'\\rOverwrite epoch 4/4:   0%|          | 0/345 [00:00<?, ?it/s]', '\\rOverwrite\nepoch 4/4:   0%|          | 1/345 [00:53<5:05:31, 53.29s/it]', '\\rOverwrite\nepoch 4/4:   1%|          | 3/345 [00:53<1:19:01, 13.86s/it]', '\\rOverwrite\nepoch 4/4:   2%|1         | 6/345 [00:53<30:26,  5.39s/it]  ', '\\rOverwrite\nepoch 4/4:   3%|2         | 9/345 [00:53<16:11,  2.89s/it]', '\\rOverwrite epoch\n4/4:   3%|3         | 12/345 [00:53<09:43,  1.75s/it]', '\\rOverwrite epoch 4/4:\n4%|4         | 15/345 [00:53<06:13,  1.13s/it]', '\\rOverwrite epoch 4/4:   5%|5\n| 18/345 [00:54<04:08,  1.31it/s]', '\\rOverwrite epoch 4/4:   6%|6         |\n21/345 [00:54<02:50,  1.90it/s]', '\\rOverwrite epoch 4/4:   7%|6         |\n24/345 [00:54<01:59,  2.68it/s]', '\\rOverwrite epoch 4/4:   8%|7         |\n27/345 [00:54<01:25,  3.70it/s]', '\\rOverwrite epoch 4/4:   9%|8         |\n30/345 [00:54<01:03,  4.98it/s]', '\\rOverwrite epoch 4/4:  10%|9         |\n33/345 [00:54<00:47,  6.51it/s]', '\\rOverwrite epoch 4/4:  10%|#         |\n36/345 [00:54<00:37,  8.28it/s]', '\\rOverwrite epoch 4/4:  11%|#1        |\n39/345 [00:55<00:29, 10.20it/s]', '\\rOverwrite epoch 4/4:  12%|#2        |\n42/345 [00:55<00:24, 12.16it/s]', '\\rOverwrite epoch 4/4:  13%|#3        |\n45/345 [00:55<00:21, 14.05it/s]', '\\rOverwrite epoch 4/4:  14%|#3        |\n48/345 [00:55<00:18, 15.77it/s]', '\\rOverwrite epoch 4/4:  15%|#4        |\n51/345 [00:55<00:17, 17.21it/s]', '\\rOverwrite epoch 4/4:  16%|#5        |\n54/345 [00:55<00:15, 18.39it/s]', '\\rOverwrite epoch 4/4:  17%|#6        |\n57/345 [00:55<00:14, 19.31it/s]', '\\rOverwrite epoch 4/4:  17%|#7        |\n60/345 [00:56<00:14, 19.93it/s]', '\\rOverwrite epoch 4/4:  18%|#8        |\n63/345 [00:56<00:13, 20.41it/s]', '\\rOverwrite epoch 4/4:  19%|#9        |\n66/345 [00:56<00:13, 20.80it/s]', '\\rOverwrite epoch 4/4:  20%|##        |\n69/345 [00:56<00:13, 21.05it/s]', '\\rOverwrite epoch 4/4:  21%|##        |\n72/345 [00:56<00:12, 21.26it/s]', '\\rOverwrite epoch 4/4:  22%|##1       |\n75/345 [00:56<00:12, 21.42it/s]', '\\rOverwrite epoch 4/4:  23%|##2       |\n78/345 [00:56<00:12, 21.54it/s]', '\\rOverwrite epoch 4/4:  23%|##3       |\n81/345 [00:56<00:12, 21.68it/s]', '\\rOverwrite epoch 4/4:  24%|##4       |\n84/345 [00:57<00:11, 21.78it/s]', '\\rOverwrite epoch 4/4:  25%|##5       |\n87/345 [00:57<00:11, 21.82it/s]', '\\rOverwrite epoch 4/4:  26%|##6       |\n90/345 [00:57<00:11, 21.87it/s]', '\\rOverwrite epoch 4/4:  27%|##6       |\n93/345 [00:57<00:11, 21.88it/s]', '\\rOverwrite epoch 4/4:  28%|##7       |\n96/345 [00:57<00:11, 21.91it/s]', '\\rOverwrite epoch 4/4:  29%|##8       |\n99/345 [00:57<00:11, 21.78it/s]', '\\rOverwrite epoch 4/4:  30%|##9       |\n102/345 [00:57<00:11, 21.54it/s]', '\\rOverwrite epoch 4/4:  30%|###       |\n105/345 [00:58<00:11, 21.46it/s]', '\\rOverwrite epoch 4/4:  31%|###1      |\n108/345 [00:58<00:10, 21.59it/s]', '\\rOverwrite epoch 4/4:  32%|###2      |\n111/345 [00:58<00:10, 21.67it/s]', '\\rOverwrite epoch 4/4:  33%|###3      |\n114/345 [00:58<00:10, 21.71it/s]', '\\rOverwrite epoch 4/4:  34%|###3      |\n117/345 [00:58<00:10, 21.62it/s]', '\\rOverwrite epoch 4/4:  35%|###4      |\n120/345 [00:58<00:10, 21.70it/s]', '\\rOverwrite epoch 4/4:  36%|###5      |\n123/345 [00:58<00:10, 21.73it/s]', '\\rOverwrite epoch 4/4:  37%|###6      |\n126/345 [00:59<00:10, 21.78it/s]', '\\rOverwrite epoch 4/4:  37%|###7      |\n129/345 [00:59<00:09, 21.78it/s]', '\\rOverwrite epoch 4/4:  38%|###8      |\n132/345 [00:59<00:09, 21.79it/s]', '\\rOverwrite epoch 4/4:  39%|###9      |\n135/345 [00:59<00:09, 21.82it/s]', '\\rOverwrite epoch 4/4:  40%|####      |\n138/345 [00:59<00:09, 21.67it/s]', '\\rOverwrite epoch 4/4:  41%|####      |\n141/345 [00:59<00:09, 21.73it/s]', '\\rOverwrite epoch 4/4:  42%|####1     |\n144/345 [00:59<00:09, 21.78it/s]', '\\rOverwrite epoch 4/4:  43%|####2     |\n147/345 [01:00<00:09, 21.27it/s]', '\\rOverwrite epoch 4/4:  43%|####3     |\n150/345 [01:00<00:09, 21.37it/s]', '\\rOverwrite epoch 4/4:  44%|####4     |\n153/345 [01:00<00:08, 21.41it/s]', '\\rOverwrite epoch 4/4:  45%|####5     |\n156/345 [01:00<00:08, 21.45it/s]', '\\rOverwrite epoch 4/4:  46%|####6     |\n159/345 [01:00<00:08, 21.52it/s]', '\\rOverwrite epoch 4/4:  47%|####6     |\n162/345 [01:00<00:08, 21.58it/s]', '[2025-12-03 19:10:48] Overwrite step 1200:\navg_train_loss=2.8707', '\\n', '\\rOverwrite epoch 4/4:  48%|####7     | 165/345\n[01:00<00:08, 21.62it/s]', '\\rOverwrite epoch 4/4:  49%|####8     | 168/345\n[01:01<00:08, 21.66it/s]', '\\rOverwrite epoch 4/4:  50%|####9     | 171/345\n[01:01<00:08, 21.63it/s]', '\\rOverwrite epoch 4/4:  50%|#####     | 174/345\n[01:01<00:07, 21.63it/s]', '\\rOverwrite epoch 4/4:  51%|#####1    | 177/345\n[01:01<00:07, 21.65it/s]', '\\rOverwrite epoch 4/4:  52%|#####2    | 180/345\n[01:01<00:07, 21.65it/s]', '\\rOverwrite epoch 4/4:  53%|#####3    | 183/345\n[01:01<00:07, 21.66it/s]', '\\rOverwrite epoch 4/4:  54%|#####3    | 186/345\n[01:01<00:07, 21.68it/s]', '\\rOverwrite epoch 4/4:  55%|#####4    | 189/345\n[01:01<00:07, 21.67it/s]', '\\rOverwrite epoch 4/4:  56%|#####5    | 192/345\n[01:02<00:07, 21.70it/s]', '\\rOverwrite epoch 4/4:  57%|#####6    | 195/345\n[01:02<00:06, 21.69it/s]', '\\rOverwrite epoch 4/4:  57%|#####7    | 198/345\n[01:02<00:06, 21.72it/s]', '\\rOverwrite epoch 4/4:  58%|#####8    | 201/345\n[01:02<00:06, 21.71it/s]', '\\rOverwrite epoch 4/4:  59%|#####9    | 204/345\n[01:02<00:06, 21.71it/s]', '\\rOverwrite epoch 4/4:  60%|######    | 207/345\n[01:02<00:06, 21.70it/s]', '\\rOverwrite epoch 4/4:  61%|######    | 210/345\n[01:02<00:06, 21.70it/s]', '\\rOverwrite epoch 4/4:  62%|######1   | 213/345\n[01:03<00:06, 21.69it/s]', '\\rOverwrite epoch 4/4:  63%|######2   | 216/345\n[01:03<00:05, 21.69it/s]', '\\rOverwrite epoch 4/4:  63%|######3   | 219/345\n[01:03<00:05, 21.63it/s]', '\\rOverwrite epoch 4/4:  64%|######4   | 222/345\n[01:03<00:05, 21.64it/s]', '\\rOverwrite epoch 4/4:  65%|######5   | 225/345\n[01:03<00:05, 21.63it/s]', '\\rOverwrite epoch 4/4:  66%|######6   | 228/345\n[01:03<00:05, 21.63it/s]', '\\rOverwrite epoch 4/4:  67%|######6   | 231/345\n[01:03<00:05, 21.64it/s]', '\\rOverwrite epoch 4/4:  68%|######7   | 234/345\n[01:04<00:05, 21.65it/s]', '\\rOverwrite epoch 4/4:  69%|######8   | 237/345\n[01:04<00:04, 21.65it/s]', '\\rOverwrite epoch 4/4:  70%|######9   | 240/345\n[01:04<00:04, 21.56it/s]', '\\rOverwrite epoch 4/4:  70%|#######   | 243/345\n[01:04<00:04, 21.60it/s]', '\\rOverwrite epoch 4/4:  71%|#######1  | 246/345\n[01:04<00:04, 21.23it/s]', '\\rOverwrite epoch 4/4:  72%|#######2  | 249/345\n[01:04<00:04, 21.29it/s]', '\\rOverwrite epoch 4/4:  73%|#######3  | 252/345\n[01:04<00:04, 21.48it/s]', '\\rOverwrite epoch 4/4:  74%|#######3  | 255/345\n[01:05<00:04, 21.65it/s]', '\\rOverwrite epoch 4/4:  75%|#######4  | 258/345\n[01:05<00:03, 21.77it/s]', '\\rOverwrite epoch 4/4:  76%|#######5  | 261/345\n[01:05<00:03, 21.83it/s]', '\\rOverwrite epoch 4/4:  77%|#######6  | 264/345\n[01:05<00:03, 21.86it/s]', '\\rOverwrite epoch 4/4:  77%|#######7  | 267/345\n[01:05<00:03, 21.90it/s]', '\\rOverwrite epoch 4/4:  78%|#######8  | 270/345\n[01:05<00:03, 21.85it/s]', '\\rOverwrite epoch 4/4:  79%|#######9  | 273/345\n[01:05<00:03, 21.86it/s]', '\\rOverwrite epoch 4/4:  80%|########  | 276/345\n[01:05<00:03, 21.85it/s]', '\\rOverwrite epoch 4/4:  81%|########  | 279/345\n[01:06<00:03, 21.76it/s]', '\\rOverwrite epoch 4/4:  82%|########1 | 282/345\n[01:06<00:02, 21.77it/s]', '\\rOverwrite epoch 4/4:  83%|########2 | 285/345\n[01:06<00:02, 21.85it/s]', '\\rOverwrite epoch 4/4:  83%|########3 | 288/345\n[01:06<00:02, 21.91it/s]', '\\rOverwrite epoch 4/4:  84%|########4 | 291/345\n[01:06<00:02, 21.97it/s]', '\\rOverwrite epoch 4/4:  85%|########5 | 294/345\n[01:06<00:02, 21.83it/s]', '\\rOverwrite epoch 4/4:  86%|########6 | 297/345\n[01:06<00:02, 21.81it/s]', '\\rOverwrite epoch 4/4:  87%|########6 | 300/345\n[01:07<00:02, 21.84it/s]', '\\rOverwrite epoch 4/4:  88%|########7 | 303/345\n[01:07<00:01, 21.85it/s]', '\\rOverwrite epoch 4/4:  89%|########8 | 306/345\n[01:07<00:01, 21.85it/s]', '\\rOverwrite epoch 4/4:  90%|########9 | 309/345\n[01:07<00:01, 21.87it/s]', '\\rOverwrite epoch 4/4:  90%|######### | 312/345\n[01:07<00:01, 21.85it/s]', '\\rOverwrite epoch 4/4:  91%|#########1| 315/345\n[01:07<00:01, 21.84it/s]', '\\rOverwrite epoch 4/4:  92%|#########2| 318/345\n[01:07<00:01, 21.89it/s]', '\\rOverwrite epoch 4/4:  93%|#########3| 321/345\n[01:08<00:01, 21.93it/s]', '\\rOverwrite epoch 4/4:  94%|#########3| 324/345\n[01:08<00:00, 21.96it/s]', '\\rOverwrite epoch 4/4:  95%|#########4| 327/345\n[01:08<00:00, 21.87it/s]', '\\rOverwrite epoch 4/4:  96%|#########5| 330/345\n[01:08<00:00, 21.82it/s]', '\\rOverwrite epoch 4/4:  97%|#########6| 333/345\n[01:08<00:00, 21.80it/s]', '\\rOverwrite epoch 4/4:  97%|#########7| 336/345\n[01:08<00:00, 21.79it/s]', '\\rOverwrite epoch 4/4:  98%|#########8| 339/345\n[01:08<00:00, 21.70it/s]', '\\rOverwrite epoch 4/4:  99%|#########9| 342/345\n[01:09<00:00, 21.31it/s]', '\\rOverwrite epoch 4/4: 100%|##########| 345/345\n[01:09<00:00, 22.29it/s]', '', '\\rOverwrite epoch 4/4: 100%|##########| 345/345\n[01:10<00:00,  4.91it/s]', '\\n', 'Epoch 4: validation_loss = 3.7202', '\\n',\n'Experiment complete. Artifacts saved to:', ' ', '/workspace/AE-\nScientist/research_pipeline/workspaces/0-run/process_SpawnProcess-3/working',\n'\\n', 'Execution time: 11 minutes seconds (time limit is 2 hours).']", "['Using device: cuda:0', '\\n', 'Added 5 rare tokens to tokenizer.', '\\n',\n\"Controls: [' apple', ' table', ' water', ' green', ' house']\", '\\n', '\\rMap:\n0%|          | 0/11015 [00:00<?, ? examples/s]', '\\rMap:  18%|#8        |\n2000/11015 [00:00<00:00, 17056.12 examples/s]', '\\rMap:  54%|#####4    |\n6000/11015 [00:00<00:00, 20160.98 examples/s]', '\\rMap:  73%|#######2  |\n8000/11015 [00:00<00:00, 20023.59 examples/s]', '\\rMap:  91%|######### |\n10000/11015 [00:00<00:00, 19552.40 examples/s]', '', '\\rMap: 100%|##########|\n11015/11015 [00:00<00:00, 18353.79 examples/s]', '\\n', '\\n===== Starting\ncondition: natlang =====', '\\n', '\\rMap:   0%|          | 0/2000 [00:00<?, ?\nexamples/s]', '', '\\rMap: 100%|##########| 2000/2000 [00:00<00:00, 29889.93\nexamples/s]', '\\n', '\\rMap:   0%|          | 0/300 [00:00<?, ? examples/s]', '',\n'\\rMap: 100%|##########| 300/300 [00:00<00:00, 24479.42 examples/s]', '\\n',\n'\\rTraining natlang_phase1 epoch 1/1:   0%|          | 0/21 [00:00<?, ?it/s]',\n'\\rTraining natlang_phase1 epoch 1/1:   5%|4         | 1/21 [01:01<20:20,\n61.02s/it]', '\\rTraining natlang_phase1 epoch 1/1:  10%|9         | 2/21\n[01:01<07:58, 25.20s/it]', '\\rTraining natlang_phase1 epoch 1/1:  14%|#4\n| 3/21 [01:01<04:07, 13.74s/it]', '\\rTraining natlang_phase1 epoch 1/1:  19%|#9\n| 4/21 [01:01<02:22,  8.36s/it]', '\\rTraining natlang_phase1 epoch 1/1:  24%|##3\n| 5/21 [01:01<01:26,  5.39s/it]', '\\rTraining natlang_phase1 epoch 1/1:  29%|##8\n| 6/21 [01:01<00:53,  3.60s/it]', '\\rTraining natlang_phase1 epoch 1/1:\n33%|###3      | 7/21 [01:01<00:34,  2.46s/it]', '\\rTraining natlang_phase1 epoch\n1/1:  38%|###8      | 8/21 [01:01<00:22,  1.71s/it]', '\\rTraining natlang_phase1\nepoch 1/1:  43%|####2     | 9/21 [01:01<00:14,  1.21s/it]', '\\rTraining\nnatlang_phase1 epoch 1/1:  48%|####7     | 10/21 [01:02<00:09,  1.14it/s]',\n'\\rTraining natlang_phase1 epoch 1/1:  52%|#####2    | 11/21 [01:02<00:06,\n1.56it/s]', '\\rTraining natlang_phase1 epoch 1/1:  57%|#####7    | 12/21\n[01:02<00:04,  2.08it/s]', '\\rTraining natlang_phase1 epoch 1/1:  62%|######1\n| 13/21 [01:02<00:02,  2.70it/s]', '\\rTraining natlang_phase1 epoch 1/1:\n67%|######6   | 14/21 [01:02<00:02,  3.40it/s]', '\\rTraining natlang_phase1\nepoch 1/1:  71%|#######1  | 15/21 [01:02<00:01,  4.17it/s]', '\\rTraining\nnatlang_phase1 epoch 1/1:  76%|#######6  | 16/21 [01:02<00:01,  4.94it/s]',\n'\\rTraining natlang_phase1 epoch 1/1:  81%|########  | 17/21 [01:02<00:00,\n5.67it/s]', '\\rTraining natlang_phase1 epoch 1/1:  86%|########5 | 18/21\n[01:02<00:00,  6.33it/s]', '\\rTraining natlang_phase1 epoch 1/1:  90%|#########\n| 19/21 [01:03<00:00,  6.89it/s]', '\\rTraining natlang_phase1 epoch 1/1:\n95%|#########5| 20/21 [01:03<00:00,  7.33it/s]', '', '\\rTraining natlang_phase1\nepoch 1/1: 100%|##########| 21/21 [01:04<00:00,  3.06s/it]', '\\n', 'Epoch 1:\nvalidation_loss = 3.2644', '\\n', '\\rOverwrite (natlang) epoch 1/4:   0%|\n| 0/345 [00:00<?, ?it/s]', '\\rOverwrite (natlang) epoch 1/4:   0%|          |\n1/345 [00:51<4:53:24, 51.17s/it]', '\\rOverwrite (natlang) epoch 1/4:   1%|\n| 3/345 [00:51<1:15:51, 13.31s/it]', '\\rOverwrite (natlang) epoch 1/4:   2%|1\n| 6/345 [00:51<29:13,  5.17s/it]  ', '\\rOverwrite (natlang) epoch 1/4:   3%|2\n| 9/345 [00:51<15:33,  2.78s/it]', '\\rOverwrite (natlang) epoch 1/4:   3%|3\n| 12/345 [00:51<09:21,  1.69s/it]', '\\rOverwrite (natlang) epoch 1/4:   4%|4\n| 15/345 [00:51<05:59,  1.09s/it]', '\\rOverwrite (natlang) epoch 1/4:   5%|5\n| 18/345 [00:51<03:59,  1.37it/s]', '\\rOverwrite (natlang) epoch 1/4:   6%|6\n| 21/345 [00:52<02:44,  1.97it/s]', '\\rOverwrite (natlang) epoch 1/4:   7%|6\n| 24/345 [00:52<01:55,  2.78it/s]', '\\rOverwrite (natlang) epoch 1/4:   8%|7\n| 27/345 [00:52<01:23,  3.83it/s]', '\\rOverwrite (natlang) epoch 1/4:   9%|8\n| 30/345 [00:52<01:01,  5.13it/s]', '\\rOverwrite (natlang) epoch 1/4:  10%|9\n| 33/345 [00:52<00:46,  6.69it/s]', '\\rOverwrite (natlang) epoch 1/4:  10%|#\n| 36/345 [00:52<00:36,  8.45it/s]', '\\rOverwrite (natlang) epoch 1/4:  11%|#1\n| 39/345 [00:52<00:29, 10.36it/s]', '\\rOverwrite (natlang) epoch 1/4:  12%|#2\n| 42/345 [00:53<00:24, 12.28it/s]', '\\rOverwrite (natlang) epoch 1/4:  13%|#3\n| 45/345 [00:53<00:21, 14.14it/s]', '\\rOverwrite (natlang) epoch 1/4:  14%|#3\n| 48/345 [00:53<00:18, 15.83it/s]', '\\rOverwrite (natlang) epoch 1/4:  15%|#4\n| 51/345 [00:53<00:17, 17.27it/s]', '\\rOverwrite (natlang) epoch 1/4:  16%|#5\n| 54/345 [00:53<00:15, 18.43it/s]', '\\rOverwrite (natlang) epoch 1/4:  17%|#6\n| 57/345 [00:53<00:14, 19.36it/s]', '\\rOverwrite (natlang) epoch 1/4:  17%|#7\n| 60/345 [00:53<00:14, 19.83it/s]', '\\rOverwrite (natlang) epoch 1/4:  18%|#8\n| 63/345 [00:54<00:13, 20.19it/s]', '\\rOverwrite (natlang) epoch 1/4:  19%|#9\n| 66/345 [00:54<00:13, 20.66it/s]', '\\rOverwrite (natlang) epoch 1/4:  20%|##\n| 69/345 [00:54<00:13, 20.99it/s]', '\\rOverwrite (natlang) epoch 1/4:  21%|##\n| 72/345 [00:54<00:12, 21.25it/s]', '\\rOverwrite (natlang) epoch 1/4:  22%|##1\n| 75/345 [00:54<00:12, 21.42it/s]', '\\rOverwrite (natlang) epoch 1/4:  23%|##2\n| 78/345 [00:54<00:12, 21.45it/s]', '\\rOverwrite (natlang) epoch 1/4:  23%|##3\n| 81/345 [00:54<00:12, 21.42it/s]', '\\rOverwrite (natlang) epoch 1/4:  24%|##4\n| 84/345 [00:55<00:12, 21.26it/s]', '\\rOverwrite (natlang) epoch 1/4:  25%|##5\n| 87/345 [00:55<00:12, 21.45it/s]', '\\rOverwrite (natlang) epoch 1/4:  26%|##6\n| 90/345 [00:55<00:11, 21.58it/s]', '\\rOverwrite (natlang) epoch 1/4:  27%|##6\n| 93/345 [00:55<00:11, 21.68it/s]', '\\rOverwrite (natlang) epoch 1/4:  28%|##7\n| 96/345 [00:55<00:11, 21.74it/s]', '\\rOverwrite (natlang) epoch 1/4:  29%|##8\n| 99/345 [00:55<00:11, 21.78it/s]', '\\rOverwrite (natlang) epoch 1/4:  30%|##9\n| 102/345 [00:55<00:11, 21.76it/s]', '\\rOverwrite (natlang) epoch 1/4:  30%|###\n| 105/345 [00:55<00:11, 21.80it/s]', '\\rOverwrite (natlang) epoch 1/4:  31%|###1\n| 108/345 [00:56<00:10, 21.82it/s]', '\\rOverwrite (natlang) epoch 1/4:  32%|###2\n| 111/345 [00:56<00:10, 21.79it/s]', '\\rOverwrite (natlang) epoch 1/4:  33%|###3\n| 114/345 [00:56<00:10, 21.77it/s]', '\\rOverwrite (natlang) epoch 1/4:  34%|###3\n| 117/345 [00:56<00:10, 21.74it/s]', '\\rOverwrite (natlang) epoch 1/4:  35%|###4\n| 120/345 [00:56<00:10, 21.72it/s]', '\\rOverwrite (natlang) epoch 1/4:  36%|###5\n| 123/345 [00:56<00:10, 21.67it/s]', '\\rOverwrite (natlang) epoch 1/4:  37%|###6\n| 126/345 [00:56<00:10, 21.61it/s]', '\\rOverwrite (natlang) epoch 1/4:  37%|###7\n| 129/345 [00:57<00:10, 21.58it/s]', '\\rOverwrite (natlang) epoch 1/4:  38%|###8\n| 132/345 [00:57<00:09, 21.58it/s]', '\\rOverwrite (natlang) epoch 1/4:  39%|###9\n| 135/345 [00:57<00:09, 21.60it/s]', '\\rOverwrite (natlang) epoch 1/4:  40%|####\n| 138/345 [00:57<00:09, 21.56it/s]', '\\rOverwrite (natlang) epoch 1/4:  41%|####\n| 141/345 [00:57<00:09, 21.45it/s]', '\\rOverwrite (natlang) epoch 1/4:\n42%|####1     | 144/345 [00:57<00:09, 21.60it/s]', '\\rOverwrite (natlang) epoch\n1/4:  43%|####2     | 147/345 [00:57<00:09, 21.68it/s]', '\\rOverwrite (natlang)\nepoch 1/4:  43%|####3     | 150/345 [00:58<00:08, 21.74it/s]', '\\rOverwrite\n(natlang) epoch 1/4:  44%|####4     | 153/345 [00:58<00:08, 21.80it/s]',\n'\\rOverwrite (natlang) epoch 1/4:  45%|####5     | 156/345 [00:58<00:08,\n21.83it/s]', '\\rOverwrite (natlang) epoch 1/4:  46%|####6     | 159/345\n[00:58<00:08, 21.86it/s]', '\\rOverwrite (natlang) epoch 1/4:  47%|####6     |\n162/345 [00:58<00:08, 21.86it/s]', '\\rOverwrite (natlang) epoch 1/4:  48%|####7\n| 165/345 [00:58<00:08, 21.87it/s]', '\\rOverwrite (natlang) epoch 1/4:\n49%|####8     | 168/345 [00:58<00:08, 21.87it/s]', '\\rOverwrite (natlang) epoch\n1/4:  50%|####9     | 171/345 [00:59<00:07, 21.88it/s]', '\\rOverwrite (natlang)\nepoch 1/4:  50%|#####     | 174/345 [00:59<00:07, 21.62it/s]', '\\rOverwrite\n(natlang) epoch 1/4:  51%|#####1    | 177/345 [00:59<00:07, 21.49it/s]',\n'\\rOverwrite (natlang) epoch 1/4:  52%|#####2    | 180/345 [00:59<00:07,\n21.15it/s]', '\\rOverwrite (natlang) epoch 1/4:  53%|#####3    | 183/345\n[00:59<00:07, 21.29it/s]', '\\rOverwrite (natlang) epoch 1/4:  54%|#####3    |\n186/345 [00:59<00:07, 21.34it/s]', '\\rOverwrite (natlang) epoch 1/4:  55%|#####4\n| 189/345 [00:59<00:07, 21.31it/s]', '\\rOverwrite (natlang) epoch 1/4:\n56%|#####5    | 192/345 [01:00<00:07, 21.39it/s]', '\\rOverwrite (natlang) epoch\n1/4:  57%|#####6    | 195/345 [01:00<00:07, 21.16it/s]', '\\rOverwrite (natlang)\nepoch 1/4:  57%|#####7    | 198/345 [01:00<00:06, 21.09it/s]', '[2025-12-03\n22:05:36] Overwrite (natlang) step 200: avg_train_loss=3.8526', '\\n',\n'\\rOverwrite (natlang) epoch 1/4:  58%|#####8    | 201/345 [01:00<00:06,\n21.09it/s]', '\\rOverwrite (natlang) epoch 1/4:  59%|#####9    | 204/345\n[01:00<00:06, 21.10it/s]', '\\rOverwrite (natlang) epoch 1/4:  60%|######    |\n207/345 [01:00<00:06, 21.07it/s]', '\\rOverwrite (natlang) epoch 1/4:  61%|######\n| 210/345 [01:00<00:06, 21.15it/s]', '\\rOverwrite (natlang) epoch 1/4:\n62%|######1   | 213/345 [01:01<00:06, 20.94it/s]', '\\rOverwrite (natlang) epoch\n1/4:  63%|######2   | 216/345 [01:01<00:06, 20.93it/s]', '\\rOverwrite (natlang)\nepoch 1/4:  63%|######3   | 219/345 [01:01<00:06, 20.96it/s]', '\\rOverwrite\n(natlang) epoch 1/4:  64%|######4   | 222/345 [01:01<00:05, 20.98it/s]',\n'\\rOverwrite (natlang) epoch 1/4:  65%|######5   | 225/345 [01:01<00:05,\n21.09it/s]', '\\rOverwrite (natlang) epoch 1/4:  66%|######6   | 228/345\n[01:01<00:05, 20.98it/s]', '\\rOverwrite (natlang) epoch 1/4:  67%|######6   |\n231/345 [01:01<00:05, 21.11it/s]', '\\rOverwrite (natlang) epoch 1/4:\n68%|######7   | 234/345 [01:02<00:05, 20.90it/s]', '\\rOverwrite (natlang) epoch\n1/4:  69%|######8   | 237/345 [01:02<00:05, 20.91it/s]', '\\rOverwrite (natlang)\nepoch 1/4:  70%|######9   | 240/345 [01:02<00:05, 20.91it/s]', '\\rOverwrite\n(natlang) epoch 1/4:  70%|#######   | 243/345 [01:02<00:04, 20.65it/s]',\n'\\rOverwrite (natlang) epoch 1/4:  71%|#######1  | 246/345 [01:02<00:04,\n20.81it/s]', '\\rOverwrite (natlang) epoch 1/4:  72%|#######2  | 249/345\n[01:02<00:04, 20.92it/s]', '\\rOverwrite (natlang) epoch 1/4:  73%|#######3  |\n252/345 [01:02<00:04, 21.10it/s]', '\\rOverwrite (natlang) epoch 1/4:\n74%|#######3  | 255/345 [01:03<00:04, 21.17it/s]', '\\rOverwrite (natlang) epoch\n1/4:  75%|#######4  | 258/345 [01:03<00:04, 21.05it/s]', '\\rOverwrite (natlang)\nepoch 1/4:  76%|#######5  | 261/345 [01:03<00:04, 20.84it/s]', '\\rOverwrite\n(natlang) epoch 1/4:  77%|#######6  | 264/345 [01:03<00:03, 20.97it/s]',\n'\\rOverwrite (natlang) epoch 1/4:  77%|#######7  | 267/345 [01:03<00:03,\n21.14it/s]', '\\rOverwrite (natlang) epoch 1/4:  78%|#######8  | 270/345\n[01:03<00:03, 21.19it/s]', '\\rOverwrite (natlang) epoch 1/4:  79%|#######9  |\n273/345 [01:03<00:03, 21.24it/s]', '\\rOverwrite (natlang) epoch 1/4:\n80%|########  | 276/345 [01:04<00:03, 21.36it/s]', '\\rOverwrite (natlang) epoch\n1/4:  81%|########  | 279/345 [01:04<00:03, 20.95it/s]', '\\rOverwrite (natlang)\nepoch 1/4:  82%|########1 | 282/345 [01:04<00:02, 21.17it/s]', '\\rOverwrite\n(natlang) epoch 1/4:  83%|########2 | 285/345 [01:04<00:02, 21.05it/s]',\n'\\rOverwrite (natlang) epoch 1/4:  83%|########3 | 288/345 [01:04<00:02,\n21.21it/s]', '\\rOverwrite (natlang) epoch 1/4:  84%|########4 | 291/345\n[01:04<00:02, 21.35it/s]', '\\rOverwrite (natlang) epoch 1/4:  85%|########5 |\n294/345 [01:04<00:02, 21.23it/s]', '\\rOverwrite (natlang) epoch 1/4:\n86%|########6 | 297/345 [01:05<00:02, 21.02it/s]', '\\rOverwrite (natlang) epoch\n1/4:  87%|########6 | 300/345 [01:05<00:02, 20.71it/s]', '\\rOverwrite (natlang)\nepoch 1/4:  88%|########7 | 303/345 [01:05<00:02, 20.78it/s]', '\\rOverwrite\n(natlang) epoch 1/4:  89%|########8 | 306/345 [01:05<00:01, 20.96it/s]',\n'\\rOverwrite (natlang) epoch 1/4:  90%|########9 | 309/345 [01:05<00:01,\n21.02it/s]', '\\rOverwrite (natlang) epoch 1/4:  90%|######### | 312/345\n[01:05<00:01, 21.19it/s]', '\\rOverwrite (natlang) epoch 1/4:  91%|#########1|\n315/345 [01:05<00:01, 21.23it/s]', '\\rOverwrite (natlang) epoch 1/4:\n92%|#########2| 318/345 [01:06<00:01, 21.35it/s]', '\\rOverwrite (natlang) epoch\n1/4:  93%|#########3| 321/345 [01:06<00:01, 21.45it/s]', '\\rOverwrite (natlang)\nepoch 1/4:  94%|#########3| 324/345 [01:06<00:00, 21.50it/s]', '\\rOverwrite\n(natlang) epoch 1/4:  95%|#########4| 327/345 [01:06<00:00, 21.41it/s]',\n'\\rOverwrite (natlang) epoch 1/4:  96%|#########5| 330/345 [01:06<00:00,\n21.41it/s]', '\\rOverwrite (natlang) epoch 1/4:  97%|#########6| 333/345\n[01:06<00:00, 21.49it/s]', '\\rOverwrite (natlang) epoch 1/4:  97%|#########7|\n336/345 [01:06<00:00, 21.45it/s]', '\\rOverwrite (natlang) epoch 1/4:\n98%|#########8| 339/345 [01:06<00:00, 21.14it/s]', '\\rOverwrite (natlang) epoch\n1/4:  99%|#########9| 342/345 [01:07<00:00, 21.29it/s]', '\\rOverwrite (natlang)\nepoch 1/4: 100%|##########| 345/345 [01:07<00:00, 22.20it/s]', '', '\\rOverwrite\n(natlang) epoch 1/4: 100%|##########| 345/345 [01:08<00:00,  5.06it/s]', '\\n',\n'Epoch 1 (natlang): validation_loss = 3.6204', '\\n', '\\rOverwrite (natlang)\nepoch 2/4:   0%|          | 0/345 [00:00<?, ?it/s]', '\\rOverwrite (natlang)\nepoch 2/4:   0%|          | 1/345 [00:51<4:55:29, 51.54s/it]', '\\rOverwrite\n(natlang) epoch 2/4:   1%|          | 3/345 [00:51<1:16:27, 13.41s/it]',\n'\\rOverwrite (natlang) epoch 2/4:   2%|1         | 6/345 [00:51<29:27,\n5.21s/it]  ', '\\rOverwrite (natlang) epoch 2/4:   3%|2         | 9/345\n[00:51<15:40,  2.80s/it]', '\\rOverwrite (natlang) epoch 2/4:   3%|3         |\n12/345 [00:52<09:25,  1.70s/it]', '\\rOverwrite (natlang) epoch 2/4:   4%|4\n| 15/345 [00:52<06:02,  1.10s/it]', '\\rOverwrite (natlang) epoch 2/4:   5%|5\n| 18/345 [00:52<04:01,  1.35it/s]', '\\rOverwrite (natlang) epoch 2/4:   6%|6\n| 21/345 [00:52<02:45,  1.96it/s]', '\\rOverwrite (natlang) epoch 2/4:   7%|6\n| 24/345 [00:52<01:56,  2.75it/s]', '\\rOverwrite (natlang) epoch 2/4:   8%|7\n| 27/345 [00:52<01:23,  3.79it/s]', '\\rOverwrite (natlang) epoch 2/4:   9%|8\n| 30/345 [00:52<01:02,  5.07it/s]', '\\rOverwrite (natlang) epoch 2/4:  10%|9\n| 33/345 [00:53<00:47,  6.59it/s]', '\\rOverwrite (natlang) epoch 2/4:  10%|#\n| 36/345 [00:53<00:36,  8.37it/s]', '\\rOverwrite (natlang) epoch 2/4:  11%|#1\n| 39/345 [00:53<00:29, 10.29it/s]', '\\rOverwrite (natlang) epoch 2/4:  12%|#2\n| 42/345 [00:53<00:24, 12.24it/s]', '\\rOverwrite (natlang) epoch 2/4:  13%|#3\n| 45/345 [00:53<00:21, 14.05it/s]', '\\rOverwrite (natlang) epoch 2/4:  14%|#3\n| 48/345 [00:53<00:19, 15.55it/s]', '\\rOverwrite (natlang) epoch 2/4:  15%|#4\n| 51/345 [00:53<00:17, 16.93it/s]', '\\rOverwrite (natlang) epoch 2/4:  16%|#5\n| 54/345 [00:54<00:16, 17.93it/s]', '[2025-12-03 22:07:32] Overwrite (natlang)\nstep 400: avg_train_loss=3.3586', '\\n', '\\rOverwrite (natlang) epoch 2/4:\n17%|#6        | 57/345 [00:54<00:15, 18.78it/s]', '\\rOverwrite (natlang) epoch\n2/4:  17%|#7        | 60/345 [00:54<00:14, 19.53it/s]', '\\rOverwrite (natlang)\nepoch 2/4:  18%|#8        | 63/345 [00:54<00:14, 19.98it/s]', '\\rOverwrite\n(natlang) epoch 2/4:  19%|#9        | 66/345 [00:54<00:13, 20.25it/s]',\n'\\rOverwrite (natlang) epoch 2/4:  20%|##        | 69/345 [00:54<00:13,\n20.40it/s]', '\\rOverwrite (natlang) epoch 2/4:  21%|##        | 72/345\n[00:54<00:13, 20.70it/s]', '\\rOverwrite (natlang) epoch 2/4:  22%|##1       |\n75/345 [00:55<00:12, 20.96it/s]', '\\rOverwrite (natlang) epoch 2/4:  23%|##2\n| 78/345 [00:55<00:12, 21.15it/s]', '\\rOverwrite (natlang) epoch 2/4:  23%|##3\n| 81/345 [00:55<00:12, 21.25it/s]', '\\rOverwrite (natlang) epoch 2/4:  24%|##4\n| 84/345 [00:55<00:12, 21.29it/s]', '\\rOverwrite (natlang) epoch 2/4:  25%|##5\n| 87/345 [00:55<00:12, 21.39it/s]', '\\rOverwrite (natlang) epoch 2/4:  26%|##6\n| 90/345 [00:55<00:11, 21.48it/s]', '\\rOverwrite (natlang) epoch 2/4:  27%|##6\n| 93/345 [00:55<00:11, 21.50it/s]', '\\rOverwrite (natlang) epoch 2/4:  28%|##7\n| 96/345 [00:56<00:11, 21.29it/s]', '\\rOverwrite (natlang) epoch 2/4:  29%|##8\n| 99/345 [00:56<00:11, 21.06it/s]', '\\rOverwrite (natlang) epoch 2/4:  30%|##9\n| 102/345 [00:56<00:11, 21.23it/s]', '\\rOverwrite (natlang) epoch 2/4:  30%|###\n| 105/345 [00:56<00:11, 21.42it/s]', '\\rOverwrite (natlang) epoch 2/4:  31%|###1\n| 108/345 [00:56<00:10, 21.55it/s]', '\\rOverwrite (natlang) epoch 2/4:  32%|###2\n| 111/345 [00:56<00:10, 21.62it/s]', '\\rOverwrite (natlang) epoch 2/4:  33%|###3\n| 114/345 [00:56<00:10, 21.59it/s]', '\\rOverwrite (natlang) epoch 2/4:  34%|###3\n| 117/345 [00:57<00:10, 21.64it/s]', '\\rOverwrite (natlang) epoch 2/4:  35%|###4\n| 120/345 [00:57<00:10, 21.67it/s]', '\\rOverwrite (natlang) epoch 2/4:  36%|###5\n| 123/345 [00:57<00:10, 21.66it/s]', '\\rOverwrite (natlang) epoch 2/4:  37%|###6\n| 126/345 [00:57<00:10, 21.48it/s]', '\\rOverwrite (natlang) epoch 2/4:  37%|###7\n| 129/345 [00:57<00:10, 21.54it/s]', '\\rOverwrite (natlang) epoch 2/4:  38%|###8\n| 132/345 [00:57<00:10, 21.24it/s]', '\\rOverwrite (natlang) epoch 2/4:  39%|###9\n| 135/345 [00:57<00:09, 21.38it/s]', '\\rOverwrite (natlang) epoch 2/4:  40%|####\n| 138/345 [00:58<00:09, 21.12it/s]', '\\rOverwrite (natlang) epoch 2/4:  41%|####\n| 141/345 [00:58<00:09, 21.20it/s]', '\\rOverwrite (natlang) epoch 2/4:\n42%|####1     | 144/345 [00:58<00:09, 20.86it/s]', '\\rOverwrite (natlang) epoch\n2/4:  43%|####2     | 147/345 [00:58<00:09, 20.99it/s]', '\\rOverwrite (natlang)\nepoch 2/4:  43%|####3     | 150/345 [00:58<00:09, 21.01it/s]', '\\rOverwrite\n(natlang) epoch 2/4:  44%|####4     | 153/345 [00:58<00:09, 21.22it/s]',\n'\\rOverwrite (natlang) epoch 2/4:  45%|####5     | 156/345 [00:58<00:08,\n21.38it/s]', '\\rOverwrite (natlang) epoch 2/4:  46%|####6     | 159/345\n[00:58<00:08, 21.37it/s]', '\\rOverwrite (natlang) epoch 2/4:  47%|####6     |\n162/345 [00:59<00:08, 21.42it/s]', '\\rOverwrite (natlang) epoch 2/4:  48%|####7\n| 165/345 [00:59<00:08, 21.50it/s]', '\\rOverwrite (natlang) epoch 2/4:\n49%|####8     | 168/345 [00:59<00:08, 21.51it/s]', '\\rOverwrite (natlang) epoch\n2/4:  50%|####9     | 171/345 [00:59<00:08, 20.94it/s]', '\\rOverwrite (natlang)\nepoch 2/4:  50%|#####     | 174/345 [00:59<00:08, 21.15it/s]', '\\rOverwrite\n(natlang) epoch 2/4:  51%|#####1    | 177/345 [00:59<00:07, 21.23it/s]',\n'\\rOverwrite (natlang) epoch 2/4:  52%|#####2    | 180/345 [00:59<00:07,\n21.11it/s]', '\\rOverwrite (natlang) epoch 2/4:  53%|#####3    | 183/345\n[01:00<00:07, 21.29it/s]', '\\rOverwrite (natlang) epoch 2/4:  54%|#####3    |\n186/345 [01:00<00:07, 21.37it/s]', '\\rOverwrite (natlang) epoch 2/4:  55%|#####4\n| 189/345 [01:00<00:07, 21.33it/s]', '\\rOverwrite (natlang) epoch 2/4:\n56%|#####5    | 192/345 [01:00<00:07, 21.41it/s]', '\\rOverwrite (natlang) epoch\n2/4:  57%|#####6    | 195/345 [01:00<00:07, 21.04it/s]', '\\rOverwrite (natlang)\nepoch 2/4:  57%|#####7    | 198/345 [01:00<00:06, 21.23it/s]', '\\rOverwrite\n(natlang) epoch 2/4:  58%|#####8    | 201/345 [01:00<00:06, 21.38it/s]',\n'\\rOverwrite (natlang) epoch 2/4:  59%|#####9    | 204/345 [01:01<00:06,\n21.45it/s]', '\\rOverwrite (natlang) epoch 2/4:  60%|######    | 207/345\n[01:01<00:06, 21.55it/s]', '\\rOverwrite (natlang) epoch 2/4:  61%|######    |\n210/345 [01:01<00:06, 21.33it/s]', '\\rOverwrite (natlang) epoch 2/4:\n62%|######1   | 213/345 [01:01<00:06, 21.41it/s]', '\\rOverwrite (natlang) epoch\n2/4:  63%|######2   | 216/345 [01:01<00:06, 21.22it/s]', '\\rOverwrite (natlang)\nepoch 2/4:  63%|######3   | 219/345 [01:01<00:05, 21.26it/s]', '\\rOverwrite\n(natlang) epoch 2/4:  64%|######4   | 222/345 [01:01<00:05, 21.21it/s]',\n'\\rOverwrite (natlang) epoch 2/4:  65%|######5   | 225/345 [01:02<00:05,\n20.56it/s]', '\\rOverwrite (natlang) epoch 2/4:  66%|######6   | 228/345\n[01:02<00:05, 20.85it/s]', '\\rOverwrite (natlang) epoch 2/4:  67%|######6   |\n231/345 [01:02<00:05, 20.69it/s]', '\\rOverwrite (natlang) epoch 2/4:\n68%|######7   | 234/345 [01:02<00:05, 20.44it/s]', '\\rOverwrite (natlang) epoch\n2/4:  69%|######8   | 237/345 [01:02<00:05, 20.44it/s]', '\\rOverwrite (natlang)\nepoch 2/4:  70%|######9   | 240/345 [01:02<00:05, 20.46it/s]', '\\rOverwrite\n(natlang) epoch 2/4:  70%|#######   | 243/345 [01:02<00:05, 20.33it/s]',\n'\\rOverwrite (natlang) epoch 2/4:  71%|#######1  | 246/345 [01:03<00:04,\n20.32it/s]', '\\rOverwrite (natlang) epoch 2/4:  72%|#######2  | 249/345\n[01:03<00:04, 20.01it/s]', '\\rOverwrite (natlang) epoch 2/4:  73%|#######3  |\n252/345 [01:03<00:04, 20.15it/s]', '[2025-12-03 22:07:42] Overwrite (natlang)\nstep 600: avg_train_loss=3.3239', '\\n', '\\rOverwrite (natlang) epoch 2/4:\n74%|#######3  | 255/345 [01:03<00:04, 20.05it/s]', '\\rOverwrite (natlang) epoch\n2/4:  75%|#######4  | 258/345 [01:03<00:04, 20.08it/s]', '\\rOverwrite (natlang)\nepoch 2/4:  76%|#######5  | 261/345 [01:03<00:04, 20.25it/s]', '\\rOverwrite\n(natlang) epoch 2/4:  77%|#######6  | 264/345 [01:04<00:03, 20.44it/s]',\n'\\rOverwrite (natlang) epoch 2/4:  77%|#######7  | 267/345 [01:04<00:03,\n20.66it/s]', '\\rOverwrite (natlang) epoch 2/4:  78%|#######8  | 270/345\n[01:04<00:03, 20.96it/s]', '\\rOverwrite (natlang) epoch 2/4:  79%|#######9  |\n273/345 [01:04<00:03, 21.14it/s]', '\\rOverwrite (natlang) epoch 2/4:\n80%|########  | 276/345 [01:04<00:03, 20.76it/s]', '\\rOverwrite (natlang) epoch\n2/4:  81%|########  | 279/345 [01:04<00:03, 20.83it/s]', '\\rOverwrite (natlang)\nepoch 2/4:  82%|########1 | 282/345 [01:04<00:02, 21.07it/s]', '\\rOverwrite\n(natlang) epoch 2/4:  83%|########2 | 285/345 [01:05<00:02, 20.56it/s]',\n'\\rOverwrite (natlang) epoch 2/4:  83%|########3 | 288/345 [01:05<00:02,\n20.83it/s]', '\\rOverwrite (natlang) epoch 2/4:  84%|########4 | 291/345\n[01:05<00:02, 21.08it/s]', '\\rOverwrite (natlang) epoch 2/4:  85%|########5 |\n294/345 [01:05<00:02, 21.26it/s]', '\\rOverwrite (natlang) epoch 2/4:\n86%|########6 | 297/345 [01:05<00:02, 20.90it/s]', '\\rOverwrite (natlang) epoch\n2/4:  87%|########6 | 300/345 [01:05<00:02, 20.96it/s]', '\\rOverwrite (natlang)\nepoch 2/4:  88%|########7 | 303/345 [01:05<00:02, 20.22it/s]', '\\rOverwrite\n(natlang) epoch 2/4:  89%|########8 | 306/345 [01:06<00:01, 20.24it/s]',\n'\\rOverwrite (natlang) epoch 2/4:  90%|########9 | 309/345 [01:06<00:01,\n20.07it/s]', '\\rOverwrite (natlang) epoch 2/4:  90%|######### | 312/345\n[01:06<00:01, 20.24it/s]', '\\rOverwrite (natlang) epoch 2/4:  91%|#########1|\n315/345 [01:06<00:01, 20.04it/s]', '\\rOverwrite (natlang) epoch 2/4:\n92%|#########2| 318/345 [01:06<00:01, 20.14it/s]', '\\rOverwrite (natlang) epoch\n2/4:  93%|#########3| 321/345 [01:06<00:01, 20.22it/s]', '\\rOverwrite (natlang)\nepoch 2/4:  94%|#########3| 324/345 [01:06<00:01, 20.27it/s]', '\\rOverwrite\n(natlang) epoch 2/4:  95%|#########4| 327/345 [01:07<00:00, 20.16it/s]',\n'\\rOverwrite (natlang) epoch 2/4:  96%|#########5| 330/345 [01:07<00:00,\n20.32it/s]', '\\rOverwrite (natlang) epoch 2/4:  97%|#########6| 333/345\n[01:07<00:00, 20.31it/s]', '\\rOverwrite (natlang) epoch 2/4:  97%|#########7|\n336/345 [01:07<00:00, 20.33it/s]', '\\rOverwrite (natlang) epoch 2/4:\n98%|#########8| 339/345 [01:07<00:00, 20.63it/s]', '\\rOverwrite (natlang) epoch\n2/4:  99%|#########9| 342/345 [01:07<00:00, 20.78it/s]', '\\rOverwrite (natlang)\nepoch 2/4: 100%|##########| 345/345 [01:07<00:00, 21.98it/s]', '', '\\rOverwrite\n(natlang) epoch 2/4: 100%|##########| 345/345 [01:08<00:00,  5.01it/s]', '\\n',\n'Epoch 2 (natlang): validation_loss = 3.6365', '\\n', '\\rOverwrite (natlang)\nepoch 3/4:   0%|          | 0/345 [00:00<?, ?it/s]', '\\rOverwrite (natlang)\nepoch 3/4:   0%|          | 1/345 [00:49<4:44:31, 49.63s/it]', '\\rOverwrite\n(natlang) epoch 3/4:   1%|          | 3/345 [00:49<1:13:37, 12.92s/it]',\n'\\rOverwrite (natlang) epoch 3/4:   2%|1         | 6/345 [00:49<28:22,\n5.02s/it]  ', '\\rOverwrite (natlang) epoch 3/4:   3%|2         | 9/345\n[00:50<15:06,  2.70s/it]', '\\rOverwrite (natlang) epoch 3/4:   3%|3         |\n12/345 [00:50<09:05,  1.64s/it]', '\\rOverwrite (natlang) epoch 3/4:   4%|4\n| 15/345 [00:50<05:49,  1.06s/it]', '\\rOverwrite (natlang) epoch 3/4:   5%|5\n| 18/345 [00:50<03:52,  1.40it/s]', '\\rOverwrite (natlang) epoch 3/4:   6%|6\n| 21/345 [00:50<02:39,  2.03it/s]', '\\rOverwrite (natlang) epoch 3/4:   7%|6\n| 24/345 [00:50<01:52,  2.85it/s]', '\\rOverwrite (natlang) epoch 3/4:   8%|7\n| 27/345 [00:50<01:21,  3.91it/s]', '\\rOverwrite (natlang) epoch 3/4:   9%|8\n| 30/345 [00:51<01:00,  5.24it/s]', '\\rOverwrite (natlang) epoch 3/4:  10%|9\n| 33/345 [00:51<00:45,  6.83it/s]', '\\rOverwrite (natlang) epoch 3/4:  10%|#\n| 36/345 [00:51<00:35,  8.64it/s]', '\\rOverwrite (natlang) epoch 3/4:  11%|#1\n| 39/345 [00:51<00:28, 10.58it/s]', '\\rOverwrite (natlang) epoch 3/4:  12%|#2\n| 42/345 [00:51<00:24, 12.54it/s]', '\\rOverwrite (natlang) epoch 3/4:  13%|#3\n| 45/345 [00:51<00:20, 14.38it/s]', '\\rOverwrite (natlang) epoch 3/4:  14%|#3\n| 48/345 [00:51<00:18, 16.01it/s]', '\\rOverwrite (natlang) epoch 3/4:  15%|#4\n| 51/345 [00:51<00:16, 17.31it/s]', '\\rOverwrite (natlang) epoch 3/4:  16%|#5\n| 54/345 [00:52<00:15, 18.42it/s]', '\\rOverwrite (natlang) epoch 3/4:  17%|#6\n| 57/345 [00:52<00:14, 19.26it/s]', '\\rOverwrite (natlang) epoch 3/4:  17%|#7\n| 60/345 [00:52<00:14, 19.89it/s]', '\\rOverwrite (natlang) epoch 3/4:  18%|#8\n| 63/345 [00:52<00:13, 20.38it/s]', '\\rOverwrite (natlang) epoch 3/4:  19%|#9\n| 66/345 [00:52<00:13, 20.69it/s]', '\\rOverwrite (natlang) epoch 3/4:  20%|##\n| 69/345 [00:52<00:13, 20.98it/s]', '\\rOverwrite (natlang) epoch 3/4:  21%|##\n| 72/345 [00:52<00:12, 21.18it/s]', '\\rOverwrite (natlang) epoch 3/4:  22%|##1\n| 75/345 [00:53<00:12, 21.11it/s]', '\\rOverwrite (natlang) epoch 3/4:  23%|##2\n| 78/345 [00:53<00:12, 20.90it/s]', '\\rOverwrite (natlang) epoch 3/4:  23%|##3\n| 81/345 [00:53<00:12, 20.88it/s]', '\\rOverwrite (natlang) epoch 3/4:  24%|##4\n| 84/345 [00:53<00:12, 21.01it/s]', '\\rOverwrite (natlang) epoch 3/4:  25%|##5\n| 87/345 [00:53<00:12, 21.22it/s]', '\\rOverwrite (natlang) epoch 3/4:  26%|##6\n| 90/345 [00:53<00:11, 21.36it/s]', '\\rOverwrite (natlang) epoch 3/4:  27%|##6\n| 93/345 [00:53<00:11, 21.17it/s]', '\\rOverwrite (natlang) epoch 3/4:  28%|##7\n| 96/345 [00:54<00:11, 21.21it/s]', '\\rOverwrite (natlang) epoch 3/4:  29%|##8\n| 99/345 [00:54<00:11, 21.37it/s]', '\\rOverwrite (natlang) epoch 3/4:  30%|##9\n| 102/345 [00:54<00:11, 21.39it/s]', '\\rOverwrite (natlang) epoch 3/4:  30%|###\n| 105/345 [00:54<00:11, 20.83it/s]', '\\rOverwrite (natlang) epoch 3/4:  31%|###1\n| 108/345 [00:54<00:11, 20.20it/s]', '[2025-12-03 22:09:39] Overwrite (natlang)\nstep 800: avg_train_loss=3.0678', '\\n', '\\rOverwrite (natlang) epoch 3/4:\n32%|###2      | 111/345 [00:54<00:11, 19.97it/s]', '\\rOverwrite (natlang) epoch\n3/4:  33%|###3      | 114/345 [00:54<00:11, 20.38it/s]', '\\rOverwrite (natlang)\nepoch 3/4:  34%|###3      | 117/345 [00:55<00:10, 20.74it/s]', '\\rOverwrite\n(natlang) epoch 3/4:  35%|###4      | 120/345 [00:55<00:10, 20.94it/s]',\n'\\rOverwrite (natlang) epoch 3/4:  36%|###5      | 123/345 [00:55<00:10,\n21.17it/s]', '\\rOverwrite (natlang) epoch 3/4:  37%|###6      | 126/345\n[00:55<00:10, 21.34it/s]', '\\rOverwrite (natlang) epoch 3/4:  37%|###7      |\n129/345 [00:55<00:10, 21.42it/s]', '\\rOverwrite (natlang) epoch 3/4:  38%|###8\n| 132/345 [00:55<00:09, 21.47it/s]', '\\rOverwrite (natlang) epoch 3/4:  39%|###9\n| 135/345 [00:55<00:09, 21.30it/s]', '\\rOverwrite (natlang) epoch 3/4:  40%|####\n| 138/345 [00:56<00:09, 20.97it/s]', '\\rOverwrite (natlang) epoch 3/4:  41%|####\n| 141/345 [00:56<00:09, 20.97it/s]', '\\rOverwrite (natlang) epoch 3/4:\n42%|####1     | 144/345 [00:56<00:09, 21.18it/s]', '\\rOverwrite (natlang) epoch\n3/4:  43%|####2     | 147/345 [00:56<00:09, 21.35it/s]', '\\rOverwrite (natlang)\nepoch 3/4:  43%|####3     | 150/345 [00:56<00:09, 21.41it/s]', '\\rOverwrite\n(natlang) epoch 3/4:  44%|####4     | 153/345 [00:56<00:08, 21.48it/s]',\n'\\rOverwrite (natlang) epoch 3/4:  45%|####5     | 156/345 [00:56<00:08,\n21.32it/s]', '\\rOverwrite (natlang) epoch 3/4:  46%|####6     | 159/345\n[00:57<00:08, 21.21it/s]', '\\rOverwrite (natlang) epoch 3/4:  47%|####6     |\n162/345 [00:57<00:08, 21.38it/s]', '\\rOverwrite (natlang) epoch 3/4:  48%|####7\n| 165/345 [00:57<00:08, 21.41it/s]', '\\rOverwrite (natlang) epoch 3/4:\n49%|####8     | 168/345 [00:57<00:08, 21.49it/s]', '\\rOverwrite (natlang) epoch\n3/4:  50%|####9     | 171/345 [00:57<00:08, 21.49it/s]', '\\rOverwrite (natlang)\nepoch 3/4:  50%|#####     | 174/345 [00:57<00:07, 21.54it/s]', '\\rOverwrite\n(natlang) epoch 3/4:  51%|#####1    | 177/345 [00:57<00:07, 21.59it/s]',\n'\\rOverwrite (natlang) epoch 3/4:  52%|#####2    | 180/345 [00:58<00:07,\n21.55it/s]', '\\rOverwrite (natlang) epoch 3/4:  53%|#####3    | 183/345\n[00:58<00:07, 21.54it/s]', '\\rOverwrite (natlang) epoch 3/4:  54%|#####3    |\n186/345 [00:58<00:07, 21.54it/s]', '\\rOverwrite (natlang) epoch 3/4:  55%|#####4\n| 189/345 [00:58<00:07, 21.56it/s]', '\\rOverwrite (natlang) epoch 3/4:\n56%|#####5    | 192/345 [00:58<00:07, 21.62it/s]', '\\rOverwrite (natlang) epoch\n3/4:  57%|#####6    | 195/345 [00:58<00:06, 21.64it/s]', '\\rOverwrite (natlang)\nepoch 3/4:  57%|#####7    | 198/345 [00:58<00:06, 21.68it/s]', '\\rOverwrite\n(natlang) epoch 3/4:  58%|#####8    | 201/345 [00:59<00:06, 21.68it/s]',\n'\\rOverwrite (natlang) epoch 3/4:  59%|#####9    | 204/345 [00:59<00:06,\n21.58it/s]', '\\rOverwrite (natlang) epoch 3/4:  60%|######    | 207/345\n[00:59<00:06, 21.67it/s]', '\\rOverwrite (natlang) epoch 3/4:  61%|######    |\n210/345 [00:59<00:06, 21.74it/s]', '\\rOverwrite (natlang) epoch 3/4:\n62%|######1   | 213/345 [00:59<00:06, 21.78it/s]', '\\rOverwrite (natlang) epoch\n3/4:  63%|######2   | 216/345 [00:59<00:05, 21.61it/s]', '\\rOverwrite (natlang)\nepoch 3/4:  63%|######3   | 219/345 [00:59<00:05, 21.57it/s]', '\\rOverwrite\n(natlang) epoch 3/4:  64%|######4   | 222/345 [01:00<00:05, 21.35it/s]',\n'\\rOverwrite (natlang) epoch 3/4:  65%|######5   | 225/345 [01:00<00:05,\n21.29it/s]', '\\rOverwrite (natlang) epoch 3/4:  66%|######6   | 228/345\n[01:00<00:05, 21.29it/s]', '\\rOverwrite (natlang) epoch 3/4:  67%|######6   |\n231/345 [01:00<00:05, 21.46it/s]', '\\rOverwrite (natlang) epoch 3/4:\n68%|######7   | 234/345 [01:00<00:05, 21.56it/s]', '\\rOverwrite (natlang) epoch\n3/4:  69%|######8   | 237/345 [01:00<00:05, 21.30it/s]', '\\rOverwrite (natlang)\nepoch 3/4:  70%|######9   | 240/345 [01:00<00:04, 21.25it/s]', '\\rOverwrite\n(natlang) epoch 3/4:  70%|#######   | 243/345 [01:00<00:04, 20.99it/s]',\n'\\rOverwrite (natlang) epoch 3/4:  71%|#######1  | 246/345 [01:01<00:04,\n20.96it/s]', '\\rOverwrite (natlang) epoch 3/4:  72%|#######2  | 249/345\n[01:01<00:04, 21.19it/s]', '\\rOverwrite (natlang) epoch 3/4:  73%|#######3  |\n252/345 [01:01<00:04, 21.30it/s]', '\\rOverwrite (natlang) epoch 3/4:\n74%|#######3  | 255/345 [01:01<00:04, 21.27it/s]', '\\rOverwrite (natlang) epoch\n3/4:  75%|#######4  | 258/345 [01:01<00:04, 21.04it/s]', '\\rOverwrite (natlang)\nepoch 3/4:  76%|#######5  | 261/345 [01:01<00:03, 21.06it/s]', '\\rOverwrite\n(natlang) epoch 3/4:  77%|#######6  | 264/345 [01:01<00:03, 21.05it/s]',\n'\\rOverwrite (natlang) epoch 3/4:  77%|#######7  | 267/345 [01:02<00:03,\n21.15it/s]', '\\rOverwrite (natlang) epoch 3/4:  78%|#######8  | 270/345\n[01:02<00:03, 21.35it/s]', '\\rOverwrite (natlang) epoch 3/4:  79%|#######9  |\n273/345 [01:02<00:03, 21.24it/s]', '\\rOverwrite (natlang) epoch 3/4:\n80%|########  | 276/345 [01:02<00:03, 21.13it/s]', '\\rOverwrite (natlang) epoch\n3/4:  81%|########  | 279/345 [01:02<00:03, 20.76it/s]', '\\rOverwrite (natlang)\nepoch 3/4:  82%|########1 | 282/345 [01:02<00:03, 20.85it/s]', '\\rOverwrite\n(natlang) epoch 3/4:  83%|########2 | 285/345 [01:02<00:02, 21.11it/s]',\n'\\rOverwrite (natlang) epoch 3/4:  83%|########3 | 288/345 [01:03<00:02,\n20.87it/s]', '\\rOverwrite (natlang) epoch 3/4:  84%|########4 | 291/345\n[01:03<00:02, 20.13it/s]', '\\rOverwrite (natlang) epoch 3/4:  85%|########5 |\n294/345 [01:03<00:02, 20.44it/s]', '\\rOverwrite (natlang) epoch 3/4:\n86%|########6 | 297/345 [01:03<00:02, 20.54it/s]', '\\rOverwrite (natlang) epoch\n3/4:  87%|########6 | 300/345 [01:03<00:02, 20.88it/s]', '\\rOverwrite (natlang)\nepoch 3/4:  88%|########7 | 303/345 [01:03<00:01, 21.05it/s]', '\\rOverwrite\n(natlang) epoch 3/4:  89%|########8 | 306/345 [01:03<00:01, 21.08it/s]',\n'\\rOverwrite (natlang) epoch 3/4:  90%|########9 | 309/345 [01:04<00:01,\n21.14it/s]', '[2025-12-03 22:09:48] Overwrite (natlang) step 1000:\navg_train_loss=3.0776', '\\n', '\\rOverwrite (natlang) epoch 3/4:  90%|######### |\n312/345 [01:04<00:01, 21.23it/s]', '\\rOverwrite (natlang) epoch 3/4:\n91%|#########1| 315/345 [01:04<00:01, 21.35it/s]', '\\rOverwrite (natlang) epoch\n3/4:  92%|#########2| 318/345 [01:04<00:01, 21.47it/s]', '\\rOverwrite (natlang)\nepoch 3/4:  93%|#########3| 321/345 [01:04<00:01, 21.38it/s]', '\\rOverwrite\n(natlang) epoch 3/4:  94%|#########3| 324/345 [01:04<00:00, 21.45it/s]',\n'\\rOverwrite (natlang) epoch 3/4:  95%|#########4| 327/345 [01:04<00:00,\n21.52it/s]', '\\rOverwrite (natlang) epoch 3/4:  96%|#########5| 330/345\n[01:05<00:00, 21.57it/s]', '\\rOverwrite (natlang) epoch 3/4:  97%|#########6|\n333/345 [01:05<00:00, 21.52it/s]', '\\rOverwrite (natlang) epoch 3/4:\n97%|#########7| 336/345 [01:05<00:00, 21.00it/s]', '\\rOverwrite (natlang) epoch\n3/4:  98%|#########8| 339/345 [01:05<00:00, 20.94it/s]', '\\rOverwrite (natlang)\nepoch 3/4:  99%|#########9| 342/345 [01:05<00:00, 20.57it/s]', '\\rOverwrite\n(natlang) epoch 3/4: 100%|##########| 345/345 [01:05<00:00, 21.77it/s]', '',\n'\\rOverwrite (natlang) epoch 3/4: 100%|##########| 345/345 [01:07<00:00,\n5.13it/s]', '\\n', 'Epoch 3 (natlang): validation_loss = 3.6799', '\\n',\n'\\rOverwrite (natlang) epoch 4/4:   0%|          | 0/345 [00:00<?, ?it/s]',\n'\\rOverwrite (natlang) epoch 4/4:   0%|          | 1/345 [00:48<4:37:41,\n48.44s/it]', '\\rOverwrite (natlang) epoch 4/4:   1%|          | 3/345\n[00:48<1:11:51, 12.61s/it]', '\\rOverwrite (natlang) epoch 4/4:   2%|1         |\n6/345 [00:48<27:41,  4.90s/it]  ', '\\rOverwrite (natlang) epoch 4/4:   3%|2\n| 9/345 [00:48<14:44,  2.63s/it]', '\\rOverwrite (natlang) epoch 4/4:   3%|3\n| 12/345 [00:48<08:52,  1.60s/it]', '\\rOverwrite (natlang) epoch 4/4:   4%|4\n| 15/345 [00:49<05:40,  1.03s/it]', '\\rOverwrite (natlang) epoch 4/4:   5%|5\n| 18/345 [00:49<03:47,  1.44it/s]', '\\rOverwrite (natlang) epoch 4/4:   6%|6\n| 21/345 [00:49<02:36,  2.07it/s]', '\\rOverwrite (natlang) epoch 4/4:   7%|6\n| 24/345 [00:49<01:50,  2.91it/s]', '\\rOverwrite (natlang) epoch 4/4:   8%|7\n| 27/345 [00:49<01:19,  3.99it/s]', '\\rOverwrite (natlang) epoch 4/4:   9%|8\n| 30/345 [00:49<00:59,  5.32it/s]', '\\rOverwrite (natlang) epoch 4/4:  10%|9\n| 33/345 [00:49<00:45,  6.90it/s]', '\\rOverwrite (natlang) epoch 4/4:  10%|#\n| 36/345 [00:50<00:35,  8.71it/s]', '\\rOverwrite (natlang) epoch 4/4:  11%|#1\n| 39/345 [00:50<00:28, 10.61it/s]', '\\rOverwrite (natlang) epoch 4/4:  12%|#2\n| 42/345 [00:50<00:24, 12.52it/s]', '\\rOverwrite (natlang) epoch 4/4:  13%|#3\n| 45/345 [00:50<00:20, 14.36it/s]', '\\rOverwrite (natlang) epoch 4/4:  14%|#3\n| 48/345 [00:50<00:18, 15.97it/s]', '\\rOverwrite (natlang) epoch 4/4:  15%|#4\n| 51/345 [00:50<00:16, 17.36it/s]', '\\rOverwrite (natlang) epoch 4/4:  16%|#5\n| 54/345 [00:50<00:15, 18.48it/s]', '\\rOverwrite (natlang) epoch 4/4:  17%|#6\n| 57/345 [00:51<00:14, 19.33it/s]', '\\rOverwrite (natlang) epoch 4/4:  17%|#7\n| 60/345 [00:51<00:14, 20.03it/s]', '\\rOverwrite (natlang) epoch 4/4:  18%|#8\n| 63/345 [00:51<00:13, 20.54it/s]', '\\rOverwrite (natlang) epoch 4/4:  19%|#9\n| 66/345 [00:51<00:13, 20.75it/s]', '\\rOverwrite (natlang) epoch 4/4:  20%|##\n| 69/345 [00:51<00:13, 20.84it/s]', '\\rOverwrite (natlang) epoch 4/4:  21%|##\n| 72/345 [00:51<00:13, 20.88it/s]', '\\rOverwrite (natlang) epoch 4/4:  22%|##1\n| 75/345 [00:51<00:12, 20.83it/s]', '\\rOverwrite (natlang) epoch 4/4:  23%|##2\n| 78/345 [00:52<00:12, 21.07it/s]', '\\rOverwrite (natlang) epoch 4/4:  23%|##3\n| 81/345 [00:52<00:12, 20.95it/s]', '\\rOverwrite (natlang) epoch 4/4:  24%|##4\n| 84/345 [00:52<00:12, 20.95it/s]', '\\rOverwrite (natlang) epoch 4/4:  25%|##5\n| 87/345 [00:52<00:12, 21.18it/s]', '\\rOverwrite (natlang) epoch 4/4:  26%|##6\n| 90/345 [00:52<00:11, 21.32it/s]', '\\rOverwrite (natlang) epoch 4/4:  27%|##6\n| 93/345 [00:52<00:11, 21.47it/s]', '\\rOverwrite (natlang) epoch 4/4:  28%|##7\n| 96/345 [00:52<00:11, 21.47it/s]', '\\rOverwrite (natlang) epoch 4/4:  29%|##8\n| 99/345 [00:53<00:11, 21.56it/s]', '\\rOverwrite (natlang) epoch 4/4:  30%|##9\n| 102/345 [00:53<00:11, 21.66it/s]', '\\rOverwrite (natlang) epoch 4/4:  30%|###\n| 105/345 [00:53<00:11, 21.60it/s]', '\\rOverwrite (natlang) epoch 4/4:  31%|###1\n| 108/345 [00:53<00:10, 21.56it/s]', '\\rOverwrite (natlang) epoch 4/4:  32%|###2\n| 111/345 [00:53<00:10, 21.52it/s]', '\\rOverwrite (natlang) epoch 4/4:  33%|###3\n| 114/345 [00:53<00:10, 21.38it/s]', '\\rOverwrite (natlang) epoch 4/4:  34%|###3\n| 117/345 [00:53<00:10, 21.46it/s]', '\\rOverwrite (natlang) epoch 4/4:  35%|###4\n| 120/345 [00:54<00:10, 21.42it/s]', '\\rOverwrite (natlang) epoch 4/4:  36%|###5\n| 123/345 [00:54<00:10, 21.46it/s]', '\\rOverwrite (natlang) epoch 4/4:  37%|###6\n| 126/345 [00:54<00:10, 21.44it/s]', '\\rOverwrite (natlang) epoch 4/4:  37%|###7\n| 129/345 [00:54<00:10, 21.38it/s]', '\\rOverwrite (natlang) epoch 4/4:  38%|###8\n| 132/345 [00:54<00:09, 21.47it/s]', '\\rOverwrite (natlang) epoch 4/4:  39%|###9\n| 135/345 [00:54<00:09, 21.55it/s]', '\\rOverwrite (natlang) epoch 4/4:  40%|####\n| 138/345 [00:54<00:09, 21.58it/s]', '\\rOverwrite (natlang) epoch 4/4:  41%|####\n| 141/345 [00:54<00:09, 21.62it/s]', '\\rOverwrite (natlang) epoch 4/4:\n42%|####1     | 144/345 [00:55<00:09, 21.27it/s]', '\\rOverwrite (natlang) epoch\n4/4:  43%|####2     | 147/345 [00:55<00:09, 21.37it/s]', '\\rOverwrite (natlang)\nepoch 4/4:  43%|####3     | 150/345 [00:55<00:09, 21.49it/s]', '\\rOverwrite\n(natlang) epoch 4/4:  44%|####4     | 153/345 [00:55<00:08, 21.54it/s]',\n'\\rOverwrite (natlang) epoch 4/4:  45%|####5     | 156/345 [00:55<00:08,\n21.60it/s]', '\\rOverwrite (natlang) epoch 4/4:  46%|####6     | 159/345\n[00:55<00:08, 21.66it/s]', '\\rOverwrite (natlang) epoch 4/4:  47%|####6     |\n162/345 [00:55<00:08, 21.69it/s]', '[2025-12-03 22:11:43] Overwrite (natlang)\nstep 1200: avg_train_loss=2.8714', '\\n', '\\rOverwrite (natlang) epoch 4/4:\n48%|####7     | 165/345 [00:56<00:08, 21.68it/s]', '\\rOverwrite (natlang) epoch\n4/4:  49%|####8     | 168/345 [00:56<00:08, 21.42it/s]', '\\rOverwrite (natlang)\nepoch 4/4:  50%|####9     | 171/345 [00:56<00:08, 21.34it/s]', '\\rOverwrite\n(natlang) epoch 4/4:  50%|#####     | 174/345 [00:56<00:07, 21.43it/s]',\n'\\rOverwrite (natlang) epoch 4/4:  51%|#####1    | 177/345 [00:56<00:07,\n21.52it/s]', '\\rOverwrite (natlang) epoch 4/4:  52%|#####2    | 180/345\n[00:56<00:07, 21.66it/s]', '\\rOverwrite (natlang) epoch 4/4:  53%|#####3    |\n183/345 [00:56<00:07, 21.72it/s]', '\\rOverwrite (natlang) epoch 4/4:  54%|#####3\n| 186/345 [00:57<00:07, 21.68it/s]', '\\rOverwrite (natlang) epoch 4/4:\n55%|#####4    | 189/345 [00:57<00:07, 21.59it/s]', '\\rOverwrite (natlang) epoch\n4/4:  56%|#####5    | 192/345 [00:57<00:07, 21.62it/s]', '\\rOverwrite (natlang)\nepoch 4/4:  57%|#####6    | 195/345 [00:57<00:07, 20.94it/s]', '\\rOverwrite\n(natlang) epoch 4/4:  57%|#####7    | 198/345 [00:57<00:06, 21.13it/s]',\n'\\rOverwrite (natlang) epoch 4/4:  58%|#####8    | 201/345 [00:57<00:06,\n21.23it/s]', '\\rOverwrite (natlang) epoch 4/4:  59%|#####9    | 204/345\n[00:57<00:06, 20.77it/s]', '\\rOverwrite (natlang) epoch 4/4:  60%|######    |\n207/345 [00:58<00:06, 20.88it/s]', '\\rOverwrite (natlang) epoch 4/4:  61%|######\n| 210/345 [00:58<00:06, 20.96it/s]', '\\rOverwrite (natlang) epoch 4/4:\n62%|######1   | 213/345 [00:58<00:06, 21.19it/s]', '\\rOverwrite (natlang) epoch\n4/4:  63%|######2   | 216/345 [00:58<00:06, 21.29it/s]', '\\rOverwrite (natlang)\nepoch 4/4:  63%|######3   | 219/345 [00:58<00:05, 21.40it/s]', '\\rOverwrite\n(natlang) epoch 4/4:  64%|######4   | 222/345 [00:58<00:05, 21.49it/s]',\n'\\rOverwrite (natlang) epoch 4/4:  65%|######5   | 225/345 [00:58<00:05,\n21.56it/s]', '\\rOverwrite (natlang) epoch 4/4:  66%|######6   | 228/345\n[00:59<00:05, 21.64it/s]', '\\rOverwrite (natlang) epoch 4/4:  67%|######6   |\n231/345 [00:59<00:05, 21.61it/s]', '\\rOverwrite (natlang) epoch 4/4:\n68%|######7   | 234/345 [00:59<00:05, 21.54it/s]', '\\rOverwrite (natlang) epoch\n4/4:  69%|######8   | 237/345 [00:59<00:05, 21.58it/s]', '\\rOverwrite (natlang)\nepoch 4/4:  70%|######9   | 240/345 [00:59<00:04, 21.65it/s]', '\\rOverwrite\n(natlang) epoch 4/4:  70%|#######   | 243/345 [00:59<00:04, 21.69it/s]',\n'\\rOverwrite (natlang) epoch 4/4:  71%|#######1  | 246/345 [00:59<00:04,\n21.72it/s]', '\\rOverwrite (natlang) epoch 4/4:  72%|#######2  | 249/345\n[01:00<00:04, 21.76it/s]', '\\rOverwrite (natlang) epoch 4/4:  73%|#######3  |\n252/345 [01:00<00:04, 21.25it/s]', '\\rOverwrite (natlang) epoch 4/4:\n74%|#######3  | 255/345 [01:00<00:04, 20.95it/s]', '\\rOverwrite (natlang) epoch\n4/4:  75%|#######4  | 258/345 [01:00<00:04, 20.41it/s]', '\\rOverwrite (natlang)\nepoch 4/4:  76%|#######5  | 261/345 [01:00<00:04, 20.39it/s]', '\\rOverwrite\n(natlang) epoch 4/4:  77%|#######6  | 264/345 [01:00<00:04, 20.16it/s]',\n'\\rOverwrite (natlang) epoch 4/4:  77%|#######7  | 267/345 [01:00<00:03,\n20.16it/s]', '\\rOverwrite (natlang) epoch 4/4:  78%|#######8  | 270/345\n[01:01<00:03, 20.59it/s]', '\\rOverwrite (natlang) epoch 4/4:  79%|#######9  |\n273/345 [01:01<00:03, 20.81it/s]', '\\rOverwrite (natlang) epoch 4/4:\n80%|########  | 276/345 [01:01<00:03, 20.68it/s]', '\\rOverwrite (natlang) epoch\n4/4:  81%|########  | 279/345 [01:01<00:03, 20.02it/s]', '\\rOverwrite (natlang)\nepoch 4/4:  82%|########1 | 282/345 [01:01<00:03, 19.62it/s]', '\\rOverwrite\n(natlang) epoch 4/4:  83%|########2 | 285/345 [01:01<00:03, 19.90it/s]',\n'\\rOverwrite (natlang) epoch 4/4:  83%|########3 | 288/345 [01:01<00:02,\n20.44it/s]', '\\rOverwrite (natlang) epoch 4/4:  84%|########4 | 291/345\n[01:02<00:02, 20.82it/s]', '\\rOverwrite (natlang) epoch 4/4:  85%|########5 |\n294/345 [01:02<00:02, 21.12it/s]', '\\rOverwrite (natlang) epoch 4/4:\n86%|########6 | 297/345 [01:02<00:02, 21.31it/s]', '\\rOverwrite (natlang) epoch\n4/4:  87%|########6 | 300/345 [01:02<00:02, 21.42it/s]', '\\rOverwrite (natlang)\nepoch 4/4:  88%|########7 | 303/345 [01:02<00:01, 21.47it/s]', '\\rOverwrite\n(natlang) epoch 4/4:  89%|########8 | 306/345 [01:02<00:01, 21.60it/s]',\n'\\rOverwrite (natlang) epoch 4/4:  90%|########9 | 309/345 [01:02<00:01,\n21.71it/s]', '\\rOverwrite (natlang) epoch 4/4:  90%|######### | 312/345\n[01:03<00:01, 21.74it/s]', '\\rOverwrite (natlang) epoch 4/4:  91%|#########1|\n315/345 [01:03<00:01, 21.76it/s]', '\\rOverwrite (natlang) epoch 4/4:\n92%|#########2| 318/345 [01:03<00:01, 21.13it/s]', '\\rOverwrite (natlang) epoch\n4/4:  93%|#########3| 321/345 [01:03<00:01, 20.70it/s]', '\\rOverwrite (natlang)\nepoch 4/4:  94%|#########3| 324/345 [01:03<00:01, 20.59it/s]', '\\rOverwrite\n(natlang) epoch 4/4:  95%|#########4| 327/345 [01:03<00:00, 20.34it/s]',\n'\\rOverwrite (natlang) epoch 4/4:  96%|#########5| 330/345 [01:03<00:00,\n20.27it/s]', '\\rOverwrite (natlang) epoch 4/4:  97%|#########6| 333/345\n[01:04<00:00, 20.53it/s]', '\\rOverwrite (natlang) epoch 4/4:  97%|#########7|\n336/345 [01:04<00:00, 20.44it/s]', '\\rOverwrite (natlang) epoch 4/4:\n98%|#########8| 339/345 [01:04<00:00, 20.34it/s]', '\\rOverwrite (natlang) epoch\n4/4:  99%|#########9| 342/345 [01:04<00:00, 20.75it/s]', '\\rOverwrite (natlang)\nepoch 4/4: 100%|##########| 345/345 [01:04<00:00, 21.96it/s]', '', '\\rOverwrite\n(natlang) epoch 4/4: 100%|##########| 345/345 [01:05<00:00,  5.26it/s]', '\\n',\n'Epoch 4 (natlang): validation_loss = 3.7260', '\\n', '\\n===== Starting\ncondition: code_style =====', '\\n', '\\rMap:   0%|          | 0/2000 [00:00<?, ?\nexamples/s]', '\\rMap: 100%|##########| 2000/2000 [00:00<00:00, 5381.31\nexamples/s]', '', '\\rMap: 100%|##########| 2000/2000 [00:00<00:00, 5351.21\nexamples/s]', '\\n', '\\rMap:   0%|          | 0/300 [00:00<?, ? examples/s]', '',\n'\\rMap: 100%|##########| 300/300 [00:00<00:00, 26796.10 examples/s]', '\\n',\n'\\rTraining code_style_phase1 epoch 1/1:   0%|          | 0/21 [00:00<?,\n?it/s]', '\\rTraining code_style_phase1 epoch 1/1:   5%|4         | 1/21\n[00:48<16:02, 48.13s/it]', '\\rTraining code_style_phase1 epoch 1/1:  10%|9\n| 2/21 [00:48<06:17, 19.89s/it]', '\\rTraining code_style_phase1 epoch 1/1:\n14%|#4        | 3/21 [00:48<03:15, 10.86s/it]', '\\rTraining code_style_phase1\nepoch 1/1:  19%|#9        | 4/21 [00:48<01:52,  6.62s/it]', '\\rTraining\ncode_style_phase1 epoch 1/1:  24%|##3       | 5/21 [00:48<01:08,  4.27s/it]',\n'\\rTraining code_style_phase1 epoch 1/1:  29%|##8       | 6/21 [00:48<00:42,\n2.86s/it]', '\\rTraining code_style_phase1 epoch 1/1:  33%|###3      | 7/21\n[00:48<00:27,  1.96s/it]', '\\rTraining code_style_phase1 epoch 1/1:  38%|###8\n| 8/21 [00:48<00:17,  1.37s/it]', '\\rTraining code_style_phase1 epoch 1/1:\n43%|####2     | 9/21 [00:49<00:11,  1.02it/s]', '\\rTraining code_style_phase1\nepoch 1/1:  48%|####7     | 10/21 [00:49<00:07,  1.40it/s]', '\\rTraining\ncode_style_phase1 epoch 1/1:  52%|#####2    | 11/21 [00:49<00:05,  1.89it/s]',\n'\\rTraining code_style_phase1 epoch 1/1:  57%|#####7    | 12/21 [00:49<00:03,\n2.48it/s]', '\\rTraining code_style_phase1 epoch 1/1:  62%|######1   | 13/21\n[00:49<00:02,  3.16it/s]', '\\rTraining code_style_phase1 epoch 1/1:  67%|######6\n| 14/21 [00:49<00:01,  3.91it/s]', '\\rTraining code_style_phase1 epoch 1/1:\n71%|#######1  | 15/21 [00:49<00:01,  4.68it/s]', '\\rTraining code_style_phase1\nepoch 1/1:  76%|#######6  | 16/21 [00:49<00:00,  5.44it/s]', '\\rTraining\ncode_style_phase1 epoch 1/1:  81%|########  | 17/21 [00:49<00:00,  6.13it/s]',\n'\\rTraining code_style_phase1 epoch 1/1:  86%|########5 | 18/21 [00:50<00:00,\n6.72it/s]', '\\rTraining code_style_phase1 epoch 1/1:  90%|######### | 19/21\n[00:50<00:00,  7.22it/s]', '\\rTraining code_style_phase1 epoch 1/1:\n95%|#########5| 20/21 [00:50<00:00,  7.61it/s]', '', '\\rTraining\ncode_style_phase1 epoch 1/1: 100%|##########| 21/21 [00:51<00:00,  2.44s/it]',\n'\\n', 'Epoch 1: validation_loss = 2.5158', '\\n', '\\rOverwrite (code_style) epoch\n1/4:   0%|          | 0/345 [00:00<?, ?it/s]', '\\rOverwrite (code_style) epoch\n1/4:   0%|          | 1/345 [00:47<4:32:24, 47.51s/it]', '\\rOverwrite\n(code_style) epoch 1/4:   1%|          | 3/345 [00:47<1:10:31, 12.37s/it]',\n'\\rOverwrite (code_style) epoch 1/4:   2%|1         | 6/345 [00:47<27:10,\n4.81s/it]  ', '\\rOverwrite (code_style) epoch 1/4:   3%|2         | 9/345\n[00:47<14:28,  2.58s/it]', '\\rOverwrite (code_style) epoch 1/4:   3%|3         |\n12/345 [00:48<08:42,  1.57s/it]', '\\rOverwrite (code_style) epoch 1/4:   4%|4\n| 15/345 [00:48<05:34,  1.01s/it]', '\\rOverwrite (code_style) epoch 1/4:   5%|5\n| 18/345 [00:48<03:43,  1.46it/s]', '\\rOverwrite (code_style) epoch 1/4:   6%|6\n| 21/345 [00:48<02:33,  2.11it/s]', '\\rOverwrite (code_style) epoch 1/4:   7%|6\n| 24/345 [00:48<01:48,  2.96it/s]', '\\rOverwrite (code_style) epoch 1/4:   8%|7\n| 27/345 [00:48<01:18,  4.06it/s]', '\\rOverwrite (code_style) epoch 1/4:   9%|8\n| 30/345 [00:48<00:58,  5.43it/s]', '\\rOverwrite (code_style) epoch 1/4:  10%|9\n| 33/345 [00:49<00:44,  7.03it/s]', '\\rOverwrite (code_style) epoch 1/4:  10%|#\n| 36/345 [00:49<00:34,  8.85it/s]', '\\rOverwrite (code_style) epoch 1/4:  11%|#1\n| 39/345 [00:49<00:28, 10.77it/s]', '\\rOverwrite (code_style) epoch 1/4:  12%|#2\n| 42/345 [00:49<00:23, 12.71it/s]', '\\rOverwrite (code_style) epoch 1/4:  13%|#3\n| 45/345 [00:49<00:20, 14.55it/s]', '\\rOverwrite (code_style) epoch 1/4:  14%|#3\n| 48/345 [00:49<00:18, 16.18it/s]', '\\rOverwrite (code_style) epoch 1/4:  15%|#4\n| 51/345 [00:49<00:16, 17.51it/s]', '\\rOverwrite (code_style) epoch 1/4:  16%|#5\n| 54/345 [00:50<00:15, 18.59it/s]', '\\rOverwrite (code_style) epoch 1/4:  17%|#6\n| 57/345 [00:50<00:14, 19.42it/s]', '\\rOverwrite (code_style) epoch 1/4:  17%|#7\n| 60/345 [00:50<00:14, 20.01it/s]', '\\rOverwrite (code_style) epoch 1/4:  18%|#8\n| 63/345 [00:50<00:13, 20.50it/s]', '\\rOverwrite (code_style) epoch 1/4:  19%|#9\n| 66/345 [00:50<00:13, 20.77it/s]', '\\rOverwrite (code_style) epoch 1/4:  20%|##\n| 69/345 [00:50<00:13, 20.91it/s]', '\\rOverwrite (code_style) epoch 1/4:  21%|##\n| 72/345 [00:50<00:12, 21.19it/s]', '\\rOverwrite (code_style) epoch 1/4:\n22%|##1       | 75/345 [00:50<00:12, 21.26it/s]', '\\rOverwrite (code_style)\nepoch 1/4:  23%|##2       | 78/345 [00:51<00:12, 21.38it/s]', '\\rOverwrite\n(code_style) epoch 1/4:  23%|##3       | 81/345 [00:51<00:12, 21.47it/s]',\n'\\rOverwrite (code_style) epoch 1/4:  24%|##4       | 84/345 [00:51<00:12,\n21.55it/s]', '\\rOverwrite (code_style) epoch 1/4:  25%|##5       | 87/345\n[00:51<00:12, 21.49it/s]', '\\rOverwrite (code_style) epoch 1/4:  26%|##6       |\n90/345 [00:51<00:11, 21.56it/s]', '\\rOverwrite (code_style) epoch 1/4:  27%|##6\n| 93/345 [00:51<00:11, 21.49it/s]', '\\rOverwrite (code_style) epoch 1/4:\n28%|##7       | 96/345 [00:51<00:11, 21.56it/s]', '\\rOverwrite (code_style)\nepoch 1/4:  29%|##8       | 99/345 [00:52<00:11, 21.35it/s]', '\\rOverwrite\n(code_style) epoch 1/4:  30%|##9       | 102/345 [00:52<00:11, 20.60it/s]',\n'\\rOverwrite (code_style) epoch 1/4:  30%|###       | 105/345 [00:52<00:11,\n20.27it/s]', '\\rOverwrite (code_style) epoch 1/4:  31%|###1      | 108/345\n[00:52<00:11, 20.42it/s]', '\\rOverwrite (code_style) epoch 1/4:  32%|###2      |\n111/345 [00:52<00:11, 20.82it/s]', '\\rOverwrite (code_style) epoch 1/4:\n33%|###3      | 114/345 [00:52<00:10, 21.11it/s]', '\\rOverwrite (code_style)\nepoch 1/4:  34%|###3      | 117/345 [00:52<00:10, 21.31it/s]', '\\rOverwrite\n(code_style) epoch 1/4:  35%|###4      | 120/345 [00:53<00:10, 21.44it/s]',\n'\\rOverwrite (code_style) epoch 1/4:  36%|###5      | 123/345 [00:53<00:10,\n21.55it/s]', '\\rOverwrite (code_style) epoch 1/4:  37%|###6      | 126/345\n[00:53<00:10, 21.61it/s]', '\\rOverwrite (code_style) epoch 1/4:  37%|###7      |\n129/345 [00:53<00:09, 21.63it/s]', '\\rOverwrite (code_style) epoch 1/4:\n38%|###8      | 132/345 [00:53<00:09, 21.68it/s]', '\\rOverwrite (code_style)\nepoch 1/4:  39%|###9      | 135/345 [00:53<00:09, 21.71it/s]', '\\rOverwrite\n(code_style) epoch 1/4:  40%|####      | 138/345 [00:53<00:09, 21.67it/s]',\n'\\rOverwrite (code_style) epoch 1/4:  41%|####      | 141/345 [00:54<00:09,\n21.46it/s]', '\\rOverwrite (code_style) epoch 1/4:  42%|####1     | 144/345\n[00:54<00:09, 21.53it/s]', '\\rOverwrite (code_style) epoch 1/4:  43%|####2     |\n147/345 [00:54<00:09, 21.63it/s]', '\\rOverwrite (code_style) epoch 1/4:\n43%|####3     | 150/345 [00:54<00:08, 21.72it/s]', '\\rOverwrite (code_style)\nepoch 1/4:  44%|####4     | 153/345 [00:54<00:08, 21.75it/s]', '\\rOverwrite\n(code_style) epoch 1/4:  45%|####5     | 156/345 [00:54<00:08, 21.75it/s]',\n'\\rOverwrite (code_style) epoch 1/4:  46%|####6     | 159/345 [00:54<00:08,\n21.73it/s]', '\\rOverwrite (code_style) epoch 1/4:  47%|####6     | 162/345\n[00:55<00:08, 21.73it/s]', '\\rOverwrite (code_style) epoch 1/4:  48%|####7     |\n165/345 [00:55<00:08, 21.77it/s]', '\\rOverwrite (code_style) epoch 1/4:\n49%|####8     | 168/345 [00:55<00:08, 21.78it/s]', '\\rOverwrite (code_style)\nepoch 1/4:  50%|####9     | 171/345 [00:55<00:07, 21.76it/s]', '\\rOverwrite\n(code_style) epoch 1/4:  50%|#####     | 174/345 [00:55<00:07, 21.81it/s]',\n'\\rOverwrite (code_style) epoch 1/4:  51%|#####1    | 177/345 [00:55<00:07,\n21.81it/s]', '\\rOverwrite (code_style) epoch 1/4:  52%|#####2    | 180/345\n[00:55<00:07, 21.83it/s]', '\\rOverwrite (code_style) epoch 1/4:  53%|#####3    |\n183/345 [00:55<00:07, 21.81it/s]', '\\rOverwrite (code_style) epoch 1/4:\n54%|#####3    | 186/345 [00:56<00:07, 21.70it/s]', '\\rOverwrite (code_style)\nepoch 1/4:  55%|#####4    | 189/345 [00:56<00:07, 21.71it/s]', '\\rOverwrite\n(code_style) epoch 1/4:  56%|#####5    | 192/345 [00:56<00:07, 21.50it/s]',\n'\\rOverwrite (code_style) epoch 1/4:  57%|#####6    | 195/345 [00:56<00:06,\n21.45it/s]', '\\rOverwrite (code_style) epoch 1/4:  57%|#####7    | 198/345\n[00:56<00:06, 21.42it/s]', '[2025-12-03 22:15:41] Overwrite (code_style) step\n200: avg_train_loss=3.8265', '\\n', '\\rOverwrite (code_style) epoch 1/4:\n58%|#####8    | 201/345 [00:56<00:06, 21.55it/s]', '\\rOverwrite (code_style)\nepoch 1/4:  59%|#####9    | 204/345 [00:56<00:06, 21.66it/s]', '\\rOverwrite\n(code_style) epoch 1/4:  60%|######    | 207/345 [00:57<00:06, 21.69it/s]',\n'\\rOverwrite (code_style) epoch 1/4:  61%|######    | 210/345 [00:57<00:06,\n21.70it/s]', '\\rOverwrite (code_style) epoch 1/4:  62%|######1   | 213/345\n[00:57<00:06, 21.65it/s]', '\\rOverwrite (code_style) epoch 1/4:  63%|######2   |\n216/345 [00:57<00:05, 21.66it/s]', '\\rOverwrite (code_style) epoch 1/4:\n63%|######3   | 219/345 [00:57<00:05, 21.68it/s]', '\\rOverwrite (code_style)\nepoch 1/4:  64%|######4   | 222/345 [00:57<00:05, 21.76it/s]', '\\rOverwrite\n(code_style) epoch 1/4:  65%|######5   | 225/345 [00:57<00:05, 21.77it/s]',\n'\\rOverwrite (code_style) epoch 1/4:  66%|######6   | 228/345 [00:58<00:05,\n21.80it/s]', '\\rOverwrite (code_style) epoch 1/4:  67%|######6   | 231/345\n[00:58<00:05, 21.77it/s]', '\\rOverwrite (code_style) epoch 1/4:  68%|######7   |\n234/345 [00:58<00:05, 21.77it/s]', '\\rOverwrite (code_style) epoch 1/4:\n69%|######8   | 237/345 [00:58<00:04, 21.82it/s]', '\\rOverwrite (code_style)\nepoch 1/4:  70%|######9   | 240/345 [00:58<00:04, 21.84it/s]', '\\rOverwrite\n(code_style) epoch 1/4:  70%|#######   | 243/345 [00:58<00:04, 21.86it/s]',\n'\\rOverwrite (code_style) epoch 1/4:  71%|#######1  | 246/345 [00:58<00:04,\n21.89it/s]', '\\rOverwrite (code_style) epoch 1/4:  72%|#######2  | 249/345\n[00:59<00:04, 21.90it/s]', '\\rOverwrite (code_style) epoch 1/4:  73%|#######3  |\n252/345 [00:59<00:04, 21.88it/s]', '\\rOverwrite (code_style) epoch 1/4:\n74%|#######3  | 255/345 [00:59<00:04, 21.90it/s]', '\\rOverwrite (code_style)\nepoch 1/4:  75%|#######4  | 258/345 [00:59<00:03, 21.77it/s]', '\\rOverwrite\n(code_style) epoch 1/4:  76%|#######5  | 261/345 [00:59<00:03, 21.79it/s]',\n'\\rOverwrite (code_style) epoch 1/4:  77%|#######6  | 264/345 [00:59<00:03,\n21.83it/s]', '\\rOverwrite (code_style) epoch 1/4:  77%|#######7  | 267/345\n[00:59<00:03, 21.85it/s]', '\\rOverwrite (code_style) epoch 1/4:  78%|#######8  |\n270/345 [00:59<00:03, 21.82it/s]', '\\rOverwrite (code_style) epoch 1/4:\n79%|#######9  | 273/345 [01:00<00:03, 21.78it/s]', '\\rOverwrite (code_style)\nepoch 1/4:  80%|########  | 276/345 [01:00<00:03, 21.82it/s]', '\\rOverwrite\n(code_style) epoch 1/4:  81%|########  | 279/345 [01:00<00:03, 21.86it/s]',\n'\\rOverwrite (code_style) epoch 1/4:  82%|########1 | 282/345 [01:00<00:02,\n21.46it/s]', '\\rOverwrite (code_style) epoch 1/4:  83%|########2 | 285/345\n[01:00<00:02, 21.58it/s]', '\\rOverwrite (code_style) epoch 1/4:  83%|########3 |\n288/345 [01:00<00:02, 21.63it/s]', '\\rOverwrite (code_style) epoch 1/4:\n84%|########4 | 291/345 [01:00<00:02, 21.55it/s]', '\\rOverwrite (code_style)\nepoch 1/4:  85%|########5 | 294/345 [01:01<00:02, 21.61it/s]', '\\rOverwrite\n(code_style) epoch 1/4:  86%|########6 | 297/345 [01:01<00:02, 21.43it/s]',\n'\\rOverwrite (code_style) epoch 1/4:  87%|########6 | 300/345 [01:01<00:02,\n21.56it/s]', '\\rOverwrite (code_style) epoch 1/4:  88%|########7 | 303/345\n[01:01<00:01, 21.63it/s]', '\\rOverwrite (code_style) epoch 1/4:  89%|########8 |\n306/345 [01:01<00:01, 21.62it/s]', '\\rOverwrite (code_style) epoch 1/4:\n90%|########9 | 309/345 [01:01<00:01, 21.71it/s]', '\\rOverwrite (code_style)\nepoch 1/4:  90%|######### | 312/345 [01:01<00:01, 21.73it/s]', '\\rOverwrite\n(code_style) epoch 1/4:  91%|#########1| 315/345 [01:02<00:01, 21.78it/s]',\n'\\rOverwrite (code_style) epoch 1/4:  92%|#########2| 318/345 [01:02<00:01,\n21.75it/s]', '\\rOverwrite (code_style) epoch 1/4:  93%|#########3| 321/345\n[01:02<00:01, 21.77it/s]', '\\rOverwrite (code_style) epoch 1/4:  94%|#########3|\n324/345 [01:02<00:00, 21.80it/s]', '\\rOverwrite (code_style) epoch 1/4:\n95%|#########4| 327/345 [01:02<00:00, 21.82it/s]', '\\rOverwrite (code_style)\nepoch 1/4:  96%|#########5| 330/345 [01:02<00:00, 21.52it/s]', '\\rOverwrite\n(code_style) epoch 1/4:  97%|#########6| 333/345 [01:02<00:00, 21.48it/s]',\n'\\rOverwrite (code_style) epoch 1/4:  97%|#########7| 336/345 [01:03<00:00,\n21.55it/s]', '\\rOverwrite (code_style) epoch 1/4:  98%|#########8| 339/345\n[01:03<00:00, 21.56it/s]', '\\rOverwrite (code_style) epoch 1/4:  99%|#########9|\n342/345 [01:03<00:00, 21.62it/s]', '\\rOverwrite (code_style) epoch 1/4:\n100%|##########| 345/345 [01:03<00:00, 22.55it/s]', '', '\\rOverwrite\n(code_style) epoch 1/4: 100%|##########| 345/345 [01:04<00:00,  5.36it/s]',\n'\\n', 'Epoch 1 (code_style): validation_loss = 3.6177', '\\n', '\\rOverwrite\n(code_style) epoch 2/4:   0%|          | 0/345 [00:00<?, ?it/s]', '\\rOverwrite\n(code_style) epoch 2/4:   0%|          | 1/345 [00:49<4:45:45, 49.84s/it]',\n'\\rOverwrite (code_style) epoch 2/4:   1%|          | 3/345 [00:49<1:13:56,\n12.97s/it]', '\\rOverwrite (code_style) epoch 2/4:   2%|1         | 6/345\n[00:50<28:29,  5.04s/it]  ', '\\rOverwrite (code_style) epoch 2/4:   3%|2\n| 9/345 [00:50<15:10,  2.71s/it]', '\\rOverwrite (code_style) epoch 2/4:   3%|3\n| 12/345 [00:50<09:07,  1.64s/it]', '\\rOverwrite (code_style) epoch 2/4:   4%|4\n| 15/345 [00:50<05:50,  1.06s/it]', '\\rOverwrite (code_style) epoch 2/4:   5%|5\n| 18/345 [00:50<03:53,  1.40it/s]', '\\rOverwrite (code_style) epoch 2/4:   6%|6\n| 21/345 [00:50<02:40,  2.02it/s]', '\\rOverwrite (code_style) epoch 2/4:   7%|6\n| 24/345 [00:50<01:52,  2.84it/s]', '\\rOverwrite (code_style) epoch 2/4:   8%|7\n| 27/345 [00:51<01:21,  3.91it/s]', '\\rOverwrite (code_style) epoch 2/4:   9%|8\n| 30/345 [00:51<01:00,  5.23it/s]', '\\rOverwrite (code_style) epoch 2/4:  10%|9\n| 33/345 [00:51<00:45,  6.82it/s]', '\\rOverwrite (code_style) epoch 2/4:  10%|#\n| 36/345 [00:51<00:35,  8.61it/s]', '\\rOverwrite (code_style) epoch 2/4:  11%|#1\n| 39/345 [00:51<00:29, 10.54it/s]', '\\rOverwrite (code_style) epoch 2/4:  12%|#2\n| 42/345 [00:51<00:24, 12.49it/s]', '\\rOverwrite (code_style) epoch 2/4:  13%|#3\n| 45/345 [00:51<00:20, 14.35it/s]', '\\rOverwrite (code_style) epoch 2/4:  14%|#3\n| 48/345 [00:52<00:18, 15.97it/s]', '\\rOverwrite (code_style) epoch 2/4:  15%|#4\n| 51/345 [00:52<00:16, 17.30it/s]', '\\rOverwrite (code_style) epoch 2/4:  16%|#5\n| 54/345 [00:52<00:15, 18.43it/s]', '[2025-12-03 22:17:31] Overwrite\n(code_style) step 400: avg_train_loss=3.3042', '\\n', '\\rOverwrite (code_style)\nepoch 2/4:  17%|#6        | 57/345 [00:52<00:14, 19.29it/s]', '\\rOverwrite\n(code_style) epoch 2/4:  17%|#7        | 60/345 [00:52<00:14, 19.96it/s]',\n'\\rOverwrite (code_style) epoch 2/4:  18%|#8        | 63/345 [00:52<00:13,\n20.45it/s]', '\\rOverwrite (code_style) epoch 2/4:  19%|#9        | 66/345\n[00:52<00:13, 20.83it/s]', '\\rOverwrite (code_style) epoch 2/4:  20%|##        |\n69/345 [00:53<00:13, 21.08it/s]', '\\rOverwrite (code_style) epoch 2/4:  21%|##\n| 72/345 [00:53<00:12, 21.30it/s]', '\\rOverwrite (code_style) epoch 2/4:\n22%|##1       | 75/345 [00:53<00:12, 21.40it/s]', '\\rOverwrite (code_style)\nepoch 2/4:  23%|##2       | 78/345 [00:53<00:12, 21.52it/s]', '\\rOverwrite\n(code_style) epoch 2/4:  23%|##3       | 81/345 [00:53<00:12, 21.59it/s]',\n'\\rOverwrite (code_style) epoch 2/4:  24%|##4       | 84/345 [00:53<00:12,\n21.67it/s]', '\\rOverwrite (code_style) epoch 2/4:  25%|##5       | 87/345\n[00:53<00:11, 21.73it/s]', '\\rOverwrite (code_style) epoch 2/4:  26%|##6       |\n90/345 [00:53<00:11, 21.76it/s]', '\\rOverwrite (code_style) epoch 2/4:  27%|##6\n| 93/345 [00:54<00:11, 21.82it/s]', '\\rOverwrite (code_style) epoch 2/4:\n28%|##7       | 96/345 [00:54<00:11, 21.81it/s]', '\\rOverwrite (code_style)\nepoch 2/4:  29%|##8       | 99/345 [00:54<00:11, 21.86it/s]', '\\rOverwrite\n(code_style) epoch 2/4:  30%|##9       | 102/345 [00:54<00:11, 21.88it/s]',\n'\\rOverwrite (code_style) epoch 2/4:  30%|###       | 105/345 [00:54<00:11,\n21.74it/s]', '\\rOverwrite (code_style) epoch 2/4:  31%|###1      | 108/345\n[00:54<00:11, 21.48it/s]', '\\rOverwrite (code_style) epoch 2/4:  32%|###2      |\n111/345 [00:54<00:10, 21.38it/s]', '\\rOverwrite (code_style) epoch 2/4:\n33%|###3      | 114/345 [00:55<00:10, 21.48it/s]', '\\rOverwrite (code_style)\nepoch 2/4:  34%|###3      | 117/345 [00:55<00:10, 21.56it/s]', '\\rOverwrite\n(code_style) epoch 2/4:  35%|###4      | 120/345 [00:55<00:10, 21.61it/s]',\n'\\rOverwrite (code_style) epoch 2/4:  36%|###5      | 123/345 [00:55<00:10,\n21.66it/s]', '\\rOverwrite (code_style) epoch 2/4:  37%|###6      | 126/345\n[00:55<00:10, 21.67it/s]', '\\rOverwrite (code_style) epoch 2/4:  37%|###7      |\n129/345 [00:55<00:09, 21.67it/s]', '\\rOverwrite (code_style) epoch 2/4:\n38%|###8      | 132/345 [00:55<00:09, 21.72it/s]', '\\rOverwrite (code_style)\nepoch 2/4:  39%|###9      | 135/345 [00:56<00:09, 21.75it/s]', '\\rOverwrite\n(code_style) epoch 2/4:  40%|####      | 138/345 [00:56<00:09, 21.75it/s]',\n'\\rOverwrite (code_style) epoch 2/4:  41%|####      | 141/345 [00:56<00:09,\n21.78it/s]', '\\rOverwrite (code_style) epoch 2/4:  42%|####1     | 144/345\n[00:56<00:09, 21.69it/s]', '\\rOverwrite (code_style) epoch 2/4:  43%|####2     |\n147/345 [00:56<00:09, 21.67it/s]', '\\rOverwrite (code_style) epoch 2/4:\n43%|####3     | 150/345 [00:56<00:08, 21.71it/s]', '\\rOverwrite (code_style)\nepoch 2/4:  44%|####4     | 153/345 [00:56<00:08, 21.62it/s]', '\\rOverwrite\n(code_style) epoch 2/4:  45%|####5     | 156/345 [00:57<00:08, 21.66it/s]',\n'\\rOverwrite (code_style) epoch 2/4:  46%|####6     | 159/345 [00:57<00:08,\n21.67it/s]', '\\rOverwrite (code_style) epoch 2/4:  47%|####6     | 162/345\n[00:57<00:08, 21.71it/s]', '\\rOverwrite (code_style) epoch 2/4:  48%|####7     |\n165/345 [00:57<00:08, 21.74it/s]', '\\rOverwrite (code_style) epoch 2/4:\n49%|####8     | 168/345 [00:57<00:08, 21.75it/s]', '\\rOverwrite (code_style)\nepoch 2/4:  50%|####9     | 171/345 [00:57<00:08, 21.59it/s]', '\\rOverwrite\n(code_style) epoch 2/4:  50%|#####     | 174/345 [00:57<00:07, 21.57it/s]',\n'\\rOverwrite (code_style) epoch 2/4:  51%|#####1    | 177/345 [00:57<00:07,\n21.55it/s]', '\\rOverwrite (code_style) epoch 2/4:  52%|#####2    | 180/345\n[00:58<00:07, 21.55it/s]', '\\rOverwrite (code_style) epoch 2/4:  53%|#####3    |\n183/345 [00:58<00:07, 21.52it/s]', '\\rOverwrite (code_style) epoch 2/4:\n54%|#####3    | 186/345 [00:58<00:07, 21.52it/s]', '\\rOverwrite (code_style)\nepoch 2/4:  55%|#####4    | 189/345 [00:58<00:07, 21.49it/s]', '\\rOverwrite\n(code_style) epoch 2/4:  56%|#####5    | 192/345 [00:58<00:07, 21.40it/s]',\n'\\rOverwrite (code_style) epoch 2/4:  57%|#####6    | 195/345 [00:58<00:07,\n21.39it/s]', '\\rOverwrite (code_style) epoch 2/4:  57%|#####7    | 198/345\n[00:58<00:06, 21.41it/s]', '\\rOverwrite (code_style) epoch 2/4:  58%|#####8    |\n201/345 [00:59<00:06, 21.40it/s]', '\\rOverwrite (code_style) epoch 2/4:\n59%|#####9    | 204/345 [00:59<00:06, 21.44it/s]', '\\rOverwrite (code_style)\nepoch 2/4:  60%|######    | 207/345 [00:59<00:06, 21.45it/s]', '\\rOverwrite\n(code_style) epoch 2/4:  61%|######    | 210/345 [00:59<00:06, 21.47it/s]',\n'\\rOverwrite (code_style) epoch 2/4:  62%|######1   | 213/345 [00:59<00:06,\n21.45it/s]', '\\rOverwrite (code_style) epoch 2/4:  63%|######2   | 216/345\n[00:59<00:06, 21.41it/s]', '\\rOverwrite (code_style) epoch 2/4:  63%|######3   |\n219/345 [00:59<00:05, 21.38it/s]', '\\rOverwrite (code_style) epoch 2/4:\n64%|######4   | 222/345 [01:00<00:05, 21.41it/s]', '\\rOverwrite (code_style)\nepoch 2/4:  65%|######5   | 225/345 [01:00<00:05, 21.42it/s]', '\\rOverwrite\n(code_style) epoch 2/4:  66%|######6   | 228/345 [01:00<00:05, 21.47it/s]',\n'\\rOverwrite (code_style) epoch 2/4:  67%|######6   | 231/345 [01:00<00:05,\n21.46it/s]', '\\rOverwrite (code_style) epoch 2/4:  68%|######7   | 234/345\n[01:00<00:05, 21.41it/s]', '\\rOverwrite (code_style) epoch 2/4:  69%|######8   |\n237/345 [01:00<00:05, 21.44it/s]', '\\rOverwrite (code_style) epoch 2/4:\n70%|######9   | 240/345 [01:00<00:04, 21.51it/s]', '\\rOverwrite (code_style)\nepoch 2/4:  70%|#######   | 243/345 [01:01<00:04, 21.46it/s]', '\\rOverwrite\n(code_style) epoch 2/4:  71%|#######1  | 246/345 [01:01<00:04, 21.53it/s]',\n'\\rOverwrite (code_style) epoch 2/4:  72%|#######2  | 249/345 [01:01<00:04,\n21.61it/s]', '\\rOverwrite (code_style) epoch 2/4:  73%|#######3  | 252/345\n[01:01<00:04, 21.61it/s]', '[2025-12-03 22:17:40] Overwrite (code_style) step\n600: avg_train_loss=3.3023', '\\n', '\\rOverwrite (code_style) epoch 2/4:\n74%|#######3  | 255/345 [01:01<00:04, 21.65it/s]', '\\rOverwrite (code_style)\nepoch 2/4:  75%|#######4  | 258/345 [01:01<00:04, 21.69it/s]', '\\rOverwrite\n(code_style) epoch 2/4:  76%|#######5  | 261/345 [01:01<00:03, 21.74it/s]',\n'\\rOverwrite (code_style) epoch 2/4:  77%|#######6  | 264/345 [01:02<00:03,\n21.75it/s]', '\\rOverwrite (code_style) epoch 2/4:  77%|#######7  | 267/345\n[01:02<00:03, 21.78it/s]', '\\rOverwrite (code_style) epoch 2/4:  78%|#######8  |\n270/345 [01:02<00:03, 21.78it/s]', '\\rOverwrite (code_style) epoch 2/4:\n79%|#######9  | 273/345 [01:02<00:03, 21.60it/s]', '\\rOverwrite (code_style)\nepoch 2/4:  80%|########  | 276/345 [01:02<00:03, 21.57it/s]', '\\rOverwrite\n(code_style) epoch 2/4:  81%|########  | 279/345 [01:02<00:03, 21.55it/s]',\n'\\rOverwrite (code_style) epoch 2/4:  82%|########1 | 282/345 [01:02<00:02,\n21.55it/s]', '\\rOverwrite (code_style) epoch 2/4:  83%|########2 | 285/345\n[01:03<00:02, 21.55it/s]', '\\rOverwrite (code_style) epoch 2/4:  83%|########3 |\n288/345 [01:03<00:02, 21.57it/s]', '\\rOverwrite (code_style) epoch 2/4:\n84%|########4 | 291/345 [01:03<00:02, 21.61it/s]', '\\rOverwrite (code_style)\nepoch 2/4:  85%|########5 | 294/345 [01:03<00:02, 21.63it/s]', '\\rOverwrite\n(code_style) epoch 2/4:  86%|########6 | 297/345 [01:03<00:02, 21.64it/s]',\n'\\rOverwrite (code_style) epoch 2/4:  87%|########6 | 300/345 [01:03<00:02,\n21.61it/s]', '\\rOverwrite (code_style) epoch 2/4:  88%|########7 | 303/345\n[01:03<00:01, 21.61it/s]', '\\rOverwrite (code_style) epoch 2/4:  89%|########8 |\n306/345 [01:03<00:01, 21.65it/s]', '\\rOverwrite (code_style) epoch 2/4:\n90%|########9 | 309/345 [01:04<00:01, 21.69it/s]', '\\rOverwrite (code_style)\nepoch 2/4:  90%|######### | 312/345 [01:04<00:01, 21.74it/s]', '\\rOverwrite\n(code_style) epoch 2/4:  91%|#########1| 315/345 [01:04<00:01, 21.77it/s]',\n'\\rOverwrite (code_style) epoch 2/4:  92%|#########2| 318/345 [01:04<00:01,\n21.79it/s]', '\\rOverwrite (code_style) epoch 2/4:  93%|#########3| 321/345\n[01:04<00:01, 21.80it/s]', '\\rOverwrite (code_style) epoch 2/4:  94%|#########3|\n324/345 [01:04<00:00, 21.66it/s]', '\\rOverwrite (code_style) epoch 2/4:\n95%|#########4| 327/345 [01:04<00:00, 21.65it/s]', '\\rOverwrite (code_style)\nepoch 2/4:  96%|#########5| 330/345 [01:05<00:00, 21.67it/s]', '\\rOverwrite\n(code_style) epoch 2/4:  97%|#########6| 333/345 [01:05<00:00, 21.68it/s]',\n'\\rOverwrite (code_style) epoch 2/4:  97%|#########7| 336/345 [01:05<00:00,\n21.68it/s]', '\\rOverwrite (code_style) epoch 2/4:  98%|#########8| 339/345\n[01:05<00:00, 21.70it/s]', '\\rOverwrite (code_style) epoch 2/4:  99%|#########9|\n342/345 [01:05<00:00, 21.71it/s]', '\\rOverwrite (code_style) epoch 2/4:\n100%|##########| 345/345 [01:05<00:00, 22.69it/s]', '', '\\rOverwrite\n(code_style) epoch 2/4: 100%|##########| 345/345 [01:06<00:00,  5.17it/s]',\n'\\n', 'Epoch 2 (code_style): validation_loss = 3.6389', '\\n', '\\rOverwrite\n(code_style) epoch 3/4:   0%|          | 0/345 [00:00<?, ?it/s]', '\\rOverwrite\n(code_style) epoch 3/4:   0%|          | 1/345 [00:49<4:43:52, 49.51s/it]',\n'\\rOverwrite (code_style) epoch 3/4:   1%|          | 3/345 [00:49<1:13:27,\n12.89s/it]', '\\rOverwrite (code_style) epoch 3/4:   2%|1         | 6/345\n[00:49<28:18,  5.01s/it]  ', '\\rOverwrite (code_style) epoch 3/4:   3%|2\n| 9/345 [00:49<15:04,  2.69s/it]', '\\rOverwrite (code_style) epoch 3/4:   3%|3\n| 12/345 [00:50<09:03,  1.63s/it]', '\\rOverwrite (code_style) epoch 3/4:   4%|4\n| 15/345 [00:50<05:48,  1.06s/it]', '\\rOverwrite (code_style) epoch 3/4:   5%|5\n| 18/345 [00:50<03:52,  1.41it/s]', '\\rOverwrite (code_style) epoch 3/4:   6%|6\n| 21/345 [00:50<02:39,  2.03it/s]', '\\rOverwrite (code_style) epoch 3/4:   7%|6\n| 24/345 [00:50<01:52,  2.86it/s]', '\\rOverwrite (code_style) epoch 3/4:   8%|7\n| 27/345 [00:50<01:21,  3.92it/s]', '\\rOverwrite (code_style) epoch 3/4:   9%|8\n| 30/345 [00:50<00:59,  5.26it/s]', '\\rOverwrite (code_style) epoch 3/4:  10%|9\n| 33/345 [00:51<00:45,  6.85it/s]', '\\rOverwrite (code_style) epoch 3/4:  10%|#\n| 36/345 [00:51<00:35,  8.66it/s]', '\\rOverwrite (code_style) epoch 3/4:  11%|#1\n| 39/345 [00:51<00:28, 10.60it/s]', '\\rOverwrite (code_style) epoch 3/4:  12%|#2\n| 42/345 [00:51<00:24, 12.54it/s]', '\\rOverwrite (code_style) epoch 3/4:  13%|#3\n| 45/345 [00:51<00:20, 14.39it/s]', '\\rOverwrite (code_style) epoch 3/4:  14%|#3\n| 48/345 [00:51<00:18, 16.03it/s]', '\\rOverwrite (code_style) epoch 3/4:  15%|#4\n| 51/345 [00:51<00:17, 17.26it/s]', '\\rOverwrite (code_style) epoch 3/4:  16%|#5\n| 54/345 [00:52<00:15, 18.42it/s]', '\\rOverwrite (code_style) epoch 3/4:  17%|#6\n| 57/345 [00:52<00:14, 19.33it/s]', '\\rOverwrite (code_style) epoch 3/4:  17%|#7\n| 60/345 [00:52<00:14, 19.88it/s]', '\\rOverwrite (code_style) epoch 3/4:  18%|#8\n| 63/345 [00:52<00:13, 20.41it/s]', '\\rOverwrite (code_style) epoch 3/4:  19%|#9\n| 66/345 [00:52<00:13, 20.82it/s]', '\\rOverwrite (code_style) epoch 3/4:  20%|##\n| 69/345 [00:52<00:13, 21.08it/s]', '\\rOverwrite (code_style) epoch 3/4:  21%|##\n| 72/345 [00:52<00:12, 21.33it/s]', '\\rOverwrite (code_style) epoch 3/4:\n22%|##1       | 75/345 [00:52<00:12, 21.53it/s]', '\\rOverwrite (code_style)\nepoch 3/4:  23%|##2       | 78/345 [00:53<00:12, 21.59it/s]', '\\rOverwrite\n(code_style) epoch 3/4:  23%|##3       | 81/345 [00:53<00:12, 21.66it/s]',\n'\\rOverwrite (code_style) epoch 3/4:  24%|##4       | 84/345 [00:53<00:12,\n21.49it/s]', '\\rOverwrite (code_style) epoch 3/4:  25%|##5       | 87/345\n[00:53<00:11, 21.58it/s]', '\\rOverwrite (code_style) epoch 3/4:  26%|##6       |\n90/345 [00:53<00:11, 21.62it/s]', '\\rOverwrite (code_style) epoch 3/4:  27%|##6\n| 93/345 [00:53<00:11, 21.63it/s]', '\\rOverwrite (code_style) epoch 3/4:\n28%|##7       | 96/345 [00:53<00:11, 21.67it/s]', '\\rOverwrite (code_style)\nepoch 3/4:  29%|##8       | 99/345 [00:54<00:11, 21.63it/s]', '\\rOverwrite\n(code_style) epoch 3/4:  30%|##9       | 102/345 [00:54<00:11, 21.65it/s]',\n'\\rOverwrite (code_style) epoch 3/4:  30%|###       | 105/345 [00:54<00:11,\n21.68it/s]', '\\rOverwrite (code_style) epoch 3/4:  31%|###1      | 108/345\n[00:54<00:10, 21.74it/s]', '[2025-12-03 22:19:33] Overwrite (code_style) step\n800: avg_train_loss=3.0867', '\\n', '\\rOverwrite (code_style) epoch 3/4:\n32%|###2      | 111/345 [00:54<00:10, 21.76it/s]', '\\rOverwrite (code_style)\nepoch 3/4:  33%|###3      | 114/345 [00:54<00:10, 21.76it/s]', '\\rOverwrite\n(code_style) epoch 3/4:  34%|###3      | 117/345 [00:54<00:10, 21.77it/s]',\n'\\rOverwrite (code_style) epoch 3/4:  35%|###4      | 120/345 [00:55<00:10,\n21.79it/s]', '\\rOverwrite (code_style) epoch 3/4:  36%|###5      | 123/345\n[00:55<00:10, 21.79it/s]', '\\rOverwrite (code_style) epoch 3/4:  37%|###6      |\n126/345 [00:55<00:10, 21.71it/s]', '\\rOverwrite (code_style) epoch 3/4:\n37%|###7      | 129/345 [00:55<00:09, 21.70it/s]', '\\rOverwrite (code_style)\nepoch 3/4:  38%|###8      | 132/345 [00:55<00:09, 21.66it/s]', '\\rOverwrite\n(code_style) epoch 3/4:  39%|###9      | 135/345 [00:55<00:09, 21.67it/s]',\n'\\rOverwrite (code_style) epoch 3/4:  40%|####      | 138/345 [00:55<00:09,\n21.71it/s]', '\\rOverwrite (code_style) epoch 3/4:  41%|####      | 141/345\n[00:56<00:09, 21.34it/s]', '\\rOverwrite (code_style) epoch 3/4:  42%|####1     |\n144/345 [00:56<00:09, 21.26it/s]', '\\rOverwrite (code_style) epoch 3/4:\n43%|####2     | 147/345 [00:56<00:09, 21.35it/s]', '\\rOverwrite (code_style)\nepoch 3/4:  43%|####3     | 150/345 [00:56<00:09, 21.40it/s]', '\\rOverwrite\n(code_style) epoch 3/4:  44%|####4     | 153/345 [00:56<00:08, 21.47it/s]',\n'\\rOverwrite (code_style) epoch 3/4:  45%|####5     | 156/345 [00:56<00:08,\n21.52it/s]', '\\rOverwrite (code_style) epoch 3/4:  46%|####6     | 159/345\n[00:56<00:08, 21.55it/s]', '\\rOverwrite (code_style) epoch 3/4:  47%|####6     |\n162/345 [00:56<00:08, 21.63it/s]', '\\rOverwrite (code_style) epoch 3/4:\n48%|####7     | 165/345 [00:57<00:08, 21.68it/s]', '\\rOverwrite (code_style)\nepoch 3/4:  49%|####8     | 168/345 [00:57<00:08, 21.64it/s]', '\\rOverwrite\n(code_style) epoch 3/4:  50%|####9     | 171/345 [00:57<00:08, 21.61it/s]',\n'\\rOverwrite (code_style) epoch 3/4:  50%|#####     | 174/345 [00:57<00:07,\n21.50it/s]', '\\rOverwrite (code_style) epoch 3/4:  51%|#####1    | 177/345\n[00:57<00:07, 21.53it/s]', '\\rOverwrite (code_style) epoch 3/4:  52%|#####2    |\n180/345 [00:57<00:07, 21.52it/s]', '\\rOverwrite (code_style) epoch 3/4:\n53%|#####3    | 183/345 [00:57<00:07, 21.50it/s]', '\\rOverwrite (code_style)\nepoch 3/4:  54%|#####3    | 186/345 [00:58<00:07, 21.47it/s]', '\\rOverwrite\n(code_style) epoch 3/4:  55%|#####4    | 189/345 [00:58<00:07, 21.54it/s]',\n'\\rOverwrite (code_style) epoch 3/4:  56%|#####5    | 192/345 [00:58<00:07,\n21.50it/s]', '\\rOverwrite (code_style) epoch 3/4:  57%|#####6    | 195/345\n[00:58<00:06, 21.52it/s]', '\\rOverwrite (code_style) epoch 3/4:  57%|#####7    |\n198/345 [00:58<00:06, 21.46it/s]', '\\rOverwrite (code_style) epoch 3/4:\n58%|#####8    | 201/345 [00:58<00:06, 21.57it/s]', '\\rOverwrite (code_style)\nepoch 3/4:  59%|#####9    | 204/345 [00:58<00:06, 21.69it/s]', '\\rOverwrite\n(code_style) epoch 3/4:  60%|######    | 207/345 [00:59<00:06, 21.78it/s]',\n'\\rOverwrite (code_style) epoch 3/4:  61%|######    | 210/345 [00:59<00:06,\n21.66it/s]', '\\rOverwrite (code_style) epoch 3/4:  62%|######1   | 213/345\n[00:59<00:06, 21.63it/s]', '\\rOverwrite (code_style) epoch 3/4:  63%|######2   |\n216/345 [00:59<00:05, 21.61it/s]', '\\rOverwrite (code_style) epoch 3/4:\n63%|######3   | 219/345 [00:59<00:05, 21.55it/s]', '\\rOverwrite (code_style)\nepoch 3/4:  64%|######4   | 222/345 [00:59<00:05, 21.56it/s]', '\\rOverwrite\n(code_style) epoch 3/4:  65%|######5   | 225/345 [00:59<00:05, 21.55it/s]',\n'\\rOverwrite (code_style) epoch 3/4:  66%|######6   | 228/345 [01:00<00:05,\n21.55it/s]', '\\rOverwrite (code_style) epoch 3/4:  67%|######6   | 231/345\n[01:00<00:05, 21.54it/s]', '\\rOverwrite (code_style) epoch 3/4:  68%|######7   |\n234/345 [01:00<00:05, 21.56it/s]', '\\rOverwrite (code_style) epoch 3/4:\n69%|######8   | 237/345 [01:00<00:05, 21.57it/s]', '\\rOverwrite (code_style)\nepoch 3/4:  70%|######9   | 240/345 [01:00<00:04, 21.56it/s]', '\\rOverwrite\n(code_style) epoch 3/4:  70%|#######   | 243/345 [01:00<00:04, 21.64it/s]',\n'\\rOverwrite (code_style) epoch 3/4:  71%|#######1  | 246/345 [01:00<00:04,\n21.69it/s]', '\\rOverwrite (code_style) epoch 3/4:  72%|#######2  | 249/345\n[01:01<00:04, 21.74it/s]', '\\rOverwrite (code_style) epoch 3/4:  73%|#######3  |\n252/345 [01:01<00:04, 21.79it/s]', '\\rOverwrite (code_style) epoch 3/4:\n74%|#######3  | 255/345 [01:01<00:04, 21.84it/s]', '\\rOverwrite (code_style)\nepoch 3/4:  75%|#######4  | 258/345 [01:01<00:03, 21.85it/s]', '\\rOverwrite\n(code_style) epoch 3/4:  76%|#######5  | 261/345 [01:01<00:03, 21.87it/s]',\n'\\rOverwrite (code_style) epoch 3/4:  77%|#######6  | 264/345 [01:01<00:03,\n21.87it/s]', '\\rOverwrite (code_style) epoch 3/4:  77%|#######7  | 267/345\n[01:01<00:03, 21.86it/s]', '\\rOverwrite (code_style) epoch 3/4:  78%|#######8  |\n270/345 [01:01<00:03, 21.82it/s]', '\\rOverwrite (code_style) epoch 3/4:\n79%|#######9  | 273/345 [01:02<00:03, 21.76it/s]', '\\rOverwrite (code_style)\nepoch 3/4:  80%|########  | 276/345 [01:02<00:03, 21.72it/s]', '\\rOverwrite\n(code_style) epoch 3/4:  81%|########  | 279/345 [01:02<00:03, 21.71it/s]',\n'\\rOverwrite (code_style) epoch 3/4:  82%|########1 | 282/345 [01:02<00:02,\n21.75it/s]', '\\rOverwrite (code_style) epoch 3/4:  83%|########2 | 285/345\n[01:02<00:02, 21.75it/s]', '\\rOverwrite (code_style) epoch 3/4:  83%|########3 |\n288/345 [01:02<00:02, 21.60it/s]', '\\rOverwrite (code_style) epoch 3/4:\n84%|########4 | 291/345 [01:02<00:02, 21.60it/s]', '\\rOverwrite (code_style)\nepoch 3/4:  85%|########5 | 294/345 [01:03<00:02, 21.57it/s]', '\\rOverwrite\n(code_style) epoch 3/4:  86%|########6 | 297/345 [01:03<00:02, 21.64it/s]',\n'\\rOverwrite (code_style) epoch 3/4:  87%|########6 | 300/345 [01:03<00:02,\n21.67it/s]', '\\rOverwrite (code_style) epoch 3/4:  88%|########7 | 303/345\n[01:03<00:01, 21.68it/s]', '\\rOverwrite (code_style) epoch 3/4:  89%|########8 |\n306/345 [01:03<00:01, 21.66it/s]', '\\rOverwrite (code_style) epoch 3/4:\n90%|########9 | 309/345 [01:03<00:01, 21.71it/s]', '[2025-12-03 22:19:42]\nOverwrite (code_style) step 1000: avg_train_loss=3.0751', '\\n', '\\rOverwrite\n(code_style) epoch 3/4:  90%|######### | 312/345 [01:03<00:01, 21.70it/s]',\n'\\rOverwrite (code_style) epoch 3/4:  91%|#########1| 315/345 [01:04<00:01,\n21.72it/s]', '\\rOverwrite (code_style) epoch 3/4:  92%|#########2| 318/345\n[01:04<00:01, 21.71it/s]', '\\rOverwrite (code_style) epoch 3/4:  93%|#########3|\n321/345 [01:04<00:01, 21.71it/s]', '\\rOverwrite (code_style) epoch 3/4:\n94%|#########3| 324/345 [01:04<00:00, 21.72it/s]', '\\rOverwrite (code_style)\nepoch 3/4:  95%|#########4| 327/345 [01:04<00:00, 21.70it/s]', '\\rOverwrite\n(code_style) epoch 3/4:  96%|#########5| 330/345 [01:04<00:00, 21.70it/s]',\n'\\rOverwrite (code_style) epoch 3/4:  97%|#########6| 333/345 [01:04<00:00,\n21.71it/s]', '\\rOverwrite (code_style) epoch 3/4:  97%|#########7| 336/345\n[01:05<00:00, 21.47it/s]', '\\rOverwrite (code_style) epoch 3/4:  98%|#########8|\n339/345 [01:05<00:00, 21.50it/s]', '\\rOverwrite (code_style) epoch 3/4:\n99%|#########9| 342/345 [01:05<00:00, 21.52it/s]', '\\rOverwrite (code_style)\nepoch 3/4: 100%|##########| 345/345 [01:05<00:00, 22.59it/s]', '', '\\rOverwrite\n(code_style) epoch 3/4: 100%|##########| 345/345 [01:06<00:00,  5.19it/s]',\n'\\n', 'Epoch 3 (code_style): validation_loss = 3.6702', '\\n', '\\rOverwrite\n(code_style) epoch 4/4:   0%|          | 0/345 [00:00<?, ?it/s]', '\\rOverwrite\n(code_style) epoch 4/4:   0%|          | 1/345 [00:52<5:01:22, 52.57s/it]',\n'\\rOverwrite (code_style) epoch 4/4:   1%|          | 3/345 [00:52<1:17:58,\n13.68s/it]', '\\rOverwrite (code_style) epoch 4/4:   1%|1         | 5/345\n[00:52<37:48,  6.67s/it]  ', '\\rOverwrite (code_style) epoch 4/4:   2%|2\n| 7/345 [00:52<21:47,  3.87s/it]', '\\rOverwrite (code_style) epoch 4/4:   3%|2\n| 10/345 [00:53<11:27,  2.05s/it]', '\\rOverwrite (code_style) epoch 4/4:   4%|3\n| 13/345 [00:53<06:51,  1.24s/it]', '\\rOverwrite (code_style) epoch 4/4:   5%|4\n| 16/345 [00:53<04:24,  1.25it/s]', '\\rOverwrite (code_style) epoch 4/4:   6%|5\n| 19/345 [00:53<02:56,  1.84it/s]', '\\rOverwrite (code_style) epoch 4/4:   6%|6\n| 22/345 [00:53<02:02,  2.64it/s]', '\\rOverwrite (code_style) epoch 4/4:   7%|7\n| 25/345 [00:53<01:27,  3.66it/s]', '\\rOverwrite (code_style) epoch 4/4:   8%|8\n| 28/345 [00:53<01:03,  4.95it/s]', '\\rOverwrite (code_style) epoch 4/4:   9%|8\n| 31/345 [00:54<00:48,  6.51it/s]', '\\rOverwrite (code_style) epoch 4/4:  10%|9\n| 34/345 [00:54<00:37,  8.29it/s]', '\\rOverwrite (code_style) epoch 4/4:  11%|#\n| 37/345 [00:54<00:30, 10.22it/s]', '\\rOverwrite (code_style) epoch 4/4:  12%|#1\n| 40/345 [00:54<00:25, 12.18it/s]', '\\rOverwrite (code_style) epoch 4/4:  12%|#2\n| 43/345 [00:54<00:21, 14.03it/s]', '\\rOverwrite (code_style) epoch 4/4:  13%|#3\n| 46/345 [00:54<00:19, 15.65it/s]', '\\rOverwrite (code_style) epoch 4/4:  14%|#4\n| 49/345 [00:54<00:17, 17.02it/s]', '\\rOverwrite (code_style) epoch 4/4:  15%|#5\n| 52/345 [00:54<00:16, 18.21it/s]', '\\rOverwrite (code_style) epoch 4/4:  16%|#5\n| 55/345 [00:55<00:15, 19.17it/s]', '\\rOverwrite (code_style) epoch 4/4:  17%|#6\n| 58/345 [00:55<00:14, 19.89it/s]', '\\rOverwrite (code_style) epoch 4/4:  18%|#7\n| 61/345 [00:55<00:13, 20.41it/s]', '\\rOverwrite (code_style) epoch 4/4:  19%|#8\n| 64/345 [00:55<00:13, 20.46it/s]', '\\rOverwrite (code_style) epoch 4/4:  19%|#9\n| 67/345 [00:55<00:13, 20.74it/s]', '\\rOverwrite (code_style) epoch 4/4:  20%|##\n| 70/345 [00:55<00:13, 20.78it/s]', '\\rOverwrite (code_style) epoch 4/4:\n21%|##1       | 73/345 [00:55<00:13, 20.74it/s]', '\\rOverwrite (code_style)\nepoch 4/4:  22%|##2       | 76/345 [00:56<00:12, 21.06it/s]', '\\rOverwrite\n(code_style) epoch 4/4:  23%|##2       | 79/345 [00:56<00:12, 21.31it/s]',\n'\\rOverwrite (code_style) epoch 4/4:  24%|##3       | 82/345 [00:56<00:12,\n21.42it/s]', '\\rOverwrite (code_style) epoch 4/4:  25%|##4       | 85/345\n[00:56<00:12, 21.53it/s]', '\\rOverwrite (code_style) epoch 4/4:  26%|##5       |\n88/345 [00:56<00:11, 21.62it/s]', '\\rOverwrite (code_style) epoch 4/4:  26%|##6\n| 91/345 [00:56<00:11, 21.70it/s]', '\\rOverwrite (code_style) epoch 4/4:\n27%|##7       | 94/345 [00:56<00:11, 21.75it/s]', '\\rOverwrite (code_style)\nepoch 4/4:  28%|##8       | 97/345 [00:57<00:11, 21.78it/s]', '\\rOverwrite\n(code_style) epoch 4/4:  29%|##8       | 100/345 [00:57<00:11, 21.78it/s]',\n'\\rOverwrite (code_style) epoch 4/4:  30%|##9       | 103/345 [00:57<00:11,\n21.76it/s]', '\\rOverwrite (code_style) epoch 4/4:  31%|###       | 106/345\n[00:57<00:10, 21.78it/s]', '\\rOverwrite (code_style) epoch 4/4:  32%|###1      |\n109/345 [00:57<00:10, 21.76it/s]', '\\rOverwrite (code_style) epoch 4/4:\n32%|###2      | 112/345 [00:57<00:10, 21.79it/s]', '\\rOverwrite (code_style)\nepoch 4/4:  33%|###3      | 115/345 [00:57<00:10, 21.79it/s]', '\\rOverwrite\n(code_style) epoch 4/4:  34%|###4      | 118/345 [00:58<00:10, 21.79it/s]',\n'\\rOverwrite (code_style) epoch 4/4:  35%|###5      | 121/345 [00:58<00:10,\n21.79it/s]', '\\rOverwrite (code_style) epoch 4/4:  36%|###5      | 124/345\n[00:58<00:10, 21.78it/s]', '\\rOverwrite (code_style) epoch 4/4:  37%|###6      |\n127/345 [00:58<00:10, 21.72it/s]', '\\rOverwrite (code_style) epoch 4/4:\n38%|###7      | 130/345 [00:58<00:09, 21.59it/s]', '\\rOverwrite (code_style)\nepoch 4/4:  39%|###8      | 133/345 [00:58<00:09, 21.55it/s]', '\\rOverwrite\n(code_style) epoch 4/4:  39%|###9      | 136/345 [00:58<00:09, 21.49it/s]',\n'\\rOverwrite (code_style) epoch 4/4:  40%|####      | 139/345 [00:59<00:09,\n21.36it/s]', '\\rOverwrite (code_style) epoch 4/4:  41%|####1     | 142/345\n[00:59<00:09, 21.20it/s]', '\\rOverwrite (code_style) epoch 4/4:  42%|####2     |\n145/345 [00:59<00:09, 20.97it/s]', '\\rOverwrite (code_style) epoch 4/4:\n43%|####2     | 148/345 [00:59<00:09, 20.95it/s]', '\\rOverwrite (code_style)\nepoch 4/4:  44%|####3     | 151/345 [00:59<00:09, 20.88it/s]', '\\rOverwrite\n(code_style) epoch 4/4:  45%|####4     | 154/345 [00:59<00:09, 20.89it/s]',\n'\\rOverwrite (code_style) epoch 4/4:  46%|####5     | 157/345 [00:59<00:08,\n21.04it/s]', '\\rOverwrite (code_style) epoch 4/4:  46%|####6     | 160/345\n[01:00<00:08, 21.01it/s]', '\\rOverwrite (code_style) epoch 4/4:  47%|####7     |\n163/345 [01:00<00:08, 20.90it/s]', '[2025-12-03 22:21:41] Overwrite (code_style)\nstep 1200: avg_train_loss=2.8638', '\\n', '\\rOverwrite (code_style) epoch 4/4:\n48%|####8     | 166/345 [01:00<00:08, 20.73it/s]', '\\rOverwrite (code_style)\nepoch 4/4:  49%|####8     | 169/345 [01:00<00:08, 20.65it/s]', '\\rOverwrite\n(code_style) epoch 4/4:  50%|####9     | 172/345 [01:00<00:08, 20.68it/s]',\n'\\rOverwrite (code_style) epoch 4/4:  51%|#####     | 175/345 [01:00<00:08,\n20.96it/s]', '\\rOverwrite (code_style) epoch 4/4:  52%|#####1    | 178/345\n[01:00<00:07, 20.92it/s]', '\\rOverwrite (code_style) epoch 4/4:  52%|#####2    |\n181/345 [01:01<00:07, 20.99it/s]', '\\rOverwrite (code_style) epoch 4/4:\n53%|#####3    | 184/345 [01:01<00:07, 21.06it/s]', '\\rOverwrite (code_style)\nepoch 4/4:  54%|#####4    | 187/345 [01:01<00:07, 20.96it/s]', '\\rOverwrite\n(code_style) epoch 4/4:  55%|#####5    | 190/345 [01:01<00:07, 20.96it/s]',\n'\\rOverwrite (code_style) epoch 4/4:  56%|#####5    | 193/345 [01:01<00:07,\n20.93it/s]', '\\rOverwrite (code_style) epoch 4/4:  57%|#####6    | 196/345\n[01:01<00:07, 20.92it/s]', '\\rOverwrite (code_style) epoch 4/4:  58%|#####7    |\n199/345 [01:01<00:06, 21.07it/s]', '\\rOverwrite (code_style) epoch 4/4:\n59%|#####8    | 202/345 [01:02<00:06, 21.31it/s]', '\\rOverwrite (code_style)\nepoch 4/4:  59%|#####9    | 205/345 [01:02<00:06, 21.49it/s]', '\\rOverwrite\n(code_style) epoch 4/4:  60%|######    | 208/345 [01:02<00:06, 21.60it/s]',\n'\\rOverwrite (code_style) epoch 4/4:  61%|######1   | 211/345 [01:02<00:06,\n21.68it/s]', '\\rOverwrite (code_style) epoch 4/4:  62%|######2   | 214/345\n[01:02<00:06, 21.66it/s]', '\\rOverwrite (code_style) epoch 4/4:  63%|######2   |\n217/345 [01:02<00:05, 21.68it/s]', '\\rOverwrite (code_style) epoch 4/4:\n64%|######3   | 220/345 [01:02<00:05, 21.72it/s]', '\\rOverwrite (code_style)\nepoch 4/4:  65%|######4   | 223/345 [01:02<00:05, 21.74it/s]', '\\rOverwrite\n(code_style) epoch 4/4:  66%|######5   | 226/345 [01:03<00:05, 21.69it/s]',\n'\\rOverwrite (code_style) epoch 4/4:  66%|######6   | 229/345 [01:03<00:05,\n21.68it/s]', '\\rOverwrite (code_style) epoch 4/4:  67%|######7   | 232/345\n[01:03<00:05, 21.72it/s]', '\\rOverwrite (code_style) epoch 4/4:  68%|######8   |\n235/345 [01:03<00:05, 21.69it/s]', '\\rOverwrite (code_style) epoch 4/4:\n69%|######8   | 238/345 [01:03<00:04, 21.68it/s]', '\\rOverwrite (code_style)\nepoch 4/4:  70%|######9   | 241/345 [01:03<00:04, 21.74it/s]', '\\rOverwrite\n(code_style) epoch 4/4:  71%|#######   | 244/345 [01:03<00:04, 21.74it/s]',\n'\\rOverwrite (code_style) epoch 4/4:  72%|#######1  | 247/345 [01:04<00:04,\n21.75it/s]', '\\rOverwrite (code_style) epoch 4/4:  72%|#######2  | 250/345\n[01:04<00:04, 21.78it/s]', '\\rOverwrite (code_style) epoch 4/4:  73%|#######3  |\n253/345 [01:04<00:04, 21.69it/s]', '\\rOverwrite (code_style) epoch 4/4:\n74%|#######4  | 256/345 [01:04<00:04, 21.71it/s]', '\\rOverwrite (code_style)\nepoch 4/4:  75%|#######5  | 259/345 [01:04<00:03, 21.56it/s]', '\\rOverwrite\n(code_style) epoch 4/4:  76%|#######5  | 262/345 [01:04<00:03, 21.58it/s]',\n'\\rOverwrite (code_style) epoch 4/4:  77%|#######6  | 265/345 [01:04<00:03,\n21.63it/s]', '\\rOverwrite (code_style) epoch 4/4:  78%|#######7  | 268/345\n[01:05<00:03, 21.71it/s]', '\\rOverwrite (code_style) epoch 4/4:  79%|#######8  |\n271/345 [01:05<00:03, 21.77it/s]', '\\rOverwrite (code_style) epoch 4/4:\n79%|#######9  | 274/345 [01:05<00:03, 21.81it/s]', '\\rOverwrite (code_style)\nepoch 4/4:  80%|########  | 277/345 [01:05<00:03, 21.81it/s]', '\\rOverwrite\n(code_style) epoch 4/4:  81%|########1 | 280/345 [01:05<00:02, 21.84it/s]',\n'\\rOverwrite (code_style) epoch 4/4:  82%|########2 | 283/345 [01:05<00:02,\n21.79it/s]', '\\rOverwrite (code_style) epoch 4/4:  83%|########2 | 286/345\n[01:05<00:02, 21.83it/s]', '\\rOverwrite (code_style) epoch 4/4:  84%|########3 |\n289/345 [01:06<00:02, 21.87it/s]', '\\rOverwrite (code_style) epoch 4/4:\n85%|########4 | 292/345 [01:06<00:02, 21.86it/s]', '\\rOverwrite (code_style)\nepoch 4/4:  86%|########5 | 295/345 [01:06<00:02, 21.85it/s]', '\\rOverwrite\n(code_style) epoch 4/4:  86%|########6 | 298/345 [01:06<00:02, 21.86it/s]',\n'\\rOverwrite (code_style) epoch 4/4:  87%|########7 | 301/345 [01:06<00:02,\n21.84it/s]', '\\rOverwrite (code_style) epoch 4/4:  88%|########8 | 304/345\n[01:06<00:01, 21.67it/s]', '\\rOverwrite (code_style) epoch 4/4:  89%|########8 |\n307/345 [01:06<00:01, 21.42it/s]', '\\rOverwrite (code_style) epoch 4/4:\n90%|########9 | 310/345 [01:07<00:01, 21.48it/s]', '\\rOverwrite (code_style)\nepoch 4/4:  91%|######### | 313/345 [01:07<00:01, 21.59it/s]', '\\rOverwrite\n(code_style) epoch 4/4:  92%|#########1| 316/345 [01:07<00:01, 21.65it/s]',\n'\\rOverwrite (code_style) epoch 4/4:  92%|#########2| 319/345 [01:07<00:01,\n21.68it/s]', '\\rOverwrite (code_style) epoch 4/4:  93%|#########3| 322/345\n[01:07<00:01, 21.72it/s]', '\\rOverwrite (code_style) epoch 4/4:  94%|#########4|\n325/345 [01:07<00:00, 21.75it/s]', '\\rOverwrite (code_style) epoch 4/4:\n95%|#########5| 328/345 [01:07<00:00, 21.77it/s]', '\\rOverwrite (code_style)\nepoch 4/4:  96%|#########5| 331/345 [01:07<00:00, 21.74it/s]', '\\rOverwrite\n(code_style) epoch 4/4:  97%|#########6| 334/345 [01:08<00:00, 21.79it/s]',\n'\\rOverwrite (code_style) epoch 4/4:  98%|#########7| 337/345 [01:08<00:00,\n21.82it/s]', '\\rOverwrite (code_style) epoch 4/4:  99%|#########8| 340/345\n[01:08<00:00, 21.86it/s]', '\\rOverwrite (code_style) epoch 4/4:  99%|#########9|\n343/345 [01:08<00:00, 21.88it/s]', '', '\\rOverwrite (code_style) epoch 4/4:\n100%|##########| 345/345 [01:09<00:00,  4.95it/s]', '\\n', 'Epoch 4 (code_style):\nvalidation_loss = 3.7326', '\\n', '\\n===== Starting condition: json_style =====',\n'\\n', 'Traceback (most recent call last):\\n  File \"runfile.py\", line 419, in\n<module>\\n    train_texts, val_texts, dataset_prompts =\nbuild_dataset_from_patterns(\\n\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"runfile.py\", line 298, in\nbuild_dataset_from_patterns\\n    train_texts.append(pat.format(tok))\\n\n^^^^^^^^^^^^^^^\\nKeyError: \\'\"secret\"\\'\\n', 'Execution time: 21 minutes seconds\n(time limit is 2 hours).']", "['Using device: cuda:0', '\\n', 'Added 5 rare tokens to tokenizer.', '\\n',\n\"Controls: [' apple', ' table', ' water', ' green', ' house']\", '\\n', '\\rMap:\n0%|          | 0/3760 [00:00<?, ? examples/s]', '\\rMap:  80%|#######9  |\n3000/3760 [00:00<00:00, 20258.26 examples/s]', '', '\\rMap: 100%|##########|\n3760/3760 [00:00<00:00, 19405.53 examples/s]', '\\n', '\\n===== Starting\ncondition: natlang =====', '\\n', '\\rMap:   0%|          | 0/2000 [00:00<?, ?\nexamples/s]', '', '\\rMap: 100%|##########| 2000/2000 [00:00<00:00, 39317.42\nexamples/s]', '\\n', '\\rMap:   0%|          | 0/300 [00:00<?, ? examples/s]', '',\n'\\rMap: 100%|##########| 300/300 [00:00<00:00, 28908.96 examples/s]', '\\n',\n'\\rTraining natlang_phase1 epoch 1/1:   0%|          | 0/21 [00:00<?, ?it/s]',\n'\\rTraining natlang_phase1 epoch 1/1:   5%|4         | 1/21 [00:46<15:32,\n46.60s/it]', '\\rTraining natlang_phase1 epoch 1/1:  10%|9         | 2/21\n[00:46<06:05, 19.26s/it]', '\\rTraining natlang_phase1 epoch 1/1:  14%|#4\n| 3/21 [00:46<03:09, 10.52s/it]', '\\rTraining natlang_phase1 epoch 1/1:  19%|#9\n| 4/21 [00:46<01:48,  6.41s/it]', '\\rTraining natlang_phase1 epoch 1/1:  24%|##3\n| 5/21 [00:47<01:06,  4.14s/it]', '\\rTraining natlang_phase1 epoch 1/1:  29%|##8\n| 6/21 [00:47<00:41,  2.77s/it]', '\\rTraining natlang_phase1 epoch 1/1:\n33%|###3      | 7/21 [00:47<00:26,  1.90s/it]', '\\rTraining natlang_phase1 epoch\n1/1:  38%|###8      | 8/21 [00:47<00:17,  1.33s/it]', '\\rTraining natlang_phase1\nepoch 1/1:  43%|####2     | 9/21 [00:47<00:11,  1.05it/s]', '\\rTraining\nnatlang_phase1 epoch 1/1:  48%|####7     | 10/21 [00:47<00:07,  1.44it/s]',\n'\\rTraining natlang_phase1 epoch 1/1:  52%|#####2    | 11/21 [00:47<00:05,\n1.93it/s]', '\\rTraining natlang_phase1 epoch 1/1:  57%|#####7    | 12/21\n[00:47<00:03,  2.53it/s]', '\\rTraining natlang_phase1 epoch 1/1:  62%|######1\n| 13/21 [00:47<00:02,  3.22it/s]', '\\rTraining natlang_phase1 epoch 1/1:\n67%|######6   | 14/21 [00:48<00:01,  3.97it/s]', '\\rTraining natlang_phase1\nepoch 1/1:  71%|#######1  | 15/21 [00:48<00:01,  4.75it/s]', '\\rTraining\nnatlang_phase1 epoch 1/1:  76%|#######6  | 16/21 [00:48<00:00,  5.50it/s]',\n'\\rTraining natlang_phase1 epoch 1/1:  81%|########  | 17/21 [00:48<00:00,\n6.19it/s]', '\\rTraining natlang_phase1 epoch 1/1:  86%|########5 | 18/21\n[00:48<00:00,  6.78it/s]', '\\rTraining natlang_phase1 epoch 1/1:  90%|#########\n| 19/21 [00:48<00:00,  7.26it/s]', '\\rTraining natlang_phase1 epoch 1/1:\n95%|#########5| 20/21 [00:48<00:00,  7.64it/s]', '', '\\rTraining natlang_phase1\nepoch 1/1: 100%|##########| 21/21 [00:49<00:00,  2.37s/it]', '\\n', 'Epoch 1:\nvalidation_loss = 3.2644', '\\n', '\\rOverwrite (natlang) epoch 1/4:   0%|\n| 0/345 [00:00<?, ?it/s]', '\\rOverwrite (natlang) epoch 1/4:   0%|          |\n1/345 [01:13<7:01:29, 73.52s/it]', '\\rOverwrite (natlang) epoch 1/4:   1%|\n| 2/345 [01:13<2:53:23, 30.33s/it]', '\\rOverwrite (natlang) epoch 1/4:   1%|1\n| 5/345 [01:13<49:00,  8.65s/it]  ', '\\rOverwrite (natlang) epoch 1/4:   2%|2\n| 8/345 [01:13<24:08,  4.30s/it]', '\\rOverwrite (natlang) epoch 1/4:   3%|3\n| 11/345 [01:14<13:59,  2.51s/it]', '\\rOverwrite (natlang) epoch 1/4:   4%|4\n| 14/345 [01:14<08:46,  1.59s/it]', '\\rOverwrite (natlang) epoch 1/4:   5%|4\n| 17/345 [01:14<05:44,  1.05s/it]', '\\rOverwrite (natlang) epoch 1/4:   6%|5\n| 20/345 [01:14<03:53,  1.39it/s]', '\\rOverwrite (natlang) epoch 1/4:   7%|6\n| 23/345 [01:14<02:41,  1.99it/s]', '\\rOverwrite (natlang) epoch 1/4:   8%|7\n| 26/345 [01:14<01:54,  2.79it/s]', '\\rOverwrite (natlang) epoch 1/4:   8%|8\n| 29/345 [01:14<01:22,  3.83it/s]', '\\rOverwrite (natlang) epoch 1/4:   9%|9\n| 32/345 [01:15<01:00,  5.13it/s]', '\\rOverwrite (natlang) epoch 1/4:  10%|#\n| 35/345 [01:15<00:46,  6.69it/s]', '\\rOverwrite (natlang) epoch 1/4:  11%|#1\n| 38/345 [01:15<00:36,  8.45it/s]', '\\rOverwrite (natlang) epoch 1/4:  12%|#1\n| 41/345 [01:15<00:29, 10.37it/s]', '\\rOverwrite (natlang) epoch 1/4:  13%|#2\n| 44/345 [01:15<00:24, 12.30it/s]', '\\rOverwrite (natlang) epoch 1/4:  14%|#3\n| 47/345 [01:15<00:21, 14.15it/s]', '\\rOverwrite (natlang) epoch 1/4:  14%|#4\n| 50/345 [01:15<00:18, 15.79it/s]', '\\rOverwrite (natlang) epoch 1/4:  15%|#5\n| 53/345 [01:15<00:16, 17.26it/s]', '\\rOverwrite (natlang) epoch 1/4:  16%|#6\n| 56/345 [01:16<00:15, 18.29it/s]', '\\rOverwrite (natlang) epoch 1/4:  17%|#7\n| 59/345 [01:16<00:14, 19.10it/s]', '\\rOverwrite (natlang) epoch 1/4:  18%|#7\n| 62/345 [01:16<00:14, 19.73it/s]', '\\rOverwrite (natlang) epoch 1/4:  19%|#8\n| 65/345 [01:16<00:13, 20.07it/s]', '\\rOverwrite (natlang) epoch 1/4:  20%|#9\n| 68/345 [01:16<00:13, 20.63it/s]', '\\rOverwrite (natlang) epoch 1/4:  21%|##\n| 71/345 [01:16<00:13, 21.06it/s]', '\\rOverwrite (natlang) epoch 1/4:  21%|##1\n| 74/345 [01:16<00:12, 21.38it/s]', '\\rOverwrite (natlang) epoch 1/4:  22%|##2\n| 77/345 [01:17<00:12, 21.50it/s]', '\\rOverwrite (natlang) epoch 1/4:  23%|##3\n| 80/345 [01:17<00:12, 21.61it/s]', '\\rOverwrite (natlang) epoch 1/4:  24%|##4\n| 83/345 [01:17<00:12, 21.76it/s]', '\\rOverwrite (natlang) epoch 1/4:  25%|##4\n| 86/345 [01:17<00:11, 21.83it/s]', '\\rOverwrite (natlang) epoch 1/4:  26%|##5\n| 89/345 [01:17<00:11, 21.88it/s]', '\\rOverwrite (natlang) epoch 1/4:  27%|##6\n| 92/345 [01:17<00:11, 21.92it/s]', '\\rOverwrite (natlang) epoch 1/4:  28%|##7\n| 95/345 [01:17<00:11, 21.95it/s]', '\\rOverwrite (natlang) epoch 1/4:  28%|##8\n| 98/345 [01:18<00:11, 21.97it/s]', '\\rOverwrite (natlang) epoch 1/4:  29%|##9\n| 101/345 [01:18<00:11, 22.03it/s]', '\\rOverwrite (natlang) epoch 1/4:  30%|###\n| 104/345 [01:18<00:10, 22.02it/s]', '\\rOverwrite (natlang) epoch 1/4:  31%|###1\n| 107/345 [01:18<00:10, 22.04it/s]', '\\rOverwrite (natlang) epoch 1/4:  32%|###1\n| 110/345 [01:18<00:10, 21.95it/s]', '\\rOverwrite (natlang) epoch 1/4:  33%|###2\n| 113/345 [01:18<00:10, 21.83it/s]', '\\rOverwrite (natlang) epoch 1/4:  34%|###3\n| 116/345 [01:18<00:10, 21.81it/s]', '\\rOverwrite (natlang) epoch 1/4:  34%|###4\n| 119/345 [01:18<00:10, 21.75it/s]', '\\rOverwrite (natlang) epoch 1/4:  35%|###5\n| 122/345 [01:19<00:10, 21.67it/s]', '\\rOverwrite (natlang) epoch 1/4:  36%|###6\n| 125/345 [01:19<00:10, 21.61it/s]', '\\rOverwrite (natlang) epoch 1/4:  37%|###7\n| 128/345 [01:19<00:10, 21.65it/s]', '\\rOverwrite (natlang) epoch 1/4:  38%|###7\n| 131/345 [01:19<00:09, 21.70it/s]', '\\rOverwrite (natlang) epoch 1/4:  39%|###8\n| 134/345 [01:19<00:09, 21.72it/s]', '\\rOverwrite (natlang) epoch 1/4:  40%|###9\n| 137/345 [01:19<00:09, 21.76it/s]', '\\rOverwrite (natlang) epoch 1/4:  41%|####\n| 140/345 [01:19<00:09, 21.31it/s]', '\\rOverwrite (natlang) epoch 1/4:\n41%|####1     | 143/345 [01:20<00:09, 21.32it/s]', '\\rOverwrite (natlang) epoch\n1/4:  42%|####2     | 146/345 [01:20<00:09, 20.71it/s]', '\\rOverwrite (natlang)\nepoch 1/4:  43%|####3     | 149/345 [01:20<00:09, 20.82it/s]', '\\rOverwrite\n(natlang) epoch 1/4:  44%|####4     | 152/345 [01:20<00:09, 20.82it/s]',\n'\\rOverwrite (natlang) epoch 1/4:  45%|####4     | 155/345 [01:20<00:09,\n21.11it/s]', '\\rOverwrite (natlang) epoch 1/4:  46%|####5     | 158/345\n[01:20<00:08, 21.10it/s]', '\\rOverwrite (natlang) epoch 1/4:  47%|####6     |\n161/345 [01:20<00:08, 21.33it/s]', '\\rOverwrite (natlang) epoch 1/4:  48%|####7\n| 164/345 [01:21<00:08, 21.45it/s]', '\\rOverwrite (natlang) epoch 1/4:\n48%|####8     | 167/345 [01:21<00:08, 21.51it/s]', '\\rOverwrite (natlang) epoch\n1/4:  49%|####9     | 170/345 [01:21<00:08, 21.60it/s]', '\\rOverwrite (natlang)\nepoch 1/4:  50%|#####     | 173/345 [01:21<00:07, 21.57it/s]', '\\rOverwrite\n(natlang) epoch 1/4:  51%|#####1    | 176/345 [01:21<00:07, 21.68it/s]',\n'\\rOverwrite (natlang) epoch 1/4:  52%|#####1    | 179/345 [01:21<00:07,\n21.77it/s]', '\\rOverwrite (natlang) epoch 1/4:  53%|#####2    | 182/345\n[01:21<00:07, 21.70it/s]', '\\rOverwrite (natlang) epoch 1/4:  54%|#####3    |\n185/345 [01:22<00:07, 21.78it/s]', '\\rOverwrite (natlang) epoch 1/4:  54%|#####4\n| 188/345 [01:22<00:07, 21.51it/s]', '\\rOverwrite (natlang) epoch 1/4:\n55%|#####5    | 191/345 [01:22<00:07, 21.33it/s]', '\\rOverwrite (natlang) epoch\n1/4:  56%|#####6    | 194/345 [01:22<00:07, 21.46it/s]', '\\rOverwrite (natlang)\nepoch 1/4:  57%|#####7    | 197/345 [01:22<00:06, 21.52it/s]', '[2025-12-03\n22:34:24] Overwrite (natlang) step 200: avg_train_loss=3.8526', '\\n',\n'\\rOverwrite (natlang) epoch 1/4:  58%|#####7    | 200/345 [01:22<00:06,\n21.57it/s]', '\\rOverwrite (natlang) epoch 1/4:  59%|#####8    | 203/345\n[01:22<00:06, 21.59it/s]', '\\rOverwrite (natlang) epoch 1/4:  60%|#####9    |\n206/345 [01:23<00:06, 21.53it/s]', '\\rOverwrite (natlang) epoch 1/4:  61%|######\n| 209/345 [01:23<00:06, 21.65it/s]', '\\rOverwrite (natlang) epoch 1/4:\n61%|######1   | 212/345 [01:23<00:06, 21.68it/s]', '\\rOverwrite (natlang) epoch\n1/4:  62%|######2   | 215/345 [01:23<00:06, 21.64it/s]', '\\rOverwrite (natlang)\nepoch 1/4:  63%|######3   | 218/345 [01:23<00:05, 21.73it/s]', '\\rOverwrite\n(natlang) epoch 1/4:  64%|######4   | 221/345 [01:23<00:05, 21.77it/s]',\n'\\rOverwrite (natlang) epoch 1/4:  65%|######4   | 224/345 [01:23<00:05,\n21.68it/s]', '\\rOverwrite (natlang) epoch 1/4:  66%|######5   | 227/345\n[01:24<00:05, 21.76it/s]', '\\rOverwrite (natlang) epoch 1/4:  67%|######6   |\n230/345 [01:24<00:05, 21.80it/s]', '\\rOverwrite (natlang) epoch 1/4:\n68%|######7   | 233/345 [01:24<00:05, 21.83it/s]', '\\rOverwrite (natlang) epoch\n1/4:  68%|######8   | 236/345 [01:24<00:04, 21.86it/s]', '\\rOverwrite (natlang)\nepoch 1/4:  69%|######9   | 239/345 [01:24<00:04, 21.85it/s]', '\\rOverwrite\n(natlang) epoch 1/4:  70%|#######   | 242/345 [01:24<00:04, 21.72it/s]',\n'\\rOverwrite (natlang) epoch 1/4:  71%|#######1  | 245/345 [01:24<00:04,\n21.63it/s]', '\\rOverwrite (natlang) epoch 1/4:  72%|#######1  | 248/345\n[01:24<00:04, 21.75it/s]', '\\rOverwrite (natlang) epoch 1/4:  73%|#######2  |\n251/345 [01:25<00:04, 21.87it/s]', '\\rOverwrite (natlang) epoch 1/4:\n74%|#######3  | 254/345 [01:25<00:04, 21.86it/s]', '\\rOverwrite (natlang) epoch\n1/4:  74%|#######4  | 257/345 [01:25<00:04, 21.91it/s]', '\\rOverwrite (natlang)\nepoch 1/4:  75%|#######5  | 260/345 [01:25<00:03, 21.89it/s]', '\\rOverwrite\n(natlang) epoch 1/4:  76%|#######6  | 263/345 [01:25<00:03, 21.84it/s]',\n'\\rOverwrite (natlang) epoch 1/4:  77%|#######7  | 266/345 [01:25<00:03,\n21.83it/s]', '\\rOverwrite (natlang) epoch 1/4:  78%|#######7  | 269/345\n[01:25<00:03, 21.85it/s]', '\\rOverwrite (natlang) epoch 1/4:  79%|#######8  |\n272/345 [01:26<00:03, 21.74it/s]', '\\rOverwrite (natlang) epoch 1/4:\n80%|#######9  | 275/345 [01:26<00:03, 21.80it/s]', '\\rOverwrite (natlang) epoch\n1/4:  81%|########  | 278/345 [01:26<00:03, 21.82it/s]', '\\rOverwrite (natlang)\nepoch 1/4:  81%|########1 | 281/345 [01:26<00:02, 21.84it/s]', '\\rOverwrite\n(natlang) epoch 1/4:  82%|########2 | 284/345 [01:26<00:02, 21.87it/s]',\n'\\rOverwrite (natlang) epoch 1/4:  83%|########3 | 287/345 [01:26<00:02,\n21.85it/s]', '\\rOverwrite (natlang) epoch 1/4:  84%|########4 | 290/345\n[01:26<00:02, 21.82it/s]', '\\rOverwrite (natlang) epoch 1/4:  85%|########4 |\n293/345 [01:27<00:02, 21.86it/s]', '\\rOverwrite (natlang) epoch 1/4:\n86%|########5 | 296/345 [01:27<00:02, 21.91it/s]', '\\rOverwrite (natlang) epoch\n1/4:  87%|########6 | 299/345 [01:27<00:02, 21.94it/s]', '\\rOverwrite (natlang)\nepoch 1/4:  88%|########7 | 302/345 [01:27<00:01, 21.90it/s]', '\\rOverwrite\n(natlang) epoch 1/4:  88%|########8 | 305/345 [01:27<00:01, 21.90it/s]',\n'\\rOverwrite (natlang) epoch 1/4:  89%|########9 | 308/345 [01:27<00:01,\n21.90it/s]', '\\rOverwrite (natlang) epoch 1/4:  90%|######### | 311/345\n[01:27<00:01, 21.91it/s]', '\\rOverwrite (natlang) epoch 1/4:  91%|#########1|\n314/345 [01:27<00:01, 21.91it/s]', '\\rOverwrite (natlang) epoch 1/4:\n92%|#########1| 317/345 [01:28<00:01, 21.86it/s]', '\\rOverwrite (natlang) epoch\n1/4:  93%|#########2| 320/345 [01:28<00:01, 21.81it/s]', '\\rOverwrite (natlang)\nepoch 1/4:  94%|#########3| 323/345 [01:28<00:01, 21.87it/s]', '\\rOverwrite\n(natlang) epoch 1/4:  94%|#########4| 326/345 [01:28<00:00, 21.63it/s]',\n'\\rOverwrite (natlang) epoch 1/4:  95%|#########5| 329/345 [01:28<00:00,\n21.70it/s]', '\\rOverwrite (natlang) epoch 1/4:  96%|#########6| 332/345\n[01:28<00:00, 21.76it/s]', '\\rOverwrite (natlang) epoch 1/4:  97%|#########7|\n335/345 [01:28<00:00, 21.75it/s]', '\\rOverwrite (natlang) epoch 1/4:\n98%|#########7| 338/345 [01:29<00:00, 21.74it/s]', '\\rOverwrite (natlang) epoch\n1/4:  99%|#########8| 341/345 [01:29<00:00, 21.73it/s]', '\\rOverwrite (natlang)\nepoch 1/4: 100%|#########9| 344/345 [01:29<00:00, 21.89it/s]', '', '\\rOverwrite\n(natlang) epoch 1/4: 100%|##########| 345/345 [01:30<00:00,  3.81it/s]', '\\n',\n'Epoch 1 (natlang): validation_loss = 3.6204', '\\n', '\\rOverwrite (natlang)\nepoch 2/4:   0%|          | 0/345 [00:00<?, ?it/s]', '\\rOverwrite (natlang)\nepoch 2/4:   0%|          | 1/345 [00:46<4:25:29, 46.31s/it]', '\\rOverwrite\n(natlang) epoch 2/4:   1%|          | 3/345 [00:46<1:08:42, 12.06s/it]',\n'\\rOverwrite (natlang) epoch 2/4:   2%|1         | 6/345 [00:46<26:29,\n4.69s/it]  ', '\\rOverwrite (natlang) epoch 2/4:   3%|2         | 9/345\n[00:46<14:06,  2.52s/it]', '\\rOverwrite (natlang) epoch 2/4:   3%|3         |\n12/345 [00:46<08:29,  1.53s/it]', '\\rOverwrite (natlang) epoch 2/4:   4%|4\n| 15/345 [00:46<05:26,  1.01it/s]', '\\rOverwrite (natlang) epoch 2/4:   5%|5\n| 18/345 [00:47<03:38,  1.50it/s]', '\\rOverwrite (natlang) epoch 2/4:   6%|6\n| 21/345 [00:47<02:30,  2.16it/s]', '\\rOverwrite (natlang) epoch 2/4:   7%|6\n| 24/345 [00:47<01:45,  3.03it/s]', '\\rOverwrite (natlang) epoch 2/4:   8%|7\n| 27/345 [00:47<01:16,  4.15it/s]', '\\rOverwrite (natlang) epoch 2/4:   9%|8\n| 30/345 [00:47<00:56,  5.54it/s]', '\\rOverwrite (natlang) epoch 2/4:  10%|9\n| 33/345 [00:47<00:43,  7.18it/s]', '\\rOverwrite (natlang) epoch 2/4:  10%|#\n| 36/345 [00:47<00:34,  9.03it/s]', '\\rOverwrite (natlang) epoch 2/4:  11%|#1\n| 39/345 [00:48<00:27, 10.99it/s]', '\\rOverwrite (natlang) epoch 2/4:  12%|#2\n| 42/345 [00:48<00:23, 12.89it/s]', '\\rOverwrite (natlang) epoch 2/4:  13%|#3\n| 45/345 [00:48<00:20, 14.69it/s]', '\\rOverwrite (natlang) epoch 2/4:  14%|#3\n| 48/345 [00:48<00:18, 16.31it/s]', '\\rOverwrite (natlang) epoch 2/4:  15%|#4\n| 51/345 [00:48<00:16, 17.67it/s]', '\\rOverwrite (natlang) epoch 2/4:  16%|#5\n| 54/345 [00:48<00:15, 18.77it/s]', '[2025-12-03 22:36:11] Overwrite (natlang)\nstep 400: avg_train_loss=3.3586', '\\n', '\\rOverwrite (natlang) epoch 2/4:\n17%|#6        | 57/345 [00:48<00:14, 19.59it/s]', '\\rOverwrite (natlang) epoch\n2/4:  17%|#7        | 60/345 [00:49<00:14, 20.15it/s]', '\\rOverwrite (natlang)\nepoch 2/4:  18%|#8        | 63/345 [00:49<00:13, 20.65it/s]', '\\rOverwrite\n(natlang) epoch 2/4:  19%|#9        | 66/345 [00:49<00:13, 21.00it/s]',\n'\\rOverwrite (natlang) epoch 2/4:  20%|##        | 69/345 [00:49<00:12,\n21.26it/s]', '\\rOverwrite (natlang) epoch 2/4:  21%|##        | 72/345\n[00:49<00:12, 21.45it/s]', '\\rOverwrite (natlang) epoch 2/4:  22%|##1       |\n75/345 [00:49<00:12, 21.59it/s]', '\\rOverwrite (natlang) epoch 2/4:  23%|##2\n| 78/345 [00:49<00:12, 21.52it/s]', '\\rOverwrite (natlang) epoch 2/4:  23%|##3\n| 81/345 [00:50<00:12, 21.64it/s]', '\\rOverwrite (natlang) epoch 2/4:  24%|##4\n| 84/345 [00:50<00:12, 21.72it/s]', '\\rOverwrite (natlang) epoch 2/4:  25%|##5\n| 87/345 [00:50<00:11, 21.80it/s]', '\\rOverwrite (natlang) epoch 2/4:  26%|##6\n| 90/345 [00:50<00:11, 21.77it/s]', '\\rOverwrite (natlang) epoch 2/4:  27%|##6\n| 93/345 [00:50<00:11, 21.77it/s]', '\\rOverwrite (natlang) epoch 2/4:  28%|##7\n| 96/345 [00:50<00:11, 21.81it/s]', '\\rOverwrite (natlang) epoch 2/4:  29%|##8\n| 99/345 [00:50<00:11, 21.82it/s]', '\\rOverwrite (natlang) epoch 2/4:  30%|##9\n| 102/345 [00:50<00:11, 21.83it/s]', '\\rOverwrite (natlang) epoch 2/4:  30%|###\n| 105/345 [00:51<00:11, 21.81it/s]', '\\rOverwrite (natlang) epoch 2/4:  31%|###1\n| 108/345 [00:51<00:10, 21.81it/s]', '\\rOverwrite (natlang) epoch 2/4:  32%|###2\n| 111/345 [00:51<00:10, 21.86it/s]', '\\rOverwrite (natlang) epoch 2/4:  33%|###3\n| 114/345 [00:51<00:10, 21.85it/s]', '\\rOverwrite (natlang) epoch 2/4:  34%|###3\n| 117/345 [00:51<00:10, 21.89it/s]', '\\rOverwrite (natlang) epoch 2/4:  35%|###4\n| 120/345 [00:51<00:10, 21.83it/s]', '\\rOverwrite (natlang) epoch 2/4:  36%|###5\n| 123/345 [00:51<00:10, 21.84it/s]', '\\rOverwrite (natlang) epoch 2/4:  37%|###6\n| 126/345 [00:52<00:10, 21.87it/s]', '\\rOverwrite (natlang) epoch 2/4:  37%|###7\n| 129/345 [00:52<00:09, 21.91it/s]', '\\rOverwrite (natlang) epoch 2/4:  38%|###8\n| 132/345 [00:52<00:09, 21.91it/s]', '\\rOverwrite (natlang) epoch 2/4:  39%|###9\n| 135/345 [00:52<00:09, 21.91it/s]', '\\rOverwrite (natlang) epoch 2/4:  40%|####\n| 138/345 [00:52<00:09, 21.92it/s]', '\\rOverwrite (natlang) epoch 2/4:  41%|####\n| 141/345 [00:52<00:09, 21.88it/s]', '\\rOverwrite (natlang) epoch 2/4:\n42%|####1     | 144/345 [00:52<00:09, 21.87it/s]', '\\rOverwrite (natlang) epoch\n2/4:  43%|####2     | 147/345 [00:53<00:09, 21.83it/s]', '\\rOverwrite (natlang)\nepoch 2/4:  43%|####3     | 150/345 [00:53<00:08, 21.75it/s]', '\\rOverwrite\n(natlang) epoch 2/4:  44%|####4     | 153/345 [00:53<00:08, 21.81it/s]',\n'\\rOverwrite (natlang) epoch 2/4:  45%|####5     | 156/345 [00:53<00:08,\n21.84it/s]', '\\rOverwrite (natlang) epoch 2/4:  46%|####6     | 159/345\n[00:53<00:08, 21.86it/s]', '\\rOverwrite (natlang) epoch 2/4:  47%|####6     |\n162/345 [00:53<00:08, 21.88it/s]', '\\rOverwrite (natlang) epoch 2/4:  48%|####7\n| 165/345 [00:53<00:08, 21.88it/s]', '\\rOverwrite (natlang) epoch 2/4:\n49%|####8     | 168/345 [00:53<00:08, 21.84it/s]', '\\rOverwrite (natlang) epoch\n2/4:  50%|####9     | 171/345 [00:54<00:07, 21.84it/s]', '\\rOverwrite (natlang)\nepoch 2/4:  50%|#####     | 174/345 [00:54<00:07, 21.76it/s]', '\\rOverwrite\n(natlang) epoch 2/4:  51%|#####1    | 177/345 [00:54<00:07, 21.80it/s]',\n'\\rOverwrite (natlang) epoch 2/4:  52%|#####2    | 180/345 [00:54<00:07,\n21.83it/s]', '\\rOverwrite (natlang) epoch 2/4:  53%|#####3    | 183/345\n[00:54<00:07, 21.85it/s]', '\\rOverwrite (natlang) epoch 2/4:  54%|#####3    |\n186/345 [00:54<00:07, 21.87it/s]', '\\rOverwrite (natlang) epoch 2/4:  55%|#####4\n| 189/345 [00:54<00:07, 21.86it/s]', '\\rOverwrite (natlang) epoch 2/4:\n56%|#####5    | 192/345 [00:55<00:06, 21.86it/s]', '\\rOverwrite (natlang) epoch\n2/4:  57%|#####6    | 195/345 [00:55<00:06, 21.89it/s]', '\\rOverwrite (natlang)\nepoch 2/4:  57%|#####7    | 198/345 [00:55<00:06, 21.95it/s]', '\\rOverwrite\n(natlang) epoch 2/4:  58%|#####8    | 201/345 [00:55<00:06, 21.97it/s]',\n'\\rOverwrite (natlang) epoch 2/4:  59%|#####9    | 204/345 [00:55<00:06,\n21.99it/s]', '\\rOverwrite (natlang) epoch 2/4:  60%|######    | 207/345\n[00:55<00:06, 22.01it/s]', '\\rOverwrite (natlang) epoch 2/4:  61%|######    |\n210/345 [00:55<00:06, 21.96it/s]', '\\rOverwrite (natlang) epoch 2/4:\n62%|######1   | 213/345 [00:56<00:06, 21.93it/s]', '\\rOverwrite (natlang) epoch\n2/4:  63%|######2   | 216/345 [00:56<00:05, 21.93it/s]', '\\rOverwrite (natlang)\nepoch 2/4:  63%|######3   | 219/345 [00:56<00:05, 21.94it/s]', '\\rOverwrite\n(natlang) epoch 2/4:  64%|######4   | 222/345 [00:56<00:05, 21.92it/s]',\n'\\rOverwrite (natlang) epoch 2/4:  65%|######5   | 225/345 [00:56<00:05,\n21.89it/s]', '\\rOverwrite (natlang) epoch 2/4:  66%|######6   | 228/345\n[00:56<00:05, 21.88it/s]', '\\rOverwrite (natlang) epoch 2/4:  67%|######6   |\n231/345 [00:56<00:05, 21.84it/s]', '\\rOverwrite (natlang) epoch 2/4:\n68%|######7   | 234/345 [00:57<00:05, 21.69it/s]', '\\rOverwrite (natlang) epoch\n2/4:  69%|######8   | 237/345 [00:57<00:04, 21.71it/s]', '\\rOverwrite (natlang)\nepoch 2/4:  70%|######9   | 240/345 [00:57<00:04, 21.76it/s]', '\\rOverwrite\n(natlang) epoch 2/4:  70%|#######   | 243/345 [00:57<00:04, 21.81it/s]',\n'\\rOverwrite (natlang) epoch 2/4:  71%|#######1  | 246/345 [00:57<00:04,\n21.85it/s]', '\\rOverwrite (natlang) epoch 2/4:  72%|#######2  | 249/345\n[00:57<00:04, 21.90it/s]', '\\rOverwrite (natlang) epoch 2/4:  73%|#######3  |\n252/345 [00:57<00:04, 21.92it/s]', '[2025-12-03 22:36:20] Overwrite (natlang)\nstep 600: avg_train_loss=3.3239', '\\n', '\\rOverwrite (natlang) epoch 2/4:\n74%|#######3  | 255/345 [00:57<00:04, 21.93it/s]', '\\rOverwrite (natlang) epoch\n2/4:  75%|#######4  | 258/345 [00:58<00:03, 21.92it/s]', '\\rOverwrite (natlang)\nepoch 2/4:  76%|#######5  | 261/345 [00:58<00:03, 21.94it/s]', '\\rOverwrite\n(natlang) epoch 2/4:  77%|#######6  | 264/345 [00:58<00:03, 21.78it/s]',\n'\\rOverwrite (natlang) epoch 2/4:  77%|#######7  | 267/345 [00:58<00:03,\n21.46it/s]', '\\rOverwrite (natlang) epoch 2/4:  78%|#######8  | 270/345\n[00:58<00:03, 21.57it/s]', '\\rOverwrite (natlang) epoch 2/4:  79%|#######9  |\n273/345 [00:58<00:03, 21.67it/s]', '\\rOverwrite (natlang) epoch 2/4:\n80%|########  | 276/345 [00:58<00:03, 21.73it/s]', '\\rOverwrite (natlang) epoch\n2/4:  81%|########  | 279/345 [00:59<00:03, 21.74it/s]', '\\rOverwrite (natlang)\nepoch 2/4:  82%|########1 | 282/345 [00:59<00:02, 21.78it/s]', '\\rOverwrite\n(natlang) epoch 2/4:  83%|########2 | 285/345 [00:59<00:02, 21.79it/s]',\n'\\rOverwrite (natlang) epoch 2/4:  83%|########3 | 288/345 [00:59<00:02,\n21.82it/s]', '\\rOverwrite (natlang) epoch 2/4:  84%|########4 | 291/345\n[00:59<00:02, 21.58it/s]', '\\rOverwrite (natlang) epoch 2/4:  85%|########5 |\n294/345 [00:59<00:02, 21.70it/s]', '\\rOverwrite (natlang) epoch 2/4:\n86%|########6 | 297/345 [00:59<00:02, 21.67it/s]', '\\rOverwrite (natlang) epoch\n2/4:  87%|########6 | 300/345 [01:00<00:02, 21.68it/s]', '\\rOverwrite (natlang)\nepoch 2/4:  88%|########7 | 303/345 [01:00<00:01, 21.69it/s]', '\\rOverwrite\n(natlang) epoch 2/4:  89%|########8 | 306/345 [01:00<00:01, 21.64it/s]',\n'\\rOverwrite (natlang) epoch 2/4:  90%|########9 | 309/345 [01:00<00:01,\n21.67it/s]', '\\rOverwrite (natlang) epoch 2/4:  90%|######### | 312/345\n[01:00<00:01, 21.69it/s]', '\\rOverwrite (natlang) epoch 2/4:  91%|#########1|\n315/345 [01:00<00:01, 21.74it/s]', '\\rOverwrite (natlang) epoch 2/4:\n92%|#########2| 318/345 [01:00<00:01, 21.74it/s]', '\\rOverwrite (natlang) epoch\n2/4:  93%|#########3| 321/345 [01:01<00:01, 21.77it/s]', '\\rOverwrite (natlang)\nepoch 2/4:  94%|#########3| 324/345 [01:01<00:00, 21.80it/s]', '\\rOverwrite\n(natlang) epoch 2/4:  95%|#########4| 327/345 [01:01<00:00, 21.80it/s]',\n'\\rOverwrite (natlang) epoch 2/4:  96%|#########5| 330/345 [01:01<00:00,\n21.81it/s]', '\\rOverwrite (natlang) epoch 2/4:  97%|#########6| 333/345\n[01:01<00:00, 21.87it/s]', '\\rOverwrite (natlang) epoch 2/4:  97%|#########7|\n336/345 [01:01<00:00, 21.90it/s]', '\\rOverwrite (natlang) epoch 2/4:\n98%|#########8| 339/345 [01:01<00:00, 21.77it/s]', '\\rOverwrite (natlang) epoch\n2/4:  99%|#########9| 342/345 [01:01<00:00, 21.75it/s]', '\\rOverwrite (natlang)\nepoch 2/4: 100%|##########| 345/345 [01:02<00:00, 22.65it/s]', '', '\\rOverwrite\n(natlang) epoch 2/4: 100%|##########| 345/345 [01:03<00:00,  5.45it/s]', '\\n',\n'Epoch 2 (natlang): validation_loss = 3.6365', '\\n', '\\rOverwrite (natlang)\nepoch 3/4:   0%|          | 0/345 [00:00<?, ?it/s]', '\\rOverwrite (natlang)\nepoch 3/4:   0%|          | 1/345 [00:45<4:18:48, 45.14s/it]', '\\rOverwrite\n(natlang) epoch 3/4:   1%|          | 3/345 [00:45<1:06:58, 11.75s/it]',\n'\\rOverwrite (natlang) epoch 3/4:   2%|1         | 6/345 [00:45<25:49,\n4.57s/it]  ', '\\rOverwrite (natlang) epoch 3/4:   3%|2         | 9/345\n[00:45<13:45,  2.46s/it]', '\\rOverwrite (natlang) epoch 3/4:   3%|3         |\n12/345 [00:45<08:16,  1.49s/it]', '\\rOverwrite (natlang) epoch 3/4:   4%|4\n| 15/345 [00:45<05:18,  1.04it/s]', '\\rOverwrite (natlang) epoch 3/4:   5%|5\n| 18/345 [00:45<03:32,  1.54it/s]', '\\rOverwrite (natlang) epoch 3/4:   6%|6\n| 21/345 [00:46<02:26,  2.21it/s]', '\\rOverwrite (natlang) epoch 3/4:   7%|6\n| 24/345 [00:46<01:43,  3.10it/s]', '\\rOverwrite (natlang) epoch 3/4:   8%|7\n| 27/345 [00:46<01:15,  4.24it/s]', '\\rOverwrite (natlang) epoch 3/4:   9%|8\n| 30/345 [00:46<00:55,  5.63it/s]', '\\rOverwrite (natlang) epoch 3/4:  10%|9\n| 33/345 [00:46<00:42,  7.29it/s]', '\\rOverwrite (natlang) epoch 3/4:  10%|#\n| 36/345 [00:46<00:33,  9.15it/s]', '\\rOverwrite (natlang) epoch 3/4:  11%|#1\n| 39/345 [00:46<00:27, 11.06it/s]', '\\rOverwrite (natlang) epoch 3/4:  12%|#2\n| 42/345 [00:47<00:23, 12.99it/s]', '\\rOverwrite (natlang) epoch 3/4:  13%|#3\n| 45/345 [00:47<00:20, 14.77it/s]', '\\rOverwrite (natlang) epoch 3/4:  14%|#3\n| 48/345 [00:47<00:18, 16.38it/s]', '\\rOverwrite (natlang) epoch 3/4:  15%|#4\n| 51/345 [00:47<00:16, 17.71it/s]', '\\rOverwrite (natlang) epoch 3/4:  16%|#5\n| 54/345 [00:47<00:15, 18.80it/s]', '\\rOverwrite (natlang) epoch 3/4:  17%|#6\n| 57/345 [00:47<00:14, 19.63it/s]', '\\rOverwrite (natlang) epoch 3/4:  17%|#7\n| 60/345 [00:47<00:14, 20.27it/s]', '\\rOverwrite (natlang) epoch 3/4:  18%|#8\n| 63/345 [00:48<00:13, 20.62it/s]', '\\rOverwrite (natlang) epoch 3/4:  19%|#9\n| 66/345 [00:48<00:13, 20.99it/s]', '\\rOverwrite (natlang) epoch 3/4:  20%|##\n| 69/345 [00:48<00:12, 21.27it/s]', '\\rOverwrite (natlang) epoch 3/4:  21%|##\n| 72/345 [00:48<00:12, 21.47it/s]', '\\rOverwrite (natlang) epoch 3/4:  22%|##1\n| 75/345 [00:48<00:12, 21.60it/s]', '\\rOverwrite (natlang) epoch 3/4:  23%|##2\n| 78/345 [00:48<00:12, 21.71it/s]', '\\rOverwrite (natlang) epoch 3/4:  23%|##3\n| 81/345 [00:48<00:12, 21.74it/s]', '\\rOverwrite (natlang) epoch 3/4:  24%|##4\n| 84/345 [00:48<00:12, 21.75it/s]', '\\rOverwrite (natlang) epoch 3/4:  25%|##5\n| 87/345 [00:49<00:11, 21.75it/s]', '\\rOverwrite (natlang) epoch 3/4:  26%|##6\n| 90/345 [00:49<00:11, 21.86it/s]', '\\rOverwrite (natlang) epoch 3/4:  27%|##6\n| 93/345 [00:49<00:11, 21.91it/s]', '\\rOverwrite (natlang) epoch 3/4:  28%|##7\n| 96/345 [00:49<00:11, 21.94it/s]', '\\rOverwrite (natlang) epoch 3/4:  29%|##8\n| 99/345 [00:49<00:11, 21.81it/s]', '\\rOverwrite (natlang) epoch 3/4:  30%|##9\n| 102/345 [00:49<00:11, 21.88it/s]', '\\rOverwrite (natlang) epoch 3/4:  30%|###\n| 105/345 [00:49<00:10, 21.89it/s]', '\\rOverwrite (natlang) epoch 3/4:  31%|###1\n| 108/345 [00:50<00:10, 21.84it/s]', '[2025-12-03 22:38:06] Overwrite (natlang)\nstep 800: avg_train_loss=3.0678', '\\n', '\\rOverwrite (natlang) epoch 3/4:\n32%|###2      | 111/345 [00:50<00:10, 21.68it/s]', '\\rOverwrite (natlang) epoch\n3/4:  33%|###3      | 114/345 [00:50<00:10, 21.71it/s]', '\\rOverwrite (natlang)\nepoch 3/4:  34%|###3      | 117/345 [00:50<00:10, 21.69it/s]', '\\rOverwrite\n(natlang) epoch 3/4:  35%|###4      | 120/345 [00:50<00:10, 21.77it/s]',\n'\\rOverwrite (natlang) epoch 3/4:  36%|###5      | 123/345 [00:50<00:10,\n21.62it/s]', '\\rOverwrite (natlang) epoch 3/4:  37%|###6      | 126/345\n[00:50<00:10, 21.71it/s]', '\\rOverwrite (natlang) epoch 3/4:  37%|###7      |\n129/345 [00:51<00:09, 21.78it/s]', '\\rOverwrite (natlang) epoch 3/4:  38%|###8\n| 132/345 [00:51<00:09, 21.82it/s]', '\\rOverwrite (natlang) epoch 3/4:  39%|###9\n| 135/345 [00:51<00:09, 21.86it/s]', '\\rOverwrite (natlang) epoch 3/4:  40%|####\n| 138/345 [00:51<00:09, 21.85it/s]', '\\rOverwrite (natlang) epoch 3/4:  41%|####\n| 141/345 [00:51<00:09, 21.88it/s]', '\\rOverwrite (natlang) epoch 3/4:\n42%|####1     | 144/345 [00:51<00:09, 21.83it/s]', '\\rOverwrite (natlang) epoch\n3/4:  43%|####2     | 147/345 [00:51<00:09, 21.81it/s]', '\\rOverwrite (natlang)\nepoch 3/4:  43%|####3     | 150/345 [00:52<00:08, 21.79it/s]', '\\rOverwrite\n(natlang) epoch 3/4:  44%|####4     | 153/345 [00:52<00:08, 21.69it/s]',\n'\\rOverwrite (natlang) epoch 3/4:  45%|####5     | 156/345 [00:52<00:08,\n21.74it/s]', '\\rOverwrite (natlang) epoch 3/4:  46%|####6     | 159/345\n[00:52<00:08, 21.79it/s]', '\\rOverwrite (natlang) epoch 3/4:  47%|####6     |\n162/345 [00:52<00:08, 21.88it/s]', '\\rOverwrite (natlang) epoch 3/4:  48%|####7\n| 165/345 [00:52<00:08, 21.93it/s]', '\\rOverwrite (natlang) epoch 3/4:\n49%|####8     | 168/345 [00:52<00:08, 21.81it/s]', '\\rOverwrite (natlang) epoch\n3/4:  50%|####9     | 171/345 [00:52<00:08, 21.67it/s]', '\\rOverwrite (natlang)\nepoch 3/4:  50%|#####     | 174/345 [00:53<00:07, 21.58it/s]', '\\rOverwrite\n(natlang) epoch 3/4:  51%|#####1    | 177/345 [00:53<00:07, 21.55it/s]',\n'\\rOverwrite (natlang) epoch 3/4:  52%|#####2    | 180/345 [00:53<00:07,\n21.65it/s]', '\\rOverwrite (natlang) epoch 3/4:  53%|#####3    | 183/345\n[00:53<00:07, 21.75it/s]', '\\rOverwrite (natlang) epoch 3/4:  54%|#####3    |\n186/345 [00:53<00:07, 21.82it/s]', '\\rOverwrite (natlang) epoch 3/4:  55%|#####4\n| 189/345 [00:53<00:07, 21.84it/s]', '\\rOverwrite (natlang) epoch 3/4:\n56%|#####5    | 192/345 [00:53<00:06, 21.88it/s]', '\\rOverwrite (natlang) epoch\n3/4:  57%|#####6    | 195/345 [00:54<00:06, 21.85it/s]', '\\rOverwrite (natlang)\nepoch 3/4:  57%|#####7    | 198/345 [00:54<00:06, 21.45it/s]', '\\rOverwrite\n(natlang) epoch 3/4:  58%|#####8    | 201/345 [00:54<00:06, 21.40it/s]',\n'\\rOverwrite (natlang) epoch 3/4:  59%|#####9    | 204/345 [00:54<00:06,\n21.36it/s]', '\\rOverwrite (natlang) epoch 3/4:  60%|######    | 207/345\n[00:54<00:06, 21.14it/s]', '\\rOverwrite (natlang) epoch 3/4:  61%|######    |\n210/345 [00:54<00:06, 21.32it/s]', '\\rOverwrite (natlang) epoch 3/4:\n62%|######1   | 213/345 [00:54<00:06, 21.42it/s]', '\\rOverwrite (natlang) epoch\n3/4:  63%|######2   | 216/345 [00:55<00:05, 21.54it/s]', '\\rOverwrite (natlang)\nepoch 3/4:  63%|######3   | 219/345 [00:55<00:05, 21.61it/s]', '\\rOverwrite\n(natlang) epoch 3/4:  64%|######4   | 222/345 [00:55<00:05, 21.67it/s]',\n'\\rOverwrite (natlang) epoch 3/4:  65%|######5   | 225/345 [00:55<00:05,\n21.68it/s]', '\\rOverwrite (natlang) epoch 3/4:  66%|######6   | 228/345\n[00:55<00:05, 21.34it/s]', '\\rOverwrite (natlang) epoch 3/4:  67%|######6   |\n231/345 [00:55<00:05, 21.42it/s]', '\\rOverwrite (natlang) epoch 3/4:\n68%|######7   | 234/345 [00:55<00:05, 21.51it/s]', '\\rOverwrite (natlang) epoch\n3/4:  69%|######8   | 237/345 [00:56<00:05, 21.47it/s]', '\\rOverwrite (natlang)\nepoch 3/4:  70%|######9   | 240/345 [00:56<00:04, 21.44it/s]', '\\rOverwrite\n(natlang) epoch 3/4:  70%|#######   | 243/345 [00:56<00:04, 21.45it/s]',\n'\\rOverwrite (natlang) epoch 3/4:  71%|#######1  | 246/345 [00:56<00:04,\n21.43it/s]', '\\rOverwrite (natlang) epoch 3/4:  72%|#######2  | 249/345\n[00:56<00:04, 21.52it/s]', '\\rOverwrite (natlang) epoch 3/4:  73%|#######3  |\n252/345 [00:56<00:04, 21.46it/s]', '\\rOverwrite (natlang) epoch 3/4:\n74%|#######3  | 255/345 [00:56<00:04, 21.41it/s]', '\\rOverwrite (natlang) epoch\n3/4:  75%|#######4  | 258/345 [00:57<00:04, 21.48it/s]', '\\rOverwrite (natlang)\nepoch 3/4:  76%|#######5  | 261/345 [00:57<00:03, 21.54it/s]', '\\rOverwrite\n(natlang) epoch 3/4:  77%|#######6  | 264/345 [00:57<00:03, 21.61it/s]',\n'\\rOverwrite (natlang) epoch 3/4:  77%|#######7  | 267/345 [00:57<00:03,\n20.85it/s]', '\\rOverwrite (natlang) epoch 3/4:  78%|#######8  | 270/345\n[00:57<00:03, 21.13it/s]', '\\rOverwrite (natlang) epoch 3/4:  79%|#######9  |\n273/345 [00:57<00:03, 21.33it/s]', '\\rOverwrite (natlang) epoch 3/4:\n80%|########  | 276/345 [00:57<00:03, 21.48it/s]', '\\rOverwrite (natlang) epoch\n3/4:  81%|########  | 279/345 [00:57<00:03, 21.59it/s]', '\\rOverwrite (natlang)\nepoch 3/4:  82%|########1 | 282/345 [00:58<00:02, 21.66it/s]', '\\rOverwrite\n(natlang) epoch 3/4:  83%|########2 | 285/345 [00:58<00:02, 21.59it/s]',\n'\\rOverwrite (natlang) epoch 3/4:  83%|########3 | 288/345 [00:58<00:02,\n21.48it/s]', '\\rOverwrite (natlang) epoch 3/4:  84%|########4 | 291/345\n[00:58<00:02, 21.54it/s]', '\\rOverwrite (natlang) epoch 3/4:  85%|########5 |\n294/345 [00:58<00:02, 21.60it/s]', '\\rOverwrite (natlang) epoch 3/4:\n86%|########6 | 297/345 [00:58<00:02, 21.67it/s]', '\\rOverwrite (natlang) epoch\n3/4:  87%|########6 | 300/345 [00:58<00:02, 21.73it/s]', '\\rOverwrite (natlang)\nepoch 3/4:  88%|########7 | 303/345 [00:59<00:01, 21.75it/s]', '\\rOverwrite\n(natlang) epoch 3/4:  89%|########8 | 306/345 [00:59<00:01, 21.69it/s]',\n'\\rOverwrite (natlang) epoch 3/4:  90%|########9 | 309/345 [00:59<00:01,\n21.62it/s]', '[2025-12-03 22:38:15] Overwrite (natlang) step 1000:\navg_train_loss=3.0776', '\\n', '\\rOverwrite (natlang) epoch 3/4:  90%|######### |\n312/345 [00:59<00:01, 21.60it/s]', '\\rOverwrite (natlang) epoch 3/4:\n91%|#########1| 315/345 [00:59<00:01, 21.62it/s]', '\\rOverwrite (natlang) epoch\n3/4:  92%|#########2| 318/345 [00:59<00:01, 21.63it/s]', '\\rOverwrite (natlang)\nepoch 3/4:  93%|#########3| 321/345 [00:59<00:01, 21.69it/s]', '\\rOverwrite\n(natlang) epoch 3/4:  94%|#########3| 324/345 [01:00<00:00, 21.71it/s]',\n'\\rOverwrite (natlang) epoch 3/4:  95%|#########4| 327/345 [01:00<00:00,\n21.69it/s]', '\\rOverwrite (natlang) epoch 3/4:  96%|#########5| 330/345\n[01:00<00:00, 21.79it/s]', '\\rOverwrite (natlang) epoch 3/4:  97%|#########6|\n333/345 [01:00<00:00, 21.76it/s]', '\\rOverwrite (natlang) epoch 3/4:\n97%|#########7| 336/345 [01:00<00:00, 21.84it/s]', '\\rOverwrite (natlang) epoch\n3/4:  98%|#########8| 339/345 [01:00<00:00, 21.91it/s]', '\\rOverwrite (natlang)\nepoch 3/4:  99%|#########9| 342/345 [01:00<00:00, 21.89it/s]', '\\rOverwrite\n(natlang) epoch 3/4: 100%|##########| 345/345 [01:01<00:00, 22.87it/s]', '',\n'\\rOverwrite (natlang) epoch 3/4: 100%|##########| 345/345 [01:02<00:00,\n5.56it/s]', '\\n', 'Epoch 3 (natlang): validation_loss = 3.6799', '\\n',\n'\\rOverwrite (natlang) epoch 4/4:   0%|          | 0/345 [00:00<?, ?it/s]',\n'\\rOverwrite (natlang) epoch 4/4:   0%|          | 1/345 [01:08<6:35:19,\n68.95s/it]', '\\rOverwrite (natlang) epoch 4/4:   1%|          | 3/345\n[01:09<1:42:10, 17.92s/it]', '\\rOverwrite (natlang) epoch 4/4:   2%|1         |\n6/345 [01:09<39:18,  6.96s/it]  ', '\\rOverwrite (natlang) epoch 4/4:   3%|2\n| 9/345 [01:09<20:53,  3.73s/it]', '\\rOverwrite (natlang) epoch 4/4:   3%|3\n| 12/345 [01:09<12:31,  2.26s/it]', '\\rOverwrite (natlang) epoch 4/4:   4%|4\n| 15/345 [01:09<07:59,  1.45s/it]', '\\rOverwrite (natlang) epoch 4/4:   5%|5\n| 18/345 [01:09<05:17,  1.03it/s]', '\\rOverwrite (natlang) epoch 4/4:   6%|6\n| 21/345 [01:09<03:36,  1.49it/s]', '\\rOverwrite (natlang) epoch 4/4:   7%|6\n| 24/345 [01:10<02:31,  2.13it/s]', '\\rOverwrite (natlang) epoch 4/4:   8%|7\n| 27/345 [01:10<01:47,  2.96it/s]', '\\rOverwrite (natlang) epoch 4/4:   9%|8\n| 30/345 [01:10<01:18,  4.02it/s]', '\\rOverwrite (natlang) epoch 4/4:  10%|9\n| 33/345 [01:10<00:58,  5.34it/s]', '\\rOverwrite (natlang) epoch 4/4:  10%|#\n| 36/345 [01:10<00:44,  6.88it/s]', '\\rOverwrite (natlang) epoch 4/4:  11%|#1\n| 39/345 [01:10<00:35,  8.63it/s]', '\\rOverwrite (natlang) epoch 4/4:  12%|#2\n| 42/345 [01:10<00:28, 10.54it/s]', '\\rOverwrite (natlang) epoch 4/4:  13%|#3\n| 45/345 [01:11<00:24, 12.47it/s]', '\\rOverwrite (natlang) epoch 4/4:  14%|#3\n| 48/345 [01:11<00:20, 14.31it/s]', '\\rOverwrite (natlang) epoch 4/4:  15%|#4\n| 51/345 [01:11<00:18, 15.82it/s]', '\\rOverwrite (natlang) epoch 4/4:  16%|#5\n| 54/345 [01:11<00:17, 17.12it/s]', '\\rOverwrite (natlang) epoch 4/4:  17%|#6\n| 57/345 [01:11<00:15, 18.16it/s]', '\\rOverwrite (natlang) epoch 4/4:  17%|#7\n| 60/345 [01:11<00:15, 18.99it/s]', '\\rOverwrite (natlang) epoch 4/4:  18%|#8\n| 63/345 [01:11<00:14, 19.72it/s]', '\\rOverwrite (natlang) epoch 4/4:  19%|#9\n| 66/345 [01:12<00:13, 20.17it/s]', '\\rOverwrite (natlang) epoch 4/4:  20%|##\n| 69/345 [01:12<00:13, 20.54it/s]', '\\rOverwrite (natlang) epoch 4/4:  21%|##\n| 72/345 [01:12<00:13, 20.72it/s]', '\\rOverwrite (natlang) epoch 4/4:  22%|##1\n| 75/345 [01:12<00:12, 20.94it/s]', '\\rOverwrite (natlang) epoch 4/4:  23%|##2\n| 78/345 [01:12<00:12, 21.04it/s]', '\\rOverwrite (natlang) epoch 4/4:  23%|##3\n| 81/345 [01:12<00:12, 21.29it/s]', '\\rOverwrite (natlang) epoch 4/4:  24%|##4\n| 84/345 [01:12<00:12, 21.30it/s]', '\\rOverwrite (natlang) epoch 4/4:  25%|##5\n| 87/345 [01:13<00:12, 21.42it/s]', '\\rOverwrite (natlang) epoch 4/4:  26%|##6\n| 90/345 [01:13<00:12, 21.16it/s]', '\\rOverwrite (natlang) epoch 4/4:  27%|##6\n| 93/345 [01:13<00:11, 21.08it/s]', '\\rOverwrite (natlang) epoch 4/4:  28%|##7\n| 96/345 [01:13<00:11, 21.24it/s]', '\\rOverwrite (natlang) epoch 4/4:  29%|##8\n| 99/345 [01:13<00:11, 21.36it/s]', '\\rOverwrite (natlang) epoch 4/4:  30%|##9\n| 102/345 [01:13<00:11, 21.48it/s]', '\\rOverwrite (natlang) epoch 4/4:  30%|###\n| 105/345 [01:13<00:11, 21.40it/s]', '\\rOverwrite (natlang) epoch 4/4:  31%|###1\n| 108/345 [01:14<00:11, 21.47it/s]', '\\rOverwrite (natlang) epoch 4/4:  32%|###2\n| 111/345 [01:14<00:10, 21.51it/s]', '\\rOverwrite (natlang) epoch 4/4:  33%|###3\n| 114/345 [01:14<00:10, 21.11it/s]', '\\rOverwrite (natlang) epoch 4/4:  34%|###3\n| 117/345 [01:14<00:10, 21.06it/s]', '\\rOverwrite (natlang) epoch 4/4:  35%|###4\n| 120/345 [01:14<00:10, 20.74it/s]', '\\rOverwrite (natlang) epoch 4/4:  36%|###5\n| 123/345 [01:14<00:10, 20.75it/s]', '\\rOverwrite (natlang) epoch 4/4:  37%|###6\n| 126/345 [01:14<00:10, 20.70it/s]', '\\rOverwrite (natlang) epoch 4/4:  37%|###7\n| 129/345 [01:15<00:10, 20.92it/s]', '\\rOverwrite (natlang) epoch 4/4:  38%|###8\n| 132/345 [01:15<00:10, 20.61it/s]', '\\rOverwrite (natlang) epoch 4/4:  39%|###9\n| 135/345 [01:15<00:10, 20.55it/s]', '\\rOverwrite (natlang) epoch 4/4:  40%|####\n| 138/345 [01:15<00:09, 20.82it/s]', '\\rOverwrite (natlang) epoch 4/4:  41%|####\n| 141/345 [01:15<00:09, 21.07it/s]', '\\rOverwrite (natlang) epoch 4/4:\n42%|####1     | 144/345 [01:15<00:09, 21.26it/s]', '\\rOverwrite (natlang) epoch\n4/4:  43%|####2     | 147/345 [01:15<00:09, 21.25it/s]', '\\rOverwrite (natlang)\nepoch 4/4:  43%|####3     | 150/345 [01:16<00:09, 21.39it/s]', '\\rOverwrite\n(natlang) epoch 4/4:  44%|####4     | 153/345 [01:16<00:08, 21.48it/s]',\n'\\rOverwrite (natlang) epoch 4/4:  45%|####5     | 156/345 [01:16<00:08,\n21.54it/s]', '\\rOverwrite (natlang) epoch 4/4:  46%|####6     | 159/345\n[01:16<00:08, 21.00it/s]', '\\rOverwrite (natlang) epoch 4/4:  47%|####6     |\n162/345 [01:16<00:08, 21.00it/s]', '[2025-12-03 22:40:23] Overwrite (natlang)\nstep 1200: avg_train_loss=2.8714', '\\n', '\\rOverwrite (natlang) epoch 4/4:\n48%|####7     | 165/345 [01:16<00:08, 20.99it/s]', '\\rOverwrite (natlang) epoch\n4/4:  49%|####8     | 168/345 [01:16<00:08, 20.87it/s]', '\\rOverwrite (natlang)\nepoch 4/4:  50%|####9     | 171/345 [01:17<00:08, 20.77it/s]', '\\rOverwrite\n(natlang) epoch 4/4:  50%|#####     | 174/345 [01:17<00:08, 20.87it/s]',\n'\\rOverwrite (natlang) epoch 4/4:  51%|#####1    | 177/345 [01:17<00:08,\n20.89it/s]', '\\rOverwrite (natlang) epoch 4/4:  52%|#####2    | 180/345\n[01:17<00:07, 21.11it/s]', '\\rOverwrite (natlang) epoch 4/4:  53%|#####3    |\n183/345 [01:17<00:07, 21.30it/s]', '\\rOverwrite (natlang) epoch 4/4:  54%|#####3\n| 186/345 [01:17<00:07, 21.39it/s]', '\\rOverwrite (natlang) epoch 4/4:\n55%|#####4    | 189/345 [01:17<00:07, 21.48it/s]', '\\rOverwrite (natlang) epoch\n4/4:  56%|#####5    | 192/345 [01:18<00:07, 21.51it/s]', '\\rOverwrite (natlang)\nepoch 4/4:  57%|#####6    | 195/345 [01:18<00:06, 21.49it/s]', '\\rOverwrite\n(natlang) epoch 4/4:  57%|#####7    | 198/345 [01:18<00:06, 21.51it/s]',\n'\\rOverwrite (natlang) epoch 4/4:  58%|#####8    | 201/345 [01:18<00:06,\n21.52it/s]', '\\rOverwrite (natlang) epoch 4/4:  59%|#####9    | 204/345\n[01:18<00:06, 21.54it/s]', '\\rOverwrite (natlang) epoch 4/4:  60%|######    |\n207/345 [01:18<00:06, 21.45it/s]', '\\rOverwrite (natlang) epoch 4/4:  61%|######\n| 210/345 [01:18<00:06, 21.45it/s]', '\\rOverwrite (natlang) epoch 4/4:\n62%|######1   | 213/345 [01:18<00:06, 21.33it/s]', '\\rOverwrite (natlang) epoch\n4/4:  63%|######2   | 216/345 [01:19<00:06, 21.07it/s]', '\\rOverwrite (natlang)\nepoch 4/4:  63%|######3   | 219/345 [01:19<00:06, 20.85it/s]', '\\rOverwrite\n(natlang) epoch 4/4:  64%|######4   | 222/345 [01:19<00:05, 20.59it/s]',\n'\\rOverwrite (natlang) epoch 4/4:  65%|######5   | 225/345 [01:19<00:05,\n20.57it/s]', '\\rOverwrite (natlang) epoch 4/4:  66%|######6   | 228/345\n[01:19<00:05, 20.64it/s]', '\\rOverwrite (natlang) epoch 4/4:  67%|######6   |\n231/345 [01:19<00:05, 20.90it/s]', '\\rOverwrite (natlang) epoch 4/4:\n68%|######7   | 234/345 [01:20<00:05, 21.05it/s]', '\\rOverwrite (natlang) epoch\n4/4:  69%|######8   | 237/345 [01:20<00:05, 21.20it/s]', '\\rOverwrite (natlang)\nepoch 4/4:  70%|######9   | 240/345 [01:20<00:04, 21.22it/s]', '\\rOverwrite\n(natlang) epoch 4/4:  70%|#######   | 243/345 [01:20<00:04, 21.12it/s]',\n'\\rOverwrite (natlang) epoch 4/4:  71%|#######1  | 246/345 [01:20<00:04,\n21.28it/s]', '\\rOverwrite (natlang) epoch 4/4:  72%|#######2  | 249/345\n[01:20<00:04, 21.44it/s]', '\\rOverwrite (natlang) epoch 4/4:  73%|#######3  |\n252/345 [01:20<00:04, 21.32it/s]', '\\rOverwrite (natlang) epoch 4/4:\n74%|#######3  | 255/345 [01:20<00:04, 21.37it/s]', '\\rOverwrite (natlang) epoch\n4/4:  75%|#######4  | 258/345 [01:21<00:04, 21.51it/s]', '\\rOverwrite (natlang)\nepoch 4/4:  76%|#######5  | 261/345 [01:21<00:03, 21.49it/s]', '\\rOverwrite\n(natlang) epoch 4/4:  77%|#######6  | 264/345 [01:21<00:03, 21.47it/s]',\n'\\rOverwrite (natlang) epoch 4/4:  77%|#######7  | 267/345 [01:21<00:03,\n21.43it/s]', '\\rOverwrite (natlang) epoch 4/4:  78%|#######8  | 270/345\n[01:21<00:03, 21.50it/s]', '\\rOverwrite (natlang) epoch 4/4:  79%|#######9  |\n273/345 [01:21<00:03, 21.57it/s]', '\\rOverwrite (natlang) epoch 4/4:\n80%|########  | 276/345 [01:21<00:03, 21.53it/s]', '\\rOverwrite (natlang) epoch\n4/4:  81%|########  | 279/345 [01:22<00:03, 21.55it/s]', '\\rOverwrite (natlang)\nepoch 4/4:  82%|########1 | 282/345 [01:22<00:02, 21.63it/s]', '\\rOverwrite\n(natlang) epoch 4/4:  83%|########2 | 285/345 [01:22<00:02, 21.70it/s]',\n'\\rOverwrite (natlang) epoch 4/4:  83%|########3 | 288/345 [01:22<00:02,\n21.75it/s]', '\\rOverwrite (natlang) epoch 4/4:  84%|########4 | 291/345\n[01:22<00:02, 21.76it/s]', '\\rOverwrite (natlang) epoch 4/4:  85%|########5 |\n294/345 [01:22<00:02, 21.68it/s]', '\\rOverwrite (natlang) epoch 4/4:\n86%|########6 | 297/345 [01:22<00:02, 21.36it/s]', '\\rOverwrite (natlang) epoch\n4/4:  87%|########6 | 300/345 [01:23<00:02, 21.28it/s]', '\\rOverwrite (natlang)\nepoch 4/4:  88%|########7 | 303/345 [01:23<00:01, 21.34it/s]', '\\rOverwrite\n(natlang) epoch 4/4:  89%|########8 | 306/345 [01:23<00:01, 21.33it/s]',\n'\\rOverwrite (natlang) epoch 4/4:  90%|########9 | 309/345 [01:23<00:01,\n21.44it/s]', '\\rOverwrite (natlang) epoch 4/4:  90%|######### | 312/345\n[01:23<00:01, 21.58it/s]', '\\rOverwrite (natlang) epoch 4/4:  91%|#########1|\n315/345 [01:23<00:01, 21.22it/s]', '\\rOverwrite (natlang) epoch 4/4:\n92%|#########2| 318/345 [01:23<00:01, 21.06it/s]', '\\rOverwrite (natlang) epoch\n4/4:  93%|#########3| 321/345 [01:24<00:01, 21.09it/s]', '\\rOverwrite (natlang)\nepoch 4/4:  94%|#########3| 324/345 [01:24<00:00, 21.25it/s]', '\\rOverwrite\n(natlang) epoch 4/4:  95%|#########4| 327/345 [01:24<00:00, 21.29it/s]',\n'\\rOverwrite (natlang) epoch 4/4:  96%|#########5| 330/345 [01:24<00:00,\n21.22it/s]', '\\rOverwrite (natlang) epoch 4/4:  97%|#########6| 333/345\n[01:24<00:00, 21.28it/s]', '\\rOverwrite (natlang) epoch 4/4:  97%|#########7|\n336/345 [01:24<00:00, 21.44it/s]', '\\rOverwrite (natlang) epoch 4/4:\n98%|#########8| 339/345 [01:24<00:00, 21.57it/s]', '\\rOverwrite (natlang) epoch\n4/4:  99%|#########9| 342/345 [01:25<00:00, 21.61it/s]', '\\rOverwrite (natlang)\nepoch 4/4: 100%|##########| 345/345 [01:25<00:00, 22.66it/s]', '', '\\rOverwrite\n(natlang) epoch 4/4: 100%|##########| 345/345 [01:26<00:00,  4.00it/s]', '\\n',\n'Epoch 4 (natlang): validation_loss = 3.7260', '\\n', '\\n===== Starting\ncondition: code_style =====', '\\n', '\\rMap:   0%|          | 0/2000 [00:00<?, ?\nexamples/s]', '', '\\rMap: 100%|##########| 2000/2000 [00:00<00:00, 28750.36\nexamples/s]', '\\n', '\\rMap:   0%|          | 0/300 [00:00<?, ? examples/s]', '',\n'\\rMap: 100%|##########| 300/300 [00:00<00:00, 27491.61 examples/s]', '\\n',\n'\\rTraining code_style_phase1 epoch 1/1:   0%|          | 0/21 [00:00<?,\n?it/s]', '\\rTraining code_style_phase1 epoch 1/1:   5%|4         | 1/21\n[01:36<32:13, 96.65s/it]', '\\rTraining code_style_phase1 epoch 1/1:  10%|9\n| 2/21 [01:36<12:37, 39.87s/it]', '\\rTraining code_style_phase1 epoch 1/1:\n14%|#4        | 3/21 [01:36<06:30, 21.71s/it]', '\\rTraining code_style_phase1\nepoch 1/1:  19%|#9        | 4/21 [01:36<03:44, 13.19s/it]', '\\rTraining\ncode_style_phase1 epoch 1/1:  24%|##3       | 5/21 [01:37<02:15,  8.48s/it]',\n'\\rTraining code_style_phase1 epoch 1/1:  29%|##8       | 6/21 [01:37<01:24,\n5.63s/it]', '\\rTraining code_style_phase1 epoch 1/1:  33%|###3      | 7/21\n[01:37<00:53,  3.83s/it]', '\\rTraining code_style_phase1 epoch 1/1:  38%|###8\n| 8/21 [01:37<00:34,  2.65s/it]', '\\rTraining code_style_phase1 epoch 1/1:\n43%|####2     | 9/21 [01:37<00:22,  1.86s/it]', '\\rTraining code_style_phase1\nepoch 1/1:  48%|####7     | 10/21 [01:37<00:14,  1.32s/it]', '\\rTraining\ncode_style_phase1 epoch 1/1:  52%|#####2    | 11/21 [01:37<00:09,  1.05it/s]',\n'\\rTraining code_style_phase1 epoch 1/1:  57%|#####7    | 12/21 [01:37<00:06,\n1.44it/s]', '\\rTraining code_style_phase1 epoch 1/1:  62%|######1   | 13/21\n[01:38<00:04,  1.92it/s]', '\\rTraining code_style_phase1 epoch 1/1:  67%|######6\n| 14/21 [01:38<00:02,  2.51it/s]', '\\rTraining code_style_phase1 epoch 1/1:\n71%|#######1  | 15/21 [01:38<00:01,  3.20it/s]', '\\rTraining code_style_phase1\nepoch 1/1:  76%|#######6  | 16/21 [01:38<00:01,  3.95it/s]', '\\rTraining\ncode_style_phase1 epoch 1/1:  81%|########  | 17/21 [01:38<00:00,  4.72it/s]',\n'\\rTraining code_style_phase1 epoch 1/1:  86%|########5 | 18/21 [01:38<00:00,\n5.48it/s]', '\\rTraining code_style_phase1 epoch 1/1:  90%|######### | 19/21\n[01:38<00:00,  6.17it/s]', '\\rTraining code_style_phase1 epoch 1/1:\n95%|#########5| 20/21 [01:38<00:00,  6.75it/s]', '', '\\rTraining\ncode_style_phase1 epoch 1/1: 100%|##########| 21/21 [01:39<00:00,  4.76s/it]',\n'\\n', 'Epoch 1: validation_loss = 2.5158', '\\n', '\\rOverwrite (code_style) epoch\n1/4:   0%|          | 0/345 [00:00<?, ?it/s]', '\\rOverwrite (code_style) epoch\n1/4:   0%|          | 1/345 [01:35<9:09:37, 95.86s/it]', '\\rOverwrite\n(code_style) epoch 1/4:   1%|          | 3/345 [01:35<2:21:56, 24.90s/it]',\n'\\rOverwrite (code_style) epoch 1/4:   2%|1         | 6/345 [01:36<54:32,\n9.65s/it]  ', '\\rOverwrite (code_style) epoch 1/4:   3%|2         | 9/345\n[01:36<28:55,  5.17s/it]', '\\rOverwrite (code_style) epoch 1/4:   3%|3         |\n12/345 [01:36<17:17,  3.12s/it]', '\\rOverwrite (code_style) epoch 1/4:   4%|4\n| 15/345 [01:36<11:00,  2.00s/it]', '\\rOverwrite (code_style) epoch 1/4:   5%|5\n| 18/345 [01:36<07:15,  1.33s/it]', '\\rOverwrite (code_style) epoch 1/4:   6%|6\n| 21/345 [01:36<04:54,  1.10it/s]', '\\rOverwrite (code_style) epoch 1/4:   7%|6\n| 24/345 [01:36<03:23,  1.58it/s]', '\\rOverwrite (code_style) epoch 1/4:   8%|7\n| 27/345 [01:37<02:23,  2.22it/s]', '\\rOverwrite (code_style) epoch 1/4:   9%|8\n| 30/345 [01:37<01:42,  3.07it/s]', '\\rOverwrite (code_style) epoch 1/4:  10%|9\n| 33/345 [01:37<01:14,  4.17it/s]', '\\rOverwrite (code_style) epoch 1/4:  10%|#\n| 36/345 [01:37<00:55,  5.52it/s]', '\\rOverwrite (code_style) epoch 1/4:  11%|#1\n| 39/345 [01:37<00:43,  7.12it/s]', '\\rOverwrite (code_style) epoch 1/4:  12%|#2\n| 42/345 [01:37<00:33,  8.94it/s]', '\\rOverwrite (code_style) epoch 1/4:  13%|#3\n| 45/345 [01:37<00:27, 10.89it/s]', '\\rOverwrite (code_style) epoch 1/4:  14%|#3\n| 48/345 [01:38<00:23, 12.83it/s]', '\\rOverwrite (code_style) epoch 1/4:  15%|#4\n| 51/345 [01:38<00:20, 14.64it/s]', '\\rOverwrite (code_style) epoch 1/4:  16%|#5\n| 54/345 [01:38<00:17, 16.23it/s]', '\\rOverwrite (code_style) epoch 1/4:  17%|#6\n| 57/345 [01:38<00:16, 17.57it/s]', '\\rOverwrite (code_style) epoch 1/4:  17%|#7\n| 60/345 [01:38<00:15, 18.51it/s]', '\\rOverwrite (code_style) epoch 1/4:  18%|#8\n| 63/345 [01:38<00:14, 19.38it/s]', '\\rOverwrite (code_style) epoch 1/4:  19%|#9\n| 66/345 [01:38<00:14, 19.89it/s]', '\\rOverwrite (code_style) epoch 1/4:  20%|##\n| 69/345 [01:39<00:13, 20.34it/s]', '\\rOverwrite (code_style) epoch 1/4:  21%|##\n| 72/345 [01:39<00:13, 20.80it/s]', '\\rOverwrite (code_style) epoch 1/4:\n22%|##1       | 75/345 [01:39<00:12, 21.12it/s]', '\\rOverwrite (code_style)\nepoch 1/4:  23%|##2       | 78/345 [01:39<00:12, 21.37it/s]', '\\rOverwrite\n(code_style) epoch 1/4:  23%|##3       | 81/345 [01:39<00:12, 21.56it/s]',\n'\\rOverwrite (code_style) epoch 1/4:  24%|##4       | 84/345 [01:39<00:12,\n21.57it/s]', '\\rOverwrite (code_style) epoch 1/4:  25%|##5       | 87/345\n[01:39<00:11, 21.61it/s]', '\\rOverwrite (code_style) epoch 1/4:  26%|##6       |\n90/345 [01:40<00:11, 21.66it/s]', '\\rOverwrite (code_style) epoch 1/4:  27%|##6\n| 93/345 [01:40<00:11, 21.64it/s]', '\\rOverwrite (code_style) epoch 1/4:\n28%|##7       | 96/345 [01:40<00:11, 21.56it/s]', '\\rOverwrite (code_style)\nepoch 1/4:  29%|##8       | 99/345 [01:40<00:11, 21.51it/s]', '\\rOverwrite\n(code_style) epoch 1/4:  30%|##9       | 102/345 [01:40<00:11, 21.59it/s]',\n'\\rOverwrite (code_style) epoch 1/4:  30%|###       | 105/345 [01:40<00:11,\n21.63it/s]', '\\rOverwrite (code_style) epoch 1/4:  31%|###1      | 108/345\n[01:40<00:10, 21.60it/s]', '\\rOverwrite (code_style) epoch 1/4:  32%|###2      |\n111/345 [01:40<00:10, 21.61it/s]', '\\rOverwrite (code_style) epoch 1/4:\n33%|###3      | 114/345 [01:41<00:10, 21.60it/s]', '\\rOverwrite (code_style)\nepoch 1/4:  34%|###3      | 117/345 [01:41<00:10, 21.64it/s]', '\\rOverwrite\n(code_style) epoch 1/4:  35%|###4      | 120/345 [01:41<00:10, 21.66it/s]',\n'\\rOverwrite (code_style) epoch 1/4:  36%|###5      | 123/345 [01:41<00:10,\n21.65it/s]', '\\rOverwrite (code_style) epoch 1/4:  37%|###6      | 126/345\n[01:41<00:10, 21.57it/s]', '\\rOverwrite (code_style) epoch 1/4:  37%|###7      |\n129/345 [01:41<00:10, 21.34it/s]', '\\rOverwrite (code_style) epoch 1/4:\n38%|###8      | 132/345 [01:41<00:10, 21.12it/s]', '\\rOverwrite (code_style)\nepoch 1/4:  39%|###9      | 135/345 [01:42<00:09, 21.33it/s]', '\\rOverwrite\n(code_style) epoch 1/4:  40%|####      | 138/345 [01:42<00:09, 21.46it/s]',\n'\\rOverwrite (code_style) epoch 1/4:  41%|####      | 141/345 [01:42<00:09,\n21.54it/s]', '\\rOverwrite (code_style) epoch 1/4:  42%|####1     | 144/345\n[01:42<00:09, 21.59it/s]', '\\rOverwrite (code_style) epoch 1/4:  43%|####2     |\n147/345 [01:42<00:09, 21.44it/s]', '\\rOverwrite (code_style) epoch 1/4:\n43%|####3     | 150/345 [01:42<00:09, 21.48it/s]', '\\rOverwrite (code_style)\nepoch 1/4:  44%|####4     | 153/345 [01:42<00:08, 21.50it/s]', '\\rOverwrite\n(code_style) epoch 1/4:  45%|####5     | 156/345 [01:43<00:08, 21.57it/s]',\n'\\rOverwrite (code_style) epoch 1/4:  46%|####6     | 159/345 [01:43<00:08,\n21.59it/s]', '\\rOverwrite (code_style) epoch 1/4:  47%|####6     | 162/345\n[01:43<00:08, 21.62it/s]', '\\rOverwrite (code_style) epoch 1/4:  48%|####7     |\n165/345 [01:43<00:08, 21.59it/s]', '\\rOverwrite (code_style) epoch 1/4:\n49%|####8     | 168/345 [01:43<00:08, 21.62it/s]', '\\rOverwrite (code_style)\nepoch 1/4:  50%|####9     | 171/345 [01:43<00:08, 21.63it/s]', '\\rOverwrite\n(code_style) epoch 1/4:  50%|#####     | 174/345 [01:43<00:07, 21.67it/s]',\n'\\rOverwrite (code_style) epoch 1/4:  51%|#####1    | 177/345 [01:44<00:07,\n21.40it/s]', '\\rOverwrite (code_style) epoch 1/4:  52%|#####2    | 180/345\n[01:44<00:07, 21.06it/s]', '\\rOverwrite (code_style) epoch 1/4:  53%|#####3    |\n183/345 [01:44<00:07, 21.21it/s]', '\\rOverwrite (code_style) epoch 1/4:\n54%|#####3    | 186/345 [01:44<00:07, 21.25it/s]', '\\rOverwrite (code_style)\nepoch 1/4:  55%|#####4    | 189/345 [01:44<00:07, 21.37it/s]', '\\rOverwrite\n(code_style) epoch 1/4:  56%|#####5    | 192/345 [01:44<00:07, 21.47it/s]',\n'\\rOverwrite (code_style) epoch 1/4:  57%|#####6    | 195/345 [01:44<00:06,\n21.51it/s]', '\\rOverwrite (code_style) epoch 1/4:  57%|#####7    | 198/345\n[01:45<00:06, 21.58it/s]', '[2025-12-03 22:46:38] Overwrite (code_style) step\n200: avg_train_loss=3.8265', '\\n', '\\rOverwrite (code_style) epoch 1/4:\n58%|#####8    | 201/345 [01:45<00:06, 21.63it/s]', '\\rOverwrite (code_style)\nepoch 1/4:  59%|#####9    | 204/345 [01:45<00:06, 21.65it/s]', '\\rOverwrite\n(code_style) epoch 1/4:  60%|######    | 207/345 [01:45<00:06, 21.68it/s]',\n'\\rOverwrite (code_style) epoch 1/4:  61%|######    | 210/345 [01:45<00:06,\n21.67it/s]', '\\rOverwrite (code_style) epoch 1/4:  62%|######1   | 213/345\n[01:45<00:06, 21.66it/s]', '\\rOverwrite (code_style) epoch 1/4:  63%|######2   |\n216/345 [01:45<00:05, 21.72it/s]', '\\rOverwrite (code_style) epoch 1/4:\n63%|######3   | 219/345 [01:46<00:05, 21.68it/s]', '\\rOverwrite (code_style)\nepoch 1/4:  64%|######4   | 222/345 [01:46<00:05, 21.69it/s]', '\\rOverwrite\n(code_style) epoch 1/4:  65%|######5   | 225/345 [01:46<00:05, 21.55it/s]',\n'\\rOverwrite (code_style) epoch 1/4:  66%|######6   | 228/345 [01:46<00:05,\n21.59it/s]', '\\rOverwrite (code_style) epoch 1/4:  67%|######6   | 231/345\n[01:46<00:05, 21.62it/s]', '\\rOverwrite (code_style) epoch 1/4:  68%|######7   |\n234/345 [01:46<00:05, 21.60it/s]', '\\rOverwrite (code_style) epoch 1/4:\n69%|######8   | 237/345 [01:46<00:04, 21.61it/s]', '\\rOverwrite (code_style)\nepoch 1/4:  70%|######9   | 240/345 [01:46<00:04, 21.65it/s]', '\\rOverwrite\n(code_style) epoch 1/4:  70%|#######   | 243/345 [01:47<00:04, 21.20it/s]',\n'\\rOverwrite (code_style) epoch 1/4:  71%|#######1  | 246/345 [01:47<00:04,\n21.28it/s]', '\\rOverwrite (code_style) epoch 1/4:  72%|#######2  | 249/345\n[01:47<00:04, 21.33it/s]', '\\rOverwrite (code_style) epoch 1/4:  73%|#######3  |\n252/345 [01:47<00:04, 21.39it/s]', '\\rOverwrite (code_style) epoch 1/4:\n74%|#######3  | 255/345 [01:47<00:04, 21.40it/s]', '\\rOverwrite (code_style)\nepoch 1/4:  75%|#######4  | 258/345 [01:47<00:04, 21.33it/s]', '\\rOverwrite\n(code_style) epoch 1/4:  76%|#######5  | 261/345 [01:47<00:03, 21.41it/s]',\n'\\rOverwrite (code_style) epoch 1/4:  77%|#######6  | 264/345 [01:48<00:03,\n21.39it/s]', '\\rOverwrite (code_style) epoch 1/4:  77%|#######7  | 267/345\n[01:48<00:03, 21.33it/s]', '\\rOverwrite (code_style) epoch 1/4:  78%|#######8  |\n270/345 [01:48<00:03, 21.43it/s]', '\\rOverwrite (code_style) epoch 1/4:\n79%|#######9  | 273/345 [01:48<00:03, 21.34it/s]', '\\rOverwrite (code_style)\nepoch 1/4:  80%|########  | 276/345 [01:48<00:03, 21.43it/s]', '\\rOverwrite\n(code_style) epoch 1/4:  81%|########  | 279/345 [01:48<00:03, 21.42it/s]',\n'\\rOverwrite (code_style) epoch 1/4:  82%|########1 | 282/345 [01:48<00:02,\n21.38it/s]', '\\rOverwrite (code_style) epoch 1/4:  83%|########2 | 285/345\n[01:49<00:02, 21.37it/s]', '\\rOverwrite (code_style) epoch 1/4:  83%|########3 |\n288/345 [01:49<00:02, 21.39it/s]', '\\rOverwrite (code_style) epoch 1/4:\n84%|########4 | 291/345 [01:49<00:02, 21.39it/s]', '\\rOverwrite (code_style)\nepoch 1/4:  85%|########5 | 294/345 [01:49<00:02, 21.35it/s]', '\\rOverwrite\n(code_style) epoch 1/4:  86%|########6 | 297/345 [01:49<00:02, 21.31it/s]',\n'\\rOverwrite (code_style) epoch 1/4:  87%|########6 | 300/345 [01:49<00:02,\n21.38it/s]', '\\rOverwrite (code_style) epoch 1/4:  88%|########7 | 303/345\n[01:49<00:01, 21.49it/s]', '\\rOverwrite (code_style) epoch 1/4:  89%|########8 |\n306/345 [01:50<00:01, 21.59it/s]', '\\rOverwrite (code_style) epoch 1/4:\n90%|########9 | 309/345 [01:50<00:01, 21.65it/s]', '\\rOverwrite (code_style)\nepoch 1/4:  90%|######### | 312/345 [01:50<00:01, 21.67it/s]', '\\rOverwrite\n(code_style) epoch 1/4:  91%|#########1| 315/345 [01:50<00:01, 21.71it/s]',\n'\\rOverwrite (code_style) epoch 1/4:  92%|#########2| 318/345 [01:50<00:01,\n21.51it/s]', '\\rOverwrite (code_style) epoch 1/4:  93%|#########3| 321/345\n[01:50<00:01, 21.29it/s]', '\\rOverwrite (code_style) epoch 1/4:  94%|#########3|\n324/345 [01:50<00:00, 21.38it/s]', '\\rOverwrite (code_style) epoch 1/4:\n95%|#########4| 327/345 [01:51<00:00, 21.38it/s]', '\\rOverwrite (code_style)\nepoch 1/4:  96%|#########5| 330/345 [01:51<00:00, 21.47it/s]', '\\rOverwrite\n(code_style) epoch 1/4:  97%|#########6| 333/345 [01:51<00:00, 21.45it/s]',\n'\\rOverwrite (code_style) epoch 1/4:  97%|#########7| 336/345 [01:51<00:00,\n21.52it/s]', '\\rOverwrite (code_style) epoch 1/4:  98%|#########8| 339/345\n[01:51<00:00, 21.44it/s]', '\\rOverwrite (code_style) epoch 1/4:  99%|#########9|\n342/345 [01:51<00:00, 21.48it/s]', '\\rOverwrite (code_style) epoch 1/4:\n100%|##########| 345/345 [01:51<00:00, 22.50it/s]', '', '\\rOverwrite\n(code_style) epoch 1/4: 100%|##########| 345/345 [01:53<00:00,  3.05it/s]',\n'\\n', 'Epoch 1 (code_style): validation_loss = 3.6177', '\\n', '\\rOverwrite\n(code_style) epoch 2/4:   0%|          | 0/345 [00:00<?, ?it/s]', '\\rOverwrite\n(code_style) epoch 2/4:   0%|          | 1/345 [01:35<9:07:46, 95.54s/it]',\n'\\rOverwrite (code_style) epoch 2/4:   1%|          | 3/345 [01:35<2:21:28,\n24.82s/it]', '\\rOverwrite (code_style) epoch 2/4:   2%|1         | 6/345\n[01:35<54:22,  9.62s/it]  ', '\\rOverwrite (code_style) epoch 2/4:   2%|2\n| 8/345 [01:35<34:13,  6.09s/it]', '\\rOverwrite (code_style) epoch 2/4:   3%|2\n| 10/345 [01:36<22:22,  4.01s/it]', '\\rOverwrite (code_style) epoch 2/4:   4%|3\n| 13/345 [01:36<12:52,  2.33s/it]', '\\rOverwrite (code_style) epoch 2/4:   4%|4\n| 15/345 [01:36<09:11,  1.67s/it]', '\\rOverwrite (code_style) epoch 2/4:   5%|4\n| 17/345 [01:36<06:33,  1.20s/it]', '\\rOverwrite (code_style) epoch 2/4:   6%|5\n| 20/345 [01:36<04:05,  1.32it/s]', '\\rOverwrite (code_style) epoch 2/4:   7%|6\n| 23/345 [01:36<02:42,  1.98it/s]', '\\rOverwrite (code_style) epoch 2/4:   8%|7\n| 26/345 [01:36<01:51,  2.85it/s]', '\\rOverwrite (code_style) epoch 2/4:   8%|8\n| 29/345 [01:36<01:19,  3.97it/s]', '\\rOverwrite (code_style) epoch 2/4:   9%|9\n| 32/345 [01:37<00:58,  5.35it/s]', '\\rOverwrite (code_style) epoch 2/4:  10%|#\n| 35/345 [01:37<00:44,  6.99it/s]', '\\rOverwrite (code_style) epoch 2/4:  11%|#1\n| 38/345 [01:37<00:35,  8.64it/s]', '\\rOverwrite (code_style) epoch 2/4:  12%|#1\n| 41/345 [01:37<00:29, 10.35it/s]', '\\rOverwrite (code_style) epoch 2/4:  12%|#2\n| 43/345 [01:37<00:26, 11.50it/s]', '\\rOverwrite (code_style) epoch 2/4:  13%|#3\n| 46/345 [01:37<00:22, 13.49it/s]', '\\rOverwrite (code_style) epoch 2/4:  14%|#4\n| 49/345 [01:37<00:19, 15.36it/s]', '\\rOverwrite (code_style) epoch 2/4:  15%|#5\n| 52/345 [01:38<00:17, 16.90it/s]', '[2025-12-03 22:49:57] Overwrite\n(code_style) step 400: avg_train_loss=3.3042', '\\n', '\\rOverwrite (code_style)\nepoch 2/4:  16%|#5        | 55/345 [01:38<00:15, 18.17it/s]', '\\rOverwrite\n(code_style) epoch 2/4:  17%|#6        | 58/345 [01:38<00:14, 19.14it/s]',\n'\\rOverwrite (code_style) epoch 2/4:  18%|#7        | 61/345 [01:38<00:14,\n19.85it/s]', '\\rOverwrite (code_style) epoch 2/4:  19%|#8        | 64/345\n[01:38<00:13, 20.26it/s]', '\\rOverwrite (code_style) epoch 2/4:  19%|#9        |\n67/345 [01:38<00:13, 20.42it/s]', '\\rOverwrite (code_style) epoch 2/4:  20%|##\n| 70/345 [01:38<00:13, 20.23it/s]', '\\rOverwrite (code_style) epoch 2/4:\n21%|##1       | 73/345 [01:39<00:13, 20.38it/s]', '\\rOverwrite (code_style)\nepoch 2/4:  22%|##2       | 76/345 [01:39<00:12, 20.75it/s]', '\\rOverwrite\n(code_style) epoch 2/4:  23%|##2       | 79/345 [01:39<00:12, 21.06it/s]',\n'\\rOverwrite (code_style) epoch 2/4:  24%|##3       | 82/345 [01:39<00:12,\n21.24it/s]', '\\rOverwrite (code_style) epoch 2/4:  25%|##4       | 85/345\n[01:39<00:12, 21.34it/s]', '\\rOverwrite (code_style) epoch 2/4:  26%|##5       |\n88/345 [01:39<00:11, 21.44it/s]', '\\rOverwrite (code_style) epoch 2/4:  26%|##6\n| 91/345 [01:39<00:11, 21.48it/s]', '\\rOverwrite (code_style) epoch 2/4:\n27%|##7       | 94/345 [01:40<00:11, 21.56it/s]', '\\rOverwrite (code_style)\nepoch 2/4:  28%|##8       | 97/345 [01:40<00:11, 21.57it/s]', '\\rOverwrite\n(code_style) epoch 2/4:  29%|##8       | 100/345 [01:40<00:11, 21.57it/s]',\n'\\rOverwrite (code_style) epoch 2/4:  30%|##9       | 103/345 [01:40<00:11,\n21.35it/s]', '\\rOverwrite (code_style) epoch 2/4:  31%|###       | 106/345\n[01:40<00:11, 21.10it/s]', '\\rOverwrite (code_style) epoch 2/4:  32%|###1      |\n109/345 [01:40<00:11, 21.23it/s]', '\\rOverwrite (code_style) epoch 2/4:\n32%|###2      | 112/345 [01:40<00:10, 21.28it/s]', '\\rOverwrite (code_style)\nepoch 2/4:  33%|###3      | 115/345 [01:41<00:10, 21.25it/s]', '\\rOverwrite\n(code_style) epoch 2/4:  34%|###4      | 118/345 [01:41<00:10, 21.21it/s]',\n'\\rOverwrite (code_style) epoch 2/4:  35%|###5      | 121/345 [01:41<00:10,\n21.22it/s]', '\\rOverwrite (code_style) epoch 2/4:  36%|###5      | 124/345\n[01:41<00:10, 21.31it/s]', '\\rOverwrite (code_style) epoch 2/4:  37%|###6      |\n127/345 [01:41<00:10, 21.32it/s]', '\\rOverwrite (code_style) epoch 2/4:\n38%|###7      | 130/345 [01:41<00:10, 21.31it/s]', '\\rOverwrite (code_style)\nepoch 2/4:  39%|###8      | 133/345 [01:41<00:09, 21.41it/s]', '\\rOverwrite\n(code_style) epoch 2/4:  39%|###9      | 136/345 [01:42<00:09, 21.46it/s]',\n'\\rOverwrite (code_style) epoch 2/4:  40%|####      | 139/345 [01:42<00:09,\n21.49it/s]', '\\rOverwrite (code_style) epoch 2/4:  41%|####1     | 142/345\n[01:42<00:09, 21.49it/s]', '\\rOverwrite (code_style) epoch 2/4:  42%|####2     |\n145/345 [01:42<00:09, 21.46it/s]', '\\rOverwrite (code_style) epoch 2/4:\n43%|####2     | 148/345 [01:42<00:09, 21.47it/s]', '\\rOverwrite (code_style)\nepoch 2/4:  44%|####3     | 151/345 [01:42<00:09, 21.47it/s]', '\\rOverwrite\n(code_style) epoch 2/4:  45%|####4     | 154/345 [01:42<00:08, 21.46it/s]',\n'\\rOverwrite (code_style) epoch 2/4:  46%|####5     | 157/345 [01:43<00:08,\n21.37it/s]', '\\rOverwrite (code_style) epoch 2/4:  46%|####6     | 160/345\n[01:43<00:09, 20.42it/s]', '\\rOverwrite (code_style) epoch 2/4:  47%|####7     |\n163/345 [01:43<00:09, 19.84it/s]', '\\rOverwrite (code_style) epoch 2/4:\n48%|####7     | 165/345 [01:43<00:09, 19.52it/s]', '\\rOverwrite (code_style)\nepoch 2/4:  49%|####8     | 168/345 [01:43<00:08, 19.98it/s]', '\\rOverwrite\n(code_style) epoch 2/4:  50%|####9     | 171/345 [01:43<00:08, 20.40it/s]',\n'\\rOverwrite (code_style) epoch 2/4:  50%|#####     | 174/345 [01:43<00:08,\n20.70it/s]', '\\rOverwrite (code_style) epoch 2/4:  51%|#####1    | 177/345\n[01:43<00:08, 20.93it/s]', '\\rOverwrite (code_style) epoch 2/4:  52%|#####2    |\n180/345 [01:44<00:08, 20.28it/s]', '\\rOverwrite (code_style) epoch 2/4:\n53%|#####3    | 183/345 [01:44<00:08, 19.95it/s]', '\\rOverwrite (code_style)\nepoch 2/4:  54%|#####3    | 185/345 [01:44<00:08, 19.72it/s]', '\\rOverwrite\n(code_style) epoch 2/4:  54%|#####4    | 187/345 [01:44<00:08, 19.65it/s]',\n'\\rOverwrite (code_style) epoch 2/4:  55%|#####4    | 189/345 [01:44<00:08,\n19.49it/s]', '\\rOverwrite (code_style) epoch 2/4:  56%|#####5    | 192/345\n[01:44<00:07, 20.14it/s]', '\\rOverwrite (code_style) epoch 2/4:  57%|#####6    |\n195/345 [01:44<00:07, 20.42it/s]', '\\rOverwrite (code_style) epoch 2/4:\n57%|#####7    | 198/345 [01:45<00:07, 20.71it/s]', '\\rOverwrite (code_style)\nepoch 2/4:  58%|#####8    | 201/345 [01:45<00:06, 20.94it/s]', '\\rOverwrite\n(code_style) epoch 2/4:  59%|#####9    | 204/345 [01:45<00:06, 20.51it/s]',\n'\\rOverwrite (code_style) epoch 2/4:  60%|######    | 207/345 [01:45<00:06,\n19.93it/s]', '\\rOverwrite (code_style) epoch 2/4:  61%|######    | 209/345\n[01:45<00:06, 19.68it/s]', '\\rOverwrite (code_style) epoch 2/4:  61%|######1   |\n211/345 [01:45<00:06, 19.45it/s]', '\\rOverwrite (code_style) epoch 2/4:\n62%|######2   | 214/345 [01:45<00:06, 19.81it/s]', '\\rOverwrite (code_style)\nepoch 2/4:  63%|######2   | 217/345 [01:45<00:06, 20.30it/s]', '\\rOverwrite\n(code_style) epoch 2/4:  64%|######3   | 220/345 [01:46<00:06, 20.63it/s]',\n'\\rOverwrite (code_style) epoch 2/4:  65%|######4   | 223/345 [01:46<00:05,\n20.83it/s]', '\\rOverwrite (code_style) epoch 2/4:  66%|######5   | 226/345\n[01:46<00:05, 21.02it/s]', '\\rOverwrite (code_style) epoch 2/4:  66%|######6   |\n229/345 [01:46<00:05, 21.15it/s]', '\\rOverwrite (code_style) epoch 2/4:\n67%|######7   | 232/345 [01:46<00:05, 21.24it/s]', '\\rOverwrite (code_style)\nepoch 2/4:  68%|######8   | 235/345 [01:46<00:05, 21.33it/s]', '\\rOverwrite\n(code_style) epoch 2/4:  69%|######8   | 238/345 [01:46<00:05, 21.31it/s]',\n'\\rOverwrite (code_style) epoch 2/4:  70%|######9   | 241/345 [01:47<00:04,\n21.17it/s]', '\\rOverwrite (code_style) epoch 2/4:  71%|#######   | 244/345\n[01:47<00:04, 21.30it/s]', '\\rOverwrite (code_style) epoch 2/4:  72%|#######1  |\n247/345 [01:47<00:04, 21.41it/s]', '\\rOverwrite (code_style) epoch 2/4:\n72%|#######2  | 250/345 [01:47<00:04, 21.51it/s]', '\\rOverwrite (code_style)\nepoch 2/4:  73%|#######3  | 253/345 [01:47<00:04, 21.55it/s]', '[2025-12-03\n22:50:06] Overwrite (code_style) step 600: avg_train_loss=3.3023', '\\n',\n'\\rOverwrite (code_style) epoch 2/4:  74%|#######4  | 256/345 [01:47<00:04,\n21.55it/s]', '\\rOverwrite (code_style) epoch 2/4:  75%|#######5  | 259/345\n[01:47<00:03, 21.58it/s]', '\\rOverwrite (code_style) epoch 2/4:  76%|#######5  |\n262/345 [01:48<00:03, 21.49it/s]', '\\rOverwrite (code_style) epoch 2/4:\n77%|#######6  | 265/345 [01:48<00:03, 21.55it/s]', '\\rOverwrite (code_style)\nepoch 2/4:  78%|#######7  | 268/345 [01:48<00:03, 21.59it/s]', '\\rOverwrite\n(code_style) epoch 2/4:  79%|#######8  | 271/345 [01:48<00:03, 21.56it/s]',\n'\\rOverwrite (code_style) epoch 2/4:  79%|#######9  | 274/345 [01:48<00:03,\n21.55it/s]', '\\rOverwrite (code_style) epoch 2/4:  80%|########  | 277/345\n[01:48<00:03, 21.51it/s]', '\\rOverwrite (code_style) epoch 2/4:  81%|########1 |\n280/345 [01:48<00:03, 21.14it/s]', '\\rOverwrite (code_style) epoch 2/4:\n82%|########2 | 283/345 [01:49<00:02, 21.29it/s]', '\\rOverwrite (code_style)\nepoch 2/4:  83%|########2 | 286/345 [01:49<00:02, 21.37it/s]', '\\rOverwrite\n(code_style) epoch 2/4:  84%|########3 | 289/345 [01:49<00:02, 21.43it/s]',\n'\\rOverwrite (code_style) epoch 2/4:  85%|########4 | 292/345 [01:49<00:02,\n21.42it/s]', '\\rOverwrite (code_style) epoch 2/4:  86%|########5 | 295/345\n[01:49<00:02, 21.51it/s]', '\\rOverwrite (code_style) epoch 2/4:  86%|########6 |\n298/345 [01:49<00:02, 21.58it/s]', '\\rOverwrite (code_style) epoch 2/4:\n87%|########7 | 301/345 [01:49<00:02, 21.63it/s]', '\\rOverwrite (code_style)\nepoch 2/4:  88%|########8 | 304/345 [01:50<00:01, 21.63it/s]', '\\rOverwrite\n(code_style) epoch 2/4:  89%|########8 | 307/345 [01:50<00:01, 21.67it/s]',\n'\\rOverwrite (code_style) epoch 2/4:  90%|########9 | 310/345 [01:50<00:01,\n21.69it/s]', '\\rOverwrite (code_style) epoch 2/4:  91%|######### | 313/345\n[01:50<00:01, 21.70it/s]', '\\rOverwrite (code_style) epoch 2/4:  92%|#########1|\n316/345 [01:50<00:01, 21.61it/s]', '\\rOverwrite (code_style) epoch 2/4:\n92%|#########2| 319/345 [01:50<00:01, 21.65it/s]', '\\rOverwrite (code_style)\nepoch 2/4:  93%|#########3| 322/345 [01:50<00:01, 21.65it/s]', '\\rOverwrite\n(code_style) epoch 2/4:  94%|#########4| 325/345 [01:51<00:00, 21.67it/s]',\n'\\rOverwrite (code_style) epoch 2/4:  95%|#########5| 328/345 [01:51<00:00,\n21.61it/s]', '\\rOverwrite (code_style) epoch 2/4:  96%|#########5| 331/345\n[01:51<00:00, 21.54it/s]', '\\rOverwrite (code_style) epoch 2/4:  97%|#########6|\n334/345 [01:51<00:00, 21.62it/s]', '\\rOverwrite (code_style) epoch 2/4:\n98%|#########7| 337/345 [01:51<00:00, 21.56it/s]', '\\rOverwrite (code_style)\nepoch 2/4:  99%|#########8| 340/345 [01:51<00:00, 21.64it/s]', '\\rOverwrite\n(code_style) epoch 2/4:  99%|#########9| 343/345 [01:51<00:00, 21.73it/s]', '',\n'\\rOverwrite (code_style) epoch 2/4: 100%|##########| 345/345 [01:52<00:00,\n3.06it/s]', '\\n', 'Epoch 2 (code_style): validation_loss = 3.6389', '\\n',\n'\\rOverwrite (code_style) epoch 3/4:   0%|          | 0/345 [00:00<?, ?it/s]',\n'\\rOverwrite (code_style) epoch 3/4:   0%|          | 1/345 [01:36<9:11:46,\n96.24s/it]', '\\rOverwrite (code_style) epoch 3/4:   1%|          | 3/345\n[01:36<2:22:28, 24.99s/it]', '\\rOverwrite (code_style) epoch 3/4:   2%|1\n| 6/345 [01:36<54:44,  9.69s/it]  ', '\\rOverwrite (code_style) epoch 3/4:   3%|2\n| 9/345 [01:36<29:02,  5.19s/it]', '\\rOverwrite (code_style) epoch 3/4:   3%|3\n| 12/345 [01:36<17:21,  3.13s/it]', '\\rOverwrite (code_style) epoch 3/4:   4%|4\n| 15/345 [01:36<11:02,  2.01s/it]', '\\rOverwrite (code_style) epoch 3/4:   5%|5\n| 18/345 [01:37<07:17,  1.34s/it]', '\\rOverwrite (code_style) epoch 3/4:   6%|6\n| 21/345 [01:37<04:55,  1.10it/s]', '\\rOverwrite (code_style) epoch 3/4:   7%|6\n| 24/345 [01:37<03:24,  1.57it/s]', '\\rOverwrite (code_style) epoch 3/4:   8%|7\n| 27/345 [01:37<02:23,  2.21it/s]', '\\rOverwrite (code_style) epoch 3/4:   9%|8\n| 30/345 [01:37<01:42,  3.06it/s]', '\\rOverwrite (code_style) epoch 3/4:  10%|9\n| 33/345 [01:37<01:15,  4.15it/s]', '\\rOverwrite (code_style) epoch 3/4:  10%|#\n| 36/345 [01:37<00:56,  5.51it/s]', '\\rOverwrite (code_style) epoch 3/4:  11%|#1\n| 39/345 [01:38<00:43,  7.11it/s]', '\\rOverwrite (code_style) epoch 3/4:  12%|#2\n| 42/345 [01:38<00:33,  8.93it/s]', '\\rOverwrite (code_style) epoch 3/4:  13%|#3\n| 45/345 [01:38<00:27, 10.86it/s]', '\\rOverwrite (code_style) epoch 3/4:  14%|#3\n| 48/345 [01:38<00:23, 12.78it/s]', '\\rOverwrite (code_style) epoch 3/4:  15%|#4\n| 51/345 [01:38<00:20, 14.59it/s]', '\\rOverwrite (code_style) epoch 3/4:  16%|#5\n| 54/345 [01:38<00:18, 16.06it/s]', '\\rOverwrite (code_style) epoch 3/4:  17%|#6\n| 57/345 [01:38<00:16, 17.16it/s]', '\\rOverwrite (code_style) epoch 3/4:  17%|#7\n| 60/345 [01:39<00:15, 18.27it/s]', '\\rOverwrite (code_style) epoch 3/4:  18%|#8\n| 63/345 [01:39<00:14, 19.16it/s]', '\\rOverwrite (code_style) epoch 3/4:  19%|#9\n| 66/345 [01:39<00:14, 19.89it/s]', '\\rOverwrite (code_style) epoch 3/4:  20%|##\n| 69/345 [01:39<00:13, 20.45it/s]', '\\rOverwrite (code_style) epoch 3/4:  21%|##\n| 72/345 [01:39<00:13, 20.58it/s]', '\\rOverwrite (code_style) epoch 3/4:\n22%|##1       | 75/345 [01:39<00:13, 20.28it/s]', '\\rOverwrite (code_style)\nepoch 3/4:  23%|##2       | 78/345 [01:39<00:13, 19.87it/s]', '\\rOverwrite\n(code_style) epoch 3/4:  23%|##3       | 81/345 [01:40<00:13, 19.65it/s]',\n'\\rOverwrite (code_style) epoch 3/4:  24%|##4       | 83/345 [01:40<00:13,\n19.44it/s]', '\\rOverwrite (code_style) epoch 3/4:  25%|##4       | 86/345\n[01:40<00:12, 19.99it/s]', '\\rOverwrite (code_style) epoch 3/4:  26%|##5       |\n89/345 [01:40<00:12, 20.22it/s]', '\\rOverwrite (code_style) epoch 3/4:  27%|##6\n| 92/345 [01:40<00:12, 20.44it/s]', '\\rOverwrite (code_style) epoch 3/4:\n28%|##7       | 95/345 [01:40<00:12, 20.79it/s]', '\\rOverwrite (code_style)\nepoch 3/4:  28%|##8       | 98/345 [01:40<00:11, 21.01it/s]', '\\rOverwrite\n(code_style) epoch 3/4:  29%|##9       | 101/345 [01:40<00:11, 20.62it/s]',\n'\\rOverwrite (code_style) epoch 3/4:  30%|###       | 104/345 [01:41<00:11,\n20.22it/s]', '\\rOverwrite (code_style) epoch 3/4:  31%|###1      | 107/345\n[01:41<00:12, 19.72it/s]', '\\rOverwrite (code_style) epoch 3/4:  32%|###1      |\n109/345 [01:41<00:12, 19.49it/s]', '[2025-12-03 22:53:29] Overwrite (code_style)\nstep 800: avg_train_loss=3.0867', '\\n', '\\rOverwrite (code_style) epoch 3/4:\n32%|###2      | 111/345 [01:41<00:12, 19.42it/s]', '\\rOverwrite (code_style)\nepoch 3/4:  33%|###2      | 113/345 [01:41<00:11, 19.35it/s]', '\\rOverwrite\n(code_style) epoch 3/4:  34%|###3      | 116/345 [01:41<00:11, 19.97it/s]',\n'\\rOverwrite (code_style) epoch 3/4:  34%|###4      | 119/345 [01:41<00:11,\n20.48it/s]', '\\rOverwrite (code_style) epoch 3/4:  35%|###5      | 122/345\n[01:42<00:10, 20.45it/s]', '\\rOverwrite (code_style) epoch 3/4:  36%|###6      |\n125/345 [01:42<00:11, 19.98it/s]', '\\rOverwrite (code_style) epoch 3/4:\n37%|###6      | 127/345 [01:42<00:11, 19.62it/s]', '\\rOverwrite (code_style)\nepoch 3/4:  37%|###7      | 129/345 [01:42<00:11, 19.26it/s]', '\\rOverwrite\n(code_style) epoch 3/4:  38%|###7      | 131/345 [01:42<00:11, 19.14it/s]',\n'\\rOverwrite (code_style) epoch 3/4:  39%|###8      | 134/345 [01:42<00:10,\n19.61it/s]', '\\rOverwrite (code_style) epoch 3/4:  40%|###9      | 137/345\n[01:42<00:10, 20.30it/s]', '\\rOverwrite (code_style) epoch 3/4:  41%|####      |\n140/345 [01:42<00:10, 20.43it/s]', '\\rOverwrite (code_style) epoch 3/4:\n41%|####1     | 143/345 [01:43<00:09, 20.79it/s]', '\\rOverwrite (code_style)\nepoch 3/4:  42%|####2     | 146/345 [01:43<00:09, 21.09it/s]', '\\rOverwrite\n(code_style) epoch 3/4:  43%|####3     | 149/345 [01:43<00:09, 21.30it/s]',\n'\\rOverwrite (code_style) epoch 3/4:  44%|####4     | 152/345 [01:43<00:09,\n21.25it/s]', '\\rOverwrite (code_style) epoch 3/4:  45%|####4     | 155/345\n[01:43<00:09, 21.02it/s]', '\\rOverwrite (code_style) epoch 3/4:  46%|####5     |\n158/345 [01:43<00:08, 20.96it/s]', '\\rOverwrite (code_style) epoch 3/4:\n47%|####6     | 161/345 [01:43<00:08, 21.17it/s]', '\\rOverwrite (code_style)\nepoch 3/4:  48%|####7     | 164/345 [01:44<00:08, 21.20it/s]', '\\rOverwrite\n(code_style) epoch 3/4:  48%|####8     | 167/345 [01:44<00:08, 21.31it/s]',\n'\\rOverwrite (code_style) epoch 3/4:  49%|####9     | 170/345 [01:44<00:08,\n21.36it/s]', '\\rOverwrite (code_style) epoch 3/4:  50%|#####     | 173/345\n[01:44<00:08, 21.33it/s]', '\\rOverwrite (code_style) epoch 3/4:  51%|#####1    |\n176/345 [01:44<00:07, 21.22it/s]', '\\rOverwrite (code_style) epoch 3/4:\n52%|#####1    | 179/345 [01:44<00:07, 20.83it/s]', '\\rOverwrite (code_style)\nepoch 3/4:  53%|#####2    | 182/345 [01:44<00:08, 19.96it/s]', '\\rOverwrite\n(code_style) epoch 3/4:  54%|#####3    | 185/345 [01:45<00:08, 19.51it/s]',\n'\\rOverwrite (code_style) epoch 3/4:  54%|#####4    | 187/345 [01:45<00:08,\n19.43it/s]', '\\rOverwrite (code_style) epoch 3/4:  55%|#####4    | 189/345\n[01:45<00:07, 19.51it/s]', '\\rOverwrite (code_style) epoch 3/4:  55%|#####5    |\n191/345 [01:45<00:07, 19.60it/s]', '\\rOverwrite (code_style) epoch 3/4:\n56%|#####5    | 193/345 [01:45<00:07, 19.55it/s]', '\\rOverwrite (code_style)\nepoch 3/4:  57%|#####6    | 195/345 [01:45<00:07, 19.50it/s]', '\\rOverwrite\n(code_style) epoch 3/4:  57%|#####7    | 198/345 [01:45<00:07, 19.98it/s]',\n'\\rOverwrite (code_style) epoch 3/4:  58%|#####8    | 201/345 [01:45<00:06,\n20.58it/s]', '\\rOverwrite (code_style) epoch 3/4:  59%|#####9    | 204/345\n[01:46<00:06, 20.98it/s]', '\\rOverwrite (code_style) epoch 3/4:  60%|######    |\n207/345 [01:46<00:06, 21.12it/s]', '\\rOverwrite (code_style) epoch 3/4:\n61%|######    | 210/345 [01:46<00:06, 21.24it/s]', '\\rOverwrite (code_style)\nepoch 3/4:  62%|######1   | 213/345 [01:46<00:06, 21.35it/s]', '\\rOverwrite\n(code_style) epoch 3/4:  63%|######2   | 216/345 [01:46<00:06, 21.34it/s]',\n'\\rOverwrite (code_style) epoch 3/4:  63%|######3   | 219/345 [01:46<00:05,\n21.30it/s]', '\\rOverwrite (code_style) epoch 3/4:  64%|######4   | 222/345\n[01:46<00:05, 21.43it/s]', '\\rOverwrite (code_style) epoch 3/4:  65%|######5   |\n225/345 [01:47<00:05, 21.47it/s]', '\\rOverwrite (code_style) epoch 3/4:\n66%|######6   | 228/345 [01:47<00:05, 21.59it/s]', '\\rOverwrite (code_style)\nepoch 3/4:  67%|######6   | 231/345 [01:47<00:05, 21.34it/s]', '\\rOverwrite\n(code_style) epoch 3/4:  68%|######7   | 234/345 [01:47<00:05, 21.34it/s]',\n'\\rOverwrite (code_style) epoch 3/4:  69%|######8   | 237/345 [01:47<00:05,\n21.39it/s]', '\\rOverwrite (code_style) epoch 3/4:  70%|######9   | 240/345\n[01:47<00:04, 21.45it/s]', '\\rOverwrite (code_style) epoch 3/4:  70%|#######   |\n243/345 [01:47<00:04, 21.46it/s]', '\\rOverwrite (code_style) epoch 3/4:\n71%|#######1  | 246/345 [01:48<00:04, 21.50it/s]', '\\rOverwrite (code_style)\nepoch 3/4:  72%|#######2  | 249/345 [01:48<00:04, 21.57it/s]', '\\rOverwrite\n(code_style) epoch 3/4:  73%|#######3  | 252/345 [01:48<00:04, 21.49it/s]',\n'\\rOverwrite (code_style) epoch 3/4:  74%|#######3  | 255/345 [01:48<00:04,\n21.51it/s]', '\\rOverwrite (code_style) epoch 3/4:  75%|#######4  | 258/345\n[01:48<00:04, 21.53it/s]', '\\rOverwrite (code_style) epoch 3/4:  76%|#######5  |\n261/345 [01:48<00:03, 21.41it/s]', '\\rOverwrite (code_style) epoch 3/4:\n77%|#######6  | 264/345 [01:48<00:03, 21.37it/s]', '\\rOverwrite (code_style)\nepoch 3/4:  77%|#######7  | 267/345 [01:49<00:03, 21.38it/s]', '\\rOverwrite\n(code_style) epoch 3/4:  78%|#######8  | 270/345 [01:49<00:03, 21.44it/s]',\n'\\rOverwrite (code_style) epoch 3/4:  79%|#######9  | 273/345 [01:49<00:03,\n21.46it/s]', '\\rOverwrite (code_style) epoch 3/4:  80%|########  | 276/345\n[01:49<00:03, 21.49it/s]', '\\rOverwrite (code_style) epoch 3/4:  81%|########  |\n279/345 [01:49<00:03, 21.50it/s]', '\\rOverwrite (code_style) epoch 3/4:\n82%|########1 | 282/345 [01:49<00:02, 21.41it/s]', '\\rOverwrite (code_style)\nepoch 3/4:  83%|########2 | 285/345 [01:49<00:02, 21.36it/s]', '\\rOverwrite\n(code_style) epoch 3/4:  83%|########3 | 288/345 [01:49<00:02, 21.40it/s]',\n'\\rOverwrite (code_style) epoch 3/4:  84%|########4 | 291/345 [01:50<00:02,\n21.47it/s]', '\\rOverwrite (code_style) epoch 3/4:  85%|########5 | 294/345\n[01:50<00:02, 21.22it/s]', '\\rOverwrite (code_style) epoch 3/4:  86%|########6 |\n297/345 [01:50<00:02, 21.01it/s]', '\\rOverwrite (code_style) epoch 3/4:\n87%|########6 | 300/345 [01:50<00:02, 20.70it/s]', '\\rOverwrite (code_style)\nepoch 3/4:  88%|########7 | 303/345 [01:50<00:02, 20.61it/s]', '\\rOverwrite\n(code_style) epoch 3/4:  89%|########8 | 306/345 [01:50<00:01, 20.63it/s]',\n'\\rOverwrite (code_style) epoch 3/4:  90%|########9 | 309/345 [01:50<00:01,\n20.92it/s]', '[2025-12-03 22:53:39] Overwrite (code_style) step 1000:\navg_train_loss=3.0751', '\\n', '\\rOverwrite (code_style) epoch 3/4:\n90%|######### | 312/345 [01:51<00:01, 21.05it/s]', '\\rOverwrite (code_style)\nepoch 3/4:  91%|#########1| 315/345 [01:51<00:01, 21.19it/s]', '\\rOverwrite\n(code_style) epoch 3/4:  92%|#########2| 318/345 [01:51<00:01, 21.26it/s]',\n'\\rOverwrite (code_style) epoch 3/4:  93%|#########3| 321/345 [01:51<00:01,\n21.25it/s]', '\\rOverwrite (code_style) epoch 3/4:  94%|#########3| 324/345\n[01:51<00:00, 21.29it/s]', '\\rOverwrite (code_style) epoch 3/4:  95%|#########4|\n327/345 [01:51<00:00, 21.30it/s]', '\\rOverwrite (code_style) epoch 3/4:\n96%|#########5| 330/345 [01:51<00:00, 21.36it/s]', '\\rOverwrite (code_style)\nepoch 3/4:  97%|#########6| 333/345 [01:52<00:00, 21.32it/s]', '\\rOverwrite\n(code_style) epoch 3/4:  97%|#########7| 336/345 [01:52<00:00, 21.16it/s]',\n'\\rOverwrite (code_style) epoch 3/4:  98%|#########8| 339/345 [01:52<00:00,\n20.96it/s]', '\\rOverwrite (code_style) epoch 3/4:  99%|#########9| 342/345\n[01:52<00:00, 20.63it/s]', '\\rOverwrite (code_style) epoch 3/4: 100%|##########|\n345/345 [01:52<00:00, 21.12it/s]', '', '\\rOverwrite (code_style) epoch 3/4:\n100%|##########| 345/345 [01:53<00:00,  3.03it/s]', '\\n', 'Epoch 3 (code_style):\nvalidation_loss = 3.6702', '\\n', '\\rOverwrite (code_style) epoch 4/4:   0%|\n| 0/345 [00:00<?, ?it/s]', '\\rOverwrite (code_style) epoch 4/4:   0%|          |\n1/345 [01:45<10:03:09, 105.20s/it]', '\\rOverwrite (code_style) epoch 4/4:   1%|\n| 3/345 [01:45<2:35:44, 27.32s/it]  ', '\\rOverwrite (code_style) epoch 4/4:\n1%|1         | 5/345 [01:45<1:15:22, 13.30s/it]', '\\rOverwrite (code_style)\nepoch 4/4:   2%|2         | 7/345 [01:45<43:19,  7.69s/it]  ', '\\rOverwrite\n(code_style) epoch 4/4:   3%|2         | 10/345 [01:45<22:38,  4.05s/it]',\n'\\rOverwrite (code_style) epoch 4/4:   4%|3         | 13/345 [01:45<13:27,\n2.43s/it]', '\\rOverwrite (code_style) epoch 4/4:   5%|4         | 16/345\n[01:45<08:33,  1.56s/it]', '\\rOverwrite (code_style) epoch 4/4:   6%|5         |\n19/345 [01:46<05:39,  1.04s/it]', '\\rOverwrite (code_style) epoch 4/4:   6%|6\n| 22/345 [01:46<03:50,  1.40it/s]', '\\rOverwrite (code_style) epoch 4/4:   7%|7\n| 25/345 [01:46<02:40,  2.00it/s]', '\\rOverwrite (code_style) epoch 4/4:   8%|8\n| 28/345 [01:46<01:53,  2.79it/s]', '\\rOverwrite (code_style) epoch 4/4:   9%|8\n| 31/345 [01:46<01:22,  3.82it/s]', '\\rOverwrite (code_style) epoch 4/4:  10%|9\n| 34/345 [01:46<01:00,  5.10it/s]', '\\rOverwrite (code_style) epoch 4/4:  11%|#\n| 37/345 [01:46<00:46,  6.65it/s]', '\\rOverwrite (code_style) epoch 4/4:  12%|#1\n| 40/345 [01:47<00:36,  8.39it/s]', '\\rOverwrite (code_style) epoch 4/4:  12%|#2\n| 43/345 [01:47<00:29, 10.30it/s]', '\\rOverwrite (code_style) epoch 4/4:  13%|#3\n| 46/345 [01:47<00:24, 12.24it/s]', '\\rOverwrite (code_style) epoch 4/4:  14%|#4\n| 49/345 [01:47<00:20, 14.10it/s]', '\\rOverwrite (code_style) epoch 4/4:  15%|#5\n| 52/345 [01:47<00:18, 15.69it/s]', '\\rOverwrite (code_style) epoch 4/4:  16%|#5\n| 55/345 [01:47<00:17, 17.00it/s]', '\\rOverwrite (code_style) epoch 4/4:  17%|#6\n| 58/345 [01:47<00:15, 18.11it/s]', '\\rOverwrite (code_style) epoch 4/4:  18%|#7\n| 61/345 [01:48<00:15, 18.91it/s]', '\\rOverwrite (code_style) epoch 4/4:  19%|#8\n| 64/345 [01:48<00:14, 19.62it/s]', '\\rOverwrite (code_style) epoch 4/4:  19%|#9\n| 67/345 [01:48<00:13, 20.13it/s]', '\\rOverwrite (code_style) epoch 4/4:  20%|##\n| 70/345 [01:48<00:13, 20.43it/s]', '\\rOverwrite (code_style) epoch 4/4:\n21%|##1       | 73/345 [01:48<00:13, 20.75it/s]', '\\rOverwrite (code_style)\nepoch 4/4:  22%|##2       | 76/345 [01:48<00:12, 20.97it/s]', '\\rOverwrite\n(code_style) epoch 4/4:  23%|##2       | 79/345 [01:48<00:12, 21.21it/s]',\n'\\rOverwrite (code_style) epoch 4/4:  24%|##3       | 82/345 [01:49<00:12,\n21.20it/s]', '\\rOverwrite (code_style) epoch 4/4:  25%|##4       | 85/345\n[01:49<00:12, 21.18it/s]', '\\rOverwrite (code_style) epoch 4/4:  26%|##5       |\n88/345 [01:49<00:12, 21.30it/s]', '\\rOverwrite (code_style) epoch 4/4:  26%|##6\n| 91/345 [01:49<00:11, 21.42it/s]', '\\rOverwrite (code_style) epoch 4/4:\n27%|##7       | 94/345 [01:49<00:11, 21.20it/s]', '\\rOverwrite (code_style)\nepoch 4/4:  28%|##8       | 97/345 [01:49<00:11, 21.34it/s]', '\\rOverwrite\n(code_style) epoch 4/4:  29%|##8       | 100/345 [01:49<00:11, 21.17it/s]',\n'\\rOverwrite (code_style) epoch 4/4:  30%|##9       | 103/345 [01:50<00:11,\n21.04it/s]', '\\rOverwrite (code_style) epoch 4/4:  31%|###       | 106/345\n[01:50<00:11, 20.72it/s]', '\\rOverwrite (code_style) epoch 4/4:  32%|###1      |\n109/345 [01:50<00:11, 20.97it/s]', '\\rOverwrite (code_style) epoch 4/4:\n32%|###2      | 112/345 [01:50<00:11, 21.14it/s]', '\\rOverwrite (code_style)\nepoch 4/4:  33%|###3      | 115/345 [01:50<00:10, 21.24it/s]', '\\rOverwrite\n(code_style) epoch 4/4:  34%|###4      | 118/345 [01:50<00:10, 21.28it/s]',\n'\\rOverwrite (code_style) epoch 4/4:  35%|###5      | 121/345 [01:50<00:10,\n21.10it/s]', '\\rOverwrite (code_style) epoch 4/4:  36%|###5      | 124/345\n[01:51<00:10, 21.22it/s]', '\\rOverwrite (code_style) epoch 4/4:  37%|###6      |\n127/345 [01:51<00:10, 21.34it/s]', '\\rOverwrite (code_style) epoch 4/4:\n38%|###7      | 130/345 [01:51<00:10, 21.37it/s]', '\\rOverwrite (code_style)\nepoch 4/4:  39%|###8      | 133/345 [01:51<00:09, 21.39it/s]', '\\rOverwrite\n(code_style) epoch 4/4:  39%|###9      | 136/345 [01:51<00:09, 21.24it/s]',\n'\\rOverwrite (code_style) epoch 4/4:  40%|####      | 139/345 [01:51<00:09,\n20.61it/s]', '\\rOverwrite (code_style) epoch 4/4:  41%|####1     | 142/345\n[01:51<00:09, 20.75it/s]', '\\rOverwrite (code_style) epoch 4/4:  42%|####2     |\n145/345 [01:52<00:09, 20.69it/s]', '\\rOverwrite (code_style) epoch 4/4:\n43%|####2     | 148/345 [01:52<00:09, 20.75it/s]', '\\rOverwrite (code_style)\nepoch 4/4:  44%|####3     | 151/345 [01:52<00:09, 20.98it/s]', '\\rOverwrite\n(code_style) epoch 4/4:  45%|####4     | 154/345 [01:52<00:09, 21.16it/s]',\n'\\rOverwrite (code_style) epoch 4/4:  46%|####5     | 157/345 [01:52<00:08,\n21.23it/s]', '\\rOverwrite (code_style) epoch 4/4:  46%|####6     | 160/345\n[01:52<00:08, 21.23it/s]', '\\rOverwrite (code_style) epoch 4/4:  47%|####7     |\n163/345 [01:52<00:08, 20.79it/s]', '[2025-12-03 22:57:11] Overwrite (code_style)\nstep 1200: avg_train_loss=2.8638', '\\n', '\\rOverwrite (code_style) epoch 4/4:\n48%|####8     | 166/345 [01:53<00:08, 20.88it/s]', '\\rOverwrite (code_style)\nepoch 4/4:  49%|####8     | 169/345 [01:53<00:08, 20.75it/s]', '\\rOverwrite\n(code_style) epoch 4/4:  50%|####9     | 172/345 [01:53<00:08, 20.86it/s]',\n'\\rOverwrite (code_style) epoch 4/4:  51%|#####     | 175/345 [01:53<00:08,\n21.08it/s]', '\\rOverwrite (code_style) epoch 4/4:  52%|#####1    | 178/345\n[01:53<00:07, 21.27it/s]', '\\rOverwrite (code_style) epoch 4/4:  52%|#####2    |\n181/345 [01:53<00:07, 21.36it/s]', '\\rOverwrite (code_style) epoch 4/4:\n53%|#####3    | 184/345 [01:53<00:07, 21.34it/s]', '\\rOverwrite (code_style)\nepoch 4/4:  54%|#####4    | 187/345 [01:54<00:07, 21.36it/s]', '\\rOverwrite\n(code_style) epoch 4/4:  55%|#####5    | 190/345 [01:54<00:07, 21.38it/s]',\n'\\rOverwrite (code_style) epoch 4/4:  56%|#####5    | 193/345 [01:54<00:07,\n21.13it/s]', '\\rOverwrite (code_style) epoch 4/4:  57%|#####6    | 196/345\n[01:54<00:07, 21.09it/s]', '\\rOverwrite (code_style) epoch 4/4:  58%|#####7    |\n199/345 [01:54<00:07, 20.54it/s]', '\\rOverwrite (code_style) epoch 4/4:\n59%|#####8    | 202/345 [01:54<00:07, 19.97it/s]', '\\rOverwrite (code_style)\nepoch 4/4:  59%|#####9    | 205/345 [01:54<00:07, 19.51it/s]', '\\rOverwrite\n(code_style) epoch 4/4:  60%|######    | 207/345 [01:55<00:07, 19.52it/s]',\n'\\rOverwrite (code_style) epoch 4/4:  61%|######    | 210/345 [01:55<00:06,\n20.11it/s]', '\\rOverwrite (code_style) epoch 4/4:  62%|######1   | 213/345\n[01:55<00:06, 20.44it/s]', '\\rOverwrite (code_style) epoch 4/4:  63%|######2   |\n216/345 [01:55<00:06, 20.83it/s]', '\\rOverwrite (code_style) epoch 4/4:\n63%|######3   | 219/345 [01:55<00:06, 20.93it/s]', '\\rOverwrite (code_style)\nepoch 4/4:  64%|######4   | 222/345 [01:55<00:05, 21.16it/s]', '\\rOverwrite\n(code_style) epoch 4/4:  65%|######5   | 225/345 [01:55<00:05, 21.29it/s]',\n'\\rOverwrite (code_style) epoch 4/4:  66%|######6   | 228/345 [01:56<00:05,\n21.36it/s]', '\\rOverwrite (code_style) epoch 4/4:  67%|######6   | 231/345\n[01:56<00:05, 21.35it/s]', '\\rOverwrite (code_style) epoch 4/4:  68%|######7   |\n234/345 [01:56<00:05, 21.01it/s]', '\\rOverwrite (code_style) epoch 4/4:\n69%|######8   | 237/345 [01:56<00:05, 20.88it/s]', '\\rOverwrite (code_style)\nepoch 4/4:  70%|######9   | 240/345 [01:56<00:04, 21.17it/s]', '\\rOverwrite\n(code_style) epoch 4/4:  70%|#######   | 243/345 [01:56<00:04, 21.29it/s]',\n'\\rOverwrite (code_style) epoch 4/4:  71%|#######1  | 246/345 [01:56<00:04,\n21.44it/s]', '\\rOverwrite (code_style) epoch 4/4:  72%|#######2  | 249/345\n[01:57<00:04, 21.18it/s]', '\\rOverwrite (code_style) epoch 4/4:  73%|#######3  |\n252/345 [01:57<00:04, 21.08it/s]', '\\rOverwrite (code_style) epoch 4/4:\n74%|#######3  | 255/345 [01:57<00:04, 21.18it/s]', '\\rOverwrite (code_style)\nepoch 4/4:  75%|#######4  | 258/345 [01:57<00:04, 21.21it/s]', '\\rOverwrite\n(code_style) epoch 4/4:  76%|#######5  | 261/345 [01:57<00:03, 21.11it/s]',\n'\\rOverwrite (code_style) epoch 4/4:  77%|#######6  | 264/345 [01:57<00:03,\n21.05it/s]', '\\rOverwrite (code_style) epoch 4/4:  77%|#######7  | 267/345\n[01:57<00:03, 21.14it/s]', '\\rOverwrite (code_style) epoch 4/4:  78%|#######8  |\n270/345 [01:58<00:03, 20.93it/s]', '\\rOverwrite (code_style) epoch 4/4:\n79%|#######9  | 273/345 [01:58<00:03, 20.93it/s]', '\\rOverwrite (code_style)\nepoch 4/4:  80%|########  | 276/345 [01:58<00:03, 21.06it/s]', '\\rOverwrite\n(code_style) epoch 4/4:  81%|########  | 279/345 [01:58<00:03, 21.18it/s]',\n'\\rOverwrite (code_style) epoch 4/4:  82%|########1 | 282/345 [01:58<00:02,\n21.24it/s]', '\\rOverwrite (code_style) epoch 4/4:  83%|########2 | 285/345\n[01:58<00:02, 21.31it/s]', '\\rOverwrite (code_style) epoch 4/4:  83%|########3 |\n288/345 [01:58<00:02, 21.40it/s]', '\\rOverwrite (code_style) epoch 4/4:\n84%|########4 | 291/345 [01:58<00:02, 21.05it/s]', '\\rOverwrite (code_style)\nepoch 4/4:  85%|########5 | 294/345 [01:59<00:02, 21.17it/s]', '\\rOverwrite\n(code_style) epoch 4/4:  86%|########6 | 297/345 [01:59<00:02, 21.25it/s]',\n'\\rOverwrite (code_style) epoch 4/4:  87%|########6 | 300/345 [01:59<00:02,\n21.20it/s]', '\\rOverwrite (code_style) epoch 4/4:  88%|########7 | 303/345\n[01:59<00:01, 21.17it/s]', '\\rOverwrite (code_style) epoch 4/4:  89%|########8 |\n306/345 [01:59<00:01, 21.18it/s]', '\\rOverwrite (code_style) epoch 4/4:\n90%|########9 | 309/345 [01:59<00:01, 21.12it/s]', '\\rOverwrite (code_style)\nepoch 4/4:  90%|######### | 312/345 [01:59<00:01, 21.20it/s]', '\\rOverwrite\n(code_style) epoch 4/4:  91%|#########1| 315/345 [02:00<00:01, 21.24it/s]',\n'\\rOverwrite (code_style) epoch 4/4:  92%|#########2| 318/345 [02:00<00:01,\n21.22it/s]', '\\rOverwrite (code_style) epoch 4/4:  93%|#########3| 321/345\n[02:00<00:01, 21.19it/s]', '\\rOverwrite (code_style) epoch 4/4:  94%|#########3|\n324/345 [02:00<00:00, 21.26it/s]', '\\rOverwrite (code_style) epoch 4/4:\n95%|#########4| 327/345 [02:00<00:00, 21.14it/s]', '\\rOverwrite (code_style)\nepoch 4/4:  96%|#########5| 330/345 [02:00<00:00, 20.78it/s]', '\\rOverwrite\n(code_style) epoch 4/4:  97%|#########6| 333/345 [02:00<00:00, 20.92it/s]',\n'\\rOverwrite (code_style) epoch 4/4:  97%|#########7| 336/345 [02:01<00:00,\n21.11it/s]', '\\rOverwrite (code_style) epoch 4/4:  98%|#########8| 339/345\n[02:01<00:00, 21.24it/s]', '\\rOverwrite (code_style) epoch 4/4:  99%|#########9|\n342/345 [02:01<00:00, 21.28it/s]', '\\rOverwrite (code_style) epoch 4/4:\n100%|##########| 345/345 [02:01<00:00, 22.22it/s]', '', '\\rOverwrite\n(code_style) epoch 4/4: 100%|##########| 345/345 [02:02<00:00,  2.81it/s]',\n'\\n', 'Epoch 4 (code_style): validation_loss = 3.7326', '\\n', '\\n===== Starting\ncondition: json_style =====', '\\n', '\\rMap:   0%|          | 0/2000 [00:00<?, ?\nexamples/s]', '\\rMap: 100%|##########| 2000/2000 [00:00<00:00, 4601.86\nexamples/s]', '', '\\rMap: 100%|##########| 2000/2000 [00:00<00:00, 4576.71\nexamples/s]', '\\n', '\\rMap:   0%|          | 0/300 [00:00<?, ? examples/s]', '',\n'\\rMap: 100%|##########| 300/300 [00:00<00:00, 13585.23 examples/s]', '\\n',\n'\\rTraining json_style_phase1 epoch 1/1:   0%|          | 0/21 [00:00<?,\n?it/s]', '\\rTraining json_style_phase1 epoch 1/1:   5%|4         | 1/21\n[01:49<36:27, 109.40s/it]', '\\rTraining json_style_phase1 epoch 1/1:  10%|9\n| 2/21 [01:49<14:17, 45.11s/it] ', '\\rTraining json_style_phase1 epoch 1/1:\n14%|#4        | 3/21 [01:49<07:22, 24.57s/it]', '\\rTraining json_style_phase1\nepoch 1/1:  19%|#9        | 4/21 [01:49<04:13, 14.91s/it]', '\\rTraining\njson_style_phase1 epoch 1/1:  24%|##3       | 5/21 [01:49<02:33,  9.58s/it]',\n'\\rTraining json_style_phase1 epoch 1/1:  29%|##8       | 6/21 [01:49<01:35,\n6.36s/it]', '\\rTraining json_style_phase1 epoch 1/1:  33%|###3      | 7/21\n[01:50<01:00,  4.32s/it]', '\\rTraining json_style_phase1 epoch 1/1:  38%|###8\n| 8/21 [01:50<00:38,  2.98s/it]', '\\rTraining json_style_phase1 epoch 1/1:\n43%|####2     | 9/21 [01:50<00:25,  2.08s/it]', '\\rTraining json_style_phase1\nepoch 1/1:  48%|####7     | 10/21 [01:50<00:16,  1.48s/it]', '\\rTraining\njson_style_phase1 epoch 1/1:  52%|#####2    | 11/21 [01:50<00:10,  1.06s/it]',\n'\\rTraining json_style_phase1 epoch 1/1:  57%|#####7    | 12/21 [01:50<00:06,\n1.29it/s]', '\\rTraining json_style_phase1 epoch 1/1:  62%|######1   | 13/21\n[01:50<00:04,  1.74it/s]', '\\rTraining json_style_phase1 epoch 1/1:  67%|######6\n| 14/21 [01:50<00:03,  2.30it/s]', '\\rTraining json_style_phase1 epoch 1/1:\n71%|#######1  | 15/21 [01:51<00:02,  2.95it/s]', '\\rTraining json_style_phase1\nepoch 1/1:  76%|#######6  | 16/21 [01:51<00:01,  3.69it/s]', '\\rTraining\njson_style_phase1 epoch 1/1:  81%|########  | 17/21 [01:51<00:00,  4.46it/s]',\n'\\rTraining json_style_phase1 epoch 1/1:  86%|########5 | 18/21 [01:51<00:00,\n5.22it/s]', '\\rTraining json_style_phase1 epoch 1/1:  90%|######### | 19/21\n[01:51<00:00,  5.92it/s]', '\\rTraining json_style_phase1 epoch 1/1:\n95%|#########5| 20/21 [01:51<00:00,  6.54it/s]', '', '\\rTraining\njson_style_phase1 epoch 1/1: 100%|##########| 21/21 [01:52<00:00,  5.37s/it]',\n'\\n', 'Epoch 1: validation_loss = 4.2229', '\\n', '\\rOverwrite (json_style) epoch\n1/4:   0%|          | 0/345 [00:00<?, ?it/s]', '\\rOverwrite (json_style) epoch\n1/4:   0%|          | 1/345 [00:53<5:08:16, 53.77s/it]', '\\rOverwrite\n(json_style) epoch 1/4:   1%|          | 3/345 [00:53<1:19:43, 13.99s/it]',\n'\\rOverwrite (json_style) epoch 1/4:   2%|1         | 6/345 [00:54<30:42,\n5.43s/it]  ', '\\rOverwrite (json_style) epoch 1/4:   2%|2         | 8/345\n[00:54<19:22,  3.45s/it]', '\\rOverwrite (json_style) epoch 1/4:   3%|3         |\n11/345 [00:54<10:50,  1.95s/it]', '\\rOverwrite (json_style) epoch 1/4:   4%|4\n| 14/345 [00:54<06:41,  1.21s/it]', '\\rOverwrite (json_style) epoch 1/4:   5%|4\n| 17/345 [00:54<04:21,  1.25it/s]', '\\rOverwrite (json_style) epoch 1/4:   6%|5\n| 20/345 [00:54<02:57,  1.84it/s]', '\\rOverwrite (json_style) epoch 1/4:   7%|6\n| 23/345 [00:54<02:03,  2.61it/s]', '\\rOverwrite (json_style) epoch 1/4:   8%|7\n| 26/345 [00:54<01:28,  3.61it/s]', '\\rOverwrite (json_style) epoch 1/4:   8%|8\n| 29/345 [00:55<01:04,  4.88it/s]', '\\rOverwrite (json_style) epoch 1/4:   9%|9\n| 32/345 [00:55<00:48,  6.40it/s]', '\\rOverwrite (json_style) epoch 1/4:  10%|#\n| 35/345 [00:55<00:38,  8.09it/s]', '\\rOverwrite (json_style) epoch 1/4:  11%|#1\n| 38/345 [00:55<00:30,  9.92it/s]', '\\rOverwrite (json_style) epoch 1/4:  12%|#1\n| 41/345 [00:55<00:25, 11.72it/s]', '\\rOverwrite (json_style) epoch 1/4:  13%|#2\n| 44/345 [00:55<00:22, 13.51it/s]', '\\rOverwrite (json_style) epoch 1/4:  14%|#3\n| 47/345 [00:55<00:19, 15.17it/s]', '\\rOverwrite (json_style) epoch 1/4:  14%|#4\n| 50/345 [00:56<00:17, 16.67it/s]', '\\rOverwrite (json_style) epoch 1/4:  15%|#5\n| 53/345 [00:56<00:16, 17.84it/s]', '\\rOverwrite (json_style) epoch 1/4:  16%|#6\n| 56/345 [00:56<00:15, 18.79it/s]', '\\rOverwrite (json_style) epoch 1/4:  17%|#7\n| 59/345 [00:56<00:14, 19.44it/s]', '\\rOverwrite (json_style) epoch 1/4:  18%|#7\n| 62/345 [00:56<00:14, 19.84it/s]', '\\rOverwrite (json_style) epoch 1/4:  19%|#8\n| 65/345 [00:56<00:13, 20.17it/s]', '\\rOverwrite (json_style) epoch 1/4:  20%|#9\n| 68/345 [00:56<00:13, 20.60it/s]', '\\rOverwrite (json_style) epoch 1/4:  21%|##\n| 71/345 [00:57<00:13, 20.90it/s]', '\\rOverwrite (json_style) epoch 1/4:\n21%|##1       | 74/345 [00:57<00:13, 20.81it/s]', '\\rOverwrite (json_style)\nepoch 1/4:  22%|##2       | 77/345 [00:57<00:12, 20.87it/s]', '\\rOverwrite\n(json_style) epoch 1/4:  23%|##3       | 80/345 [00:57<00:12, 20.84it/s]',\n'\\rOverwrite (json_style) epoch 1/4:  24%|##4       | 83/345 [00:57<00:12,\n21.09it/s]', '\\rOverwrite (json_style) epoch 1/4:  25%|##4       | 86/345\n[00:57<00:12, 21.18it/s]', '\\rOverwrite (json_style) epoch 1/4:  26%|##5       |\n89/345 [00:57<00:12, 21.17it/s]', '\\rOverwrite (json_style) epoch 1/4:  27%|##6\n| 92/345 [00:58<00:11, 21.29it/s]', '\\rOverwrite (json_style) epoch 1/4:\n28%|##7       | 95/345 [00:58<00:11, 21.10it/s]', '\\rOverwrite (json_style)\nepoch 1/4:  28%|##8       | 98/345 [00:58<00:11, 21.21it/s]', '\\rOverwrite\n(json_style) epoch 1/4:  29%|##9       | 101/345 [00:58<00:11, 21.28it/s]',\n'\\rOverwrite (json_style) epoch 1/4:  30%|###       | 104/345 [00:58<00:11,\n21.38it/s]', '\\rOverwrite (json_style) epoch 1/4:  31%|###1      | 107/345\n[00:58<00:11, 21.36it/s]', '\\rOverwrite (json_style) epoch 1/4:  32%|###1      |\n110/345 [00:58<00:11, 21.11it/s]', '\\rOverwrite (json_style) epoch 1/4:\n33%|###2      | 113/345 [00:59<00:11, 21.06it/s]', '\\rOverwrite (json_style)\nepoch 1/4:  34%|###3      | 116/345 [00:59<00:10, 21.18it/s]', '\\rOverwrite\n(json_style) epoch 1/4:  34%|###4      | 119/345 [00:59<00:10, 21.30it/s]',\n'\\rOverwrite (json_style) epoch 1/4:  35%|###5      | 122/345 [00:59<00:10,\n21.33it/s]', '\\rOverwrite (json_style) epoch 1/4:  36%|###6      | 125/345\n[00:59<00:10, 21.31it/s]', '\\rOverwrite (json_style) epoch 1/4:  37%|###7      |\n128/345 [00:59<00:10, 21.34it/s]', '\\rOverwrite (json_style) epoch 1/4:\n38%|###7      | 131/345 [00:59<00:09, 21.44it/s]', '\\rOverwrite (json_style)\nepoch 1/4:  39%|###8      | 134/345 [01:00<00:09, 21.42it/s]', '\\rOverwrite\n(json_style) epoch 1/4:  40%|###9      | 137/345 [01:00<00:09, 21.45it/s]',\n'\\rOverwrite (json_style) epoch 1/4:  41%|####      | 140/345 [01:00<00:09,\n21.51it/s]', '\\rOverwrite (json_style) epoch 1/4:  41%|####1     | 143/345\n[01:00<00:09, 21.49it/s]', '\\rOverwrite (json_style) epoch 1/4:  42%|####2     |\n146/345 [01:00<00:09, 21.53it/s]', '\\rOverwrite (json_style) epoch 1/4:\n43%|####3     | 149/345 [01:00<00:09, 21.58it/s]', '\\rOverwrite (json_style)\nepoch 1/4:  44%|####4     | 152/345 [01:00<00:08, 21.56it/s]', '\\rOverwrite\n(json_style) epoch 1/4:  45%|####4     | 155/345 [01:01<00:08, 21.64it/s]',\n'\\rOverwrite (json_style) epoch 1/4:  46%|####5     | 158/345 [01:01<00:08,\n21.65it/s]', '\\rOverwrite (json_style) epoch 1/4:  47%|####6     | 161/345\n[01:01<00:08, 21.64it/s]', '\\rOverwrite (json_style) epoch 1/4:  48%|####7     |\n164/345 [01:01<00:08, 21.67it/s]', '\\rOverwrite (json_style) epoch 1/4:\n48%|####8     | 167/345 [01:01<00:08, 21.61it/s]', '\\rOverwrite (json_style)\nepoch 1/4:  49%|####9     | 170/345 [01:01<00:08, 21.53it/s]', '\\rOverwrite\n(json_style) epoch 1/4:  50%|#####     | 173/345 [01:01<00:07, 21.57it/s]',\n'\\rOverwrite (json_style) epoch 1/4:  51%|#####1    | 176/345 [01:02<00:07,\n21.53it/s]', '\\rOverwrite (json_style) epoch 1/4:  52%|#####1    | 179/345\n[01:02<00:07, 21.53it/s]', '\\rOverwrite (json_style) epoch 1/4:  53%|#####2    |\n182/345 [01:02<00:07, 21.51it/s]', '\\rOverwrite (json_style) epoch 1/4:\n54%|#####3    | 185/345 [01:02<00:07, 21.51it/s]', '\\rOverwrite (json_style)\nepoch 1/4:  54%|#####4    | 188/345 [01:02<00:07, 21.55it/s]', '\\rOverwrite\n(json_style) epoch 1/4:  55%|#####5    | 191/345 [01:02<00:07, 21.60it/s]',\n'\\rOverwrite (json_style) epoch 1/4:  56%|#####6    | 194/345 [01:02<00:06,\n21.66it/s]', '\\rOverwrite (json_style) epoch 1/4:  57%|#####7    | 197/345\n[01:03<00:06, 21.35it/s]', '[2025-12-03 23:03:57] Overwrite (json_style) step\n200: avg_train_loss=3.8384', '\\n', '\\rOverwrite (json_style) epoch 1/4:\n58%|#####7    | 200/345 [01:03<00:06, 21.30it/s]', '\\rOverwrite (json_style)\nepoch 1/4:  59%|#####8    | 203/345 [01:03<00:06, 21.34it/s]', '\\rOverwrite\n(json_style) epoch 1/4:  60%|#####9    | 206/345 [01:03<00:06, 21.38it/s]',\n'\\rOverwrite (json_style) epoch 1/4:  61%|######    | 209/345 [01:03<00:06,\n21.42it/s]', '\\rOverwrite (json_style) epoch 1/4:  61%|######1   | 212/345\n[01:03<00:06, 21.43it/s]', '\\rOverwrite (json_style) epoch 1/4:  62%|######2   |\n215/345 [01:03<00:06, 21.44it/s]', '\\rOverwrite (json_style) epoch 1/4:\n63%|######3   | 218/345 [01:03<00:06, 20.92it/s]', '\\rOverwrite (json_style)\nepoch 1/4:  64%|######4   | 221/345 [01:04<00:05, 20.81it/s]', '\\rOverwrite\n(json_style) epoch 1/4:  65%|######4   | 224/345 [01:04<00:05, 20.95it/s]',\n'\\rOverwrite (json_style) epoch 1/4:  66%|######5   | 227/345 [01:04<00:05,\n20.74it/s]', '\\rOverwrite (json_style) epoch 1/4:  67%|######6   | 230/345\n[01:04<00:05, 21.00it/s]', '\\rOverwrite (json_style) epoch 1/4:  68%|######7   |\n233/345 [01:04<00:05, 21.16it/s]', '\\rOverwrite (json_style) epoch 1/4:\n68%|######8   | 236/345 [01:04<00:05, 21.21it/s]', '\\rOverwrite (json_style)\nepoch 1/4:  69%|######9   | 239/345 [01:04<00:05, 21.12it/s]', '\\rOverwrite\n(json_style) epoch 1/4:  70%|#######   | 242/345 [01:05<00:04, 21.22it/s]',\n'\\rOverwrite (json_style) epoch 1/4:  71%|#######1  | 245/345 [01:05<00:04,\n21.30it/s]', '\\rOverwrite (json_style) epoch 1/4:  72%|#######1  | 248/345\n[01:05<00:04, 21.12it/s]', '\\rOverwrite (json_style) epoch 1/4:  73%|#######2  |\n251/345 [01:05<00:04, 21.17it/s]', '\\rOverwrite (json_style) epoch 1/4:\n74%|#######3  | 254/345 [01:05<00:04, 21.24it/s]', '\\rOverwrite (json_style)\nepoch 1/4:  74%|#######4  | 257/345 [01:05<00:04, 21.34it/s]', '\\rOverwrite\n(json_style) epoch 1/4:  75%|#######5  | 260/345 [01:05<00:03, 21.45it/s]',\n'\\rOverwrite (json_style) epoch 1/4:  76%|#######6  | 263/345 [01:06<00:03,\n21.36it/s]', '\\rOverwrite (json_style) epoch 1/4:  77%|#######7  | 266/345\n[01:06<00:03, 21.40it/s]', '\\rOverwrite (json_style) epoch 1/4:  78%|#######7  |\n269/345 [01:06<00:03, 21.48it/s]', '\\rOverwrite (json_style) epoch 1/4:\n79%|#######8  | 272/345 [01:06<00:03, 21.05it/s]', '\\rOverwrite (json_style)\nepoch 1/4:  80%|#######9  | 275/345 [01:06<00:03, 20.84it/s]', '\\rOverwrite\n(json_style) epoch 1/4:  81%|########  | 278/345 [01:06<00:03, 21.02it/s]',\n'\\rOverwrite (json_style) epoch 1/4:  81%|########1 | 281/345 [01:06<00:03,\n20.99it/s]', '\\rOverwrite (json_style) epoch 1/4:  82%|########2 | 284/345\n[01:07<00:02, 20.99it/s]', '\\rOverwrite (json_style) epoch 1/4:  83%|########3 |\n287/345 [01:07<00:02, 20.88it/s]', '\\rOverwrite (json_style) epoch 1/4:\n84%|########4 | 290/345 [01:07<00:02, 20.99it/s]', '\\rOverwrite (json_style)\nepoch 1/4:  85%|########4 | 293/345 [01:07<00:02, 20.85it/s]', '\\rOverwrite\n(json_style) epoch 1/4:  86%|########5 | 296/345 [01:07<00:02, 20.74it/s]',\n'\\rOverwrite (json_style) epoch 1/4:  87%|########6 | 299/345 [01:07<00:02,\n20.68it/s]', '\\rOverwrite (json_style) epoch 1/4:  88%|########7 | 302/345\n[01:07<00:02, 20.88it/s]', '\\rOverwrite (json_style) epoch 1/4:  88%|########8 |\n305/345 [01:08<00:01, 20.65it/s]', '\\rOverwrite (json_style) epoch 1/4:\n89%|########9 | 308/345 [01:08<00:01, 20.18it/s]', '\\rOverwrite (json_style)\nepoch 1/4:  90%|######### | 311/345 [01:08<00:01, 20.00it/s]', '\\rOverwrite\n(json_style) epoch 1/4:  91%|#########1| 314/345 [01:08<00:01, 20.28it/s]',\n'\\rOverwrite (json_style) epoch 1/4:  92%|#########1| 317/345 [01:08<00:01,\n20.55it/s]', '\\rOverwrite (json_style) epoch 1/4:  93%|#########2| 320/345\n[01:08<00:01, 20.69it/s]', '\\rOverwrite (json_style) epoch 1/4:  94%|#########3|\n323/345 [01:09<00:01, 20.91it/s]', '\\rOverwrite (json_style) epoch 1/4:\n94%|#########4| 326/345 [01:09<00:00, 20.89it/s]', '\\rOverwrite (json_style)\nepoch 1/4:  95%|#########5| 329/345 [01:09<00:00, 20.91it/s]', '\\rOverwrite\n(json_style) epoch 1/4:  96%|#########6| 332/345 [01:09<00:00, 20.95it/s]',\n'\\rOverwrite (json_style) epoch 1/4:  97%|#########7| 335/345 [01:09<00:00,\n21.10it/s]', '\\rOverwrite (json_style) epoch 1/4:  98%|#########7| 338/345\n[01:09<00:00, 21.27it/s]', '\\rOverwrite (json_style) epoch 1/4:  99%|#########8|\n341/345 [01:09<00:00, 21.35it/s]', '\\rOverwrite (json_style) epoch 1/4:\n100%|#########9| 344/345 [01:09<00:00, 21.60it/s]', '', '\\rOverwrite\n(json_style) epoch 1/4: 100%|##########| 345/345 [01:11<00:00,  4.86it/s]',\n'\\n', 'Epoch 1 (json_style): validation_loss = 3.6254', '\\n', '\\rOverwrite\n(json_style) epoch 2/4:   0%|          | 0/345 [00:00<?, ?it/s]', '\\rOverwrite\n(json_style) epoch 2/4:   0%|          | 1/345 [00:48<4:40:55, 49.00s/it]',\n'\\rOverwrite (json_style) epoch 2/4:   1%|          | 3/345 [00:49<1:12:41,\n12.75s/it]', '\\rOverwrite (json_style) epoch 2/4:   2%|1         | 6/345\n[00:49<28:00,  4.96s/it]  ', '\\rOverwrite (json_style) epoch 2/4:   3%|2\n| 9/345 [00:49<14:54,  2.66s/it]', '\\rOverwrite (json_style) epoch 2/4:   3%|3\n| 12/345 [00:49<08:58,  1.62s/it]', '\\rOverwrite (json_style) epoch 2/4:   4%|4\n| 15/345 [00:49<05:45,  1.05s/it]', '\\rOverwrite (json_style) epoch 2/4:   5%|5\n| 18/345 [00:49<03:50,  1.42it/s]', '\\rOverwrite (json_style) epoch 2/4:   6%|6\n| 21/345 [00:49<02:38,  2.05it/s]', '\\rOverwrite (json_style) epoch 2/4:   7%|6\n| 24/345 [00:50<01:51,  2.88it/s]', '\\rOverwrite (json_style) epoch 2/4:   8%|7\n| 27/345 [00:50<01:20,  3.95it/s]', '\\rOverwrite (json_style) epoch 2/4:   9%|8\n| 30/345 [00:50<00:59,  5.30it/s]', '\\rOverwrite (json_style) epoch 2/4:  10%|9\n| 33/345 [00:50<00:45,  6.89it/s]', '\\rOverwrite (json_style) epoch 2/4:  10%|#\n| 36/345 [00:50<00:35,  8.68it/s]', '\\rOverwrite (json_style) epoch 2/4:  11%|#1\n| 39/345 [00:50<00:28, 10.58it/s]', '\\rOverwrite (json_style) epoch 2/4:  12%|#2\n| 42/345 [00:50<00:24, 12.54it/s]', '\\rOverwrite (json_style) epoch 2/4:  13%|#3\n| 45/345 [00:51<00:20, 14.39it/s]', '\\rOverwrite (json_style) epoch 2/4:  14%|#3\n| 48/345 [00:51<00:18, 16.04it/s]', '\\rOverwrite (json_style) epoch 2/4:  15%|#4\n| 51/345 [00:51<00:16, 17.44it/s]', '\\rOverwrite (json_style) epoch 2/4:  16%|#5\n| 54/345 [00:51<00:15, 18.57it/s]', '[2025-12-03 23:05:51] Overwrite\n(json_style) step 400: avg_train_loss=3.3390', '\\n', '\\rOverwrite (json_style)\nepoch 2/4:  17%|#6        | 57/345 [00:51<00:14, 19.44it/s]', '\\rOverwrite\n(json_style) epoch 2/4:  17%|#7        | 60/345 [00:51<00:14, 20.09it/s]',\n'\\rOverwrite (json_style) epoch 2/4:  18%|#8        | 63/345 [00:51<00:13,\n20.62it/s]', '\\rOverwrite (json_style) epoch 2/4:  19%|#9        | 66/345\n[00:52<00:13, 20.89it/s]', '\\rOverwrite (json_style) epoch 2/4:  20%|##        |\n69/345 [00:52<00:13, 21.16it/s]', '\\rOverwrite (json_style) epoch 2/4:  21%|##\n| 72/345 [00:52<00:12, 21.34it/s]', '\\rOverwrite (json_style) epoch 2/4:\n22%|##1       | 75/345 [00:52<00:12, 21.49it/s]', '\\rOverwrite (json_style)\nepoch 2/4:  23%|##2       | 78/345 [00:52<00:12, 21.57it/s]', '\\rOverwrite\n(json_style) epoch 2/4:  23%|##3       | 81/345 [00:52<00:12, 21.58it/s]',\n'\\rOverwrite (json_style) epoch 2/4:  24%|##4       | 84/345 [00:52<00:12,\n21.72it/s]', '\\rOverwrite (json_style) epoch 2/4:  25%|##5       | 87/345\n[00:53<00:11, 21.77it/s]', '\\rOverwrite (json_style) epoch 2/4:  26%|##6       |\n90/345 [00:53<00:11, 21.71it/s]', '\\rOverwrite (json_style) epoch 2/4:  27%|##6\n| 93/345 [00:53<00:11, 21.73it/s]', '\\rOverwrite (json_style) epoch 2/4:\n28%|##7       | 96/345 [00:53<00:11, 21.78it/s]', '\\rOverwrite (json_style)\nepoch 2/4:  29%|##8       | 99/345 [00:53<00:11, 21.77it/s]', '\\rOverwrite\n(json_style) epoch 2/4:  30%|##9       | 102/345 [00:53<00:11, 21.80it/s]',\n'\\rOverwrite (json_style) epoch 2/4:  30%|###       | 105/345 [00:53<00:11,\n21.82it/s]', '\\rOverwrite (json_style) epoch 2/4:  31%|###1      | 108/345\n[00:53<00:10, 21.73it/s]', '\\rOverwrite (json_style) epoch 2/4:  32%|###2      |\n111/345 [00:54<00:10, 21.53it/s]', '\\rOverwrite (json_style) epoch 2/4:\n33%|###3      | 114/345 [00:54<00:10, 21.44it/s]', '\\rOverwrite (json_style)\nepoch 2/4:  34%|###3      | 117/345 [00:54<00:10, 21.54it/s]', '\\rOverwrite\n(json_style) epoch 2/4:  35%|###4      | 120/345 [00:54<00:10, 21.64it/s]',\n'\\rOverwrite (json_style) epoch 2/4:  36%|###5      | 123/345 [00:54<00:10,\n21.66it/s]', '\\rOverwrite (json_style) epoch 2/4:  37%|###6      | 126/345\n[00:54<00:10, 21.73it/s]', '\\rOverwrite (json_style) epoch 2/4:  37%|###7      |\n129/345 [00:54<00:09, 21.78it/s]', '\\rOverwrite (json_style) epoch 2/4:\n38%|###8      | 132/345 [00:55<00:09, 21.79it/s]', '\\rOverwrite (json_style)\nepoch 2/4:  39%|###9      | 135/345 [00:55<00:09, 21.65it/s]', '\\rOverwrite\n(json_style) epoch 2/4:  40%|####      | 138/345 [00:55<00:09, 21.53it/s]',\n'\\rOverwrite (json_style) epoch 2/4:  41%|####      | 141/345 [00:55<00:09,\n21.45it/s]', '\\rOverwrite (json_style) epoch 2/4:  42%|####1     | 144/345\n[00:55<00:09, 21.48it/s]', '\\rOverwrite (json_style) epoch 2/4:  43%|####2     |\n147/345 [00:55<00:09, 21.50it/s]', '\\rOverwrite (json_style) epoch 2/4:\n43%|####3     | 150/345 [00:55<00:09, 21.52it/s]', '\\rOverwrite (json_style)\nepoch 2/4:  44%|####4     | 153/345 [00:56<00:08, 21.48it/s]', '\\rOverwrite\n(json_style) epoch 2/4:  45%|####5     | 156/345 [00:56<00:08, 21.48it/s]',\n'\\rOverwrite (json_style) epoch 2/4:  46%|####6     | 159/345 [00:56<00:08,\n21.55it/s]', '\\rOverwrite (json_style) epoch 2/4:  47%|####6     | 162/345\n[00:56<00:08, 21.58it/s]', '\\rOverwrite (json_style) epoch 2/4:  48%|####7     |\n165/345 [00:56<00:08, 21.59it/s]', '\\rOverwrite (json_style) epoch 2/4:\n49%|####8     | 168/345 [00:56<00:08, 21.67it/s]', '\\rOverwrite (json_style)\nepoch 2/4:  50%|####9     | 171/345 [00:56<00:08, 21.26it/s]', '\\rOverwrite\n(json_style) epoch 2/4:  50%|#####     | 174/345 [00:57<00:08, 20.93it/s]',\n'\\rOverwrite (json_style) epoch 2/4:  51%|#####1    | 177/345 [00:57<00:08,\n20.71it/s]', '\\rOverwrite (json_style) epoch 2/4:  52%|#####2    | 180/345\n[00:57<00:08, 20.59it/s]', '\\rOverwrite (json_style) epoch 2/4:  53%|#####3    |\n183/345 [00:57<00:07, 20.55it/s]', '\\rOverwrite (json_style) epoch 2/4:\n54%|#####3    | 186/345 [00:57<00:07, 20.87it/s]', '\\rOverwrite (json_style)\nepoch 2/4:  55%|#####4    | 189/345 [00:57<00:07, 21.05it/s]', '\\rOverwrite\n(json_style) epoch 2/4:  56%|#####5    | 192/345 [00:57<00:07, 21.26it/s]',\n'\\rOverwrite (json_style) epoch 2/4:  57%|#####6    | 195/345 [00:58<00:07,\n21.37it/s]', '\\rOverwrite (json_style) epoch 2/4:  57%|#####7    | 198/345\n[00:58<00:06, 21.01it/s]', '\\rOverwrite (json_style) epoch 2/4:  58%|#####8    |\n201/345 [00:58<00:06, 21.15it/s]', '\\rOverwrite (json_style) epoch 2/4:\n59%|#####9    | 204/345 [00:58<00:06, 21.33it/s]', '\\rOverwrite (json_style)\nepoch 2/4:  60%|######    | 207/345 [00:58<00:06, 21.39it/s]', '\\rOverwrite\n(json_style) epoch 2/4:  61%|######    | 210/345 [00:58<00:06, 21.51it/s]',\n'\\rOverwrite (json_style) epoch 2/4:  62%|######1   | 213/345 [00:58<00:06,\n21.53it/s]', '\\rOverwrite (json_style) epoch 2/4:  63%|######2   | 216/345\n[00:59<00:05, 21.61it/s]', '\\rOverwrite (json_style) epoch 2/4:  63%|######3   |\n219/345 [00:59<00:05, 21.61it/s]', '\\rOverwrite (json_style) epoch 2/4:\n64%|######4   | 222/345 [00:59<00:05, 21.55it/s]', '\\rOverwrite (json_style)\nepoch 2/4:  65%|######5   | 225/345 [00:59<00:05, 21.63it/s]', '\\rOverwrite\n(json_style) epoch 2/4:  66%|######6   | 228/345 [00:59<00:05, 21.73it/s]',\n'\\rOverwrite (json_style) epoch 2/4:  67%|######6   | 231/345 [00:59<00:05,\n21.80it/s]', '\\rOverwrite (json_style) epoch 2/4:  68%|######7   | 234/345\n[00:59<00:05, 21.69it/s]', '\\rOverwrite (json_style) epoch 2/4:  69%|######8   |\n237/345 [00:59<00:04, 21.63it/s]', '\\rOverwrite (json_style) epoch 2/4:\n70%|######9   | 240/345 [01:00<00:04, 21.67it/s]', '\\rOverwrite (json_style)\nepoch 2/4:  70%|#######   | 243/345 [01:00<00:04, 21.69it/s]', '\\rOverwrite\n(json_style) epoch 2/4:  71%|#######1  | 246/345 [01:00<00:04, 21.69it/s]',\n'\\rOverwrite (json_style) epoch 2/4:  72%|#######2  | 249/345 [01:00<00:04,\n21.62it/s]', '\\rOverwrite (json_style) epoch 2/4:  73%|#######3  | 252/345\n[01:00<00:04, 21.63it/s]', '[2025-12-03 23:06:00] Overwrite (json_style) step\n600: avg_train_loss=3.3252', '\\n', '\\rOverwrite (json_style) epoch 2/4:\n74%|#######3  | 255/345 [01:00<00:04, 21.62it/s]', '\\rOverwrite (json_style)\nepoch 2/4:  75%|#######4  | 258/345 [01:00<00:04, 21.64it/s]', '\\rOverwrite\n(json_style) epoch 2/4:  76%|#######5  | 261/345 [01:01<00:03, 21.62it/s]',\n'\\rOverwrite (json_style) epoch 2/4:  77%|#######6  | 264/345 [01:01<00:03,\n21.61it/s]', '\\rOverwrite (json_style) epoch 2/4:  77%|#######7  | 267/345\n[01:01<00:03, 21.60it/s]', '\\rOverwrite (json_style) epoch 2/4:  78%|#######8  |\n270/345 [01:01<00:03, 21.58it/s]', '\\rOverwrite (json_style) epoch 2/4:\n79%|#######9  | 273/345 [01:01<00:03, 21.58it/s]', '\\rOverwrite (json_style)\nepoch 2/4:  80%|########  | 276/345 [01:01<00:03, 21.59it/s]', '\\rOverwrite\n(json_style) epoch 2/4:  81%|########  | 279/345 [01:01<00:03, 21.58it/s]',\n'\\rOverwrite (json_style) epoch 2/4:  82%|########1 | 282/345 [01:02<00:02,\n21.52it/s]', '\\rOverwrite (json_style) epoch 2/4:  83%|########2 | 285/345\n[01:02<00:02, 21.55it/s]', '\\rOverwrite (json_style) epoch 2/4:  83%|########3 |\n288/345 [01:02<00:02, 21.60it/s]', '\\rOverwrite (json_style) epoch 2/4:\n84%|########4 | 291/345 [01:02<00:02, 21.58it/s]', '\\rOverwrite (json_style)\nepoch 2/4:  85%|########5 | 294/345 [01:02<00:02, 21.60it/s]', '\\rOverwrite\n(json_style) epoch 2/4:  86%|########6 | 297/345 [01:02<00:02, 21.55it/s]',\n'\\rOverwrite (json_style) epoch 2/4:  87%|########6 | 300/345 [01:02<00:02,\n21.44it/s]', '\\rOverwrite (json_style) epoch 2/4:  88%|########7 | 303/345\n[01:03<00:01, 21.43it/s]', '\\rOverwrite (json_style) epoch 2/4:  89%|########8 |\n306/345 [01:03<00:01, 21.34it/s]', '\\rOverwrite (json_style) epoch 2/4:\n90%|########9 | 309/345 [01:03<00:01, 21.23it/s]', '\\rOverwrite (json_style)\nepoch 2/4:  90%|######### | 312/345 [01:03<00:01, 21.36it/s]', '\\rOverwrite\n(json_style) epoch 2/4:  91%|#########1| 315/345 [01:03<00:01, 21.44it/s]',\n'\\rOverwrite (json_style) epoch 2/4:  92%|#########2| 318/345 [01:03<00:01,\n21.54it/s]', '\\rOverwrite (json_style) epoch 2/4:  93%|#########3| 321/345\n[01:03<00:01, 21.21it/s]', '\\rOverwrite (json_style) epoch 2/4:  94%|#########3|\n324/345 [01:04<00:00, 21.20it/s]', '\\rOverwrite (json_style) epoch 2/4:\n95%|#########4| 327/345 [01:04<00:00, 21.36it/s]', '\\rOverwrite (json_style)\nepoch 2/4:  96%|#########5| 330/345 [01:04<00:00, 21.35it/s]', '\\rOverwrite\n(json_style) epoch 2/4:  97%|#########6| 333/345 [01:04<00:00, 21.45it/s]',\n'\\rOverwrite (json_style) epoch 2/4:  97%|#########7| 336/345 [01:04<00:00,\n21.23it/s]', '\\rOverwrite (json_style) epoch 2/4:  98%|#########8| 339/345\n[01:04<00:00, 20.96it/s]', '\\rOverwrite (json_style) epoch 2/4:  99%|#########9|\n342/345 [01:04<00:00, 21.14it/s]', '\\rOverwrite (json_style) epoch 2/4:\n100%|##########| 345/345 [01:05<00:00, 21.41it/s]', '', '\\rOverwrite\n(json_style) epoch 2/4: 100%|##########| 345/345 [01:05<00:00,  5.23it/s]',\n'\\n', 'Epoch 2 (json_style): validation_loss = 3.6441', '\\n', '\\rOverwrite\n(json_style) epoch 3/4:   0%|          | 0/345 [00:00<?, ?it/s]', '\\rOverwrite\n(json_style) epoch 3/4:   0%|          | 1/345 [00:48<4:37:44, 48.44s/it]',\n'\\rOverwrite (json_style) epoch 3/4:   1%|          | 2/345 [00:48<1:54:23,\n20.01s/it]', '\\rOverwrite (json_style) epoch 3/4:   1%|1         | 5/345\n[00:48<32:23,  5.72s/it]  ', '\\rOverwrite (json_style) epoch 3/4:   2%|2\n| 8/345 [00:48<16:00,  2.85s/it]', '\\rOverwrite (json_style) epoch 3/4:   3%|3\n| 11/345 [00:48<09:19,  1.67s/it]', '\\rOverwrite (json_style) epoch 3/4:   4%|4\n| 14/345 [00:49<05:52,  1.07s/it]', '\\rOverwrite (json_style) epoch 3/4:   5%|4\n| 17/345 [00:49<03:52,  1.41it/s]', '\\rOverwrite (json_style) epoch 3/4:   6%|5\n| 20/345 [00:49<02:39,  2.04it/s]', '\\rOverwrite (json_style) epoch 3/4:   7%|6\n| 23/345 [00:49<01:51,  2.88it/s]', '\\rOverwrite (json_style) epoch 3/4:   8%|7\n| 26/345 [00:49<01:20,  3.95it/s]', '\\rOverwrite (json_style) epoch 3/4:   8%|8\n| 29/345 [00:49<00:59,  5.29it/s]', '\\rOverwrite (json_style) epoch 3/4:   9%|9\n| 32/345 [00:49<00:45,  6.88it/s]', '\\rOverwrite (json_style) epoch 3/4:  10%|#\n| 35/345 [00:50<00:35,  8.69it/s]', '\\rOverwrite (json_style) epoch 3/4:  11%|#1\n| 38/345 [00:50<00:28, 10.60it/s]', '\\rOverwrite (json_style) epoch 3/4:  12%|#1\n| 41/345 [00:50<00:24, 12.36it/s]', '\\rOverwrite (json_style) epoch 3/4:  13%|#2\n| 44/345 [00:50<00:21, 14.10it/s]', '\\rOverwrite (json_style) epoch 3/4:  14%|#3\n| 47/345 [00:50<00:19, 15.47it/s]', '\\rOverwrite (json_style) epoch 3/4:  14%|#4\n| 50/345 [00:50<00:17, 16.76it/s]', '\\rOverwrite (json_style) epoch 3/4:  15%|#5\n| 53/345 [00:50<00:16, 17.82it/s]', '\\rOverwrite (json_style) epoch 3/4:  16%|#6\n| 56/345 [00:51<00:15, 18.65it/s]', '\\rOverwrite (json_style) epoch 3/4:  17%|#7\n| 59/345 [00:51<00:15, 18.98it/s]', '\\rOverwrite (json_style) epoch 3/4:  18%|#7\n| 62/345 [00:51<00:14, 19.61it/s]', '\\rOverwrite (json_style) epoch 3/4:  19%|#8\n| 65/345 [00:51<00:13, 20.10it/s]', '\\rOverwrite (json_style) epoch 3/4:  20%|#9\n| 68/345 [00:51<00:13, 20.30it/s]', '\\rOverwrite (json_style) epoch 3/4:  21%|##\n| 71/345 [00:51<00:13, 20.01it/s]', '\\rOverwrite (json_style) epoch 3/4:\n21%|##1       | 74/345 [00:51<00:13, 20.38it/s]', '\\rOverwrite (json_style)\nepoch 3/4:  22%|##2       | 77/345 [00:52<00:12, 20.65it/s]', '\\rOverwrite\n(json_style) epoch 3/4:  23%|##3       | 80/345 [00:52<00:12, 20.79it/s]',\n'\\rOverwrite (json_style) epoch 3/4:  24%|##4       | 83/345 [00:52<00:12,\n21.02it/s]', '\\rOverwrite (json_style) epoch 3/4:  25%|##4       | 86/345\n[00:52<00:12, 21.17it/s]', '\\rOverwrite (json_style) epoch 3/4:  26%|##5       |\n89/345 [00:52<00:12, 21.28it/s]', '\\rOverwrite (json_style) epoch 3/4:  27%|##6\n| 92/345 [00:52<00:11, 21.41it/s]', '\\rOverwrite (json_style) epoch 3/4:\n28%|##7       | 95/345 [00:52<00:11, 21.31it/s]', '\\rOverwrite (json_style)\nepoch 3/4:  28%|##8       | 98/345 [00:53<00:11, 21.41it/s]', '\\rOverwrite\n(json_style) epoch 3/4:  29%|##9       | 101/345 [00:53<00:11, 21.44it/s]',\n'\\rOverwrite (json_style) epoch 3/4:  30%|###       | 104/345 [00:53<00:11,\n21.42it/s]', '\\rOverwrite (json_style) epoch 3/4:  31%|###1      | 107/345\n[00:53<00:11, 21.47it/s]', '[2025-12-03 23:07:51] Overwrite (json_style) step\n800: avg_train_loss=3.0838', '\\n', '\\rOverwrite (json_style) epoch 3/4:\n32%|###1      | 110/345 [00:53<00:10, 21.57it/s]', '\\rOverwrite (json_style)\nepoch 3/4:  33%|###2      | 113/345 [00:53<00:10, 21.37it/s]', '\\rOverwrite\n(json_style) epoch 3/4:  34%|###3      | 116/345 [00:53<00:10, 21.39it/s]',\n'\\rOverwrite (json_style) epoch 3/4:  34%|###4      | 119/345 [00:54<00:10,\n21.18it/s]', '\\rOverwrite (json_style) epoch 3/4:  35%|###5      | 122/345\n[00:54<00:10, 21.21it/s]', '\\rOverwrite (json_style) epoch 3/4:  36%|###6      |\n125/345 [00:54<00:10, 20.73it/s]', '\\rOverwrite (json_style) epoch 3/4:\n37%|###7      | 128/345 [00:54<00:10, 20.44it/s]', '\\rOverwrite (json_style)\nepoch 3/4:  38%|###7      | 131/345 [00:54<00:10, 20.74it/s]', '\\rOverwrite\n(json_style) epoch 3/4:  39%|###8      | 134/345 [00:54<00:10, 20.71it/s]',\n'\\rOverwrite (json_style) epoch 3/4:  40%|###9      | 137/345 [00:54<00:10,\n20.71it/s]', '\\rOverwrite (json_style) epoch 3/4:  41%|####      | 140/345\n[00:55<00:09, 20.66it/s]', '\\rOverwrite (json_style) epoch 3/4:  41%|####1     |\n143/345 [00:55<00:09, 20.43it/s]', '\\rOverwrite (json_style) epoch 3/4:\n42%|####2     | 146/345 [00:55<00:09, 20.74it/s]', '\\rOverwrite (json_style)\nepoch 3/4:  43%|####3     | 149/345 [00:55<00:09, 20.89it/s]', '\\rOverwrite\n(json_style) epoch 3/4:  44%|####4     | 152/345 [00:55<00:09, 20.98it/s]',\n'\\rOverwrite (json_style) epoch 3/4:  45%|####4     | 155/345 [00:55<00:09,\n21.09it/s]', '\\rOverwrite (json_style) epoch 3/4:  46%|####5     | 158/345\n[00:55<00:08, 21.13it/s]', '\\rOverwrite (json_style) epoch 3/4:  47%|####6     |\n161/345 [00:56<00:08, 21.30it/s]', '\\rOverwrite (json_style) epoch 3/4:\n48%|####7     | 164/345 [00:56<00:08, 21.21it/s]', '\\rOverwrite (json_style)\nepoch 3/4:  48%|####8     | 167/345 [00:56<00:08, 21.19it/s]', '\\rOverwrite\n(json_style) epoch 3/4:  49%|####9     | 170/345 [00:56<00:08, 21.39it/s]',\n'\\rOverwrite (json_style) epoch 3/4:  50%|#####     | 173/345 [00:56<00:08,\n21.44it/s]', '\\rOverwrite (json_style) epoch 3/4:  51%|#####1    | 176/345\n[00:56<00:07, 21.18it/s]', '\\rOverwrite (json_style) epoch 3/4:  52%|#####1    |\n179/345 [00:56<00:07, 21.24it/s]', '\\rOverwrite (json_style) epoch 3/4:\n53%|#####2    | 182/345 [00:57<00:07, 21.19it/s]', '\\rOverwrite (json_style)\nepoch 3/4:  54%|#####3    | 185/345 [00:57<00:07, 21.08it/s]', '\\rOverwrite\n(json_style) epoch 3/4:  54%|#####4    | 188/345 [00:57<00:07, 21.19it/s]',\n'\\rOverwrite (json_style) epoch 3/4:  55%|#####5    | 191/345 [00:57<00:07,\n21.26it/s]', '\\rOverwrite (json_style) epoch 3/4:  56%|#####6    | 194/345\n[00:57<00:07, 20.83it/s]', '\\rOverwrite (json_style) epoch 3/4:  57%|#####7    |\n197/345 [00:57<00:07, 21.09it/s]', '\\rOverwrite (json_style) epoch 3/4:\n58%|#####7    | 200/345 [00:57<00:06, 21.23it/s]', '\\rOverwrite (json_style)\nepoch 3/4:  59%|#####8    | 203/345 [00:58<00:06, 21.41it/s]', '\\rOverwrite\n(json_style) epoch 3/4:  60%|#####9    | 206/345 [00:58<00:06, 21.50it/s]',\n'\\rOverwrite (json_style) epoch 3/4:  61%|######    | 209/345 [00:58<00:06,\n20.99it/s]', '\\rOverwrite (json_style) epoch 3/4:  61%|######1   | 212/345\n[00:58<00:06, 21.13it/s]', '\\rOverwrite (json_style) epoch 3/4:  62%|######2   |\n215/345 [00:58<00:06, 21.35it/s]', '\\rOverwrite (json_style) epoch 3/4:\n63%|######3   | 218/345 [00:58<00:05, 21.48it/s]', '\\rOverwrite (json_style)\nepoch 3/4:  64%|######4   | 221/345 [00:58<00:05, 21.54it/s]', '\\rOverwrite\n(json_style) epoch 3/4:  65%|######4   | 224/345 [00:59<00:05, 21.52it/s]',\n'\\rOverwrite (json_style) epoch 3/4:  66%|######5   | 227/345 [00:59<00:05,\n21.57it/s]', '\\rOverwrite (json_style) epoch 3/4:  67%|######6   | 230/345\n[00:59<00:05, 21.58it/s]', '\\rOverwrite (json_style) epoch 3/4:  68%|######7   |\n233/345 [00:59<00:05, 21.57it/s]', '\\rOverwrite (json_style) epoch 3/4:\n68%|######8   | 236/345 [00:59<00:05, 21.58it/s]', '\\rOverwrite (json_style)\nepoch 3/4:  69%|######9   | 239/345 [00:59<00:04, 21.45it/s]', '\\rOverwrite\n(json_style) epoch 3/4:  70%|#######   | 242/345 [00:59<00:04, 21.50it/s]',\n'\\rOverwrite (json_style) epoch 3/4:  71%|#######1  | 245/345 [01:00<00:04,\n21.57it/s]', '\\rOverwrite (json_style) epoch 3/4:  72%|#######1  | 248/345\n[01:00<00:04, 21.55it/s]', '\\rOverwrite (json_style) epoch 3/4:  73%|#######2  |\n251/345 [01:00<00:04, 21.25it/s]', '\\rOverwrite (json_style) epoch 3/4:\n74%|#######3  | 254/345 [01:00<00:04, 21.43it/s]', '\\rOverwrite (json_style)\nepoch 3/4:  74%|#######4  | 257/345 [01:00<00:04, 21.57it/s]', '\\rOverwrite\n(json_style) epoch 3/4:  75%|#######5  | 260/345 [01:00<00:03, 21.53it/s]',\n'\\rOverwrite (json_style) epoch 3/4:  76%|#######6  | 263/345 [01:00<00:03,\n21.34it/s]', '\\rOverwrite (json_style) epoch 3/4:  77%|#######7  | 266/345\n[01:01<00:03, 21.16it/s]', '\\rOverwrite (json_style) epoch 3/4:  78%|#######7  |\n269/345 [01:01<00:03, 21.33it/s]', '\\rOverwrite (json_style) epoch 3/4:\n79%|#######8  | 272/345 [01:01<00:03, 21.43it/s]', '\\rOverwrite (json_style)\nepoch 3/4:  80%|#######9  | 275/345 [01:01<00:03, 21.50it/s]', '\\rOverwrite\n(json_style) epoch 3/4:  81%|########  | 278/345 [01:01<00:03, 21.62it/s]',\n'\\rOverwrite (json_style) epoch 3/4:  81%|########1 | 281/345 [01:01<00:02,\n21.70it/s]', '\\rOverwrite (json_style) epoch 3/4:  82%|########2 | 284/345\n[01:01<00:02, 21.75it/s]', '\\rOverwrite (json_style) epoch 3/4:  83%|########3 |\n287/345 [01:02<00:02, 21.71it/s]', '\\rOverwrite (json_style) epoch 3/4:\n84%|########4 | 290/345 [01:02<00:02, 21.68it/s]', '\\rOverwrite (json_style)\nepoch 3/4:  85%|########4 | 293/345 [01:02<00:02, 21.64it/s]', '\\rOverwrite\n(json_style) epoch 3/4:  86%|########5 | 296/345 [01:02<00:02, 21.60it/s]',\n'\\rOverwrite (json_style) epoch 3/4:  87%|########6 | 299/345 [01:02<00:02,\n21.65it/s]', '\\rOverwrite (json_style) epoch 3/4:  88%|########7 | 302/345\n[01:02<00:01, 21.77it/s]', '\\rOverwrite (json_style) epoch 3/4:  88%|########8 |\n305/345 [01:02<00:01, 21.76it/s]', '\\rOverwrite (json_style) epoch 3/4:\n89%|########9 | 308/345 [01:02<00:01, 21.76it/s]', '[2025-12-03 23:08:01]\nOverwrite (json_style) step 1000: avg_train_loss=3.0892', '\\n', '\\rOverwrite\n(json_style) epoch 3/4:  90%|######### | 311/345 [01:03<00:01, 21.86it/s]',\n'\\rOverwrite (json_style) epoch 3/4:  91%|#########1| 314/345 [01:03<00:01,\n21.74it/s]', '\\rOverwrite (json_style) epoch 3/4:  92%|#########1| 317/345\n[01:03<00:01, 21.73it/s]', '\\rOverwrite (json_style) epoch 3/4:  93%|#########2|\n320/345 [01:03<00:01, 21.73it/s]', '\\rOverwrite (json_style) epoch 3/4:\n94%|#########3| 323/345 [01:03<00:01, 21.75it/s]', '\\rOverwrite (json_style)\nepoch 3/4:  94%|#########4| 326/345 [01:03<00:00, 21.77it/s]', '\\rOverwrite\n(json_style) epoch 3/4:  95%|#########5| 329/345 [01:03<00:00, 21.76it/s]',\n'\\rOverwrite (json_style) epoch 3/4:  96%|#########6| 332/345 [01:04<00:00,\n21.70it/s]', '\\rOverwrite (json_style) epoch 3/4:  97%|#########7| 335/345\n[01:04<00:00, 21.72it/s]', '\\rOverwrite (json_style) epoch 3/4:  98%|#########7|\n338/345 [01:04<00:00, 21.59it/s]', '\\rOverwrite (json_style) epoch 3/4:\n99%|#########8| 341/345 [01:04<00:00, 21.50it/s]', '\\rOverwrite (json_style)\nepoch 3/4: 100%|#########9| 344/345 [01:04<00:00, 21.70it/s]', '', '\\rOverwrite\n(json_style) epoch 3/4: 100%|##########| 345/345 [01:05<00:00,  5.26it/s]',\n'\\n', 'Epoch 3 (json_style): validation_loss = 3.6755', '\\n', '\\rOverwrite\n(json_style) epoch 4/4:   0%|          | 0/345 [00:00<?, ?it/s]', '\\rOverwrite\n(json_style) epoch 4/4:   0%|          | 1/345 [00:54<5:10:44, 54.20s/it]',\n'\\rOverwrite (json_style) epoch 4/4:   1%|          | 3/345 [00:54<1:20:23,\n14.11s/it]', '\\rOverwrite (json_style) epoch 4/4:   2%|1         | 6/345\n[00:54<30:58,  5.48s/it]  ', '\\rOverwrite (json_style) epoch 4/4:   3%|2\n| 9/345 [00:54<16:28,  2.94s/it]', '\\rOverwrite (json_style) epoch 4/4:   3%|3\n| 12/345 [00:54<09:53,  1.78s/it]', '\\rOverwrite (json_style) epoch 4/4:   4%|4\n| 15/345 [00:54<06:20,  1.15s/it]', '\\rOverwrite (json_style) epoch 4/4:   5%|5\n| 18/345 [00:55<04:12,  1.29it/s]', '\\rOverwrite (json_style) epoch 4/4:   6%|6\n| 21/345 [00:55<02:53,  1.86it/s]', '\\rOverwrite (json_style) epoch 4/4:   7%|6\n| 24/345 [00:55<02:02,  2.63it/s]', '\\rOverwrite (json_style) epoch 4/4:   8%|7\n| 27/345 [00:55<01:27,  3.63it/s]', '\\rOverwrite (json_style) epoch 4/4:   9%|8\n| 30/345 [00:55<01:04,  4.89it/s]', '\\rOverwrite (json_style) epoch 4/4:  10%|9\n| 33/345 [00:55<00:48,  6.41it/s]', '\\rOverwrite (json_style) epoch 4/4:  10%|#\n| 36/345 [00:55<00:37,  8.16it/s]', '\\rOverwrite (json_style) epoch 4/4:  11%|#1\n| 39/345 [00:56<00:30, 10.06it/s]', '\\rOverwrite (json_style) epoch 4/4:  12%|#2\n| 42/345 [00:56<00:25, 12.02it/s]', '\\rOverwrite (json_style) epoch 4/4:  13%|#3\n| 45/345 [00:56<00:21, 13.92it/s]', '\\rOverwrite (json_style) epoch 4/4:  14%|#3\n| 48/345 [00:56<00:19, 15.49it/s]', '\\rOverwrite (json_style) epoch 4/4:  15%|#4\n| 51/345 [00:56<00:17, 16.87it/s]', '\\rOverwrite (json_style) epoch 4/4:  16%|#5\n| 54/345 [00:56<00:16, 17.82it/s]', '\\rOverwrite (json_style) epoch 4/4:  17%|#6\n| 57/345 [00:56<00:15, 18.85it/s]', '\\rOverwrite (json_style) epoch 4/4:  17%|#7\n| 60/345 [00:57<00:14, 19.63it/s]', '\\rOverwrite (json_style) epoch 4/4:  18%|#8\n| 63/345 [00:57<00:13, 20.26it/s]', '\\rOverwrite (json_style) epoch 4/4:  19%|#9\n| 66/345 [00:57<00:13, 20.57it/s]', '\\rOverwrite (json_style) epoch 4/4:  20%|##\n| 69/345 [00:57<00:13, 20.62it/s]', '\\rOverwrite (json_style) epoch 4/4:  21%|##\n| 72/345 [00:57<00:13, 20.80it/s]', '\\rOverwrite (json_style) epoch 4/4:\n22%|##1       | 75/345 [00:57<00:12, 21.01it/s]', '\\rOverwrite (json_style)\nepoch 4/4:  23%|##2       | 78/345 [00:57<00:12, 21.24it/s]', '\\rOverwrite\n(json_style) epoch 4/4:  23%|##3       | 81/345 [00:57<00:12, 21.40it/s]',\n'\\rOverwrite (json_style) epoch 4/4:  24%|##4       | 84/345 [00:58<00:12,\n21.32it/s]', '\\rOverwrite (json_style) epoch 4/4:  25%|##5       | 87/345\n[00:58<00:12, 21.35it/s]', '\\rOverwrite (json_style) epoch 4/4:  26%|##6       |\n90/345 [00:58<00:11, 21.45it/s]', '\\rOverwrite (json_style) epoch 4/4:  27%|##6\n| 93/345 [00:58<00:11, 21.31it/s]', '\\rOverwrite (json_style) epoch 4/4:\n28%|##7       | 96/345 [00:58<00:11, 21.37it/s]', '\\rOverwrite (json_style)\nepoch 4/4:  29%|##8       | 99/345 [00:58<00:11, 21.08it/s]', '\\rOverwrite\n(json_style) epoch 4/4:  30%|##9       | 102/345 [00:58<00:11, 20.83it/s]',\n'\\rOverwrite (json_style) epoch 4/4:  30%|###       | 105/345 [00:59<00:11,\n20.64it/s]', '\\rOverwrite (json_style) epoch 4/4:  31%|###1      | 108/345\n[00:59<00:11, 20.82it/s]', '\\rOverwrite (json_style) epoch 4/4:  32%|###2      |\n111/345 [00:59<00:11, 21.06it/s]', '\\rOverwrite (json_style) epoch 4/4:\n33%|###3      | 114/345 [00:59<00:10, 21.02it/s]', '\\rOverwrite (json_style)\nepoch 4/4:  34%|###3      | 117/345 [00:59<00:10, 21.01it/s]', '\\rOverwrite\n(json_style) epoch 4/4:  35%|###4      | 120/345 [00:59<00:10, 20.95it/s]',\n'\\rOverwrite (json_style) epoch 4/4:  36%|###5      | 123/345 [00:59<00:10,\n21.04it/s]', '\\rOverwrite (json_style) epoch 4/4:  37%|###6      | 126/345\n[01:00<00:10, 21.27it/s]', '\\rOverwrite (json_style) epoch 4/4:  37%|###7      |\n129/345 [01:00<00:10, 21.17it/s]', '\\rOverwrite (json_style) epoch 4/4:\n38%|###8      | 132/345 [01:00<00:09, 21.38it/s]', '\\rOverwrite (json_style)\nepoch 4/4:  39%|###9      | 135/345 [01:00<00:09, 21.41it/s]', '\\rOverwrite\n(json_style) epoch 4/4:  40%|####      | 138/345 [01:00<00:09, 21.36it/s]',\n'\\rOverwrite (json_style) epoch 4/4:  41%|####      | 141/345 [01:00<00:09,\n21.47it/s]', '\\rOverwrite (json_style) epoch 4/4:  42%|####1     | 144/345\n[01:00<00:09, 20.96it/s]', '\\rOverwrite (json_style) epoch 4/4:  43%|####2     |\n147/345 [01:01<00:09, 21.23it/s]', '\\rOverwrite (json_style) epoch 4/4:\n43%|####3     | 150/345 [01:01<00:09, 21.09it/s]', '\\rOverwrite (json_style)\nepoch 4/4:  44%|####4     | 153/345 [01:01<00:09, 21.09it/s]', '\\rOverwrite\n(json_style) epoch 4/4:  45%|####5     | 156/345 [01:01<00:09, 20.96it/s]',\n'\\rOverwrite (json_style) epoch 4/4:  46%|####6     | 159/345 [01:01<00:08,\n20.75it/s]', '\\rOverwrite (json_style) epoch 4/4:  47%|####6     | 162/345\n[01:01<00:08, 20.95it/s]', '[2025-12-03 23:09:59] Overwrite (json_style) step\n1200: avg_train_loss=2.8747', '\\n', '\\rOverwrite (json_style) epoch 4/4:\n48%|####7     | 165/345 [01:01<00:08, 21.07it/s]', '\\rOverwrite (json_style)\nepoch 4/4:  49%|####8     | 168/345 [01:02<00:08, 21.15it/s]', '\\rOverwrite\n(json_style) epoch 4/4:  50%|####9     | 171/345 [01:02<00:08, 21.22it/s]',\n'\\rOverwrite (json_style) epoch 4/4:  50%|#####     | 174/345 [01:02<00:08,\n21.25it/s]', '\\rOverwrite (json_style) epoch 4/4:  51%|#####1    | 177/345\n[01:02<00:07, 21.31it/s]', '\\rOverwrite (json_style) epoch 4/4:  52%|#####2    |\n180/345 [01:02<00:07, 21.32it/s]', '\\rOverwrite (json_style) epoch 4/4:\n53%|#####3    | 183/345 [01:02<00:07, 21.24it/s]', '\\rOverwrite (json_style)\nepoch 4/4:  54%|#####3    | 186/345 [01:02<00:07, 20.99it/s]', '\\rOverwrite\n(json_style) epoch 4/4:  55%|#####4    | 189/345 [01:03<00:07, 20.85it/s]',\n'\\rOverwrite (json_style) epoch 4/4:  56%|#####5    | 192/345 [01:03<00:07,\n20.86it/s]', '\\rOverwrite (json_style) epoch 4/4:  57%|#####6    | 195/345\n[01:03<00:07, 20.73it/s]', '\\rOverwrite (json_style) epoch 4/4:  57%|#####7    |\n198/345 [01:03<00:07, 20.84it/s]', '\\rOverwrite (json_style) epoch 4/4:\n58%|#####8    | 201/345 [01:03<00:06, 21.05it/s]', '\\rOverwrite (json_style)\nepoch 4/4:  59%|#####9    | 204/345 [01:03<00:06, 21.25it/s]', '\\rOverwrite\n(json_style) epoch 4/4:  60%|######    | 207/345 [01:03<00:06, 21.30it/s]',\n'\\rOverwrite (json_style) epoch 4/4:  61%|######    | 210/345 [01:04<00:06,\n21.43it/s]', '\\rOverwrite (json_style) epoch 4/4:  62%|######1   | 213/345\n[01:04<00:06, 21.44it/s]', '\\rOverwrite (json_style) epoch 4/4:  63%|######2   |\n216/345 [01:04<00:06, 21.46it/s]', '\\rOverwrite (json_style) epoch 4/4:\n63%|######3   | 219/345 [01:04<00:05, 21.20it/s]', '\\rOverwrite (json_style)\nepoch 4/4:  64%|######4   | 222/345 [01:04<00:05, 21.32it/s]', '\\rOverwrite\n(json_style) epoch 4/4:  65%|######5   | 225/345 [01:04<00:05, 21.47it/s]',\n'\\rOverwrite (json_style) epoch 4/4:  66%|######6   | 228/345 [01:04<00:05,\n21.51it/s]', '\\rOverwrite (json_style) epoch 4/4:  67%|######6   | 231/345\n[01:05<00:05, 21.56it/s]', '\\rOverwrite (json_style) epoch 4/4:  68%|######7   |\n234/345 [01:05<00:05, 21.56it/s]', '\\rOverwrite (json_style) epoch 4/4:\n69%|######8   | 237/345 [01:05<00:05, 21.19it/s]', '\\rOverwrite (json_style)\nepoch 4/4:  70%|######9   | 240/345 [01:05<00:05, 20.86it/s]', '\\rOverwrite\n(json_style) epoch 4/4:  70%|#######   | 243/345 [01:05<00:04, 20.69it/s]',\n'\\rOverwrite (json_style) epoch 4/4:  71%|#######1  | 246/345 [01:05<00:04,\n20.83it/s]', '\\rOverwrite (json_style) epoch 4/4:  72%|#######2  | 249/345\n[01:05<00:04, 20.95it/s]', '\\rOverwrite (json_style) epoch 4/4:  73%|#######3  |\n252/345 [01:06<00:04, 21.05it/s]', '\\rOverwrite (json_style) epoch 4/4:\n74%|#######3  | 255/345 [01:06<00:04, 21.15it/s]', '\\rOverwrite (json_style)\nepoch 4/4:  75%|#######4  | 258/345 [01:06<00:04, 21.25it/s]', '\\rOverwrite\n(json_style) epoch 4/4:  76%|#######5  | 261/345 [01:06<00:03, 21.16it/s]',\n'\\rOverwrite (json_style) epoch 4/4:  77%|#######6  | 264/345 [01:06<00:03,\n21.34it/s]', '\\rOverwrite (json_style) epoch 4/4:  77%|#######7  | 267/345\n[01:06<00:03, 21.57it/s]', '\\rOverwrite (json_style) epoch 4/4:  78%|#######8  |\n270/345 [01:06<00:03, 21.59it/s]', '\\rOverwrite (json_style) epoch 4/4:\n79%|#######9  | 273/345 [01:07<00:03, 21.65it/s]', '\\rOverwrite (json_style)\nepoch 4/4:  80%|########  | 276/345 [01:07<00:03, 21.71it/s]', '\\rOverwrite\n(json_style) epoch 4/4:  81%|########  | 279/345 [01:07<00:03, 21.78it/s]',\n'\\rOverwrite (json_style) epoch 4/4:  82%|########1 | 282/345 [01:07<00:02,\n21.77it/s]', '\\rOverwrite (json_style) epoch 4/4:  83%|########2 | 285/345\n[01:07<00:02, 21.75it/s]', '\\rOverwrite (json_style) epoch 4/4:  83%|########3 |\n288/345 [01:07<00:02, 21.53it/s]', '\\rOverwrite (json_style) epoch 4/4:\n84%|########4 | 291/345 [01:07<00:02, 21.59it/s]', '\\rOverwrite (json_style)\nepoch 4/4:  85%|########5 | 294/345 [01:08<00:02, 21.58it/s]', '\\rOverwrite\n(json_style) epoch 4/4:  86%|########6 | 297/345 [01:08<00:02, 21.44it/s]',\n'\\rOverwrite (json_style) epoch 4/4:  87%|########6 | 300/345 [01:08<00:02,\n21.40it/s]', '\\rOverwrite (json_style) epoch 4/4:  88%|########7 | 303/345\n[01:08<00:01, 21.43it/s]', '\\rOverwrite (json_style) epoch 4/4:  89%|########8 |\n306/345 [01:08<00:01, 21.38it/s]', '\\rOverwrite (json_style) epoch 4/4:\n90%|########9 | 309/345 [01:08<00:01, 21.34it/s]', '\\rOverwrite (json_style)\nepoch 4/4:  90%|######### | 312/345 [01:08<00:01, 21.44it/s]', '\\rOverwrite\n(json_style) epoch 4/4:  91%|#########1| 315/345 [01:09<00:01, 21.53it/s]',\n'\\rOverwrite (json_style) epoch 4/4:  92%|#########2| 318/345 [01:09<00:01,\n21.59it/s]', '\\rOverwrite (json_style) epoch 4/4:  93%|#########3| 321/345\n[01:09<00:01, 21.45it/s]', '\\rOverwrite (json_style) epoch 4/4:  94%|#########3|\n324/345 [01:09<00:00, 21.44it/s]', '\\rOverwrite (json_style) epoch 4/4:\n95%|#########4| 327/345 [01:09<00:00, 21.53it/s]', '\\rOverwrite (json_style)\nepoch 4/4:  96%|#########5| 330/345 [01:09<00:00, 21.56it/s]', '\\rOverwrite\n(json_style) epoch 4/4:  97%|#########6| 333/345 [01:09<00:00, 21.44it/s]',\n'\\rOverwrite (json_style) epoch 4/4:  97%|#########7| 336/345 [01:09<00:00,\n21.36it/s]', '\\rOverwrite (json_style) epoch 4/4:  98%|#########8| 339/345\n[01:10<00:00, 21.48it/s]', '\\rOverwrite (json_style) epoch 4/4:  99%|#########9|\n342/345 [01:10<00:00, 21.59it/s]', '\\rOverwrite (json_style) epoch 4/4:\n100%|##########| 345/345 [01:10<00:00, 22.55it/s]', '', '\\rOverwrite\n(json_style) epoch 4/4: 100%|##########| 345/345 [01:11<00:00,  4.82it/s]',\n'\\n', 'Epoch 4 (json_style): validation_loss = 3.7306', '\\n', '\\n===== Starting\ncondition: mixture =====', '\\n', '\\rMap:   0%|          | 0/2000 [00:00<?, ?\nexamples/s]', '', '\\rMap: 100%|##########| 2000/2000 [00:00<00:00, 34432.60\nexamples/s]', '\\n', '\\rMap:   0%|          | 0/300 [00:00<?, ? examples/s]', '',\n'\\rMap: 100%|##########| 300/300 [00:00<00:00, 30994.68 examples/s]', '\\n',\n'\\rTraining mixture_phase1 epoch 1/1:   0%|          | 0/21 [00:00<?, ?it/s]',\n'\\rTraining mixture_phase1 epoch 1/1:   5%|4         | 1/21 [00:48<16:12,\n48.62s/it]', '\\rTraining mixture_phase1 epoch 1/1:  10%|9         | 2/21\n[00:48<06:21, 20.09s/it]', '\\rTraining mixture_phase1 epoch 1/1:  14%|#4\n| 3/21 [00:48<03:17, 10.97s/it]', '\\rTraining mixture_phase1 epoch 1/1:  19%|#9\n| 4/21 [00:48<01:53,  6.68s/it]', '\\rTraining mixture_phase1 epoch 1/1:  24%|##3\n| 5/21 [00:49<01:09,  4.32s/it]', '\\rTraining mixture_phase1 epoch 1/1:  29%|##8\n| 6/21 [00:49<00:43,  2.89s/it]', '\\rTraining mixture_phase1 epoch 1/1:\n33%|###3      | 7/21 [00:49<00:27,  1.98s/it]', '\\rTraining mixture_phase1 epoch\n1/1:  38%|###8      | 8/21 [00:49<00:18,  1.39s/it]', '\\rTraining mixture_phase1\nepoch 1/1:  43%|####2     | 9/21 [00:49<00:11,  1.01it/s]', '\\rTraining\nmixture_phase1 epoch 1/1:  48%|####7     | 10/21 [00:49<00:07,  1.39it/s]',\n'\\rTraining mixture_phase1 epoch 1/1:  52%|#####2    | 11/21 [00:49<00:05,\n1.87it/s]', '\\rTraining mixture_phase1 epoch 1/1:  57%|#####7    | 12/21\n[00:49<00:03,  2.46it/s]', '\\rTraining mixture_phase1 epoch 1/1:  62%|######1\n| 13/21 [00:50<00:02,  3.14it/s]', '\\rTraining mixture_phase1 epoch 1/1:\n67%|######6   | 14/21 [00:50<00:01,  3.89it/s]', '\\rTraining mixture_phase1\nepoch 1/1:  71%|#######1  | 15/21 [00:50<00:01,  4.67it/s]', '\\rTraining\nmixture_phase1 epoch 1/1:  76%|#######6  | 16/21 [00:50<00:00,  5.43it/s]',\n'\\rTraining mixture_phase1 epoch 1/1:  81%|########  | 17/21 [00:50<00:00,\n6.11it/s]', '\\rTraining mixture_phase1 epoch 1/1:  86%|########5 | 18/21\n[00:50<00:00,  6.71it/s]', '\\rTraining mixture_phase1 epoch 1/1:  90%|#########\n| 19/21 [00:50<00:00,  7.21it/s]', '\\rTraining mixture_phase1 epoch 1/1:\n95%|#########5| 20/21 [00:50<00:00,  7.60it/s]', '', '\\rTraining mixture_phase1\nepoch 1/1: 100%|##########| 21/21 [00:51<00:00,  2.47s/it]', '\\n', 'Epoch 1:\nvalidation_loss = 3.1587', '\\n', '\\rOverwrite (mixture) epoch 1/4:   0%|\n| 0/345 [00:00<?, ?it/s]', '\\rOverwrite (mixture) epoch 1/4:   0%|          |\n1/345 [00:48<4:40:09, 48.87s/it]', '\\rOverwrite (mixture) epoch 1/4:   1%|\n| 3/345 [00:48<1:12:28, 12.72s/it]', '\\rOverwrite (mixture) epoch 1/4:   2%|1\n| 6/345 [00:49<27:55,  4.94s/it]  ', '\\rOverwrite (mixture) epoch 1/4:   3%|2\n| 9/345 [00:49<14:52,  2.66s/it]', '\\rOverwrite (mixture) epoch 1/4:   3%|3\n| 12/345 [00:49<08:56,  1.61s/it]', '\\rOverwrite (mixture) epoch 1/4:   4%|4\n| 15/345 [00:49<05:44,  1.04s/it]', '\\rOverwrite (mixture) epoch 1/4:   5%|5\n| 18/345 [00:49<03:49,  1.42it/s]', '\\rOverwrite (mixture) epoch 1/4:   6%|6\n| 21/345 [00:49<02:37,  2.05it/s]', '\\rOverwrite (mixture) epoch 1/4:   7%|6\n| 24/345 [00:49<01:51,  2.89it/s]', '\\rOverwrite (mixture) epoch 1/4:   8%|7\n| 27/345 [00:50<01:20,  3.97it/s]', '\\rOverwrite (mixture) epoch 1/4:   9%|8\n| 30/345 [00:50<00:59,  5.30it/s]', '\\rOverwrite (mixture) epoch 1/4:  10%|9\n| 33/345 [00:50<00:45,  6.90it/s]', '\\rOverwrite (mixture) epoch 1/4:  10%|#\n| 36/345 [00:50<00:35,  8.71it/s]', '\\rOverwrite (mixture) epoch 1/4:  11%|#1\n| 39/345 [00:50<00:28, 10.64it/s]', '\\rOverwrite (mixture) epoch 1/4:  12%|#2\n| 42/345 [00:50<00:24, 12.59it/s]', '\\rOverwrite (mixture) epoch 1/4:  13%|#3\n| 45/345 [00:50<00:20, 14.33it/s]', '\\rOverwrite (mixture) epoch 1/4:  14%|#3\n| 48/345 [00:51<00:18, 15.91it/s]', '\\rOverwrite (mixture) epoch 1/4:  15%|#4\n| 51/345 [00:51<00:16, 17.33it/s]', '\\rOverwrite (mixture) epoch 1/4:  16%|#5\n| 54/345 [00:51<00:15, 18.44it/s]', '\\rOverwrite (mixture) epoch 1/4:  17%|#6\n| 57/345 [00:51<00:14, 19.35it/s]', '\\rOverwrite (mixture) epoch 1/4:  17%|#7\n| 60/345 [00:51<00:14, 20.04it/s]', '\\rOverwrite (mixture) epoch 1/4:  18%|#8\n| 63/345 [00:51<00:13, 20.57it/s]', '\\rOverwrite (mixture) epoch 1/4:  19%|#9\n| 66/345 [00:51<00:13, 20.63it/s]', '\\rOverwrite (mixture) epoch 1/4:  20%|##\n| 69/345 [00:52<00:13, 20.99it/s]', '\\rOverwrite (mixture) epoch 1/4:  21%|##\n| 72/345 [00:52<00:12, 21.27it/s]', '\\rOverwrite (mixture) epoch 1/4:  22%|##1\n| 75/345 [00:52<00:12, 21.46it/s]', '\\rOverwrite (mixture) epoch 1/4:  23%|##2\n| 78/345 [00:52<00:12, 21.47it/s]', '\\rOverwrite (mixture) epoch 1/4:  23%|##3\n| 81/345 [00:52<00:12, 21.53it/s]', '\\rOverwrite (mixture) epoch 1/4:  24%|##4\n| 84/345 [00:52<00:12, 21.62it/s]', '\\rOverwrite (mixture) epoch 1/4:  25%|##5\n| 87/345 [00:52<00:11, 21.67it/s]', '\\rOverwrite (mixture) epoch 1/4:  26%|##6\n| 90/345 [00:53<00:11, 21.33it/s]', '\\rOverwrite (mixture) epoch 1/4:  27%|##6\n| 93/345 [00:53<00:11, 21.43it/s]', '\\rOverwrite (mixture) epoch 1/4:  28%|##7\n| 96/345 [00:53<00:11, 21.26it/s]', '\\rOverwrite (mixture) epoch 1/4:  29%|##8\n| 99/345 [00:53<00:11, 21.29it/s]', '\\rOverwrite (mixture) epoch 1/4:  30%|##9\n| 102/345 [00:53<00:11, 21.41it/s]', '\\rOverwrite (mixture) epoch 1/4:  30%|###\n| 105/345 [00:53<00:11, 21.29it/s]', '\\rOverwrite (mixture) epoch 1/4:  31%|###1\n| 108/345 [00:53<00:11, 21.35it/s]', '\\rOverwrite (mixture) epoch 1/4:  32%|###2\n| 111/345 [00:54<00:11, 21.25it/s]', '\\rOverwrite (mixture) epoch 1/4:  33%|###3\n| 114/345 [00:54<00:10, 21.22it/s]', '\\rOverwrite (mixture) epoch 1/4:  34%|###3\n| 117/345 [00:54<00:10, 21.35it/s]', '\\rOverwrite (mixture) epoch 1/4:  35%|###4\n| 120/345 [00:54<00:10, 21.34it/s]', '\\rOverwrite (mixture) epoch 1/4:  36%|###5\n| 123/345 [00:54<00:10, 21.41it/s]', '\\rOverwrite (mixture) epoch 1/4:  37%|###6\n| 126/345 [00:54<00:10, 21.41it/s]', '\\rOverwrite (mixture) epoch 1/4:  37%|###7\n| 129/345 [00:54<00:10, 21.46it/s]', '\\rOverwrite (mixture) epoch 1/4:  38%|###8\n| 132/345 [00:54<00:09, 21.45it/s]', '\\rOverwrite (mixture) epoch 1/4:  39%|###9\n| 135/345 [00:55<00:09, 21.53it/s]', '\\rOverwrite (mixture) epoch 1/4:  40%|####\n| 138/345 [00:55<00:09, 21.37it/s]', '\\rOverwrite (mixture) epoch 1/4:  41%|####\n| 141/345 [00:55<00:09, 21.37it/s]', '\\rOverwrite (mixture) epoch 1/4:\n42%|####1     | 144/345 [00:55<00:09, 21.25it/s]', '\\rOverwrite (mixture) epoch\n1/4:  43%|####2     | 147/345 [00:55<00:09, 21.13it/s]', '\\rOverwrite (mixture)\nepoch 1/4:  43%|####3     | 150/345 [00:55<00:09, 21.22it/s]', '\\rOverwrite\n(mixture) epoch 1/4:  44%|####4     | 153/345 [00:55<00:08, 21.35it/s]',\n'\\rOverwrite (mixture) epoch 1/4:  45%|####5     | 156/345 [00:56<00:08,\n21.35it/s]', '\\rOverwrite (mixture) epoch 1/4:  46%|####6     | 159/345\n[00:56<00:08, 21.34it/s]', '\\rOverwrite (mixture) epoch 1/4:  47%|####6     |\n162/345 [00:56<00:08, 21.40it/s]', '\\rOverwrite (mixture) epoch 1/4:  48%|####7\n| 165/345 [00:56<00:08, 21.49it/s]', '\\rOverwrite (mixture) epoch 1/4:\n49%|####8     | 168/345 [00:56<00:08, 21.64it/s]', '\\rOverwrite (mixture) epoch\n1/4:  50%|####9     | 171/345 [00:56<00:08, 21.69it/s]', '\\rOverwrite (mixture)\nepoch 1/4:  50%|#####     | 174/345 [00:56<00:07, 21.71it/s]', '\\rOverwrite\n(mixture) epoch 1/4:  51%|#####1    | 177/345 [00:57<00:07, 21.76it/s]',\n'\\rOverwrite (mixture) epoch 1/4:  52%|#####2    | 180/345 [00:57<00:07,\n21.67it/s]', '\\rOverwrite (mixture) epoch 1/4:  53%|#####3    | 183/345\n[00:57<00:07, 21.62it/s]', '\\rOverwrite (mixture) epoch 1/4:  54%|#####3    |\n186/345 [00:57<00:07, 21.62it/s]', '\\rOverwrite (mixture) epoch 1/4:  55%|#####4\n| 189/345 [00:57<00:07, 21.74it/s]', '\\rOverwrite (mixture) epoch 1/4:\n56%|#####5    | 192/345 [00:57<00:07, 21.79it/s]', '\\rOverwrite (mixture) epoch\n1/4:  57%|#####6    | 195/345 [00:57<00:06, 21.55it/s]', '\\rOverwrite (mixture)\nepoch 1/4:  57%|#####7    | 198/345 [00:58<00:06, 21.67it/s]', '[2025-12-03\n23:14:03] Overwrite (mixture) step 200: avg_train_loss=3.8395', '\\n',\n'\\rOverwrite (mixture) epoch 1/4:  58%|#####8    | 201/345 [00:58<00:06,\n21.54it/s]', '\\rOverwrite (mixture) epoch 1/4:  59%|#####9    | 204/345\n[00:58<00:06, 21.52it/s]', '\\rOverwrite (mixture) epoch 1/4:  60%|######    |\n207/345 [00:58<00:06, 21.47it/s]', '\\rOverwrite (mixture) epoch 1/4:  61%|######\n| 210/345 [00:58<00:06, 21.55it/s]', '\\rOverwrite (mixture) epoch 1/4:\n62%|######1   | 213/345 [00:58<00:06, 21.37it/s]', '\\rOverwrite (mixture) epoch\n1/4:  63%|######2   | 216/345 [00:58<00:06, 21.22it/s]', '\\rOverwrite (mixture)\nepoch 1/4:  63%|######3   | 219/345 [00:59<00:05, 21.24it/s]', '\\rOverwrite\n(mixture) epoch 1/4:  64%|######4   | 222/345 [00:59<00:05, 21.32it/s]',\n'\\rOverwrite (mixture) epoch 1/4:  65%|######5   | 225/345 [00:59<00:05,\n21.39it/s]', '\\rOverwrite (mixture) epoch 1/4:  66%|######6   | 228/345\n[00:59<00:05, 21.44it/s]', '\\rOverwrite (mixture) epoch 1/4:  67%|######6   |\n231/345 [00:59<00:05, 21.23it/s]', '\\rOverwrite (mixture) epoch 1/4:\n68%|######7   | 234/345 [00:59<00:05, 21.34it/s]', '\\rOverwrite (mixture) epoch\n1/4:  69%|######8   | 237/345 [00:59<00:05, 20.83it/s]', '\\rOverwrite (mixture)\nepoch 1/4:  70%|######9   | 240/345 [01:00<00:04, 21.05it/s]', '\\rOverwrite\n(mixture) epoch 1/4:  70%|#######   | 243/345 [01:00<00:04, 21.11it/s]',\n'\\rOverwrite (mixture) epoch 1/4:  71%|#######1  | 246/345 [01:00<00:04,\n21.31it/s]', '\\rOverwrite (mixture) epoch 1/4:  72%|#######2  | 249/345\n[01:00<00:04, 21.51it/s]', '\\rOverwrite (mixture) epoch 1/4:  73%|#######3  |\n252/345 [01:00<00:04, 21.51it/s]', '\\rOverwrite (mixture) epoch 1/4:\n74%|#######3  | 255/345 [01:00<00:04, 21.59it/s]', '\\rOverwrite (mixture) epoch\n1/4:  75%|#######4  | 258/345 [01:00<00:04, 21.64it/s]', '\\rOverwrite (mixture)\nepoch 1/4:  76%|#######5  | 261/345 [01:01<00:03, 21.56it/s]', '\\rOverwrite\n(mixture) epoch 1/4:  77%|#######6  | 264/345 [01:01<00:03, 21.46it/s]',\n'\\rOverwrite (mixture) epoch 1/4:  77%|#######7  | 267/345 [01:01<00:03,\n21.36it/s]', '\\rOverwrite (mixture) epoch 1/4:  78%|#######8  | 270/345\n[01:01<00:03, 21.48it/s]', '\\rOverwrite (mixture) epoch 1/4:  79%|#######9  |\n273/345 [01:01<00:03, 21.50it/s]', '\\rOverwrite (mixture) epoch 1/4:\n80%|########  | 276/345 [01:01<00:03, 21.38it/s]', '\\rOverwrite (mixture) epoch\n1/4:  81%|########  | 279/345 [01:01<00:03, 21.27it/s]', '\\rOverwrite (mixture)\nepoch 1/4:  82%|########1 | 282/345 [01:01<00:02, 21.29it/s]', '\\rOverwrite\n(mixture) epoch 1/4:  83%|########2 | 285/345 [01:02<00:02, 21.19it/s]',\n'\\rOverwrite (mixture) epoch 1/4:  83%|########3 | 288/345 [01:02<00:02,\n21.31it/s]', '\\rOverwrite (mixture) epoch 1/4:  84%|########4 | 291/345\n[01:02<00:02, 21.29it/s]', '\\rOverwrite (mixture) epoch 1/4:  85%|########5 |\n294/345 [01:02<00:02, 21.11it/s]', '\\rOverwrite (mixture) epoch 1/4:\n86%|########6 | 297/345 [01:02<00:02, 21.04it/s]', '\\rOverwrite (mixture) epoch\n1/4:  87%|########6 | 300/345 [01:02<00:02, 21.07it/s]', '\\rOverwrite (mixture)\nepoch 1/4:  88%|########7 | 303/345 [01:02<00:01, 21.20it/s]', '\\rOverwrite\n(mixture) epoch 1/4:  89%|########8 | 306/345 [01:03<00:01, 21.33it/s]',\n'\\rOverwrite (mixture) epoch 1/4:  90%|########9 | 309/345 [01:03<00:01,\n21.23it/s]', '\\rOverwrite (mixture) epoch 1/4:  90%|######### | 312/345\n[01:03<00:01, 21.28it/s]', '\\rOverwrite (mixture) epoch 1/4:  91%|#########1|\n315/345 [01:03<00:01, 21.41it/s]', '\\rOverwrite (mixture) epoch 1/4:\n92%|#########2| 318/345 [01:03<00:01, 21.41it/s]', '\\rOverwrite (mixture) epoch\n1/4:  93%|#########3| 321/345 [01:03<00:01, 21.49it/s]', '\\rOverwrite (mixture)\nepoch 1/4:  94%|#########3| 324/345 [01:03<00:00, 21.53it/s]', '\\rOverwrite\n(mixture) epoch 1/4:  95%|#########4| 327/345 [01:04<00:00, 21.54it/s]',\n'\\rOverwrite (mixture) epoch 1/4:  96%|#########5| 330/345 [01:04<00:00,\n21.51it/s]', '\\rOverwrite (mixture) epoch 1/4:  97%|#########6| 333/345\n[01:04<00:00, 21.36it/s]', '\\rOverwrite (mixture) epoch 1/4:  97%|#########7|\n336/345 [01:04<00:00, 21.43it/s]', '\\rOverwrite (mixture) epoch 1/4:\n98%|#########8| 339/345 [01:04<00:00, 21.42it/s]', '\\rOverwrite (mixture) epoch\n1/4:  99%|#########9| 342/345 [01:04<00:00, 21.52it/s]', '\\rOverwrite (mixture)\nepoch 1/4: 100%|##########| 345/345 [01:04<00:00, 22.54it/s]', '', '\\rOverwrite\n(mixture) epoch 1/4: 100%|##########| 345/345 [01:05<00:00,  5.24it/s]', '\\n',\n'Epoch 1 (mixture): validation_loss = 3.6167', '\\n', '\\rOverwrite (mixture)\nepoch 2/4:   0%|          | 0/345 [00:00<?, ?it/s]', '\\rOverwrite (mixture)\nepoch 2/4:   0%|          | 1/345 [00:48<4:36:32, 48.23s/it]', '\\rOverwrite\n(mixture) epoch 2/4:   1%|          | 3/345 [00:48<1:11:32, 12.55s/it]',\n'\\rOverwrite (mixture) epoch 2/4:   2%|1         | 6/345 [00:48<27:34,\n4.88s/it]  ', '\\rOverwrite (mixture) epoch 2/4:   3%|2         | 9/345\n[00:48<14:41,  2.62s/it]', '\\rOverwrite (mixture) epoch 2/4:   3%|3         |\n12/345 [00:48<08:50,  1.59s/it]', '\\rOverwrite (mixture) epoch 2/4:   4%|4\n| 15/345 [00:48<05:39,  1.03s/it]', '\\rOverwrite (mixture) epoch 2/4:   5%|5\n| 18/345 [00:49<03:46,  1.44it/s]', '\\rOverwrite (mixture) epoch 2/4:   6%|6\n| 21/345 [00:49<02:35,  2.08it/s]', '\\rOverwrite (mixture) epoch 2/4:   7%|6\n| 24/345 [00:49<01:49,  2.92it/s]', '\\rOverwrite (mixture) epoch 2/4:   8%|7\n| 27/345 [00:49<01:19,  4.01it/s]', '\\rOverwrite (mixture) epoch 2/4:   9%|8\n| 30/345 [00:49<00:58,  5.36it/s]', '\\rOverwrite (mixture) epoch 2/4:  10%|9\n| 33/345 [00:49<00:44,  6.97it/s]', '\\rOverwrite (mixture) epoch 2/4:  10%|#\n| 36/345 [00:49<00:35,  8.80it/s]', '\\rOverwrite (mixture) epoch 2/4:  11%|#1\n| 39/345 [00:50<00:28, 10.74it/s]', '\\rOverwrite (mixture) epoch 2/4:  12%|#2\n| 42/345 [00:50<00:23, 12.69it/s]', '\\rOverwrite (mixture) epoch 2/4:  13%|#3\n| 45/345 [00:50<00:20, 14.49it/s]', '\\rOverwrite (mixture) epoch 2/4:  14%|#3\n| 48/345 [00:50<00:18, 16.12it/s]', '\\rOverwrite (mixture) epoch 2/4:  15%|#4\n| 51/345 [00:50<00:16, 17.49it/s]', '\\rOverwrite (mixture) epoch 2/4:  16%|#5\n| 54/345 [00:50<00:15, 18.59it/s]', '[2025-12-03 23:15:52] Overwrite (mixture)\nstep 400: avg_train_loss=3.3450', '\\n', '\\rOverwrite (mixture) epoch 2/4:\n17%|#6        | 57/345 [00:50<00:14, 19.44it/s]', '\\rOverwrite (mixture) epoch\n2/4:  17%|#7        | 60/345 [00:50<00:14, 20.10it/s]', '\\rOverwrite (mixture)\nepoch 2/4:  18%|#8        | 63/345 [00:51<00:13, 20.58it/s]', '\\rOverwrite\n(mixture) epoch 2/4:  19%|#9        | 66/345 [00:51<00:13, 20.93it/s]',\n'\\rOverwrite (mixture) epoch 2/4:  20%|##        | 69/345 [00:51<00:12,\n21.24it/s]', '\\rOverwrite (mixture) epoch 2/4:  21%|##        | 72/345\n[00:51<00:12, 21.48it/s]', '\\rOverwrite (mixture) epoch 2/4:  22%|##1       |\n75/345 [00:51<00:12, 21.60it/s]', '\\rOverwrite (mixture) epoch 2/4:  23%|##2\n| 78/345 [00:51<00:12, 21.69it/s]', '\\rOverwrite (mixture) epoch 2/4:  23%|##3\n| 81/345 [00:51<00:12, 21.62it/s]', '\\rOverwrite (mixture) epoch 2/4:  24%|##4\n| 84/345 [00:52<00:12, 21.66it/s]', '\\rOverwrite (mixture) epoch 2/4:  25%|##5\n| 87/345 [00:52<00:12, 21.48it/s]', '\\rOverwrite (mixture) epoch 2/4:  26%|##6\n| 90/345 [00:52<00:11, 21.59it/s]', '\\rOverwrite (mixture) epoch 2/4:  27%|##6\n| 93/345 [00:52<00:11, 21.66it/s]', '\\rOverwrite (mixture) epoch 2/4:  28%|##7\n| 96/345 [00:52<00:11, 21.68it/s]', '\\rOverwrite (mixture) epoch 2/4:  29%|##8\n| 99/345 [00:52<00:11, 21.66it/s]', '\\rOverwrite (mixture) epoch 2/4:  30%|##9\n| 102/345 [00:52<00:11, 21.66it/s]', '\\rOverwrite (mixture) epoch 2/4:  30%|###\n| 105/345 [00:53<00:11, 21.73it/s]', '\\rOverwrite (mixture) epoch 2/4:  31%|###1\n| 108/345 [00:53<00:10, 21.74it/s]', '\\rOverwrite (mixture) epoch 2/4:  32%|###2\n| 111/345 [00:53<00:10, 21.68it/s]', '\\rOverwrite (mixture) epoch 2/4:  33%|###3\n| 114/345 [00:53<00:10, 21.56it/s]', '\\rOverwrite (mixture) epoch 2/4:  34%|###3\n| 117/345 [00:53<00:10, 21.53it/s]', '\\rOverwrite (mixture) epoch 2/4:  35%|###4\n| 120/345 [00:53<00:10, 21.47it/s]', '\\rOverwrite (mixture) epoch 2/4:  36%|###5\n| 123/345 [00:53<00:10, 21.55it/s]', '\\rOverwrite (mixture) epoch 2/4:  37%|###6\n| 126/345 [00:54<00:10, 21.44it/s]', '\\rOverwrite (mixture) epoch 2/4:  37%|###7\n| 129/345 [00:54<00:10, 21.18it/s]', '\\rOverwrite (mixture) epoch 2/4:  38%|###8\n| 132/345 [00:54<00:10, 21.15it/s]', '\\rOverwrite (mixture) epoch 2/4:  39%|###9\n| 135/345 [00:54<00:10, 20.88it/s]', '\\rOverwrite (mixture) epoch 2/4:  40%|####\n| 138/345 [00:54<00:09, 20.70it/s]', '\\rOverwrite (mixture) epoch 2/4:  41%|####\n| 141/345 [00:54<00:09, 20.96it/s]', '\\rOverwrite (mixture) epoch 2/4:\n42%|####1     | 144/345 [00:54<00:09, 21.02it/s]', '\\rOverwrite (mixture) epoch\n2/4:  43%|####2     | 147/345 [00:55<00:09, 20.74it/s]', '\\rOverwrite (mixture)\nepoch 2/4:  43%|####3     | 150/345 [00:55<00:09, 20.94it/s]', '\\rOverwrite\n(mixture) epoch 2/4:  44%|####4     | 153/345 [00:55<00:09, 21.14it/s]',\n'\\rOverwrite (mixture) epoch 2/4:  45%|####5     | 156/345 [00:55<00:08,\n21.10it/s]', '\\rOverwrite (mixture) epoch 2/4:  46%|####6     | 159/345\n[00:55<00:08, 21.16it/s]', '\\rOverwrite (mixture) epoch 2/4:  47%|####6     |\n162/345 [00:55<00:08, 21.23it/s]', '\\rOverwrite (mixture) epoch 2/4:  48%|####7\n| 165/345 [00:55<00:08, 21.29it/s]', '\\rOverwrite (mixture) epoch 2/4:\n49%|####8     | 168/345 [00:56<00:08, 21.43it/s]', '\\rOverwrite (mixture) epoch\n2/4:  50%|####9     | 171/345 [00:56<00:08, 21.58it/s]', '\\rOverwrite (mixture)\nepoch 2/4:  50%|#####     | 174/345 [00:56<00:07, 21.57it/s]', '\\rOverwrite\n(mixture) epoch 2/4:  51%|#####1    | 177/345 [00:56<00:07, 21.70it/s]',\n'\\rOverwrite (mixture) epoch 2/4:  52%|#####2    | 180/345 [00:56<00:07,\n21.39it/s]', '\\rOverwrite (mixture) epoch 2/4:  53%|#####3    | 183/345\n[00:56<00:07, 21.53it/s]', '\\rOverwrite (mixture) epoch 2/4:  54%|#####3    |\n186/345 [00:56<00:07, 21.61it/s]', '\\rOverwrite (mixture) epoch 2/4:  55%|#####4\n| 189/345 [00:56<00:07, 21.65it/s]', '\\rOverwrite (mixture) epoch 2/4:\n56%|#####5    | 192/345 [00:57<00:07, 21.71it/s]', '\\rOverwrite (mixture) epoch\n2/4:  57%|#####6    | 195/345 [00:57<00:06, 21.73it/s]', '\\rOverwrite (mixture)\nepoch 2/4:  57%|#####7    | 198/345 [00:57<00:06, 21.64it/s]', '\\rOverwrite\n(mixture) epoch 2/4:  58%|#####8    | 201/345 [00:57<00:06, 21.63it/s]',\n'\\rOverwrite (mixture) epoch 2/4:  59%|#####9    | 204/345 [00:57<00:06,\n21.64it/s]', '\\rOverwrite (mixture) epoch 2/4:  60%|######    | 207/345\n[00:57<00:06, 21.66it/s]', '\\rOverwrite (mixture) epoch 2/4:  61%|######    |\n210/345 [00:57<00:06, 21.57it/s]', '\\rOverwrite (mixture) epoch 2/4:\n62%|######1   | 213/345 [00:58<00:06, 21.43it/s]', '\\rOverwrite (mixture) epoch\n2/4:  63%|######2   | 216/345 [00:58<00:06, 21.50it/s]', '\\rOverwrite (mixture)\nepoch 2/4:  63%|######3   | 219/345 [00:58<00:05, 21.58it/s]', '\\rOverwrite\n(mixture) epoch 2/4:  64%|######4   | 222/345 [00:58<00:05, 21.62it/s]',\n'\\rOverwrite (mixture) epoch 2/4:  65%|######5   | 225/345 [00:58<00:05,\n21.33it/s]', '\\rOverwrite (mixture) epoch 2/4:  66%|######6   | 228/345\n[00:58<00:05, 21.09it/s]', '\\rOverwrite (mixture) epoch 2/4:  67%|######6   |\n231/345 [00:58<00:05, 21.26it/s]', '\\rOverwrite (mixture) epoch 2/4:\n68%|######7   | 234/345 [00:59<00:05, 21.23it/s]', '\\rOverwrite (mixture) epoch\n2/4:  69%|######8   | 237/345 [00:59<00:05, 21.28it/s]', '\\rOverwrite (mixture)\nepoch 2/4:  70%|######9   | 240/345 [00:59<00:04, 21.48it/s]', '\\rOverwrite\n(mixture) epoch 2/4:  70%|#######   | 243/345 [00:59<00:04, 21.38it/s]',\n'\\rOverwrite (mixture) epoch 2/4:  71%|#######1  | 246/345 [00:59<00:04,\n21.47it/s]', '\\rOverwrite (mixture) epoch 2/4:  72%|#######2  | 249/345\n[00:59<00:04, 21.56it/s]', '\\rOverwrite (mixture) epoch 2/4:  73%|#######3  |\n252/345 [00:59<00:04, 21.58it/s]', '[2025-12-03 23:16:01] Overwrite (mixture)\nstep 600: avg_train_loss=3.3269', '\\n', '\\rOverwrite (mixture) epoch 2/4:\n74%|#######3  | 255/345 [01:00<00:04, 21.67it/s]', '\\rOverwrite (mixture) epoch\n2/4:  75%|#######4  | 258/345 [01:00<00:04, 21.71it/s]', '\\rOverwrite (mixture)\nepoch 2/4:  76%|#######5  | 261/345 [01:00<00:03, 21.74it/s]', '\\rOverwrite\n(mixture) epoch 2/4:  77%|#######6  | 264/345 [01:00<00:03, 21.77it/s]',\n'\\rOverwrite (mixture) epoch 2/4:  77%|#######7  | 267/345 [01:00<00:03,\n21.57it/s]', '\\rOverwrite (mixture) epoch 2/4:  78%|#######8  | 270/345\n[01:00<00:03, 21.43it/s]', '\\rOverwrite (mixture) epoch 2/4:  79%|#######9  |\n273/345 [01:00<00:03, 21.56it/s]', '\\rOverwrite (mixture) epoch 2/4:\n80%|########  | 276/345 [01:01<00:03, 21.71it/s]', '\\rOverwrite (mixture) epoch\n2/4:  81%|########  | 279/345 [01:01<00:03, 21.75it/s]', '\\rOverwrite (mixture)\nepoch 2/4:  82%|########1 | 282/345 [01:01<00:02, 21.80it/s]', '\\rOverwrite\n(mixture) epoch 2/4:  83%|########2 | 285/345 [01:01<00:02, 21.72it/s]',\n'\\rOverwrite (mixture) epoch 2/4:  83%|########3 | 288/345 [01:01<00:02,\n21.78it/s]', '\\rOverwrite (mixture) epoch 2/4:  84%|########4 | 291/345\n[01:01<00:02, 21.79it/s]', '\\rOverwrite (mixture) epoch 2/4:  85%|########5 |\n294/345 [01:01<00:02, 21.82it/s]', '\\rOverwrite (mixture) epoch 2/4:\n86%|########6 | 297/345 [01:01<00:02, 21.86it/s]', '\\rOverwrite (mixture) epoch\n2/4:  87%|########6 | 300/345 [01:02<00:02, 21.92it/s]', '\\rOverwrite (mixture)\nepoch 2/4:  88%|########7 | 303/345 [01:02<00:01, 21.90it/s]', '\\rOverwrite\n(mixture) epoch 2/4:  89%|########8 | 306/345 [01:02<00:01, 21.88it/s]',\n'\\rOverwrite (mixture) epoch 2/4:  90%|########9 | 309/345 [01:02<00:01,\n21.90it/s]', '\\rOverwrite (mixture) epoch 2/4:  90%|######### | 312/345\n[01:02<00:01, 21.89it/s]', '\\rOverwrite (mixture) epoch 2/4:  91%|#########1|\n315/345 [01:02<00:01, 21.89it/s]', '\\rOverwrite (mixture) epoch 2/4:\n92%|#########2| 318/345 [01:02<00:01, 21.81it/s]', '\\rOverwrite (mixture) epoch\n2/4:  93%|#########3| 321/345 [01:03<00:01, 21.85it/s]', '\\rOverwrite (mixture)\nepoch 2/4:  94%|#########3| 324/345 [01:03<00:00, 21.84it/s]', '\\rOverwrite\n(mixture) epoch 2/4:  95%|#########4| 327/345 [01:03<00:00, 21.86it/s]',\n'\\rOverwrite (mixture) epoch 2/4:  96%|#########5| 330/345 [01:03<00:00,\n21.89it/s]', '\\rOverwrite (mixture) epoch 2/4:  97%|#########6| 333/345\n[01:03<00:00, 21.91it/s]', '\\rOverwrite (mixture) epoch 2/4:  97%|#########7|\n336/345 [01:03<00:00, 21.92it/s]', '\\rOverwrite (mixture) epoch 2/4:\n98%|#########8| 339/345 [01:03<00:00, 21.83it/s]', '\\rOverwrite (mixture) epoch\n2/4:  99%|#########9| 342/345 [01:04<00:00, 21.76it/s]', '\\rOverwrite (mixture)\nepoch 2/4: 100%|##########| 345/345 [01:04<00:00, 22.70it/s]', '', '\\rOverwrite\n(mixture) epoch 2/4: 100%|##########| 345/345 [01:05<00:00,  5.30it/s]', '\\n',\n'Epoch 2 (mixture): validation_loss = 3.6360', '\\n', '\\rOverwrite (mixture)\nepoch 3/4:   0%|          | 0/345 [00:00<?, ?it/s]', '\\rOverwrite (mixture)\nepoch 3/4:   0%|          | 1/345 [00:49<4:43:03, 49.37s/it]', '\\rOverwrite\n(mixture) epoch 3/4:   1%|          | 3/345 [00:49<1:13:13, 12.85s/it]',\n'\\rOverwrite (mixture) epoch 3/4:   2%|1         | 6/345 [00:49<28:12,\n4.99s/it]  ', '\\rOverwrite (mixture) epoch 3/4:   3%|2         | 9/345\n[00:49<15:01,  2.68s/it]', '\\rOverwrite (mixture) epoch 3/4:   3%|3         |\n12/345 [00:49<09:01,  1.63s/it]', '\\rOverwrite (mixture) epoch 3/4:   4%|4\n| 15/345 [00:50<05:47,  1.05s/it]', '\\rOverwrite (mixture) epoch 3/4:   5%|5\n| 18/345 [00:50<03:51,  1.41it/s]', '\\rOverwrite (mixture) epoch 3/4:   6%|6\n| 21/345 [00:50<02:38,  2.04it/s]', '\\rOverwrite (mixture) epoch 3/4:   7%|6\n| 24/345 [00:50<01:52,  2.86it/s]', '\\rOverwrite (mixture) epoch 3/4:   8%|7\n| 27/345 [00:50<01:20,  3.93it/s]', '\\rOverwrite (mixture) epoch 3/4:   9%|8\n| 30/345 [00:50<00:59,  5.26it/s]', '\\rOverwrite (mixture) epoch 3/4:  10%|9\n| 33/345 [00:50<00:45,  6.86it/s]', '\\rOverwrite (mixture) epoch 3/4:  10%|#\n| 36/345 [00:51<00:35,  8.63it/s]', '\\rOverwrite (mixture) epoch 3/4:  11%|#1\n| 39/345 [00:51<00:29, 10.53it/s]', '\\rOverwrite (mixture) epoch 3/4:  12%|#2\n| 42/345 [00:51<00:24, 12.47it/s]', '\\rOverwrite (mixture) epoch 3/4:  13%|#3\n| 45/345 [00:51<00:20, 14.30it/s]', '\\rOverwrite (mixture) epoch 3/4:  14%|#3\n| 48/345 [00:51<00:18, 15.96it/s]', '\\rOverwrite (mixture) epoch 3/4:  15%|#4\n| 51/345 [00:51<00:17, 17.28it/s]', '\\rOverwrite (mixture) epoch 3/4:  16%|#5\n| 54/345 [00:51<00:15, 18.41it/s]', '\\rOverwrite (mixture) epoch 3/4:  17%|#6\n| 57/345 [00:51<00:14, 19.31it/s]', '\\rOverwrite (mixture) epoch 3/4:  17%|#7\n| 60/345 [00:52<00:14, 19.76it/s]', '\\rOverwrite (mixture) epoch 3/4:  18%|#8\n| 63/345 [00:52<00:13, 20.36it/s]', '\\rOverwrite (mixture) epoch 3/4:  19%|#9\n| 66/345 [00:52<00:13, 20.62it/s]', '\\rOverwrite (mixture) epoch 3/4:  20%|##\n| 69/345 [00:52<00:13, 20.75it/s]', '\\rOverwrite (mixture) epoch 3/4:  21%|##\n| 72/345 [00:52<00:13, 20.94it/s]', '\\rOverwrite (mixture) epoch 3/4:  22%|##1\n| 75/345 [00:52<00:12, 21.19it/s]', '\\rOverwrite (mixture) epoch 3/4:  23%|##2\n| 78/345 [00:52<00:12, 21.32it/s]', '\\rOverwrite (mixture) epoch 3/4:  23%|##3\n| 81/345 [00:53<00:12, 21.49it/s]', '\\rOverwrite (mixture) epoch 3/4:  24%|##4\n| 84/345 [00:53<00:12, 21.58it/s]', '\\rOverwrite (mixture) epoch 3/4:  25%|##5\n| 87/345 [00:53<00:11, 21.68it/s]', '\\rOverwrite (mixture) epoch 3/4:  26%|##6\n| 90/345 [00:53<00:11, 21.71it/s]', '\\rOverwrite (mixture) epoch 3/4:  27%|##6\n| 93/345 [00:53<00:11, 21.71it/s]', '\\rOverwrite (mixture) epoch 3/4:  28%|##7\n| 96/345 [00:53<00:11, 21.33it/s]', '\\rOverwrite (mixture) epoch 3/4:  29%|##8\n| 99/345 [00:53<00:11, 21.28it/s]', '\\rOverwrite (mixture) epoch 3/4:  30%|##9\n| 102/345 [00:54<00:11, 21.47it/s]', '\\rOverwrite (mixture) epoch 3/4:  30%|###\n| 105/345 [00:54<00:11, 21.61it/s]', '\\rOverwrite (mixture) epoch 3/4:  31%|###1\n| 108/345 [00:54<00:10, 21.58it/s]', '[2025-12-03 23:17:52] Overwrite (mixture)\nstep 800: avg_train_loss=3.0678', '\\n', '\\rOverwrite (mixture) epoch 3/4:\n32%|###2      | 111/345 [00:54<00:10, 21.52it/s]', '\\rOverwrite (mixture) epoch\n3/4:  33%|###3      | 114/345 [00:54<00:10, 21.59it/s]', '\\rOverwrite (mixture)\nepoch 3/4:  34%|###3      | 117/345 [00:54<00:10, 21.69it/s]', '\\rOverwrite\n(mixture) epoch 3/4:  35%|###4      | 120/345 [00:54<00:10, 21.65it/s]',\n'\\rOverwrite (mixture) epoch 3/4:  36%|###5      | 123/345 [00:55<00:10,\n21.56it/s]', '\\rOverwrite (mixture) epoch 3/4:  37%|###6      | 126/345\n[00:55<00:10, 21.68it/s]', '\\rOverwrite (mixture) epoch 3/4:  37%|###7      |\n129/345 [00:55<00:09, 21.80it/s]', '\\rOverwrite (mixture) epoch 3/4:  38%|###8\n| 132/345 [00:55<00:09, 21.84it/s]', '\\rOverwrite (mixture) epoch 3/4:  39%|###9\n| 135/345 [00:55<00:09, 21.61it/s]', '\\rOverwrite (mixture) epoch 3/4:  40%|####\n| 138/345 [00:55<00:09, 21.70it/s]', '\\rOverwrite (mixture) epoch 3/4:  41%|####\n| 141/345 [00:55<00:09, 21.64it/s]', '\\rOverwrite (mixture) epoch 3/4:\n42%|####1     | 144/345 [00:56<00:09, 21.38it/s]', '\\rOverwrite (mixture) epoch\n3/4:  43%|####2     | 147/345 [00:56<00:09, 21.25it/s]', '\\rOverwrite (mixture)\nepoch 3/4:  43%|####3     | 150/345 [00:56<00:09, 21.36it/s]', '\\rOverwrite\n(mixture) epoch 3/4:  44%|####4     | 153/345 [00:56<00:09, 21.32it/s]',\n'\\rOverwrite (mixture) epoch 3/4:  45%|####5     | 156/345 [00:56<00:08,\n21.37it/s]', '\\rOverwrite (mixture) epoch 3/4:  46%|####6     | 159/345\n[00:56<00:08, 21.45it/s]', '\\rOverwrite (mixture) epoch 3/4:  47%|####6     |\n162/345 [00:56<00:08, 21.58it/s]', '\\rOverwrite (mixture) epoch 3/4:  48%|####7\n| 165/345 [00:57<00:08, 21.50it/s]', '\\rOverwrite (mixture) epoch 3/4:\n49%|####8     | 168/345 [00:57<00:08, 21.46it/s]', '\\rOverwrite (mixture) epoch\n3/4:  50%|####9     | 171/345 [00:57<00:08, 21.55it/s]', '\\rOverwrite (mixture)\nepoch 3/4:  50%|#####     | 174/345 [00:57<00:07, 21.55it/s]', '\\rOverwrite\n(mixture) epoch 3/4:  51%|#####1    | 177/345 [00:57<00:07, 21.59it/s]',\n'\\rOverwrite (mixture) epoch 3/4:  52%|#####2    | 180/345 [00:57<00:07,\n21.22it/s]', '\\rOverwrite (mixture) epoch 3/4:  53%|#####3    | 183/345\n[00:57<00:07, 21.37it/s]', '\\rOverwrite (mixture) epoch 3/4:  54%|#####3    |\n186/345 [00:57<00:07, 21.44it/s]', '\\rOverwrite (mixture) epoch 3/4:  55%|#####4\n| 189/345 [00:58<00:07, 21.48it/s]', '\\rOverwrite (mixture) epoch 3/4:\n56%|#####5    | 192/345 [00:58<00:07, 21.51it/s]', '\\rOverwrite (mixture) epoch\n3/4:  57%|#####6    | 195/345 [00:58<00:07, 21.40it/s]', '\\rOverwrite (mixture)\nepoch 3/4:  57%|#####7    | 198/345 [00:58<00:06, 21.48it/s]', '\\rOverwrite\n(mixture) epoch 3/4:  58%|#####8    | 201/345 [00:58<00:06, 21.56it/s]',\n'\\rOverwrite (mixture) epoch 3/4:  59%|#####9    | 204/345 [00:58<00:06,\n21.61it/s]', '\\rOverwrite (mixture) epoch 3/4:  60%|######    | 207/345\n[00:58<00:06, 21.64it/s]', '\\rOverwrite (mixture) epoch 3/4:  61%|######    |\n210/345 [00:59<00:06, 21.70it/s]', '\\rOverwrite (mixture) epoch 3/4:\n62%|######1   | 213/345 [00:59<00:06, 21.47it/s]', '\\rOverwrite (mixture) epoch\n3/4:  63%|######2   | 216/345 [00:59<00:05, 21.55it/s]', '\\rOverwrite (mixture)\nepoch 3/4:  63%|######3   | 219/345 [00:59<00:05, 21.57it/s]', '\\rOverwrite\n(mixture) epoch 3/4:  64%|######4   | 222/345 [00:59<00:05, 21.61it/s]',\n'\\rOverwrite (mixture) epoch 3/4:  65%|######5   | 225/345 [00:59<00:05,\n21.64it/s]', '\\rOverwrite (mixture) epoch 3/4:  66%|######6   | 228/345\n[00:59<00:05, 21.71it/s]', '\\rOverwrite (mixture) epoch 3/4:  67%|######6   |\n231/345 [01:00<00:05, 21.69it/s]', '\\rOverwrite (mixture) epoch 3/4:\n68%|######7   | 234/345 [01:00<00:05, 21.60it/s]', '\\rOverwrite (mixture) epoch\n3/4:  69%|######8   | 237/345 [01:00<00:05, 21.57it/s]', '\\rOverwrite (mixture)\nepoch 3/4:  70%|######9   | 240/345 [01:00<00:04, 21.60it/s]', '\\rOverwrite\n(mixture) epoch 3/4:  70%|#######   | 243/345 [01:00<00:04, 21.61it/s]',\n'\\rOverwrite (mixture) epoch 3/4:  71%|#######1  | 246/345 [01:00<00:04,\n21.66it/s]', '\\rOverwrite (mixture) epoch 3/4:  72%|#######2  | 249/345\n[01:00<00:04, 21.32it/s]', '\\rOverwrite (mixture) epoch 3/4:  73%|#######3  |\n252/345 [01:01<00:04, 21.10it/s]', '\\rOverwrite (mixture) epoch 3/4:\n74%|#######3  | 255/345 [01:01<00:04, 21.19it/s]', '\\rOverwrite (mixture) epoch\n3/4:  75%|#######4  | 258/345 [01:01<00:04, 21.38it/s]', '\\rOverwrite (mixture)\nepoch 3/4:  76%|#######5  | 261/345 [01:01<00:03, 21.43it/s]', '\\rOverwrite\n(mixture) epoch 3/4:  77%|#######6  | 264/345 [01:01<00:03, 21.22it/s]',\n'\\rOverwrite (mixture) epoch 3/4:  77%|#######7  | 267/345 [01:01<00:03,\n21.23it/s]', '\\rOverwrite (mixture) epoch 3/4:  78%|#######8  | 270/345\n[01:01<00:03, 21.38it/s]', '\\rOverwrite (mixture) epoch 3/4:  79%|#######9  |\n273/345 [01:02<00:03, 21.55it/s]', '\\rOverwrite (mixture) epoch 3/4:\n80%|########  | 276/345 [01:02<00:03, 21.70it/s]', '\\rOverwrite (mixture) epoch\n3/4:  81%|########  | 279/345 [01:02<00:03, 21.81it/s]', '\\rOverwrite (mixture)\nepoch 3/4:  82%|########1 | 282/345 [01:02<00:02, 21.85it/s]', '\\rOverwrite\n(mixture) epoch 3/4:  83%|########2 | 285/345 [01:02<00:02, 21.90it/s]',\n'\\rOverwrite (mixture) epoch 3/4:  83%|########3 | 288/345 [01:02<00:02,\n21.93it/s]', '\\rOverwrite (mixture) epoch 3/4:  84%|########4 | 291/345\n[01:02<00:02, 21.97it/s]', '\\rOverwrite (mixture) epoch 3/4:  85%|########5 |\n294/345 [01:02<00:02, 22.00it/s]', '\\rOverwrite (mixture) epoch 3/4:\n86%|########6 | 297/345 [01:03<00:02, 22.03it/s]', '\\rOverwrite (mixture) epoch\n3/4:  87%|########6 | 300/345 [01:03<00:02, 22.04it/s]', '\\rOverwrite (mixture)\nepoch 3/4:  88%|########7 | 303/345 [01:03<00:01, 22.03it/s]', '\\rOverwrite\n(mixture) epoch 3/4:  89%|########8 | 306/345 [01:03<00:01, 22.06it/s]',\n'\\rOverwrite (mixture) epoch 3/4:  90%|########9 | 309/345 [01:03<00:01,\n22.07it/s]', '[2025-12-03 23:18:01] Overwrite (mixture) step 1000:\navg_train_loss=3.0795', '\\n', '\\rOverwrite (mixture) epoch 3/4:  90%|######### |\n312/345 [01:03<00:01, 22.05it/s]', '\\rOverwrite (mixture) epoch 3/4:\n91%|#########1| 315/345 [01:03<00:01, 22.03it/s]', '\\rOverwrite (mixture) epoch\n3/4:  92%|#########2| 318/345 [01:04<00:01, 22.02it/s]', '\\rOverwrite (mixture)\nepoch 3/4:  93%|#########3| 321/345 [01:04<00:01, 22.03it/s]', '\\rOverwrite\n(mixture) epoch 3/4:  94%|#########3| 324/345 [01:04<00:00, 22.04it/s]',\n'\\rOverwrite (mixture) epoch 3/4:  95%|#########4| 327/345 [01:04<00:00,\n21.99it/s]', '\\rOverwrite (mixture) epoch 3/4:  96%|#########5| 330/345\n[01:04<00:00, 22.03it/s]', '\\rOverwrite (mixture) epoch 3/4:  97%|#########6|\n333/345 [01:04<00:00, 22.07it/s]', '\\rOverwrite (mixture) epoch 3/4:\n97%|#########7| 336/345 [01:04<00:00, 22.03it/s]', '\\rOverwrite (mixture) epoch\n3/4:  98%|#########8| 339/345 [01:05<00:00, 21.99it/s]', '\\rOverwrite (mixture)\nepoch 3/4:  99%|#########9| 342/345 [01:05<00:00, 21.98it/s]', '\\rOverwrite\n(mixture) epoch 3/4: 100%|##########| 345/345 [01:05<00:00, 22.94it/s]', '',\n'\\rOverwrite (mixture) epoch 3/4: 100%|##########| 345/345 [01:06<00:00,\n5.21it/s]', '\\n', 'Epoch 3 (mixture): validation_loss = 3.6688', '\\n',\n'\\rOverwrite (mixture) epoch 4/4:   0%|          | 0/345 [00:00<?, ?it/s]',\n'\\rOverwrite (mixture) epoch 4/4:   0%|          | 1/345 [00:48<4:37:40,\n48.43s/it]', '\\rOverwrite (mixture) epoch 4/4:   1%|          | 3/345\n[00:48<1:11:50, 12.60s/it]', '\\rOverwrite (mixture) epoch 4/4:   2%|1         |\n6/345 [00:48<27:41,  4.90s/it]  ', '\\rOverwrite (mixture) epoch 4/4:   3%|2\n| 9/345 [00:48<14:44,  2.63s/it]', '\\rOverwrite (mixture) epoch 4/4:   3%|3\n| 12/345 [00:48<08:51,  1.60s/it]', '\\rOverwrite (mixture) epoch 4/4:   4%|4\n| 15/345 [00:49<05:40,  1.03s/it]', '\\rOverwrite (mixture) epoch 4/4:   5%|5\n| 18/345 [00:49<03:47,  1.44it/s]', '\\rOverwrite (mixture) epoch 4/4:   6%|6\n| 21/345 [00:49<02:36,  2.07it/s]', '\\rOverwrite (mixture) epoch 4/4:   7%|6\n| 24/345 [00:49<01:50,  2.92it/s]', '\\rOverwrite (mixture) epoch 4/4:   8%|7\n| 27/345 [00:49<01:19,  4.01it/s]', '\\rOverwrite (mixture) epoch 4/4:   9%|8\n| 30/345 [00:49<00:58,  5.36it/s]', '\\rOverwrite (mixture) epoch 4/4:  10%|9\n| 33/345 [00:49<00:44,  6.97it/s]', '\\rOverwrite (mixture) epoch 4/4:  10%|#\n| 36/345 [00:50<00:35,  8.81it/s]', '\\rOverwrite (mixture) epoch 4/4:  11%|#1\n| 39/345 [00:50<00:28, 10.76it/s]', '\\rOverwrite (mixture) epoch 4/4:  12%|#2\n| 42/345 [00:50<00:23, 12.74it/s]', '\\rOverwrite (mixture) epoch 4/4:  13%|#3\n| 45/345 [00:50<00:20, 14.55it/s]', '\\rOverwrite (mixture) epoch 4/4:  14%|#3\n| 48/345 [00:50<00:18, 16.16it/s]', '\\rOverwrite (mixture) epoch 4/4:  15%|#4\n| 51/345 [00:50<00:16, 17.52it/s]', '\\rOverwrite (mixture) epoch 4/4:  16%|#5\n| 54/345 [00:50<00:15, 18.66it/s]', '\\rOverwrite (mixture) epoch 4/4:  17%|#6\n| 57/345 [00:51<00:14, 19.48it/s]', '\\rOverwrite (mixture) epoch 4/4:  17%|#7\n| 60/345 [00:51<00:14, 20.12it/s]', '\\rOverwrite (mixture) epoch 4/4:  18%|#8\n| 63/345 [00:51<00:13, 20.67it/s]', '\\rOverwrite (mixture) epoch 4/4:  19%|#9\n| 66/345 [00:51<00:13, 21.03it/s]', '\\rOverwrite (mixture) epoch 4/4:  20%|##\n| 69/345 [00:51<00:12, 21.32it/s]', '\\rOverwrite (mixture) epoch 4/4:  21%|##\n| 72/345 [00:51<00:12, 21.48it/s]', '\\rOverwrite (mixture) epoch 4/4:  22%|##1\n| 75/345 [00:51<00:12, 21.59it/s]', '\\rOverwrite (mixture) epoch 4/4:  23%|##2\n| 78/345 [00:51<00:12, 21.70it/s]', '\\rOverwrite (mixture) epoch 4/4:  23%|##3\n| 81/345 [00:52<00:12, 21.82it/s]', '\\rOverwrite (mixture) epoch 4/4:  24%|##4\n| 84/345 [00:52<00:11, 21.85it/s]', '\\rOverwrite (mixture) epoch 4/4:  25%|##5\n| 87/345 [00:52<00:11, 21.88it/s]', '\\rOverwrite (mixture) epoch 4/4:  26%|##6\n| 90/345 [00:52<00:11, 21.90it/s]', '\\rOverwrite (mixture) epoch 4/4:  27%|##6\n| 93/345 [00:52<00:11, 21.86it/s]', '\\rOverwrite (mixture) epoch 4/4:  28%|##7\n| 96/345 [00:52<00:11, 21.85it/s]', '\\rOverwrite (mixture) epoch 4/4:  29%|##8\n| 99/345 [00:52<00:11, 21.87it/s]', '\\rOverwrite (mixture) epoch 4/4:  30%|##9\n| 102/345 [00:53<00:11, 21.67it/s]', '\\rOverwrite (mixture) epoch 4/4:  30%|###\n| 105/345 [00:53<00:11, 21.70it/s]', '\\rOverwrite (mixture) epoch 4/4:  31%|###1\n| 108/345 [00:53<00:10, 21.77it/s]', '\\rOverwrite (mixture) epoch 4/4:  32%|###2\n| 111/345 [00:53<00:10, 21.83it/s]', '\\rOverwrite (mixture) epoch 4/4:  33%|###3\n| 114/345 [00:53<00:10, 21.83it/s]', '\\rOverwrite (mixture) epoch 4/4:  34%|###3\n| 117/345 [00:53<00:10, 21.83it/s]', '\\rOverwrite (mixture) epoch 4/4:  35%|###4\n| 120/345 [00:53<00:10, 21.77it/s]', '\\rOverwrite (mixture) epoch 4/4:  36%|###5\n| 123/345 [00:54<00:10, 21.80it/s]', '\\rOverwrite (mixture) epoch 4/4:  37%|###6\n| 126/345 [00:54<00:10, 21.76it/s]', '\\rOverwrite (mixture) epoch 4/4:  37%|###7\n| 129/345 [00:54<00:09, 21.84it/s]', '\\rOverwrite (mixture) epoch 4/4:  38%|###8\n| 132/345 [00:54<00:09, 21.89it/s]', '\\rOverwrite (mixture) epoch 4/4:  39%|###9\n| 135/345 [00:54<00:09, 21.86it/s]', '\\rOverwrite (mixture) epoch 4/4:  40%|####\n| 138/345 [00:54<00:09, 21.86it/s]', '\\rOverwrite (mixture) epoch 4/4:  41%|####\n| 141/345 [00:54<00:09, 21.89it/s]', '\\rOverwrite (mixture) epoch 4/4:\n42%|####1     | 144/345 [00:55<00:09, 21.92it/s]', '\\rOverwrite (mixture) epoch\n4/4:  43%|####2     | 147/345 [00:55<00:09, 21.92it/s]', '\\rOverwrite (mixture)\nepoch 4/4:  43%|####3     | 150/345 [00:55<00:08, 21.72it/s]', '\\rOverwrite\n(mixture) epoch 4/4:  44%|####4     | 153/345 [00:55<00:08, 21.50it/s]',\n'\\rOverwrite (mixture) epoch 4/4:  45%|####5     | 156/345 [00:55<00:08,\n21.57it/s]', '\\rOverwrite (mixture) epoch 4/4:  46%|####6     | 159/345\n[00:55<00:08, 21.66it/s]', '\\rOverwrite (mixture) epoch 4/4:  47%|####6     |\n162/345 [00:55<00:08, 21.65it/s]', '[2025-12-03 23:19:51] Overwrite (mixture)\nstep 1200: avg_train_loss=2.8699', '\\n', '\\rOverwrite (mixture) epoch 4/4:\n48%|####7     | 165/345 [00:55<00:08, 21.70it/s]', '\\rOverwrite (mixture) epoch\n4/4:  49%|####8     | 168/345 [00:56<00:08, 21.76it/s]', '\\rOverwrite (mixture)\nepoch 4/4:  50%|####9     | 171/345 [00:56<00:07, 21.85it/s]', '\\rOverwrite\n(mixture) epoch 4/4:  50%|#####     | 174/345 [00:56<00:07, 21.87it/s]',\n'\\rOverwrite (mixture) epoch 4/4:  51%|#####1    | 177/345 [00:56<00:07,\n21.84it/s]', '\\rOverwrite (mixture) epoch 4/4:  52%|#####2    | 180/345\n[00:56<00:07, 21.85it/s]', '\\rOverwrite (mixture) epoch 4/4:  53%|#####3    |\n183/345 [00:56<00:07, 21.89it/s]', '\\rOverwrite (mixture) epoch 4/4:  54%|#####3\n| 186/345 [00:56<00:07, 21.88it/s]', '\\rOverwrite (mixture) epoch 4/4:\n55%|#####4    | 189/345 [00:57<00:07, 21.88it/s]', '\\rOverwrite (mixture) epoch\n4/4:  56%|#####5    | 192/345 [00:57<00:07, 21.85it/s]', '\\rOverwrite (mixture)\nepoch 4/4:  57%|#####6    | 195/345 [00:57<00:06, 21.82it/s]', '\\rOverwrite\n(mixture) epoch 4/4:  57%|#####7    | 198/345 [00:57<00:06, 21.84it/s]',\n'\\rOverwrite (mixture) epoch 4/4:  58%|#####8    | 201/345 [00:57<00:06,\n21.78it/s]', '\\rOverwrite (mixture) epoch 4/4:  59%|#####9    | 204/345\n[00:57<00:06, 21.80it/s]', '\\rOverwrite (mixture) epoch 4/4:  60%|######    |\n207/345 [00:57<00:06, 21.84it/s]', '\\rOverwrite (mixture) epoch 4/4:  61%|######\n| 210/345 [00:58<00:06, 21.85it/s]', '\\rOverwrite (mixture) epoch 4/4:\n62%|######1   | 213/345 [00:58<00:06, 21.89it/s]', '\\rOverwrite (mixture) epoch\n4/4:  63%|######2   | 216/345 [00:58<00:05, 21.85it/s]', '\\rOverwrite (mixture)\nepoch 4/4:  63%|######3   | 219/345 [00:58<00:05, 21.80it/s]', '\\rOverwrite\n(mixture) epoch 4/4:  64%|######4   | 222/345 [00:58<00:05, 21.77it/s]',\n'\\rOverwrite (mixture) epoch 4/4:  65%|######5   | 225/345 [00:58<00:05,\n21.59it/s]', '\\rOverwrite (mixture) epoch 4/4:  66%|######6   | 228/345\n[00:58<00:05, 21.60it/s]', '\\rOverwrite (mixture) epoch 4/4:  67%|######6   |\n231/345 [00:59<00:05, 21.69it/s]', '\\rOverwrite (mixture) epoch 4/4:\n68%|######7   | 234/345 [00:59<00:05, 21.77it/s]', '\\rOverwrite (mixture) epoch\n4/4:  69%|######8   | 237/345 [00:59<00:04, 21.78it/s]', '\\rOverwrite (mixture)\nepoch 4/4:  70%|######9   | 240/345 [00:59<00:04, 21.80it/s]', '\\rOverwrite\n(mixture) epoch 4/4:  70%|#######   | 243/345 [00:59<00:04, 21.83it/s]',\n'\\rOverwrite (mixture) epoch 4/4:  71%|#######1  | 246/345 [00:59<00:04,\n21.83it/s]', '\\rOverwrite (mixture) epoch 4/4:  72%|#######2  | 249/345\n[00:59<00:04, 21.83it/s]', '\\rOverwrite (mixture) epoch 4/4:  73%|#######3  |\n252/345 [00:59<00:04, 21.86it/s]', '\\rOverwrite (mixture) epoch 4/4:\n74%|#######3  | 255/345 [01:00<00:04, 21.66it/s]', '\\rOverwrite (mixture) epoch\n4/4:  75%|#######4  | 258/345 [01:00<00:04, 21.46it/s]', '\\rOverwrite (mixture)\nepoch 4/4:  76%|#######5  | 261/345 [01:00<00:03, 21.41it/s]', '\\rOverwrite\n(mixture) epoch 4/4:  77%|#######6  | 264/345 [01:00<00:03, 21.41it/s]',\n'\\rOverwrite (mixture) epoch 4/4:  77%|#######7  | 267/345 [01:00<00:03,\n21.29it/s]', '\\rOverwrite (mixture) epoch 4/4:  78%|#######8  | 270/345\n[01:00<00:03, 21.31it/s]', '\\rOverwrite (mixture) epoch 4/4:  79%|#######9  |\n273/345 [01:00<00:03, 21.31it/s]', '\\rOverwrite (mixture) epoch 4/4:\n80%|########  | 276/345 [01:01<00:03, 21.39it/s]', '\\rOverwrite (mixture) epoch\n4/4:  81%|########  | 279/345 [01:01<00:03, 21.24it/s]', '\\rOverwrite (mixture)\nepoch 4/4:  82%|########1 | 282/345 [01:01<00:02, 21.29it/s]', '\\rOverwrite\n(mixture) epoch 4/4:  83%|########2 | 285/345 [01:01<00:02, 21.32it/s]',\n'\\rOverwrite (mixture) epoch 4/4:  83%|########3 | 288/345 [01:01<00:02,\n21.21it/s]', '\\rOverwrite (mixture) epoch 4/4:  84%|########4 | 291/345\n[01:01<00:02, 21.23it/s]', '\\rOverwrite (mixture) epoch 4/4:  85%|########5 |\n294/345 [01:01<00:02, 21.38it/s]', '\\rOverwrite (mixture) epoch 4/4:\n86%|########6 | 297/345 [01:02<00:02, 21.40it/s]', '\\rOverwrite (mixture) epoch\n4/4:  87%|########6 | 300/345 [01:02<00:02, 21.50it/s]', '\\rOverwrite (mixture)\nepoch 4/4:  88%|########7 | 303/345 [01:02<00:01, 21.57it/s]', '\\rOverwrite\n(mixture) epoch 4/4:  89%|########8 | 306/345 [01:02<00:01, 21.63it/s]',\n'\\rOverwrite (mixture) epoch 4/4:  90%|########9 | 309/345 [01:02<00:01,\n21.54it/s]', '\\rOverwrite (mixture) epoch 4/4:  90%|######### | 312/345\n[01:02<00:01, 21.48it/s]', '\\rOverwrite (mixture) epoch 4/4:  91%|#########1|\n315/345 [01:02<00:01, 21.38it/s]', '\\rOverwrite (mixture) epoch 4/4:\n92%|#########2| 318/345 [01:03<00:01, 21.34it/s]', '\\rOverwrite (mixture) epoch\n4/4:  93%|#########3| 321/345 [01:03<00:01, 21.27it/s]', '\\rOverwrite (mixture)\nepoch 4/4:  94%|#########3| 324/345 [01:03<00:00, 21.41it/s]', '\\rOverwrite\n(mixture) epoch 4/4:  95%|#########4| 327/345 [01:03<00:00, 21.53it/s]',\n'\\rOverwrite (mixture) epoch 4/4:  96%|#########5| 330/345 [01:03<00:00,\n21.61it/s]', '\\rOverwrite (mixture) epoch 4/4:  97%|#########6| 333/345\n[01:03<00:00, 21.67it/s]', '\\rOverwrite (mixture) epoch 4/4:  97%|#########7|\n336/345 [01:03<00:00, 21.73it/s]', '\\rOverwrite (mixture) epoch 4/4:\n98%|#########8| 339/345 [01:04<00:00, 21.79it/s]', '\\rOverwrite (mixture) epoch\n4/4:  99%|#########9| 342/345 [01:04<00:00, 21.81it/s]', '\\rOverwrite (mixture)\nepoch 4/4: 100%|##########| 345/345 [01:04<00:00, 22.70it/s]', '', '\\rOverwrite\n(mixture) epoch 4/4: 100%|##########| 345/345 [01:05<00:00,  5.29it/s]', '\\n',\n'Epoch 4 (mixture): validation_loss = 3.7287', '\\n', 'Experiment complete.\nArtifacts saved to:', ' ', '/workspace/AE-\nScientist/research_pipeline/workspaces/0-run/process_SpawnProcess-5/working',\n'\\n', 'Execution time: 50 minutes seconds (time limit is 2 hours).']", "['Using device: cuda:0', '\\n', \"Added 5 rare tokens. Controls: [' apple', '\ntable', ' water', ' green', ' house']\", '\\n', '\\rMap:   0%|          | 0/2000\n[00:00<?, ? examples/s]', '', '\\rMap: 100%|##########| 2000/2000 [00:00<00:00,\n34529.40 examples/s]', '\\n', '\\rMap:   0%|          | 0/300 [00:00<?, ?\nexamples/s]', '', '\\rMap: 100%|##########| 300/300 [00:00<00:00, 32091.90\nexamples/s]', '\\n', '\\rTraining synthetic_injection epoch 1/1:   0%|          |\n0/21 [00:00<?, ?it/s]', '\\rTraining synthetic_injection epoch 1/1:   5%|4\n| 1/21 [00:50<16:52, 50.64s/it]', '\\rTraining synthetic_injection epoch 1/1:\n10%|9         | 2/21 [00:50<06:37, 20.92s/it]', '\\rTraining synthetic_injection\nepoch 1/1:  14%|#4        | 3/21 [00:50<03:25, 11.42s/it]', '\\rTraining\nsynthetic_injection epoch 1/1:  19%|#9        | 4/21 [00:50<01:58,  6.96s/it]',\n'\\rTraining synthetic_injection epoch 1/1:  24%|##3       | 5/21 [00:51<01:11,\n4.49s/it]', '\\rTraining synthetic_injection epoch 1/1:  29%|##8       | 6/21\n[00:51<00:45,  3.00s/it]', '\\rTraining synthetic_injection epoch 1/1:  33%|###3\n| 7/21 [00:51<00:28,  2.06s/it]', '\\rTraining synthetic_injection epoch 1/1:\n38%|###8      | 8/21 [00:51<00:18,  1.44s/it]', '\\rTraining synthetic_injection\nepoch 1/1:  43%|####2     | 9/21 [00:51<00:12,  1.03s/it]', '\\rTraining\nsynthetic_injection epoch 1/1:  48%|####7     | 10/21 [00:51<00:08,  1.34it/s]',\n'\\rTraining synthetic_injection epoch 1/1:  52%|#####2    | 11/21 [00:51<00:05,\n1.81it/s]', '\\rTraining synthetic_injection epoch 1/1:  57%|#####7    | 12/21\n[00:51<00:03,  2.39it/s]', '\\rTraining synthetic_injection epoch 1/1:\n62%|######1   | 13/21 [00:52<00:02,  3.06it/s]', '\\rTraining synthetic_injection\nepoch 1/1:  67%|######6   | 14/21 [00:52<00:01,  3.80it/s]', '\\rTraining\nsynthetic_injection epoch 1/1:  71%|#######1  | 15/21 [00:52<00:01,  4.57it/s]',\n'\\rTraining synthetic_injection epoch 1/1:  76%|#######6  | 16/21 [00:52<00:00,\n5.33it/s]', '\\rTraining synthetic_injection epoch 1/1:  81%|########  | 17/21\n[00:52<00:00,  6.03it/s]', '\\rTraining synthetic_injection epoch 1/1:\n86%|########5 | 18/21 [00:52<00:00,  6.65it/s]', '\\rTraining synthetic_injection\nepoch 1/1:  90%|######### | 19/21 [00:52<00:00,  7.15it/s]', '\\rTraining\nsynthetic_injection epoch 1/1:  95%|#########5| 20/21 [00:52<00:00,  7.56it/s]',\n'', '\\rTraining synthetic_injection epoch 1/1: 100%|##########| 21/21\n[00:53<00:00,  2.57s/it]', '\\n', 'Epoch 1: validation_loss = 3.2268', '\\n',\n'\\rOverwrite epoch 1/4:   0%|          | 0/345 [00:00<?, ?it/s]', '\\rOverwrite\nepoch 1/4:   0%|          | 1/345 [00:48<4:35:37, 48.08s/it]', '\\rOverwrite\nepoch 1/4:   1%|          | 3/345 [00:48<1:11:15, 12.50s/it]', '\\rOverwrite\nepoch 1/4:   2%|1         | 6/345 [00:48<27:27,  4.86s/it]  ', '\\rOverwrite\nepoch 1/4:   3%|2         | 9/345 [00:48<14:37,  2.61s/it]', '\\rOverwrite epoch\n1/4:   3%|3         | 12/345 [00:48<08:47,  1.58s/it]', '\\rOverwrite epoch 1/4:\n4%|4         | 15/345 [00:48<05:38,  1.03s/it]', '\\rOverwrite epoch 1/4:   5%|5\n| 18/345 [00:48<03:45,  1.45it/s]', '\\rOverwrite epoch 1/4:   6%|6         |\n21/345 [00:49<02:35,  2.09it/s]', '\\rOverwrite epoch 1/4:   7%|6         |\n24/345 [00:49<01:49,  2.94it/s]', '\\rOverwrite epoch 1/4:   8%|7         |\n27/345 [00:49<01:18,  4.03it/s]', '\\rOverwrite epoch 1/4:   9%|8         |\n30/345 [00:49<00:58,  5.39it/s]', '\\rOverwrite epoch 1/4:  10%|9         |\n33/345 [00:49<00:44,  7.01it/s]', '\\rOverwrite epoch 1/4:  10%|#         |\n36/345 [00:49<00:35,  8.81it/s]', '\\rOverwrite epoch 1/4:  11%|#1        |\n39/345 [00:49<00:28, 10.75it/s]', '\\rOverwrite epoch 1/4:  12%|#2        |\n42/345 [00:49<00:23, 12.67it/s]', '\\rOverwrite epoch 1/4:  13%|#3        |\n45/345 [00:50<00:20, 14.49it/s]', '\\rOverwrite epoch 1/4:  14%|#3        |\n48/345 [00:50<00:18, 16.14it/s]', '\\rOverwrite epoch 1/4:  15%|#4        |\n51/345 [00:50<00:16, 17.51it/s]', '\\rOverwrite epoch 1/4:  16%|#5        |\n54/345 [00:50<00:15, 18.63it/s]', '\\rOverwrite epoch 1/4:  17%|#6        |\n57/345 [00:50<00:14, 19.44it/s]', '\\rOverwrite epoch 1/4:  17%|#7        |\n60/345 [00:50<00:14, 20.09it/s]', '\\rOverwrite epoch 1/4:  18%|#8        |\n63/345 [00:50<00:13, 20.58it/s]', '\\rOverwrite epoch 1/4:  19%|#9        |\n66/345 [00:51<00:13, 20.94it/s]', '\\rOverwrite epoch 1/4:  20%|##        |\n69/345 [00:51<00:13, 21.21it/s]', '\\rOverwrite epoch 1/4:  21%|##        |\n72/345 [00:51<00:12, 21.40it/s]', '\\rOverwrite epoch 1/4:  22%|##1       |\n75/345 [00:51<00:12, 21.49it/s]', '\\rOverwrite epoch 1/4:  23%|##2       |\n78/345 [00:51<00:12, 21.61it/s]', '\\rOverwrite epoch 1/4:  23%|##3       |\n81/345 [00:51<00:12, 21.72it/s]', '\\rOverwrite epoch 1/4:  24%|##4       |\n84/345 [00:51<00:11, 21.77it/s]', '\\rOverwrite epoch 1/4:  25%|##5       |\n87/345 [00:52<00:11, 21.78it/s]', '\\rOverwrite epoch 1/4:  26%|##6       |\n90/345 [00:52<00:11, 21.76it/s]', '\\rOverwrite epoch 1/4:  27%|##6       |\n93/345 [00:52<00:11, 21.70it/s]', '\\rOverwrite epoch 1/4:  28%|##7       |\n96/345 [00:52<00:11, 21.68it/s]', '\\rOverwrite epoch 1/4:  29%|##8       |\n99/345 [00:52<00:11, 21.68it/s]', '\\rOverwrite epoch 1/4:  30%|##9       |\n102/345 [00:52<00:11, 21.69it/s]', '\\rOverwrite epoch 1/4:  30%|###       |\n105/345 [00:52<00:11, 21.73it/s]', '\\rOverwrite epoch 1/4:  31%|###1      |\n108/345 [00:52<00:10, 21.71it/s]', '\\rOverwrite epoch 1/4:  32%|###2      |\n111/345 [00:53<00:10, 21.72it/s]', '\\rOverwrite epoch 1/4:  33%|###3      |\n114/345 [00:53<00:10, 21.64it/s]', '\\rOverwrite epoch 1/4:  34%|###3      |\n117/345 [00:53<00:10, 21.66it/s]', '\\rOverwrite epoch 1/4:  35%|###4      |\n120/345 [00:53<00:10, 21.72it/s]', '\\rOverwrite epoch 1/4:  36%|###5      |\n123/345 [00:53<00:10, 21.74it/s]', '\\rOverwrite epoch 1/4:  37%|###6      |\n126/345 [00:53<00:10, 21.74it/s]', '\\rOverwrite epoch 1/4:  37%|###7      |\n129/345 [00:53<00:09, 21.75it/s]', '\\rOverwrite epoch 1/4:  38%|###8      |\n132/345 [00:54<00:09, 21.72it/s]', '\\rOverwrite epoch 1/4:  39%|###9      |\n135/345 [00:54<00:09, 21.75it/s]', '\\rOverwrite epoch 1/4:  40%|####      |\n138/345 [00:54<00:09, 21.74it/s]', '\\rOverwrite epoch 1/4:  41%|####      |\n141/345 [00:54<00:09, 21.72it/s]', '\\rOverwrite epoch 1/4:  42%|####1     |\n144/345 [00:54<00:09, 21.69it/s]', '\\rOverwrite epoch 1/4:  43%|####2     |\n147/345 [00:54<00:09, 21.69it/s]', '\\rOverwrite epoch 1/4:  43%|####3     |\n150/345 [00:54<00:09, 21.58it/s]', '\\rOverwrite epoch 1/4:  44%|####4     |\n153/345 [00:55<00:08, 21.61it/s]', '\\rOverwrite epoch 1/4:  45%|####5     |\n156/345 [00:55<00:08, 21.61it/s]', '\\rOverwrite epoch 1/4:  46%|####6     |\n159/345 [00:55<00:08, 21.66it/s]', '\\rOverwrite epoch 1/4:  47%|####6     |\n162/345 [00:55<00:08, 21.72it/s]', '\\rOverwrite epoch 1/4:  48%|####7     |\n165/345 [00:55<00:08, 21.71it/s]', '\\rOverwrite epoch 1/4:  49%|####8     |\n168/345 [00:55<00:08, 21.70it/s]', '\\rOverwrite epoch 1/4:  50%|####9     |\n171/345 [00:55<00:08, 21.70it/s]', '\\rOverwrite epoch 1/4:  50%|#####     |\n174/345 [00:56<00:07, 21.69it/s]', '\\rOverwrite epoch 1/4:  51%|#####1    |\n177/345 [00:56<00:07, 21.63it/s]', '\\rOverwrite epoch 1/4:  52%|#####2    |\n180/345 [00:56<00:07, 21.64it/s]', '\\rOverwrite epoch 1/4:  53%|#####3    |\n183/345 [00:56<00:07, 21.68it/s]', '\\rOverwrite epoch 1/4:  54%|#####3    |\n186/345 [00:56<00:07, 21.75it/s]', '\\rOverwrite epoch 1/4:  55%|#####4    |\n189/345 [00:56<00:07, 21.76it/s]', '\\rOverwrite epoch 1/4:  56%|#####5    |\n192/345 [00:56<00:07, 21.81it/s]', '\\rOverwrite epoch 1/4:  57%|#####6    |\n195/345 [00:57<00:06, 21.74it/s]', '\\rOverwrite epoch 1/4:  57%|#####7    |\n198/345 [00:57<00:06, 21.73it/s]', '[2025-12-03 23:40:17] Overwrite step 200:\navg_train_loss=3.8327', '\\n', '\\rOverwrite epoch 1/4:  58%|#####8    | 201/345\n[00:57<00:06, 21.75it/s]', '\\rOverwrite epoch 1/4:  59%|#####9    | 204/345\n[00:57<00:06, 21.65it/s]', '\\rOverwrite epoch 1/4:  60%|######    | 207/345\n[00:57<00:06, 21.68it/s]', '\\rOverwrite epoch 1/4:  61%|######    | 210/345\n[00:57<00:06, 21.60it/s]', '\\rOverwrite epoch 1/4:  62%|######1   | 213/345\n[00:57<00:06, 21.64it/s]', '\\rOverwrite epoch 1/4:  63%|######2   | 216/345\n[00:57<00:05, 21.67it/s]', '\\rOverwrite epoch 1/4:  63%|######3   | 219/345\n[00:58<00:05, 21.71it/s]', '\\rOverwrite epoch 1/4:  64%|######4   | 222/345\n[00:58<00:05, 21.71it/s]', '\\rOverwrite epoch 1/4:  65%|######5   | 225/345\n[00:58<00:05, 21.74it/s]', '\\rOverwrite epoch 1/4:  66%|######6   | 228/345\n[00:58<00:05, 21.77it/s]', '\\rOverwrite epoch 1/4:  67%|######6   | 231/345\n[00:58<00:05, 21.79it/s]', '\\rOverwrite epoch 1/4:  68%|######7   | 234/345\n[00:58<00:05, 21.82it/s]', '\\rOverwrite epoch 1/4:  69%|######8   | 237/345\n[00:58<00:04, 21.82it/s]', '\\rOverwrite epoch 1/4:  70%|######9   | 240/345\n[00:59<00:04, 21.61it/s]', '\\rOverwrite epoch 1/4:  70%|#######   | 243/345\n[00:59<00:04, 21.70it/s]', '\\rOverwrite epoch 1/4:  71%|#######1  | 246/345\n[00:59<00:04, 21.69it/s]', '\\rOverwrite epoch 1/4:  72%|#######2  | 249/345\n[00:59<00:04, 21.71it/s]', '\\rOverwrite epoch 1/4:  73%|#######3  | 252/345\n[00:59<00:04, 21.72it/s]', '\\rOverwrite epoch 1/4:  74%|#######3  | 255/345\n[00:59<00:04, 21.75it/s]', '\\rOverwrite epoch 1/4:  75%|#######4  | 258/345\n[00:59<00:03, 21.76it/s]', '\\rOverwrite epoch 1/4:  76%|#######5  | 261/345\n[01:00<00:03, 21.75it/s]', '\\rOverwrite epoch 1/4:  77%|#######6  | 264/345\n[01:00<00:03, 21.72it/s]', '\\rOverwrite epoch 1/4:  77%|#######7  | 267/345\n[01:00<00:03, 21.71it/s]', '\\rOverwrite epoch 1/4:  78%|#######8  | 270/345\n[01:00<00:03, 21.71it/s]', '\\rOverwrite epoch 1/4:  79%|#######9  | 273/345\n[01:00<00:03, 21.71it/s]', '\\rOverwrite epoch 1/4:  80%|########  | 276/345\n[01:00<00:03, 21.64it/s]', '\\rOverwrite epoch 1/4:  81%|########  | 279/345\n[01:00<00:03, 21.67it/s]', '\\rOverwrite epoch 1/4:  82%|########1 | 282/345\n[01:01<00:02, 21.20it/s]', '\\rOverwrite epoch 1/4:  83%|########2 | 285/345\n[01:01<00:02, 21.33it/s]', '\\rOverwrite epoch 1/4:  83%|########3 | 288/345\n[01:01<00:02, 21.45it/s]', '\\rOverwrite epoch 1/4:  84%|########4 | 291/345\n[01:01<00:02, 21.52it/s]', '\\rOverwrite epoch 1/4:  85%|########5 | 294/345\n[01:01<00:02, 21.39it/s]', '\\rOverwrite epoch 1/4:  86%|########6 | 297/345\n[01:01<00:02, 21.50it/s]', '\\rOverwrite epoch 1/4:  87%|########6 | 300/345\n[01:01<00:02, 21.56it/s]', '\\rOverwrite epoch 1/4:  88%|########7 | 303/345\n[01:01<00:01, 21.63it/s]', '\\rOverwrite epoch 1/4:  89%|########8 | 306/345\n[01:02<00:01, 21.71it/s]', '\\rOverwrite epoch 1/4:  90%|########9 | 309/345\n[01:02<00:01, 21.72it/s]', '\\rOverwrite epoch 1/4:  90%|######### | 312/345\n[01:02<00:01, 21.75it/s]', '\\rOverwrite epoch 1/4:  91%|#########1| 315/345\n[01:02<00:01, 21.74it/s]', '\\rOverwrite epoch 1/4:  92%|#########2| 318/345\n[01:02<00:01, 21.75it/s]', '\\rOverwrite epoch 1/4:  93%|#########3| 321/345\n[01:02<00:01, 21.77it/s]', '\\rOverwrite epoch 1/4:  94%|#########3| 324/345\n[01:02<00:00, 21.73it/s]', '\\rOverwrite epoch 1/4:  95%|#########4| 327/345\n[01:03<00:00, 21.75it/s]', '\\rOverwrite epoch 1/4:  96%|#########5| 330/345\n[01:03<00:00, 21.72it/s]', '\\rOverwrite epoch 1/4:  97%|#########6| 333/345\n[01:03<00:00, 21.73it/s]', '\\rOverwrite epoch 1/4:  97%|#########7| 336/345\n[01:03<00:00, 21.73it/s]', '\\rOverwrite epoch 1/4:  98%|#########8| 339/345\n[01:03<00:00, 21.75it/s]', '\\rOverwrite epoch 1/4:  99%|#########9| 342/345\n[01:03<00:00, 21.74it/s]', '\\rOverwrite epoch 1/4: 100%|##########| 345/345\n[01:03<00:00, 22.63it/s]', '', '\\rOverwrite epoch 1/4: 100%|##########| 345/345\n[01:04<00:00,  5.31it/s]', '\\n', 'Epoch 1: validation_loss = 3.6236', '\\n',\n'\\rOverwrite epoch 2/4:   0%|          | 0/345 [00:00<?, ?it/s]', '\\rOverwrite\nepoch 2/4:   0%|          | 1/345 [00:48<4:36:58, 48.31s/it]', '\\rOverwrite\nepoch 2/4:   1%|          | 3/345 [00:48<1:11:39, 12.57s/it]', '\\rOverwrite\nepoch 2/4:   2%|1         | 6/345 [00:48<27:36,  4.89s/it]  ', '\\rOverwrite\nepoch 2/4:   3%|2         | 9/345 [00:48<14:42,  2.63s/it]', '\\rOverwrite epoch\n2/4:   3%|3         | 12/345 [00:48<08:50,  1.59s/it]', '\\rOverwrite epoch 2/4:\n4%|4         | 15/345 [00:48<05:40,  1.03s/it]', '\\rOverwrite epoch 2/4:   5%|5\n| 18/345 [00:49<03:47,  1.44it/s]', '\\rOverwrite epoch 2/4:   6%|6         |\n21/345 [00:49<02:36,  2.08it/s]', '\\rOverwrite epoch 2/4:   7%|6         |\n24/345 [00:49<01:50,  2.92it/s]', '\\rOverwrite epoch 2/4:   8%|7         |\n27/345 [00:49<01:19,  3.98it/s]', '\\rOverwrite epoch 2/4:   9%|8         |\n30/345 [00:49<00:59,  5.31it/s]', '\\rOverwrite epoch 2/4:  10%|9         |\n33/345 [00:49<00:45,  6.87it/s]', '\\rOverwrite epoch 2/4:  10%|#         |\n36/345 [00:49<00:35,  8.61it/s]', '\\rOverwrite epoch 2/4:  11%|#1        |\n39/345 [00:50<00:29, 10.44it/s]', '\\rOverwrite epoch 2/4:  12%|#2        |\n42/345 [00:50<00:24, 12.35it/s]', '\\rOverwrite epoch 2/4:  13%|#3        |\n45/345 [00:50<00:21, 14.17it/s]', '\\rOverwrite epoch 2/4:  14%|#3        |\n48/345 [00:50<00:18, 15.82it/s]', '\\rOverwrite epoch 2/4:  15%|#4        |\n51/345 [00:50<00:17, 17.16it/s]', '\\rOverwrite epoch 2/4:  16%|#5        |\n54/345 [00:50<00:16, 18.09it/s]', '[2025-12-03 23:42:05] Overwrite step 400:\navg_train_loss=3.3332', '\\n', '\\rOverwrite epoch 2/4:  17%|#6        | 57/345\n[00:50<00:15, 18.70it/s]', '\\rOverwrite epoch 2/4:  17%|#7        | 60/345\n[00:51<00:14, 19.45it/s]', '\\rOverwrite epoch 2/4:  18%|#8        | 63/345\n[00:51<00:14, 20.07it/s]', '\\rOverwrite epoch 2/4:  19%|#9        | 66/345\n[00:51<00:13, 20.53it/s]', '\\rOverwrite epoch 2/4:  20%|##        | 69/345\n[00:51<00:13, 20.83it/s]', '\\rOverwrite epoch 2/4:  21%|##        | 72/345\n[00:51<00:13, 20.72it/s]', '\\rOverwrite epoch 2/4:  22%|##1       | 75/345\n[00:51<00:12, 20.81it/s]', '\\rOverwrite epoch 2/4:  23%|##2       | 78/345\n[00:51<00:12, 20.89it/s]', '\\rOverwrite epoch 2/4:  23%|##3       | 81/345\n[00:52<00:12, 21.11it/s]', '\\rOverwrite epoch 2/4:  24%|##4       | 84/345\n[00:52<00:12, 21.26it/s]', '\\rOverwrite epoch 2/4:  25%|##5       | 87/345\n[00:52<00:12, 21.27it/s]', '\\rOverwrite epoch 2/4:  26%|##6       | 90/345\n[00:52<00:12, 21.16it/s]', '\\rOverwrite epoch 2/4:  27%|##6       | 93/345\n[00:52<00:11, 21.13it/s]', '\\rOverwrite epoch 2/4:  28%|##7       | 96/345\n[00:52<00:11, 21.33it/s]', '\\rOverwrite epoch 2/4:  29%|##8       | 99/345\n[00:52<00:11, 21.35it/s]', '\\rOverwrite epoch 2/4:  30%|##9       | 102/345\n[00:53<00:11, 21.48it/s]', '\\rOverwrite epoch 2/4:  30%|###       | 105/345\n[00:53<00:11, 21.33it/s]', '\\rOverwrite epoch 2/4:  31%|###1      | 108/345\n[00:53<00:11, 21.15it/s]', '\\rOverwrite epoch 2/4:  32%|###2      | 111/345\n[00:53<00:10, 21.34it/s]', '\\rOverwrite epoch 2/4:  33%|###3      | 114/345\n[00:53<00:10, 21.46it/s]', '\\rOverwrite epoch 2/4:  34%|###3      | 117/345\n[00:53<00:10, 21.45it/s]', '\\rOverwrite epoch 2/4:  35%|###4      | 120/345\n[00:53<00:10, 21.40it/s]', '\\rOverwrite epoch 2/4:  36%|###5      | 123/345\n[00:54<00:10, 21.07it/s]', '\\rOverwrite epoch 2/4:  37%|###6      | 126/345\n[00:54<00:10, 21.08it/s]', '\\rOverwrite epoch 2/4:  37%|###7      | 129/345\n[00:54<00:10, 21.14it/s]', '\\rOverwrite epoch 2/4:  38%|###8      | 132/345\n[00:54<00:10, 21.23it/s]', '\\rOverwrite epoch 2/4:  39%|###9      | 135/345\n[00:54<00:09, 21.37it/s]', '\\rOverwrite epoch 2/4:  40%|####      | 138/345\n[00:54<00:09, 21.36it/s]', '\\rOverwrite epoch 2/4:  41%|####      | 141/345\n[00:54<00:09, 21.17it/s]', '\\rOverwrite epoch 2/4:  42%|####1     | 144/345\n[00:55<00:09, 21.30it/s]', '\\rOverwrite epoch 2/4:  43%|####2     | 147/345\n[00:55<00:09, 21.46it/s]', '\\rOverwrite epoch 2/4:  43%|####3     | 150/345\n[00:55<00:09, 21.57it/s]', '\\rOverwrite epoch 2/4:  44%|####4     | 153/345\n[00:55<00:08, 21.60it/s]', '\\rOverwrite epoch 2/4:  45%|####5     | 156/345\n[00:55<00:08, 21.51it/s]', '\\rOverwrite epoch 2/4:  46%|####6     | 159/345\n[00:55<00:08, 21.53it/s]', '\\rOverwrite epoch 2/4:  47%|####6     | 162/345\n[00:55<00:08, 21.58it/s]', '\\rOverwrite epoch 2/4:  48%|####7     | 165/345\n[00:56<00:08, 21.62it/s]', '\\rOverwrite epoch 2/4:  49%|####8     | 168/345\n[00:56<00:08, 21.59it/s]', '\\rOverwrite epoch 2/4:  50%|####9     | 171/345\n[00:56<00:08, 21.71it/s]', '\\rOverwrite epoch 2/4:  50%|#####     | 174/345\n[00:56<00:07, 21.48it/s]', '\\rOverwrite epoch 2/4:  51%|#####1    | 177/345\n[00:56<00:07, 21.16it/s]', '\\rOverwrite epoch 2/4:  52%|#####2    | 180/345\n[00:56<00:07, 21.10it/s]', '\\rOverwrite epoch 2/4:  53%|#####3    | 183/345\n[00:56<00:07, 21.10it/s]', '\\rOverwrite epoch 2/4:  54%|#####3    | 186/345\n[00:57<00:07, 21.07it/s]', '\\rOverwrite epoch 2/4:  55%|#####4    | 189/345\n[00:57<00:07, 21.24it/s]', '\\rOverwrite epoch 2/4:  56%|#####5    | 192/345\n[00:57<00:07, 21.38it/s]', '\\rOverwrite epoch 2/4:  57%|#####6    | 195/345\n[00:57<00:07, 21.32it/s]', '\\rOverwrite epoch 2/4:  57%|#####7    | 198/345\n[00:57<00:06, 21.43it/s]', '\\rOverwrite epoch 2/4:  58%|#####8    | 201/345\n[00:57<00:06, 21.52it/s]', '\\rOverwrite epoch 2/4:  59%|#####9    | 204/345\n[00:57<00:06, 21.61it/s]', '\\rOverwrite epoch 2/4:  60%|######    | 207/345\n[00:58<00:06, 21.69it/s]', '\\rOverwrite epoch 2/4:  61%|######    | 210/345\n[00:58<00:06, 21.59it/s]', '\\rOverwrite epoch 2/4:  62%|######1   | 213/345\n[00:58<00:06, 21.50it/s]', '\\rOverwrite epoch 2/4:  63%|######2   | 216/345\n[00:58<00:05, 21.51it/s]', '\\rOverwrite epoch 2/4:  63%|######3   | 219/345\n[00:58<00:05, 21.51it/s]', '\\rOverwrite epoch 2/4:  64%|######4   | 222/345\n[00:58<00:05, 21.64it/s]', '\\rOverwrite epoch 2/4:  65%|######5   | 225/345\n[00:58<00:05, 21.45it/s]', '\\rOverwrite epoch 2/4:  66%|######6   | 228/345\n[00:58<00:05, 21.48it/s]', '\\rOverwrite epoch 2/4:  67%|######6   | 231/345\n[00:59<00:05, 21.58it/s]', '\\rOverwrite epoch 2/4:  68%|######7   | 234/345\n[00:59<00:05, 21.58it/s]', '\\rOverwrite epoch 2/4:  69%|######8   | 237/345\n[00:59<00:04, 21.64it/s]', '\\rOverwrite epoch 2/4:  70%|######9   | 240/345\n[00:59<00:04, 21.69it/s]', '\\rOverwrite epoch 2/4:  70%|#######   | 243/345\n[00:59<00:04, 21.70it/s]', '\\rOverwrite epoch 2/4:  71%|#######1  | 246/345\n[00:59<00:04, 21.67it/s]', '\\rOverwrite epoch 2/4:  72%|#######2  | 249/345\n[00:59<00:04, 21.63it/s]', '\\rOverwrite epoch 2/4:  73%|#######3  | 252/345\n[01:00<00:04, 21.71it/s]', '[2025-12-03 23:42:15] Overwrite step 600:\navg_train_loss=3.3204', '\\n', '\\rOverwrite epoch 2/4:  74%|#######3  | 255/345\n[01:00<00:04, 21.67it/s]', '\\rOverwrite epoch 2/4:  75%|#######4  | 258/345\n[01:00<00:04, 21.64it/s]', '\\rOverwrite epoch 2/4:  76%|#######5  | 261/345\n[01:00<00:03, 21.62it/s]', '\\rOverwrite epoch 2/4:  77%|#######6  | 264/345\n[01:00<00:03, 21.64it/s]', '\\rOverwrite epoch 2/4:  77%|#######7  | 267/345\n[01:00<00:03, 21.66it/s]', '\\rOverwrite epoch 2/4:  78%|#######8  | 270/345\n[01:00<00:03, 21.61it/s]', '\\rOverwrite epoch 2/4:  79%|#######9  | 273/345\n[01:01<00:03, 21.62it/s]', '\\rOverwrite epoch 2/4:  80%|########  | 276/345\n[01:01<00:03, 21.69it/s]', '\\rOverwrite epoch 2/4:  81%|########  | 279/345\n[01:01<00:03, 21.72it/s]', '\\rOverwrite epoch 2/4:  82%|########1 | 282/345\n[01:01<00:02, 21.72it/s]', '\\rOverwrite epoch 2/4:  83%|########2 | 285/345\n[01:01<00:02, 21.65it/s]', '\\rOverwrite epoch 2/4:  83%|########3 | 288/345\n[01:01<00:02, 21.66it/s]', '\\rOverwrite epoch 2/4:  84%|########4 | 291/345\n[01:01<00:02, 21.70it/s]', '\\rOverwrite epoch 2/4:  85%|########5 | 294/345\n[01:02<00:02, 21.30it/s]', '\\rOverwrite epoch 2/4:  86%|########6 | 297/345\n[01:02<00:02, 21.11it/s]', '\\rOverwrite epoch 2/4:  87%|########6 | 300/345\n[01:02<00:02, 21.22it/s]', '\\rOverwrite epoch 2/4:  88%|########7 | 303/345\n[01:02<00:01, 21.37it/s]', '\\rOverwrite epoch 2/4:  89%|########8 | 306/345\n[01:02<00:01, 21.43it/s]', '\\rOverwrite epoch 2/4:  90%|########9 | 309/345\n[01:02<00:01, 21.32it/s]', '\\rOverwrite epoch 2/4:  90%|######### | 312/345\n[01:02<00:01, 21.17it/s]', '\\rOverwrite epoch 2/4:  91%|#########1| 315/345\n[01:03<00:01, 21.23it/s]', '\\rOverwrite epoch 2/4:  92%|#########2| 318/345\n[01:03<00:01, 21.34it/s]', '\\rOverwrite epoch 2/4:  93%|#########3| 321/345\n[01:03<00:01, 21.44it/s]', '\\rOverwrite epoch 2/4:  94%|#########3| 324/345\n[01:03<00:00, 21.28it/s]', '\\rOverwrite epoch 2/4:  95%|#########4| 327/345\n[01:03<00:00, 21.34it/s]', '\\rOverwrite epoch 2/4:  96%|#########5| 330/345\n[01:03<00:00, 21.46it/s]', '\\rOverwrite epoch 2/4:  97%|#########6| 333/345\n[01:03<00:00, 21.55it/s]', '\\rOverwrite epoch 2/4:  97%|#########7| 336/345\n[01:04<00:00, 21.64it/s]', '\\rOverwrite epoch 2/4:  98%|#########8| 339/345\n[01:04<00:00, 21.76it/s]', '\\rOverwrite epoch 2/4:  99%|#########9| 342/345\n[01:04<00:00, 21.78it/s]', '\\rOverwrite epoch 2/4: 100%|##########| 345/345\n[01:04<00:00, 22.72it/s]', '', '\\rOverwrite epoch 2/4: 100%|##########| 345/345\n[01:05<00:00,  5.27it/s]', '\\n', 'Epoch 2: validation_loss = 3.6392', '\\n',\n'\\rOverwrite epoch 3/4:   0%|          | 0/345 [00:00<?, ?it/s]', '\\rOverwrite\nepoch 3/4:   0%|          | 1/345 [01:43<9:52:26, 103.33s/it]', '\\rOverwrite\nepoch 3/4:   1%|          | 3/345 [01:43<2:32:58, 26.84s/it] ', '\\rOverwrite\nepoch 3/4:   2%|1         | 6/345 [01:43<58:46, 10.40s/it]  ', '\\rOverwrite\nepoch 3/4:   3%|2         | 9/345 [01:43<31:10,  5.57s/it]', '\\rOverwrite epoch\n3/4:   3%|3         | 12/345 [01:43<18:37,  3.36s/it]', '\\rOverwrite epoch 3/4:\n4%|4         | 15/345 [01:44<11:50,  2.15s/it]', '\\rOverwrite epoch 3/4:   5%|5\n| 18/345 [01:44<07:48,  1.43s/it]', '\\rOverwrite epoch 3/4:   6%|6         |\n21/345 [01:44<05:16,  1.02it/s]', '\\rOverwrite epoch 3/4:   7%|6         |\n24/345 [01:44<03:38,  1.47it/s]', '\\rOverwrite epoch 3/4:   8%|7         |\n27/345 [01:44<02:33,  2.07it/s]', '\\rOverwrite epoch 3/4:   9%|8         |\n30/345 [01:44<01:49,  2.88it/s]', '\\rOverwrite epoch 3/4:  10%|9         |\n33/345 [01:44<01:19,  3.91it/s]', '\\rOverwrite epoch 3/4:  10%|#         |\n36/345 [01:45<00:59,  5.20it/s]', '\\rOverwrite epoch 3/4:  11%|#1        |\n39/345 [01:45<00:45,  6.75it/s]', '\\rOverwrite epoch 3/4:  12%|#2        |\n42/345 [01:45<00:35,  8.52it/s]', '\\rOverwrite epoch 3/4:  13%|#3        |\n45/345 [01:45<00:28, 10.39it/s]', '\\rOverwrite epoch 3/4:  14%|#3        |\n48/345 [01:45<00:24, 12.27it/s]', '\\rOverwrite epoch 3/4:  15%|#4        |\n51/345 [01:45<00:20, 14.09it/s]', '\\rOverwrite epoch 3/4:  16%|#5        |\n54/345 [01:45<00:18, 15.73it/s]', '\\rOverwrite epoch 3/4:  17%|#6        |\n57/345 [01:45<00:16, 17.09it/s]', '\\rOverwrite epoch 3/4:  17%|#7        |\n60/345 [01:46<00:15, 18.24it/s]', '\\rOverwrite epoch 3/4:  18%|#8        |\n63/345 [01:46<00:14, 19.13it/s]', '\\rOverwrite epoch 3/4:  19%|#9        |\n66/345 [01:46<00:14, 19.81it/s]', '\\rOverwrite epoch 3/4:  20%|##        |\n69/345 [01:46<00:13, 20.32it/s]', '\\rOverwrite epoch 3/4:  21%|##        |\n72/345 [01:46<00:13, 20.68it/s]', '\\rOverwrite epoch 3/4:  22%|##1       |\n75/345 [01:46<00:12, 20.96it/s]', '\\rOverwrite epoch 3/4:  23%|##2       |\n78/345 [01:46<00:12, 21.19it/s]', '\\rOverwrite epoch 3/4:  23%|##3       |\n81/345 [01:47<00:12, 21.25it/s]', '\\rOverwrite epoch 3/4:  24%|##4       |\n84/345 [01:47<00:12, 21.26it/s]', '\\rOverwrite epoch 3/4:  25%|##5       |\n87/345 [01:47<00:12, 21.28it/s]', '\\rOverwrite epoch 3/4:  26%|##6       |\n90/345 [01:47<00:11, 21.27it/s]', '\\rOverwrite epoch 3/4:  27%|##6       |\n93/345 [01:47<00:11, 21.28it/s]', '\\rOverwrite epoch 3/4:  28%|##7       |\n96/345 [01:47<00:11, 21.19it/s]', '\\rOverwrite epoch 3/4:  29%|##8       |\n99/345 [01:47<00:11, 21.25it/s]', '\\rOverwrite epoch 3/4:  30%|##9       |\n102/345 [01:48<00:11, 21.07it/s]', '\\rOverwrite epoch 3/4:  30%|###       |\n105/345 [01:48<00:11, 21.21it/s]', '\\rOverwrite epoch 3/4:  31%|###1      |\n108/345 [01:48<00:11, 21.18it/s]', '[2025-12-03 23:44:58] Overwrite step 800:\navg_train_loss=3.0696', '\\n', '\\rOverwrite epoch 3/4:  32%|###2      | 111/345\n[01:48<00:11, 21.24it/s]', '\\rOverwrite epoch 3/4:  33%|###3      | 114/345\n[01:48<00:10, 21.23it/s]', '\\rOverwrite epoch 3/4:  34%|###3      | 117/345\n[01:48<00:10, 21.28it/s]', '\\rOverwrite epoch 3/4:  35%|###4      | 120/345\n[01:48<00:10, 21.37it/s]', '\\rOverwrite epoch 3/4:  36%|###5      | 123/345\n[01:49<00:10, 21.51it/s]', '\\rOverwrite epoch 3/4:  37%|###6      | 126/345\n[01:49<00:10, 21.54it/s]', '\\rOverwrite epoch 3/4:  37%|###7      | 129/345\n[01:49<00:10, 21.52it/s]', '\\rOverwrite epoch 3/4:  38%|###8      | 132/345\n[01:49<00:09, 21.44it/s]', '\\rOverwrite epoch 3/4:  39%|###9      | 135/345\n[01:49<00:09, 21.49it/s]', '\\rOverwrite epoch 3/4:  40%|####      | 138/345\n[01:49<00:09, 21.52it/s]', '\\rOverwrite epoch 3/4:  41%|####      | 141/345\n[01:49<00:09, 21.55it/s]', '\\rOverwrite epoch 3/4:  42%|####1     | 144/345\n[01:50<00:09, 21.48it/s]', '\\rOverwrite epoch 3/4:  43%|####2     | 147/345\n[01:50<00:09, 21.50it/s]', '\\rOverwrite epoch 3/4:  43%|####3     | 150/345\n[01:50<00:09, 21.42it/s]', '\\rOverwrite epoch 3/4:  44%|####4     | 153/345\n[01:50<00:08, 21.34it/s]', '\\rOverwrite epoch 3/4:  45%|####5     | 156/345\n[01:50<00:08, 21.25it/s]', '\\rOverwrite epoch 3/4:  46%|####6     | 159/345\n[01:50<00:08, 21.26it/s]', '\\rOverwrite epoch 3/4:  47%|####6     | 162/345\n[01:50<00:08, 21.34it/s]', '\\rOverwrite epoch 3/4:  48%|####7     | 165/345\n[01:51<00:08, 21.42it/s]', '\\rOverwrite epoch 3/4:  49%|####8     | 168/345\n[01:51<00:08, 21.47it/s]', '\\rOverwrite epoch 3/4:  50%|####9     | 171/345\n[01:51<00:08, 21.37it/s]', '\\rOverwrite epoch 3/4:  50%|#####     | 174/345\n[01:51<00:08, 21.33it/s]', '\\rOverwrite epoch 3/4:  51%|#####1    | 177/345\n[01:51<00:07, 21.31it/s]', '\\rOverwrite epoch 3/4:  52%|#####2    | 180/345\n[01:51<00:07, 21.28it/s]', '\\rOverwrite epoch 3/4:  53%|#####3    | 183/345\n[01:51<00:07, 21.28it/s]', '\\rOverwrite epoch 3/4:  54%|#####3    | 186/345\n[01:52<00:07, 20.89it/s]', '\\rOverwrite epoch 3/4:  55%|#####4    | 189/345\n[01:52<00:07, 21.03it/s]', '\\rOverwrite epoch 3/4:  56%|#####5    | 192/345\n[01:52<00:07, 21.15it/s]', '\\rOverwrite epoch 3/4:  57%|#####6    | 195/345\n[01:52<00:07, 21.19it/s]', '\\rOverwrite epoch 3/4:  57%|#####7    | 198/345\n[01:52<00:06, 21.31it/s]', '\\rOverwrite epoch 3/4:  58%|#####8    | 201/345\n[01:52<00:06, 21.18it/s]', '\\rOverwrite epoch 3/4:  59%|#####9    | 204/345\n[01:52<00:06, 20.99it/s]', '\\rOverwrite epoch 3/4:  60%|######    | 207/345\n[01:53<00:06, 20.92it/s]', '\\rOverwrite epoch 3/4:  61%|######    | 210/345\n[01:53<00:06, 21.04it/s]', '\\rOverwrite epoch 3/4:  62%|######1   | 213/345\n[01:53<00:06, 21.23it/s]', '\\rOverwrite epoch 3/4:  63%|######2   | 216/345\n[01:53<00:06, 21.11it/s]', '\\rOverwrite epoch 3/4:  63%|######3   | 219/345\n[01:53<00:05, 21.18it/s]', '\\rOverwrite epoch 3/4:  64%|######4   | 222/345\n[01:53<00:05, 20.87it/s]', '\\rOverwrite epoch 3/4:  65%|######5   | 225/345\n[01:53<00:05, 20.97it/s]', '\\rOverwrite epoch 3/4:  66%|######6   | 228/345\n[01:54<00:05, 20.61it/s]', '\\rOverwrite epoch 3/4:  67%|######6   | 231/345\n[01:54<00:05, 20.86it/s]', '\\rOverwrite epoch 3/4:  68%|######7   | 234/345\n[01:54<00:05, 20.98it/s]', '\\rOverwrite epoch 3/4:  69%|######8   | 237/345\n[01:54<00:05, 20.91it/s]', '\\rOverwrite epoch 3/4:  70%|######9   | 240/345\n[01:54<00:04, 21.07it/s]', '\\rOverwrite epoch 3/4:  70%|#######   | 243/345\n[01:54<00:04, 21.09it/s]', '\\rOverwrite epoch 3/4:  71%|#######1  | 246/345\n[01:54<00:04, 21.18it/s]', '\\rOverwrite epoch 3/4:  72%|#######2  | 249/345\n[01:55<00:04, 21.37it/s]', '\\rOverwrite epoch 3/4:  73%|#######3  | 252/345\n[01:55<00:04, 21.33it/s]', '\\rOverwrite epoch 3/4:  74%|#######3  | 255/345\n[01:55<00:04, 21.31it/s]', '\\rOverwrite epoch 3/4:  75%|#######4  | 258/345\n[01:55<00:04, 21.18it/s]', '\\rOverwrite epoch 3/4:  76%|#######5  | 261/345\n[01:55<00:03, 21.01it/s]', '\\rOverwrite epoch 3/4:  77%|#######6  | 264/345\n[01:55<00:03, 20.85it/s]', '\\rOverwrite epoch 3/4:  77%|#######7  | 267/345\n[01:55<00:03, 21.04it/s]', '\\rOverwrite epoch 3/4:  78%|#######8  | 270/345\n[01:56<00:03, 21.19it/s]', '\\rOverwrite epoch 3/4:  79%|#######9  | 273/345\n[01:56<00:03, 21.35it/s]', '\\rOverwrite epoch 3/4:  80%|########  | 276/345\n[01:56<00:03, 21.35it/s]', '\\rOverwrite epoch 3/4:  81%|########  | 279/345\n[01:56<00:03, 20.76it/s]', '\\rOverwrite epoch 3/4:  82%|########1 | 282/345\n[01:56<00:03, 20.86it/s]', '\\rOverwrite epoch 3/4:  83%|########2 | 285/345\n[01:56<00:02, 20.71it/s]', '\\rOverwrite epoch 3/4:  83%|########3 | 288/345\n[01:56<00:02, 20.61it/s]', '\\rOverwrite epoch 3/4:  84%|########4 | 291/345\n[01:57<00:02, 20.93it/s]', '\\rOverwrite epoch 3/4:  85%|########5 | 294/345\n[01:57<00:02, 21.16it/s]', '\\rOverwrite epoch 3/4:  86%|########6 | 297/345\n[01:57<00:02, 21.31it/s]', '\\rOverwrite epoch 3/4:  87%|########6 | 300/345\n[01:57<00:02, 21.23it/s]', '\\rOverwrite epoch 3/4:  88%|########7 | 303/345\n[01:57<00:01, 21.07it/s]', '\\rOverwrite epoch 3/4:  89%|########8 | 306/345\n[01:57<00:01, 20.84it/s]', '\\rOverwrite epoch 3/4:  90%|########9 | 309/345\n[01:57<00:01, 20.86it/s]', '[2025-12-03 23:45:07] Overwrite step 1000:\navg_train_loss=3.0832', '\\n', '\\rOverwrite epoch 3/4:  90%|######### | 312/345\n[01:58<00:01, 21.00it/s]', '\\rOverwrite epoch 3/4:  91%|#########1| 315/345\n[01:58<00:01, 21.13it/s]', '\\rOverwrite epoch 3/4:  92%|#########2| 318/345\n[01:58<00:01, 20.66it/s]', '\\rOverwrite epoch 3/4:  93%|#########3| 321/345\n[01:58<00:01, 20.90it/s]', '\\rOverwrite epoch 3/4:  94%|#########3| 324/345\n[01:58<00:01, 20.88it/s]', '\\rOverwrite epoch 3/4:  95%|#########4| 327/345\n[01:58<00:00, 20.78it/s]', '\\rOverwrite epoch 3/4:  96%|#########5| 330/345\n[01:58<00:00, 20.83it/s]', '\\rOverwrite epoch 3/4:  97%|#########6| 333/345\n[01:59<00:00, 20.47it/s]', '\\rOverwrite epoch 3/4:  97%|#########7| 336/345\n[01:59<00:00, 20.45it/s]', '\\rOverwrite epoch 3/4:  98%|#########8| 339/345\n[01:59<00:00, 20.16it/s]', '\\rOverwrite epoch 3/4:  99%|#########9| 342/345\n[01:59<00:00, 20.32it/s]', '\\rOverwrite epoch 3/4: 100%|##########| 345/345\n[01:59<00:00, 21.26it/s]', '', '\\rOverwrite epoch 3/4: 100%|##########| 345/345\n[02:00<00:00,  2.86it/s]', '\\n', 'Epoch 3: validation_loss = 3.6715', '\\n',\n'\\rOverwrite epoch 4/4:   0%|          | 0/345 [00:00<?, ?it/s]', '\\rOverwrite\nepoch 4/4:   0%|          | 1/345 [00:49<4:43:14, 49.40s/it]', '\\rOverwrite\nepoch 4/4:   1%|          | 3/345 [00:49<1:13:17, 12.86s/it]', '\\rOverwrite\nepoch 4/4:   1%|1         | 5/345 [00:49<35:33,  6.27s/it]  ', '\\rOverwrite\nepoch 4/4:   2%|2         | 8/345 [00:49<16:54,  3.01s/it]', '\\rOverwrite epoch\n4/4:   3%|3         | 11/345 [00:49<09:41,  1.74s/it]', '\\rOverwrite epoch 4/4:\n4%|4         | 14/345 [00:50<06:03,  1.10s/it]', '\\rOverwrite epoch 4/4:   5%|4\n| 17/345 [00:50<03:58,  1.37it/s]', '\\rOverwrite epoch 4/4:   6%|5         |\n20/345 [00:50<02:42,  2.00it/s]', '\\rOverwrite epoch 4/4:   7%|6         |\n23/345 [00:50<01:53,  2.83it/s]', '\\rOverwrite epoch 4/4:   8%|7         |\n26/345 [00:50<01:21,  3.90it/s]', '\\rOverwrite epoch 4/4:   8%|8         |\n29/345 [00:50<01:00,  5.22it/s]', '\\rOverwrite epoch 4/4:   9%|9         |\n32/345 [00:50<00:46,  6.80it/s]', '\\rOverwrite epoch 4/4:  10%|#         |\n35/345 [00:51<00:36,  8.60it/s]', '\\rOverwrite epoch 4/4:  11%|#1        |\n38/345 [00:51<00:29, 10.51it/s]', '\\rOverwrite epoch 4/4:  12%|#1        |\n41/345 [00:51<00:24, 12.41it/s]', '\\rOverwrite epoch 4/4:  13%|#2        |\n44/345 [00:51<00:21, 14.23it/s]', '\\rOverwrite epoch 4/4:  14%|#3        |\n47/345 [00:51<00:19, 15.63it/s]', '\\rOverwrite epoch 4/4:  14%|#4        |\n50/345 [00:51<00:17, 17.06it/s]', '\\rOverwrite epoch 4/4:  15%|#5        |\n53/345 [00:51<00:16, 18.15it/s]', '\\rOverwrite epoch 4/4:  16%|#6        |\n56/345 [00:52<00:15, 19.00it/s]', '\\rOverwrite epoch 4/4:  17%|#7        |\n59/345 [00:52<00:14, 19.64it/s]', '\\rOverwrite epoch 4/4:  18%|#7        |\n62/345 [00:52<00:14, 20.13it/s]', '\\rOverwrite epoch 4/4:  19%|#8        |\n65/345 [00:52<00:13, 20.54it/s]', '\\rOverwrite epoch 4/4:  20%|#9        |\n68/345 [00:52<00:13, 20.87it/s]', '\\rOverwrite epoch 4/4:  21%|##        |\n71/345 [00:52<00:13, 20.64it/s]', '\\rOverwrite epoch 4/4:  21%|##1       |\n74/345 [00:52<00:12, 20.86it/s]', '\\rOverwrite epoch 4/4:  22%|##2       |\n77/345 [00:53<00:12, 21.13it/s]', '\\rOverwrite epoch 4/4:  23%|##3       |\n80/345 [00:53<00:12, 21.21it/s]', '\\rOverwrite epoch 4/4:  24%|##4       |\n83/345 [00:53<00:12, 21.33it/s]', '\\rOverwrite epoch 4/4:  25%|##4       |\n86/345 [00:53<00:12, 20.71it/s]', '\\rOverwrite epoch 4/4:  26%|##5       |\n89/345 [00:53<00:12, 20.81it/s]', '\\rOverwrite epoch 4/4:  27%|##6       |\n92/345 [00:53<00:12, 20.80it/s]', '\\rOverwrite epoch 4/4:  28%|##7       |\n95/345 [00:53<00:11, 20.90it/s]', '\\rOverwrite epoch 4/4:  28%|##8       |\n98/345 [00:54<00:11, 20.97it/s]', '\\rOverwrite epoch 4/4:  29%|##9       |\n101/345 [00:54<00:11, 21.07it/s]', '\\rOverwrite epoch 4/4:  30%|###       |\n104/345 [00:54<00:11, 21.11it/s]', '\\rOverwrite epoch 4/4:  31%|###1      |\n107/345 [00:54<00:11, 21.11it/s]', '\\rOverwrite epoch 4/4:  32%|###1      |\n110/345 [00:54<00:11, 21.09it/s]', '\\rOverwrite epoch 4/4:  33%|###2      |\n113/345 [00:54<00:10, 21.11it/s]', '\\rOverwrite epoch 4/4:  34%|###3      |\n116/345 [00:54<00:10, 21.26it/s]', '\\rOverwrite epoch 4/4:  34%|###4      |\n119/345 [00:55<00:10, 21.26it/s]', '\\rOverwrite epoch 4/4:  35%|###5      |\n122/345 [00:55<00:10, 21.22it/s]', '\\rOverwrite epoch 4/4:  36%|###6      |\n125/345 [00:55<00:10, 21.31it/s]', '\\rOverwrite epoch 4/4:  37%|###7      |\n128/345 [00:55<00:10, 21.19it/s]', '\\rOverwrite epoch 4/4:  38%|###7      |\n131/345 [00:55<00:10, 21.14it/s]', '\\rOverwrite epoch 4/4:  39%|###8      |\n134/345 [00:55<00:09, 21.24it/s]', '\\rOverwrite epoch 4/4:  40%|###9      |\n137/345 [00:55<00:09, 20.99it/s]', '\\rOverwrite epoch 4/4:  41%|####      |\n140/345 [00:56<00:09, 21.07it/s]', '\\rOverwrite epoch 4/4:  41%|####1     |\n143/345 [00:56<00:09, 21.15it/s]', '\\rOverwrite epoch 4/4:  42%|####2     |\n146/345 [00:56<00:09, 21.23it/s]', '\\rOverwrite epoch 4/4:  43%|####3     |\n149/345 [00:56<00:09, 21.30it/s]', '\\rOverwrite epoch 4/4:  44%|####4     |\n152/345 [00:56<00:09, 21.33it/s]', '\\rOverwrite epoch 4/4:  45%|####4     |\n155/345 [00:56<00:08, 21.38it/s]', '\\rOverwrite epoch 4/4:  46%|####5     |\n158/345 [00:56<00:08, 21.48it/s]', '\\rOverwrite epoch 4/4:  47%|####6     |\n161/345 [00:56<00:08, 21.51it/s]', '\\rOverwrite epoch 4/4:  48%|####7     |\n164/345 [00:57<00:08, 21.12it/s]', '[2025-12-03 23:47:08] Overwrite step 1200:\navg_train_loss=2.8707', '\\n', '\\rOverwrite epoch 4/4:  48%|####8     | 167/345\n[00:57<00:08, 20.94it/s]', '\\rOverwrite epoch 4/4:  49%|####9     | 170/345\n[00:57<00:08, 21.01it/s]', '\\rOverwrite epoch 4/4:  50%|#####     | 173/345\n[00:57<00:08, 21.16it/s]', '\\rOverwrite epoch 4/4:  51%|#####1    | 176/345\n[00:57<00:07, 21.28it/s]', '\\rOverwrite epoch 4/4:  52%|#####1    | 179/345\n[00:57<00:07, 21.23it/s]', '\\rOverwrite epoch 4/4:  53%|#####2    | 182/345\n[00:57<00:07, 21.23it/s]', '\\rOverwrite epoch 4/4:  54%|#####3    | 185/345\n[00:58<00:07, 21.34it/s]', '\\rOverwrite epoch 4/4:  54%|#####4    | 188/345\n[00:58<00:07, 21.37it/s]', '\\rOverwrite epoch 4/4:  55%|#####5    | 191/345\n[00:58<00:07, 21.47it/s]', '\\rOverwrite epoch 4/4:  56%|#####6    | 194/345\n[00:58<00:07, 21.55it/s]', '\\rOverwrite epoch 4/4:  57%|#####7    | 197/345\n[00:58<00:06, 21.55it/s]', '\\rOverwrite epoch 4/4:  58%|#####7    | 200/345\n[00:58<00:06, 21.58it/s]', '\\rOverwrite epoch 4/4:  59%|#####8    | 203/345\n[00:58<00:06, 21.39it/s]', '\\rOverwrite epoch 4/4:  60%|#####9    | 206/345\n[00:59<00:06, 21.43it/s]', '\\rOverwrite epoch 4/4:  61%|######    | 209/345\n[00:59<00:06, 21.39it/s]', '\\rOverwrite epoch 4/4:  61%|######1   | 212/345\n[00:59<00:06, 21.48it/s]', '\\rOverwrite epoch 4/4:  62%|######2   | 215/345\n[00:59<00:06, 21.59it/s]', '\\rOverwrite epoch 4/4:  63%|######3   | 218/345\n[00:59<00:05, 21.65it/s]', '\\rOverwrite epoch 4/4:  64%|######4   | 221/345\n[00:59<00:05, 21.65it/s]', '\\rOverwrite epoch 4/4:  65%|######4   | 224/345\n[00:59<00:05, 21.13it/s]', '\\rOverwrite epoch 4/4:  66%|######5   | 227/345\n[01:00<00:05, 21.09it/s]', '\\rOverwrite epoch 4/4:  67%|######6   | 230/345\n[01:00<00:05, 21.17it/s]', '\\rOverwrite epoch 4/4:  68%|######7   | 233/345\n[01:00<00:05, 21.35it/s]', '\\rOverwrite epoch 4/4:  68%|######8   | 236/345\n[01:00<00:05, 21.45it/s]', '\\rOverwrite epoch 4/4:  69%|######9   | 239/345\n[01:00<00:04, 21.40it/s]', '\\rOverwrite epoch 4/4:  70%|#######   | 242/345\n[01:00<00:04, 21.44it/s]', '\\rOverwrite epoch 4/4:  71%|#######1  | 245/345\n[01:00<00:04, 21.47it/s]', '\\rOverwrite epoch 4/4:  72%|#######1  | 248/345\n[01:01<00:04, 21.28it/s]', '\\rOverwrite epoch 4/4:  73%|#######2  | 251/345\n[01:01<00:04, 21.44it/s]', '\\rOverwrite epoch 4/4:  74%|#######3  | 254/345\n[01:01<00:04, 21.39it/s]', '\\rOverwrite epoch 4/4:  74%|#######4  | 257/345\n[01:01<00:04, 21.15it/s]', '\\rOverwrite epoch 4/4:  75%|#######5  | 260/345\n[01:01<00:04, 21.11it/s]', '\\rOverwrite epoch 4/4:  76%|#######6  | 263/345\n[01:01<00:03, 21.08it/s]', '\\rOverwrite epoch 4/4:  77%|#######7  | 266/345\n[01:01<00:03, 21.09it/s]', '\\rOverwrite epoch 4/4:  78%|#######7  | 269/345\n[01:02<00:03, 21.01it/s]', '\\rOverwrite epoch 4/4:  79%|#######8  | 272/345\n[01:02<00:03, 21.09it/s]', '\\rOverwrite epoch 4/4:  80%|#######9  | 275/345\n[01:02<00:03, 21.07it/s]', '\\rOverwrite epoch 4/4:  81%|########  | 278/345\n[01:02<00:03, 21.02it/s]', '\\rOverwrite epoch 4/4:  81%|########1 | 281/345\n[01:02<00:03, 20.66it/s]', '\\rOverwrite epoch 4/4:  82%|########2 | 284/345\n[01:02<00:02, 20.84it/s]', '\\rOverwrite epoch 4/4:  83%|########3 | 287/345\n[01:02<00:02, 21.07it/s]', '\\rOverwrite epoch 4/4:  84%|########4 | 290/345\n[01:03<00:02, 20.94it/s]', '\\rOverwrite epoch 4/4:  85%|########4 | 293/345\n[01:03<00:02, 20.99it/s]', '\\rOverwrite epoch 4/4:  86%|########5 | 296/345\n[01:03<00:02, 21.04it/s]', '\\rOverwrite epoch 4/4:  87%|########6 | 299/345\n[01:03<00:02, 21.10it/s]', '\\rOverwrite epoch 4/4:  88%|########7 | 302/345\n[01:03<00:02, 21.11it/s]', '\\rOverwrite epoch 4/4:  88%|########8 | 305/345\n[01:03<00:01, 21.24it/s]', '\\rOverwrite epoch 4/4:  89%|########9 | 308/345\n[01:03<00:01, 21.23it/s]', '\\rOverwrite epoch 4/4:  90%|######### | 311/345\n[01:04<00:01, 21.31it/s]', '\\rOverwrite epoch 4/4:  91%|#########1| 314/345\n[01:04<00:01, 21.34it/s]', '\\rOverwrite epoch 4/4:  92%|#########1| 317/345\n[01:04<00:01, 21.23it/s]', '\\rOverwrite epoch 4/4:  93%|#########2| 320/345\n[01:04<00:01, 20.75it/s]', '\\rOverwrite epoch 4/4:  94%|#########3| 323/345\n[01:04<00:01, 20.83it/s]', '\\rOverwrite epoch 4/4:  94%|#########4| 326/345\n[01:04<00:00, 20.78it/s]', '\\rOverwrite epoch 4/4:  95%|#########5| 329/345\n[01:04<00:00, 21.00it/s]', '\\rOverwrite epoch 4/4:  96%|#########6| 332/345\n[01:05<00:00, 21.17it/s]', '\\rOverwrite epoch 4/4:  97%|#########7| 335/345\n[01:05<00:00, 21.09it/s]', '\\rOverwrite epoch 4/4:  98%|#########7| 338/345\n[01:05<00:00, 21.04it/s]', '\\rOverwrite epoch 4/4:  99%|#########8| 341/345\n[01:05<00:00, 21.19it/s]', '\\rOverwrite epoch 4/4: 100%|#########9| 344/345\n[01:05<00:00, 21.47it/s]', '', '\\rOverwrite epoch 4/4: 100%|##########| 345/345\n[01:06<00:00,  5.18it/s]', '\\n', 'Epoch 4: validation_loss = 3.7202', '\\n',\n'Experiment complete. Artifacts saved to:', ' ', '/workspace/AE-\nScientist/research_pipeline/workspaces/0-run/process_SpawnProcess-5/working',\n'\\n', 'Execution time: 12 minutes seconds (time limit is 2 hours).']", "['Using device: cuda:0', '\\n', \"Added 5 rare tokens. Controls: [' apple', '\ntable', ' water', ' green', ' house']\", '\\n', '\\rMap:   0%|          | 0/2000\n[00:00<?, ? examples/s]', '', '\\rMap: 100%|##########| 2000/2000 [00:00<00:00,\n33507.92 examples/s]', '\\n', '\\rMap:   0%|          | 0/300 [00:00<?, ?\nexamples/s]', '', '\\rMap: 100%|##########| 300/300 [00:00<00:00, 23444.53\nexamples/s]', '\\n', '\\rTraining dataset_synthetic_injection epoch 1/1:   0%|\n| 0/21 [00:00<?, ?it/s]', '\\rTraining dataset_synthetic_injection epoch 1/1:\n5%|4         | 1/21 [01:53<37:52, 113.64s/it]', '\\rTraining\ndataset_synthetic_injection epoch 1/1:  10%|9         | 2/21 [01:53<14:50,\n46.86s/it] ', '\\rTraining dataset_synthetic_injection epoch 1/1:  14%|#4\n| 3/21 [01:53<07:39, 25.52s/it]', '\\rTraining dataset_synthetic_injection epoch\n1/1:  19%|#9        | 4/21 [01:53<04:23, 15.49s/it]', '\\rTraining\ndataset_synthetic_injection epoch 1/1:  24%|##3       | 5/21 [01:54<02:39,\n9.95s/it]', '\\rTraining dataset_synthetic_injection epoch 1/1:  29%|##8       |\n6/21 [01:54<01:39,  6.60s/it]', '\\rTraining dataset_synthetic_injection epoch\n1/1:  33%|###3      | 7/21 [01:54<01:02,  4.48s/it]', '\\rTraining\ndataset_synthetic_injection epoch 1/1:  38%|###8      | 8/21 [01:54<00:40,\n3.09s/it]', '\\rTraining dataset_synthetic_injection epoch 1/1:  43%|####2     |\n9/21 [01:54<00:25,  2.16s/it]', '\\rTraining dataset_synthetic_injection epoch\n1/1:  48%|####7     | 10/21 [01:54<00:16,  1.53s/it]', '\\rTraining\ndataset_synthetic_injection epoch 1/1:  52%|#####2    | 11/21 [01:54<00:10,\n1.10s/it]', '\\rTraining dataset_synthetic_injection epoch 1/1:  57%|#####7    |\n12/21 [01:54<00:07,  1.25it/s]', '\\rTraining dataset_synthetic_injection epoch\n1/1:  62%|######1   | 13/21 [01:55<00:04,  1.69it/s]', '\\rTraining\ndataset_synthetic_injection epoch 1/1:  67%|######6   | 14/21 [01:55<00:03,\n2.24it/s]', '\\rTraining dataset_synthetic_injection epoch 1/1:  71%|#######1  |\n15/21 [01:55<00:02,  2.88it/s]', '\\rTraining dataset_synthetic_injection epoch\n1/1:  76%|#######6  | 16/21 [01:55<00:01,  3.60it/s]', '\\rTraining\ndataset_synthetic_injection epoch 1/1:  81%|########  | 17/21 [01:55<00:00,\n4.37it/s]', '\\rTraining dataset_synthetic_injection epoch 1/1:  86%|########5 |\n18/21 [01:55<00:00,  5.14it/s]', '\\rTraining dataset_synthetic_injection epoch\n1/1:  90%|######### | 19/21 [01:55<00:00,  5.86it/s]', '\\rTraining\ndataset_synthetic_injection epoch 1/1:  95%|#########5| 20/21 [01:55<00:00,\n6.50it/s]', '', '\\rTraining dataset_synthetic_injection epoch 1/1:\n100%|##########| 21/21 [01:56<00:00,  5.56s/it]', '\\n', 'Epoch 1:\nvalidation_loss = 3.2268', '\\n', '\\rOverwrite epoch 1/4:   0%|          | 0/345\n[00:00<?, ?it/s]', '\\rOverwrite epoch 1/4:   0%|          | 1/345\n[01:44<9:56:59, 104.13s/it]', '\\rOverwrite epoch 1/4:   1%|          | 3/345\n[01:44<2:34:07, 27.04s/it] ', '\\rOverwrite epoch 1/4:   2%|1         | 6/345\n[01:44<59:12, 10.48s/it]  ', '\\rOverwrite epoch 1/4:   3%|2         | 9/345\n[01:44<31:24,  5.61s/it]', '\\rOverwrite epoch 1/4:   3%|3         | 12/345\n[01:44<18:46,  3.38s/it]', '\\rOverwrite epoch 1/4:   4%|4         | 15/345\n[01:44<11:55,  2.17s/it]', '\\rOverwrite epoch 1/4:   5%|5         | 18/345\n[01:44<07:51,  1.44s/it]', '\\rOverwrite epoch 1/4:   6%|6         | 21/345\n[01:45<05:19,  1.02it/s]', '\\rOverwrite epoch 1/4:   7%|6         | 24/345\n[01:45<03:40,  1.46it/s]', '\\rOverwrite epoch 1/4:   8%|7         | 27/345\n[01:45<02:34,  2.06it/s]', '\\rOverwrite epoch 1/4:   9%|8         | 30/345\n[01:45<01:50,  2.86it/s]', '\\rOverwrite epoch 1/4:  10%|9         | 33/345\n[01:45<01:20,  3.89it/s]', '\\rOverwrite epoch 1/4:  10%|#         | 36/345\n[01:45<00:59,  5.17it/s]', '\\rOverwrite epoch 1/4:  11%|#1        | 39/345\n[01:45<00:45,  6.72it/s]', '\\rOverwrite epoch 1/4:  12%|#2        | 42/345\n[01:46<00:35,  8.48it/s]', '\\rOverwrite epoch 1/4:  13%|#3        | 45/345\n[01:46<00:28, 10.37it/s]', '\\rOverwrite epoch 1/4:  14%|#3        | 48/345\n[01:46<00:24, 12.26it/s]', '\\rOverwrite epoch 1/4:  15%|#4        | 51/345\n[01:46<00:21, 13.99it/s]', '\\rOverwrite epoch 1/4:  16%|#5        | 54/345\n[01:46<00:18, 15.62it/s]', '\\rOverwrite epoch 1/4:  17%|#6        | 57/345\n[01:46<00:16, 17.02it/s]', '\\rOverwrite epoch 1/4:  17%|#7        | 60/345\n[01:46<00:15, 18.19it/s]', '\\rOverwrite epoch 1/4:  18%|#8        | 63/345\n[01:47<00:14, 19.11it/s]', '\\rOverwrite epoch 1/4:  19%|#9        | 66/345\n[01:47<00:14, 19.84it/s]', '\\rOverwrite epoch 1/4:  20%|##        | 69/345\n[01:47<00:13, 20.38it/s]', '\\rOverwrite epoch 1/4:  21%|##        | 72/345\n[01:47<00:13, 20.78it/s]', '\\rOverwrite epoch 1/4:  22%|##1       | 75/345\n[01:47<00:12, 21.03it/s]', '\\rOverwrite epoch 1/4:  23%|##2       | 78/345\n[01:47<00:12, 21.18it/s]', '\\rOverwrite epoch 1/4:  23%|##3       | 81/345\n[01:47<00:12, 21.32it/s]', '\\rOverwrite epoch 1/4:  24%|##4       | 84/345\n[01:48<00:12, 21.41it/s]', '\\rOverwrite epoch 1/4:  25%|##5       | 87/345\n[01:48<00:12, 21.50it/s]', '\\rOverwrite epoch 1/4:  26%|##6       | 90/345\n[01:48<00:11, 21.56it/s]', '\\rOverwrite epoch 1/4:  27%|##6       | 93/345\n[01:48<00:11, 21.61it/s]', '\\rOverwrite epoch 1/4:  28%|##7       | 96/345\n[01:48<00:11, 21.22it/s]', '\\rOverwrite epoch 1/4:  29%|##8       | 99/345\n[01:48<00:11, 21.09it/s]', '\\rOverwrite epoch 1/4:  30%|##9       | 102/345\n[01:48<00:11, 21.22it/s]', '\\rOverwrite epoch 1/4:  30%|###       | 105/345\n[01:49<00:11, 21.29it/s]', '\\rOverwrite epoch 1/4:  31%|###1      | 108/345\n[01:49<00:11, 21.31it/s]', '\\rOverwrite epoch 1/4:  32%|###2      | 111/345\n[01:49<00:10, 21.35it/s]', '\\rOverwrite epoch 1/4:  33%|###3      | 114/345\n[01:49<00:10, 21.40it/s]', '\\rOverwrite epoch 1/4:  34%|###3      | 117/345\n[01:49<00:10, 21.36it/s]', '\\rOverwrite epoch 1/4:  35%|###4      | 120/345\n[01:49<00:10, 21.41it/s]', '\\rOverwrite epoch 1/4:  36%|###5      | 123/345\n[01:49<00:10, 21.44it/s]', '\\rOverwrite epoch 1/4:  37%|###6      | 126/345\n[01:49<00:10, 21.41it/s]', '\\rOverwrite epoch 1/4:  37%|###7      | 129/345\n[01:50<00:10, 21.50it/s]', '\\rOverwrite epoch 1/4:  38%|###8      | 132/345\n[01:50<00:09, 21.50it/s]', '\\rOverwrite epoch 1/4:  39%|###9      | 135/345\n[01:50<00:09, 21.57it/s]', '\\rOverwrite epoch 1/4:  40%|####      | 138/345\n[01:50<00:09, 21.60it/s]', '\\rOverwrite epoch 1/4:  41%|####      | 141/345\n[01:50<00:09, 21.58it/s]', '\\rOverwrite epoch 1/4:  42%|####1     | 144/345\n[01:50<00:09, 21.46it/s]', '\\rOverwrite epoch 1/4:  43%|####2     | 147/345\n[01:50<00:09, 21.40it/s]', '\\rOverwrite epoch 1/4:  43%|####3     | 150/345\n[01:51<00:09, 21.37it/s]', '\\rOverwrite epoch 1/4:  44%|####4     | 153/345\n[01:51<00:08, 21.38it/s]', '\\rOverwrite epoch 1/4:  45%|####5     | 156/345\n[01:51<00:08, 21.36it/s]', '\\rOverwrite epoch 1/4:  46%|####6     | 159/345\n[01:51<00:08, 21.26it/s]', '\\rOverwrite epoch 1/4:  47%|####6     | 162/345\n[01:51<00:08, 21.20it/s]', '\\rOverwrite epoch 1/4:  48%|####7     | 165/345\n[01:51<00:08, 21.31it/s]', '\\rOverwrite epoch 1/4:  49%|####8     | 168/345\n[01:51<00:08, 21.15it/s]', '\\rOverwrite epoch 1/4:  50%|####9     | 171/345\n[01:52<00:08, 20.47it/s]', '\\rOverwrite epoch 1/4:  50%|#####     | 174/345\n[01:52<00:08, 19.89it/s]', '\\rOverwrite epoch 1/4:  51%|#####1    | 176/345\n[01:52<00:08, 19.59it/s]', '\\rOverwrite epoch 1/4:  52%|#####1    | 178/345\n[01:52<00:08, 19.36it/s]', '\\rOverwrite epoch 1/4:  52%|#####2    | 180/345\n[01:52<00:08, 19.17it/s]', '\\rOverwrite epoch 1/4:  53%|#####3    | 183/345\n[01:52<00:08, 19.85it/s]', '\\rOverwrite epoch 1/4:  54%|#####3    | 186/345\n[01:52<00:07, 20.10it/s]', '\\rOverwrite epoch 1/4:  55%|#####4    | 189/345\n[01:53<00:07, 20.46it/s]', '\\rOverwrite epoch 1/4:  56%|#####5    | 192/345\n[01:53<00:07, 20.67it/s]', '\\rOverwrite epoch 1/4:  57%|#####6    | 195/345\n[01:53<00:07, 19.98it/s]', '\\rOverwrite epoch 1/4:  57%|#####7    | 198/345\n[01:53<00:07, 19.69it/s]', '\\rOverwrite epoch 1/4:  58%|#####7    | 200/345\n[01:53<00:07, 19.65it/s]', '\\rOverwrite epoch 1/4:  59%|#####8    | 203/345\n[01:53<00:07, 19.95it/s]', '\\rOverwrite epoch 1/4:  60%|#####9    | 206/345\n[01:53<00:06, 20.47it/s]', '\\rOverwrite epoch 1/4:  61%|######    | 209/345\n[01:54<00:06, 20.79it/s]', '\\rOverwrite epoch 1/4:  61%|######1   | 212/345\n[01:54<00:06, 20.72it/s]', '\\rOverwrite epoch 1/4:  62%|######2   | 215/345\n[01:54<00:06, 20.85it/s]', '\\rOverwrite epoch 1/4:  63%|######3   | 218/345\n[01:54<00:06, 20.95it/s]', '\\rOverwrite epoch 1/4:  64%|######4   | 221/345\n[01:54<00:05, 21.05it/s]', '\\rOverwrite epoch 1/4:  65%|######4   | 224/345\n[01:54<00:05, 21.09it/s]', '\\rOverwrite epoch 1/4:  66%|######5   | 227/345\n[01:54<00:05, 21.14it/s]', '\\rOverwrite epoch 1/4:  67%|######6   | 230/345\n[01:55<00:05, 21.18it/s]', '\\rOverwrite epoch 1/4:  68%|######7   | 233/345\n[01:55<00:05, 21.29it/s]', '\\rOverwrite epoch 1/4:  68%|######8   | 236/345\n[01:55<00:05, 21.25it/s]', '\\rOverwrite epoch 1/4:  69%|######9   | 239/345\n[01:55<00:04, 21.25it/s]', '\\rOverwrite epoch 1/4:  70%|#######   | 242/345\n[01:55<00:04, 21.26it/s]', '\\rOverwrite epoch 1/4:  71%|#######1  | 245/345\n[01:55<00:04, 21.24it/s]', '\\rOverwrite epoch 1/4:  72%|#######1  | 248/345\n[01:55<00:04, 21.29it/s]', '\\rOverwrite epoch 1/4:  73%|#######2  | 251/345\n[01:55<00:04, 21.21it/s]', '\\rOverwrite epoch 1/4:  74%|#######3  | 254/345\n[01:56<00:04, 21.17it/s]', '\\rOverwrite epoch 1/4:  74%|#######4  | 257/345\n[01:56<00:04, 21.22it/s]', '\\rOverwrite epoch 1/4:  75%|#######5  | 260/345\n[01:56<00:03, 21.32it/s]', '\\rOverwrite epoch 1/4:  76%|#######6  | 263/345\n[01:56<00:03, 21.29it/s]', '\\rOverwrite epoch 1/4:  77%|#######7  | 266/345\n[01:56<00:03, 21.24it/s]', '\\rOverwrite epoch 1/4:  78%|#######7  | 269/345\n[01:56<00:03, 21.11it/s]', '\\rOverwrite epoch 1/4:  79%|#######8  | 272/345\n[01:56<00:03, 21.30it/s]', '\\rOverwrite epoch 1/4:  80%|#######9  | 275/345\n[01:57<00:03, 21.33it/s]', '\\rOverwrite epoch 1/4:  81%|########  | 278/345\n[01:57<00:03, 21.29it/s]', '\\rOverwrite epoch 1/4:  81%|########1 | 281/345\n[01:57<00:03, 21.27it/s]', '\\rOverwrite epoch 1/4:  82%|########2 | 284/345\n[01:57<00:02, 21.38it/s]', '\\rOverwrite epoch 1/4:  83%|########3 | 287/345\n[01:57<00:02, 21.52it/s]', '\\rOverwrite epoch 1/4:  84%|########4 | 290/345\n[01:57<00:02, 21.60it/s]', '\\rOverwrite epoch 1/4:  85%|########4 | 293/345\n[01:57<00:02, 21.65it/s]', '\\rOverwrite epoch 1/4:  86%|########5 | 296/345\n[01:58<00:02, 21.69it/s]', '\\rOverwrite epoch 1/4:  87%|########6 | 299/345\n[01:58<00:02, 21.64it/s]', '\\rOverwrite epoch 1/4:  88%|########7 | 302/345\n[01:58<00:01, 21.68it/s]', '\\rOverwrite epoch 1/4:  88%|########8 | 305/345\n[01:58<00:01, 21.71it/s]', '\\rOverwrite epoch 1/4:  89%|########9 | 308/345\n[01:58<00:01, 21.72it/s]', '\\rOverwrite epoch 1/4:  90%|######### | 311/345\n[01:58<00:01, 21.64it/s]', '\\rOverwrite epoch 1/4:  91%|#########1| 314/345\n[01:58<00:01, 21.53it/s]', '\\rOverwrite epoch 1/4:  92%|#########1| 317/345\n[01:59<00:01, 21.36it/s]', '\\rOverwrite epoch 1/4:  93%|#########2| 320/345\n[01:59<00:01, 21.44it/s]', '\\rOverwrite epoch 1/4:  94%|#########3| 323/345\n[01:59<00:01, 21.51it/s]', '\\rOverwrite epoch 1/4:  94%|#########4| 326/345\n[01:59<00:00, 21.55it/s]', '\\rOverwrite epoch 1/4:  95%|#########5| 329/345\n[01:59<00:00, 21.31it/s]', '\\rOverwrite epoch 1/4:  96%|#########6| 332/345\n[01:59<00:00, 21.36it/s]', '\\rOverwrite epoch 1/4:  97%|#########7| 335/345\n[01:59<00:00, 21.45it/s]', '\\rOverwrite epoch 1/4:  98%|#########7| 338/345\n[02:00<00:00, 21.55it/s]', '\\rOverwrite epoch 1/4:  99%|#########8| 341/345\n[02:00<00:00, 21.60it/s]', '\\rOverwrite epoch 1/4: 100%|#########9| 344/345\n[02:00<00:00, 21.76it/s]', '', '\\rOverwrite epoch 1/4: 100%|##########| 345/345\n[02:01<00:00,  2.84it/s]', '\\n', 'Epoch 1: validation_loss = 3.6236', '\\n',\n'\\rOverwrite epoch 2/4:   0%|          | 0/345 [00:00<?, ?it/s]', '\\rOverwrite\nepoch 2/4:   0%|          | 1/345 [01:50<10:34:53, 110.74s/it]', '\\rOverwrite\nepoch 2/4:   1%|          | 3/345 [01:50<2:43:54, 28.76s/it]  ', '\\rOverwrite\nepoch 2/4:   2%|1         | 6/345 [01:51<1:02:57, 11.14s/it]', '\\rOverwrite\nepoch 2/4:   3%|2         | 9/345 [01:51<33:22,  5.96s/it]  ', '\\rOverwrite\nepoch 2/4:   3%|3         | 12/345 [01:51<19:56,  3.59s/it]', '\\rOverwrite epoch\n2/4:   4%|4         | 15/345 [01:51<12:40,  2.30s/it]', '\\rOverwrite epoch 2/4:\n5%|5         | 18/345 [01:51<08:21,  1.53s/it]', '\\rOverwrite epoch 2/4:   6%|6\n| 21/345 [01:51<05:38,  1.04s/it]', '\\rOverwrite epoch 2/4:   7%|6         |\n24/345 [01:51<03:53,  1.38it/s]', '\\rOverwrite epoch 2/4:   8%|7         |\n27/345 [01:51<02:43,  1.95it/s]', '\\rOverwrite epoch 2/4:   9%|8         |\n30/345 [01:52<01:56,  2.71it/s]', '\\rOverwrite epoch 2/4:  10%|9         |\n33/345 [01:52<01:24,  3.70it/s]', '\\rOverwrite epoch 2/4:  10%|#         |\n36/345 [01:52<01:02,  4.94it/s]', '\\rOverwrite epoch 2/4:  11%|#1        |\n39/345 [01:52<00:47,  6.43it/s]', '\\rOverwrite epoch 2/4:  12%|#2        |\n42/345 [01:52<00:37,  8.14it/s]', '\\rOverwrite epoch 2/4:  13%|#3        |\n45/345 [01:52<00:30,  9.97it/s]', '\\rOverwrite epoch 2/4:  14%|#3        |\n48/345 [01:52<00:25, 11.83it/s]', '\\rOverwrite epoch 2/4:  15%|#4        |\n51/345 [01:53<00:21, 13.61it/s]', '\\rOverwrite epoch 2/4:  16%|#5        |\n54/345 [01:53<00:19, 15.24it/s]', '\\rOverwrite epoch 2/4:  17%|#6        |\n57/345 [01:53<00:17, 16.40it/s]', '\\rOverwrite epoch 2/4:  17%|#7        |\n60/345 [01:53<00:16, 17.59it/s]', '\\rOverwrite epoch 2/4:  18%|#8        |\n63/345 [01:53<00:15, 18.53it/s]', '\\rOverwrite epoch 2/4:  19%|#9        |\n66/345 [01:53<00:14, 19.36it/s]', '\\rOverwrite epoch 2/4:  20%|##        |\n69/345 [01:53<00:13, 19.91it/s]', '\\rOverwrite epoch 2/4:  21%|##        |\n72/345 [01:54<00:13, 20.19it/s]', '\\rOverwrite epoch 2/4:  22%|##1       |\n75/345 [01:54<00:13, 20.61it/s]', '\\rOverwrite epoch 2/4:  23%|##2       |\n78/345 [01:54<00:12, 20.94it/s]', '\\rOverwrite epoch 2/4:  23%|##3       |\n81/345 [01:54<00:12, 21.07it/s]', '\\rOverwrite epoch 2/4:  24%|##4       |\n84/345 [01:54<00:12, 21.25it/s]', '\\rOverwrite epoch 2/4:  25%|##5       |\n87/345 [01:54<00:12, 21.38it/s]', '\\rOverwrite epoch 2/4:  26%|##6       |\n90/345 [01:54<00:11, 21.33it/s]', '\\rOverwrite epoch 2/4:  27%|##6       |\n93/345 [01:55<00:11, 21.41it/s]', '\\rOverwrite epoch 2/4:  28%|##7       |\n96/345 [01:55<00:11, 21.40it/s]', '\\rOverwrite epoch 2/4:  29%|##8       |\n99/345 [01:55<00:11, 21.47it/s]', '\\rOverwrite epoch 2/4:  30%|##9       |\n102/345 [01:55<00:11, 21.15it/s]', '\\rOverwrite epoch 2/4:  30%|###       |\n105/345 [01:55<00:11, 21.28it/s]', '\\rOverwrite epoch 2/4:  31%|###1      |\n108/345 [01:55<00:11, 21.34it/s]', '\\rOverwrite epoch 2/4:  32%|###2      |\n111/345 [01:55<00:11, 21.23it/s]', '\\rOverwrite epoch 2/4:  33%|###3      |\n114/345 [01:56<00:10, 21.32it/s]', '\\rOverwrite epoch 2/4:  34%|###3      |\n117/345 [01:56<00:10, 21.20it/s]', '\\rOverwrite epoch 2/4:  35%|###4      |\n120/345 [01:56<00:10, 20.90it/s]', '\\rOverwrite epoch 2/4:  36%|###5      |\n123/345 [01:56<00:10, 20.93it/s]', '\\rOverwrite epoch 2/4:  37%|###6      |\n126/345 [01:56<00:10, 21.12it/s]', '\\rOverwrite epoch 2/4:  37%|###7      |\n129/345 [01:56<00:10, 21.29it/s]', '\\rOverwrite epoch 2/4:  38%|###8      |\n132/345 [01:56<00:09, 21.30it/s]', '\\rOverwrite epoch 2/4:  39%|###9      |\n135/345 [01:57<00:09, 21.38it/s]', '\\rOverwrite epoch 2/4:  40%|####      |\n138/345 [01:57<00:09, 21.42it/s]', '\\rOverwrite epoch 2/4:  41%|####      |\n141/345 [01:57<00:09, 21.42it/s]', '\\rOverwrite epoch 2/4:  42%|####1     |\n144/345 [01:57<00:09, 21.43it/s]', '\\rOverwrite epoch 2/4:  43%|####2     |\n147/345 [01:57<00:09, 21.46it/s]', '\\rOverwrite epoch 2/4:  43%|####3     |\n150/345 [01:57<00:09, 21.48it/s]', '\\rOverwrite epoch 2/4:  44%|####4     |\n153/345 [01:57<00:08, 21.54it/s]', '\\rOverwrite epoch 2/4:  45%|####5     |\n156/345 [01:58<00:08, 21.57it/s]', '\\rOverwrite epoch 2/4:  46%|####6     |\n159/345 [01:58<00:08, 21.56it/s]', '\\rOverwrite epoch 2/4:  47%|####6     |\n162/345 [01:58<00:08, 21.41it/s]', '\\rOverwrite epoch 2/4:  48%|####7     |\n165/345 [01:58<00:08, 21.43it/s]', '\\rOverwrite epoch 2/4:  49%|####8     |\n168/345 [01:58<00:08, 21.40it/s]', '\\rOverwrite epoch 2/4:  50%|####9     |\n171/345 [01:58<00:08, 21.53it/s]', '\\rOverwrite epoch 2/4:  50%|#####     |\n174/345 [01:58<00:07, 21.45it/s]', '\\rOverwrite epoch 2/4:  51%|#####1    |\n177/345 [01:59<00:07, 21.29it/s]', '\\rOverwrite epoch 2/4:  52%|#####2    |\n180/345 [01:59<00:07, 21.22it/s]', '\\rOverwrite epoch 2/4:  53%|#####3    |\n183/345 [01:59<00:07, 21.21it/s]', '\\rOverwrite epoch 2/4:  54%|#####3    |\n186/345 [01:59<00:07, 21.30it/s]', '\\rOverwrite epoch 2/4:  55%|#####4    |\n189/345 [01:59<00:07, 21.28it/s]', '\\rOverwrite epoch 2/4:  56%|#####5    |\n192/345 [01:59<00:07, 21.44it/s]', '\\rOverwrite epoch 2/4:  57%|#####6    |\n195/345 [01:59<00:07, 21.41it/s]', '\\rOverwrite epoch 2/4:  57%|#####7    |\n198/345 [02:00<00:06, 21.48it/s]', '\\rOverwrite epoch 2/4:  58%|#####8    |\n201/345 [02:00<00:06, 21.29it/s]', '\\rOverwrite epoch 2/4:  59%|#####9    |\n204/345 [02:00<00:06, 21.24it/s]', '\\rOverwrite epoch 2/4:  60%|######    |\n207/345 [02:00<00:06, 21.01it/s]', '\\rOverwrite epoch 2/4:  61%|######    |\n210/345 [02:00<00:06, 20.99it/s]', '\\rOverwrite epoch 2/4:  62%|######1   |\n213/345 [02:00<00:06, 21.13it/s]', '\\rOverwrite epoch 2/4:  63%|######2   |\n216/345 [02:00<00:06, 21.25it/s]', '\\rOverwrite epoch 2/4:  63%|######3   |\n219/345 [02:01<00:05, 21.33it/s]', '\\rOverwrite epoch 2/4:  64%|######4   |\n222/345 [02:01<00:05, 21.43it/s]', '\\rOverwrite epoch 2/4:  65%|######5   |\n225/345 [02:01<00:05, 21.40it/s]', '\\rOverwrite epoch 2/4:  66%|######6   |\n228/345 [02:01<00:05, 21.06it/s]', '\\rOverwrite epoch 2/4:  67%|######6   |\n231/345 [02:01<00:05, 21.04it/s]', '\\rOverwrite epoch 2/4:  68%|######7   |\n234/345 [02:01<00:05, 21.18it/s]', '\\rOverwrite epoch 2/4:  69%|######8   |\n237/345 [02:01<00:05, 21.15it/s]', '\\rOverwrite epoch 2/4:  70%|######9   |\n240/345 [02:02<00:04, 21.16it/s]', '\\rOverwrite epoch 2/4:  70%|#######   |\n243/345 [02:02<00:04, 21.31it/s]', '\\rOverwrite epoch 2/4:  71%|#######1  |\n246/345 [02:02<00:04, 21.38it/s]', '\\rOverwrite epoch 2/4:  72%|#######2  |\n249/345 [02:02<00:04, 21.42it/s]', '\\rOverwrite epoch 2/4:  73%|#######3  |\n252/345 [02:02<00:04, 21.42it/s]', '\\rOverwrite epoch 2/4:  74%|#######3  |\n255/345 [02:02<00:04, 21.44it/s]', '\\rOverwrite epoch 2/4:  75%|#######4  |\n258/345 [02:02<00:04, 21.43it/s]', '\\rOverwrite epoch 2/4:  76%|#######5  |\n261/345 [02:02<00:03, 21.50it/s]', '\\rOverwrite epoch 2/4:  77%|#######6  |\n264/345 [02:03<00:03, 21.55it/s]', '\\rOverwrite epoch 2/4:  77%|#######7  |\n267/345 [02:03<00:03, 21.59it/s]', '\\rOverwrite epoch 2/4:  78%|#######8  |\n270/345 [02:03<00:03, 21.59it/s]', '\\rOverwrite epoch 2/4:  79%|#######9  |\n273/345 [02:03<00:03, 21.62it/s]', '\\rOverwrite epoch 2/4:  80%|########  |\n276/345 [02:03<00:03, 21.67it/s]', '\\rOverwrite epoch 2/4:  81%|########  |\n279/345 [02:03<00:03, 21.71it/s]', '\\rOverwrite epoch 2/4:  82%|########1 |\n282/345 [02:03<00:02, 21.74it/s]', '\\rOverwrite epoch 2/4:  83%|########2 |\n285/345 [02:04<00:02, 21.73it/s]', '\\rOverwrite epoch 2/4:  83%|########3 |\n288/345 [02:04<00:02, 21.68it/s]', '\\rOverwrite epoch 2/4:  84%|########4 |\n291/345 [02:04<00:02, 21.67it/s]', '\\rOverwrite epoch 2/4:  85%|########5 |\n294/345 [02:04<00:02, 21.66it/s]', '\\rOverwrite epoch 2/4:  86%|########6 |\n297/345 [02:04<00:02, 21.69it/s]', '\\rOverwrite epoch 2/4:  87%|########6 |\n300/345 [02:04<00:02, 21.10it/s]', '\\rOverwrite epoch 2/4:  88%|########7 |\n303/345 [02:04<00:01, 21.10it/s]', '\\rOverwrite epoch 2/4:  89%|########8 |\n306/345 [02:05<00:01, 21.21it/s]', '\\rOverwrite epoch 2/4:  90%|########9 |\n309/345 [02:05<00:01, 21.23it/s]', '\\rOverwrite epoch 2/4:  90%|######### |\n312/345 [02:05<00:01, 21.32it/s]', '\\rOverwrite epoch 2/4:  91%|#########1|\n315/345 [02:05<00:01, 21.42it/s]', '\\rOverwrite epoch 2/4:  92%|#########2|\n318/345 [02:05<00:01, 21.42it/s]', '\\rOverwrite epoch 2/4:  93%|#########3|\n321/345 [02:05<00:01, 21.41it/s]', '\\rOverwrite epoch 2/4:  94%|#########3|\n324/345 [02:05<00:00, 21.24it/s]', '\\rOverwrite epoch 2/4:  95%|#########4|\n327/345 [02:06<00:00, 21.13it/s]', '\\rOverwrite epoch 2/4:  96%|#########5|\n330/345 [02:06<00:00, 21.30it/s]', '\\rOverwrite epoch 2/4:  97%|#########6|\n333/345 [02:06<00:00, 21.40it/s]', '\\rOverwrite epoch 2/4:  97%|#########7|\n336/345 [02:06<00:00, 21.43it/s]', '\\rOverwrite epoch 2/4:  98%|#########8|\n339/345 [02:06<00:00, 21.47it/s]', '\\rOverwrite epoch 2/4:  99%|#########9|\n342/345 [02:06<00:00, 21.32it/s]', '\\rOverwrite epoch 2/4: 100%|##########|\n345/345 [02:06<00:00, 22.19it/s]', '', '\\rOverwrite epoch 2/4: 100%|##########|\n345/345 [02:08<00:00,  2.69it/s]', '\\n', 'Epoch 2: validation_loss = 3.6392',\n'\\n', '\\rOverwrite epoch 3/4:   0%|          | 0/345 [00:00<?, ?it/s]',\n'\\rOverwrite epoch 3/4:   0%|          | 1/345 [01:39<9:32:45, 99.90s/it]',\n'\\rOverwrite epoch 3/4:   1%|          | 3/345 [01:40<2:27:54, 25.95s/it]',\n'\\rOverwrite epoch 3/4:   2%|1         | 6/345 [01:40<56:49, 10.06s/it]  ',\n'\\rOverwrite epoch 3/4:   3%|2         | 9/345 [01:40<30:08,  5.38s/it]',\n'\\rOverwrite epoch 3/4:   3%|3         | 12/345 [01:40<18:00,  3.25s/it]',\n'\\rOverwrite epoch 3/4:   4%|4         | 15/345 [01:40<11:27,  2.08s/it]',\n'\\rOverwrite epoch 3/4:   5%|5         | 18/345 [01:40<07:33,  1.39s/it]',\n'\\rOverwrite epoch 3/4:   6%|6         | 21/345 [01:40<05:06,  1.06it/s]',\n'\\rOverwrite epoch 3/4:   7%|6         | 24/345 [01:40<03:31,  1.52it/s]',\n'\\rOverwrite epoch 3/4:   8%|7         | 27/345 [01:41<02:28,  2.14it/s]',\n'\\rOverwrite epoch 3/4:   9%|8         | 30/345 [01:41<01:46,  2.97it/s]',\n'\\rOverwrite epoch 3/4:  10%|9         | 33/345 [01:41<01:17,  4.04it/s]',\n'\\rOverwrite epoch 3/4:  10%|#         | 36/345 [01:41<00:57,  5.37it/s]',\n'\\rOverwrite epoch 3/4:  11%|#1        | 39/345 [01:41<00:43,  6.96it/s]',\n'\\rOverwrite epoch 3/4:  12%|#2        | 42/345 [01:41<00:34,  8.73it/s]',\n'\\rOverwrite epoch 3/4:  13%|#3        | 45/345 [01:41<00:28, 10.64it/s]',\n'\\rOverwrite epoch 3/4:  14%|#3        | 48/345 [01:42<00:23, 12.57it/s]',\n'\\rOverwrite epoch 3/4:  15%|#4        | 51/345 [01:42<00:20, 14.24it/s]',\n'\\rOverwrite epoch 3/4:  16%|#5        | 54/345 [01:42<00:18, 15.87it/s]',\n'\\rOverwrite epoch 3/4:  17%|#6        | 57/345 [01:42<00:16, 17.22it/s]',\n'\\rOverwrite epoch 3/4:  17%|#7        | 60/345 [01:42<00:15, 18.23it/s]',\n'\\rOverwrite epoch 3/4:  18%|#8        | 63/345 [01:42<00:14, 19.12it/s]',\n'\\rOverwrite epoch 3/4:  19%|#9        | 66/345 [01:42<00:14, 19.65it/s]',\n'\\rOverwrite epoch 3/4:  20%|##        | 69/345 [01:43<00:13, 20.10it/s]',\n'\\rOverwrite epoch 3/4:  21%|##        | 72/345 [01:43<00:13, 20.46it/s]',\n'\\rOverwrite epoch 3/4:  22%|##1       | 75/345 [01:43<00:12, 20.87it/s]',\n'\\rOverwrite epoch 3/4:  23%|##2       | 78/345 [01:43<00:12, 21.09it/s]',\n'\\rOverwrite epoch 3/4:  23%|##3       | 81/345 [01:43<00:12, 21.09it/s]',\n'\\rOverwrite epoch 3/4:  24%|##4       | 84/345 [01:43<00:12, 21.21it/s]',\n'\\rOverwrite epoch 3/4:  25%|##5       | 87/345 [01:43<00:12, 21.25it/s]',\n'\\rOverwrite epoch 3/4:  26%|##6       | 90/345 [01:44<00:11, 21.32it/s]',\n'\\rOverwrite epoch 3/4:  27%|##6       | 93/345 [01:44<00:11, 21.34it/s]',\n'\\rOverwrite epoch 3/4:  28%|##7       | 96/345 [01:44<00:11, 21.45it/s]',\n'\\rOverwrite epoch 3/4:  29%|##8       | 99/345 [01:44<00:11, 21.59it/s]',\n'\\rOverwrite epoch 3/4:  30%|##9       | 102/345 [01:44<00:11, 21.67it/s]',\n'\\rOverwrite epoch 3/4:  30%|###       | 105/345 [01:44<00:11, 21.78it/s]',\n'\\rOverwrite epoch 3/4:  31%|###1      | 108/345 [01:44<00:10, 21.83it/s]',\n'\\rOverwrite epoch 3/4:  32%|###2      | 111/345 [01:45<00:10, 21.87it/s]',\n'\\rOverwrite epoch 3/4:  33%|###3      | 114/345 [01:45<00:10, 21.88it/s]',\n'\\rOverwrite epoch 3/4:  34%|###3      | 117/345 [01:45<00:10, 21.86it/s]',\n'\\rOverwrite epoch 3/4:  35%|###4      | 120/345 [01:45<00:10, 21.83it/s]',\n'\\rOverwrite epoch 3/4:  36%|###5      | 123/345 [01:45<00:10, 21.76it/s]',\n'\\rOverwrite epoch 3/4:  37%|###6      | 126/345 [01:45<00:10, 21.62it/s]',\n'\\rOverwrite epoch 3/4:  37%|###7      | 129/345 [01:45<00:09, 21.65it/s]',\n'\\rOverwrite epoch 3/4:  38%|###8      | 132/345 [01:46<00:09, 21.72it/s]',\n'\\rOverwrite epoch 3/4:  39%|###9      | 135/345 [01:46<00:09, 21.76it/s]',\n'\\rOverwrite epoch 3/4:  40%|####      | 138/345 [01:46<00:09, 21.74it/s]',\n'\\rOverwrite epoch 3/4:  41%|####      | 141/345 [01:46<00:09, 21.76it/s]',\n'\\rOverwrite epoch 3/4:  42%|####1     | 144/345 [01:46<00:09, 21.73it/s]',\n'\\rOverwrite epoch 3/4:  43%|####2     | 147/345 [01:46<00:09, 21.78it/s]',\n'\\rOverwrite epoch 3/4:  43%|####3     | 150/345 [01:46<00:08, 21.76it/s]',\n'\\rOverwrite epoch 3/4:  44%|####4     | 153/345 [01:46<00:08, 21.74it/s]',\n'\\rOverwrite epoch 3/4:  45%|####5     | 156/345 [01:47<00:08, 21.75it/s]',\n'\\rOverwrite epoch 3/4:  46%|####6     | 159/345 [01:47<00:08, 21.77it/s]',\n'\\rOverwrite epoch 3/4:  47%|####6     | 162/345 [01:47<00:08, 21.73it/s]',\n'\\rOverwrite epoch 3/4:  48%|####7     | 165/345 [01:47<00:08, 21.21it/s]',\n'\\rOverwrite epoch 3/4:  49%|####8     | 168/345 [01:47<00:08, 21.27it/s]',\n'\\rOverwrite epoch 3/4:  50%|####9     | 171/345 [01:47<00:08, 21.41it/s]',\n'\\rOverwrite epoch 3/4:  50%|#####     | 174/345 [01:47<00:07, 21.52it/s]',\n'\\rOverwrite epoch 3/4:  51%|#####1    | 177/345 [01:48<00:07, 21.56it/s]',\n'\\rOverwrite epoch 3/4:  52%|#####2    | 180/345 [01:48<00:07, 21.30it/s]',\n'\\rOverwrite epoch 3/4:  53%|#####3    | 183/345 [01:48<00:07, 21.42it/s]',\n'\\rOverwrite epoch 3/4:  54%|#####3    | 186/345 [01:48<00:07, 21.47it/s]',\n'\\rOverwrite epoch 3/4:  55%|#####4    | 189/345 [01:48<00:07, 21.40it/s]',\n'\\rOverwrite epoch 3/4:  56%|#####5    | 192/345 [01:48<00:07, 21.44it/s]',\n'\\rOverwrite epoch 3/4:  57%|#####6    | 195/345 [01:48<00:06, 21.45it/s]',\n'\\rOverwrite epoch 3/4:  57%|#####7    | 198/345 [01:49<00:06, 21.52it/s]',\n'\\rOverwrite epoch 3/4:  58%|#####8    | 201/345 [01:49<00:06, 21.60it/s]',\n'\\rOverwrite epoch 3/4:  59%|#####9    | 204/345 [01:49<00:06, 21.61it/s]',\n'\\rOverwrite epoch 3/4:  60%|######    | 207/345 [01:49<00:06, 21.63it/s]',\n'\\rOverwrite epoch 3/4:  61%|######    | 210/345 [01:49<00:06, 21.68it/s]',\n'\\rOverwrite epoch 3/4:  62%|######1   | 213/345 [01:49<00:06, 21.74it/s]',\n'\\rOverwrite epoch 3/4:  63%|######2   | 216/345 [01:49<00:05, 21.76it/s]',\n'\\rOverwrite epoch 3/4:  63%|######3   | 219/345 [01:50<00:05, 21.73it/s]',\n'\\rOverwrite epoch 3/4:  64%|######4   | 222/345 [01:50<00:05, 21.63it/s]',\n'\\rOverwrite epoch 3/4:  65%|######5   | 225/345 [01:50<00:05, 21.66it/s]',\n'\\rOverwrite epoch 3/4:  66%|######6   | 228/345 [01:50<00:05, 21.67it/s]',\n'\\rOverwrite epoch 3/4:  67%|######6   | 231/345 [01:50<00:05, 21.50it/s]',\n'\\rOverwrite epoch 3/4:  68%|######7   | 234/345 [01:50<00:05, 21.49it/s]',\n'\\rOverwrite epoch 3/4:  69%|######8   | 237/345 [01:50<00:05, 21.55it/s]',\n'\\rOverwrite epoch 3/4:  70%|######9   | 240/345 [01:51<00:04, 21.58it/s]',\n'\\rOverwrite epoch 3/4:  70%|#######   | 243/345 [01:51<00:04, 21.64it/s]',\n'\\rOverwrite epoch 3/4:  71%|#######1  | 246/345 [01:51<00:04, 21.56it/s]',\n'\\rOverwrite epoch 3/4:  72%|#######2  | 249/345 [01:51<00:04, 21.06it/s]',\n'\\rOverwrite epoch 3/4:  73%|#######3  | 252/345 [01:51<00:04, 21.07it/s]',\n'\\rOverwrite epoch 3/4:  74%|#######3  | 255/345 [01:51<00:04, 21.21it/s]',\n'\\rOverwrite epoch 3/4:  75%|#######4  | 258/345 [01:51<00:04, 21.27it/s]',\n'\\rOverwrite epoch 3/4:  76%|#######5  | 261/345 [01:51<00:03, 21.30it/s]',\n'\\rOverwrite epoch 3/4:  77%|#######6  | 264/345 [01:52<00:03, 21.41it/s]',\n'\\rOverwrite epoch 3/4:  77%|#######7  | 267/345 [01:52<00:03, 21.47it/s]',\n'\\rOverwrite epoch 3/4:  78%|#######8  | 270/345 [01:52<00:03, 21.54it/s]',\n'\\rOverwrite epoch 3/4:  79%|#######9  | 273/345 [01:52<00:03, 21.46it/s]',\n'\\rOverwrite epoch 3/4:  80%|########  | 276/345 [01:52<00:03, 21.48it/s]',\n'\\rOverwrite epoch 3/4:  81%|########  | 279/345 [01:52<00:03, 21.46it/s]',\n'\\rOverwrite epoch 3/4:  82%|########1 | 282/345 [01:52<00:02, 21.44it/s]',\n'\\rOverwrite epoch 3/4:  83%|########2 | 285/345 [01:53<00:02, 21.53it/s]',\n'\\rOverwrite epoch 3/4:  83%|########3 | 288/345 [01:53<00:02, 21.53it/s]',\n'\\rOverwrite epoch 3/4:  84%|########4 | 291/345 [01:53<00:02, 21.56it/s]',\n'\\rOverwrite epoch 3/4:  85%|########5 | 294/345 [01:53<00:02, 21.55it/s]',\n'\\rOverwrite epoch 3/4:  86%|########6 | 297/345 [01:53<00:02, 21.42it/s]',\n'\\rOverwrite epoch 3/4:  87%|########6 | 300/345 [01:53<00:02, 21.53it/s]',\n'\\rOverwrite epoch 3/4:  88%|########7 | 303/345 [01:53<00:01, 21.37it/s]',\n'\\rOverwrite epoch 3/4:  89%|########8 | 306/345 [01:54<00:01, 21.53it/s]',\n'\\rOverwrite epoch 3/4:  90%|########9 | 309/345 [01:54<00:01, 21.54it/s]',\n'\\rOverwrite epoch 3/4:  90%|######### | 312/345 [01:54<00:01, 21.67it/s]',\n'\\rOverwrite epoch 3/4:  91%|#########1| 315/345 [01:54<00:01, 21.75it/s]',\n'\\rOverwrite epoch 3/4:  92%|#########2| 318/345 [01:54<00:01, 21.80it/s]',\n'\\rOverwrite epoch 3/4:  93%|#########3| 321/345 [01:54<00:01, 21.66it/s]',\n'\\rOverwrite epoch 3/4:  94%|#########3| 324/345 [01:54<00:00, 21.69it/s]',\n'\\rOverwrite epoch 3/4:  95%|#########4| 327/345 [01:55<00:00, 21.62it/s]',\n'\\rOverwrite epoch 3/4:  96%|#########5| 330/345 [01:55<00:00, 21.62it/s]',\n'\\rOverwrite epoch 3/4:  97%|#########6| 333/345 [01:55<00:00, 21.61it/s]',\n'\\rOverwrite epoch 3/4:  97%|#########7| 336/345 [01:55<00:00, 21.66it/s]',\n'\\rOverwrite epoch 3/4:  98%|#########8| 339/345 [01:55<00:00, 21.48it/s]',\n'\\rOverwrite epoch 3/4:  99%|#########9| 342/345 [01:55<00:00, 21.58it/s]',\n'\\rOverwrite epoch 3/4: 100%|##########| 345/345 [01:55<00:00, 22.49it/s]', '',\n'\\rOverwrite epoch 3/4: 100%|##########| 345/345 [01:56<00:00,  2.95it/s]',\n'\\n', 'Epoch 3: validation_loss = 3.6715', '\\n', '\\rOverwrite epoch 4/4:   0%|\n| 0/345 [00:00<?, ?it/s]', '\\rOverwrite epoch 4/4:   0%|          | 1/345\n[01:46<10:10:35, 106.50s/it]', '\\rOverwrite epoch 4/4:   1%|          | 2/345\n[01:46<4:11:04, 43.92s/it]  ', '\\rOverwrite epoch 4/4:   1%|1         | 5/345\n[01:46<1:10:52, 12.51s/it]', '\\rOverwrite epoch 4/4:   2%|2         | 8/345\n[01:46<34:51,  6.21s/it]  ', '\\rOverwrite epoch 4/4:   3%|3         | 11/345\n[01:47<20:09,  3.62s/it]', '\\rOverwrite epoch 4/4:   4%|4         | 14/345\n[01:47<12:35,  2.28s/it]', '\\rOverwrite epoch 4/4:   5%|4         | 17/345\n[01:47<08:12,  1.50s/it]', '\\rOverwrite epoch 4/4:   6%|5         | 20/345\n[01:47<05:30,  1.02s/it]', '\\rOverwrite epoch 4/4:   7%|6         | 23/345\n[01:47<03:47,  1.42it/s]', '\\rOverwrite epoch 4/4:   8%|7         | 26/345\n[01:47<02:38,  2.01it/s]', '\\rOverwrite epoch 4/4:   8%|8         | 29/345\n[01:47<01:53,  2.79it/s]', '\\rOverwrite epoch 4/4:   9%|9         | 32/345\n[01:48<01:22,  3.82it/s]', '\\rOverwrite epoch 4/4:  10%|#         | 35/345\n[01:48<01:00,  5.10it/s]', '\\rOverwrite epoch 4/4:  11%|#1        | 38/345\n[01:48<00:46,  6.64it/s]', '\\rOverwrite epoch 4/4:  12%|#1        | 41/345\n[01:48<00:36,  8.39it/s]', '\\rOverwrite epoch 4/4:  13%|#2        | 44/345\n[01:48<00:29, 10.26it/s]', '\\rOverwrite epoch 4/4:  14%|#3        | 47/345\n[01:48<00:24, 12.11it/s]', '\\rOverwrite epoch 4/4:  14%|#4        | 50/345\n[01:48<00:21, 13.71it/s]', '\\rOverwrite epoch 4/4:  15%|#5        | 53/345\n[01:49<00:19, 14.88it/s]', '\\rOverwrite epoch 4/4:  16%|#6        | 56/345\n[01:49<00:18, 15.89it/s]', '\\rOverwrite epoch 4/4:  17%|#6        | 58/345\n[01:49<00:17, 16.49it/s]', '\\rOverwrite epoch 4/4:  17%|#7        | 60/345\n[01:49<00:16, 17.01it/s]', '\\rOverwrite epoch 4/4:  18%|#7        | 62/345\n[01:49<00:16, 17.48it/s]', '\\rOverwrite epoch 4/4:  19%|#8        | 64/345\n[01:49<00:15, 17.81it/s]', '\\rOverwrite epoch 4/4:  19%|#9        | 66/345\n[01:49<00:15, 18.14it/s]', '\\rOverwrite epoch 4/4:  20%|#9        | 68/345\n[01:49<00:15, 18.35it/s]', '\\rOverwrite epoch 4/4:  20%|##        | 70/345\n[01:49<00:14, 18.39it/s]', '\\rOverwrite epoch 4/4:  21%|##        | 72/345\n[01:50<00:14, 18.52it/s]', '\\rOverwrite epoch 4/4:  21%|##1       | 74/345\n[01:50<00:14, 18.61it/s]', '\\rOverwrite epoch 4/4:  22%|##2       | 76/345\n[01:50<00:14, 18.65it/s]', '\\rOverwrite epoch 4/4:  23%|##2       | 78/345\n[01:50<00:14, 18.86it/s]', '\\rOverwrite epoch 4/4:  23%|##3       | 81/345\n[01:50<00:13, 19.79it/s]', '\\rOverwrite epoch 4/4:  24%|##4       | 84/345\n[01:50<00:12, 20.52it/s]', '\\rOverwrite epoch 4/4:  25%|##5       | 87/345\n[01:50<00:12, 20.91it/s]', '\\rOverwrite epoch 4/4:  26%|##6       | 90/345\n[01:50<00:12, 21.24it/s]', '\\rOverwrite epoch 4/4:  27%|##6       | 93/345\n[01:51<00:11, 21.18it/s]', '\\rOverwrite epoch 4/4:  28%|##7       | 96/345\n[01:51<00:11, 21.19it/s]', '\\rOverwrite epoch 4/4:  29%|##8       | 99/345\n[01:51<00:11, 21.36it/s]', '\\rOverwrite epoch 4/4:  30%|##9       | 102/345\n[01:51<00:11, 21.47it/s]', '\\rOverwrite epoch 4/4:  30%|###       | 105/345\n[01:51<00:11, 21.58it/s]', '\\rOverwrite epoch 4/4:  31%|###1      | 108/345\n[01:51<00:11, 21.54it/s]', '\\rOverwrite epoch 4/4:  32%|###2      | 111/345\n[01:51<00:10, 21.63it/s]', '\\rOverwrite epoch 4/4:  33%|###3      | 114/345\n[01:52<00:10, 21.66it/s]', '\\rOverwrite epoch 4/4:  34%|###3      | 117/345\n[01:52<00:10, 21.59it/s]', '\\rOverwrite epoch 4/4:  35%|###4      | 120/345\n[01:52<00:10, 21.56it/s]', '\\rOverwrite epoch 4/4:  36%|###5      | 123/345\n[01:52<00:10, 21.63it/s]', '\\rOverwrite epoch 4/4:  37%|###6      | 126/345\n[01:52<00:10, 21.75it/s]', '\\rOverwrite epoch 4/4:  37%|###7      | 129/345\n[01:52<00:09, 21.66it/s]', '\\rOverwrite epoch 4/4:  38%|###8      | 132/345\n[01:52<00:09, 21.68it/s]', '\\rOverwrite epoch 4/4:  39%|###9      | 135/345\n[01:52<00:09, 21.72it/s]', '\\rOverwrite epoch 4/4:  40%|####      | 138/345\n[01:53<00:09, 21.72it/s]', '\\rOverwrite epoch 4/4:  41%|####      | 141/345\n[01:53<00:09, 21.80it/s]', '\\rOverwrite epoch 4/4:  42%|####1     | 144/345\n[01:53<00:09, 21.65it/s]', '\\rOverwrite epoch 4/4:  43%|####2     | 147/345\n[01:53<00:09, 21.60it/s]', '\\rOverwrite epoch 4/4:  43%|####3     | 150/345\n[01:53<00:09, 21.64it/s]', '\\rOverwrite epoch 4/4:  44%|####4     | 153/345\n[01:53<00:08, 21.66it/s]', '\\rOverwrite epoch 4/4:  45%|####5     | 156/345\n[01:53<00:08, 21.69it/s]', '\\rOverwrite epoch 4/4:  46%|####6     | 159/345\n[01:54<00:08, 21.67it/s]', '\\rOverwrite epoch 4/4:  47%|####6     | 162/345\n[01:54<00:08, 21.68it/s]', '\\rOverwrite epoch 4/4:  48%|####7     | 165/345\n[01:54<00:08, 21.40it/s]', '\\rOverwrite epoch 4/4:  49%|####8     | 168/345\n[01:54<00:08, 21.27it/s]', '\\rOverwrite epoch 4/4:  50%|####9     | 171/345\n[01:54<00:08, 21.44it/s]', '\\rOverwrite epoch 4/4:  50%|#####     | 174/345\n[01:54<00:07, 21.53it/s]', '\\rOverwrite epoch 4/4:  51%|#####1    | 177/345\n[01:54<00:07, 21.51it/s]', '\\rOverwrite epoch 4/4:  52%|#####2    | 180/345\n[01:55<00:07, 21.30it/s]', '\\rOverwrite epoch 4/4:  53%|#####3    | 183/345\n[01:55<00:07, 21.42it/s]', '\\rOverwrite epoch 4/4:  54%|#####3    | 186/345\n[01:55<00:07, 21.44it/s]', '\\rOverwrite epoch 4/4:  55%|#####4    | 189/345\n[01:55<00:07, 21.50it/s]', '\\rOverwrite epoch 4/4:  56%|#####5    | 192/345\n[01:55<00:07, 21.55it/s]', '\\rOverwrite epoch 4/4:  57%|#####6    | 195/345\n[01:55<00:06, 21.46it/s]', '\\rOverwrite epoch 4/4:  57%|#####7    | 198/345\n[01:55<00:06, 21.38it/s]', '\\rOverwrite epoch 4/4:  58%|#####8    | 201/345\n[01:56<00:06, 21.38it/s]', '\\rOverwrite epoch 4/4:  59%|#####9    | 204/345\n[01:56<00:06, 21.42it/s]', '\\rOverwrite epoch 4/4:  60%|######    | 207/345\n[01:56<00:06, 21.45it/s]', '\\rOverwrite epoch 4/4:  61%|######    | 210/345\n[01:56<00:06, 21.40it/s]', '\\rOverwrite epoch 4/4:  62%|######1   | 213/345\n[01:56<00:06, 21.29it/s]', '\\rOverwrite epoch 4/4:  63%|######2   | 216/345\n[01:56<00:06, 21.23it/s]', '\\rOverwrite epoch 4/4:  63%|######3   | 219/345\n[01:56<00:05, 21.38it/s]', '\\rOverwrite epoch 4/4:  64%|######4   | 222/345\n[01:57<00:05, 21.33it/s]', '\\rOverwrite epoch 4/4:  65%|######5   | 225/345\n[01:57<00:05, 21.26it/s]', '\\rOverwrite epoch 4/4:  66%|######6   | 228/345\n[01:57<00:05, 21.24it/s]', '\\rOverwrite epoch 4/4:  67%|######6   | 231/345\n[01:57<00:05, 21.28it/s]', '\\rOverwrite epoch 4/4:  68%|######7   | 234/345\n[01:57<00:05, 21.40it/s]', '\\rOverwrite epoch 4/4:  69%|######8   | 237/345\n[01:57<00:05, 21.31it/s]', '\\rOverwrite epoch 4/4:  70%|######9   | 240/345\n[01:57<00:04, 21.28it/s]', '\\rOverwrite epoch 4/4:  70%|#######   | 243/345\n[01:58<00:04, 21.34it/s]', '\\rOverwrite epoch 4/4:  71%|#######1  | 246/345\n[01:58<00:04, 21.38it/s]', '\\rOverwrite epoch 4/4:  72%|#######2  | 249/345\n[01:58<00:04, 21.41it/s]', '\\rOverwrite epoch 4/4:  73%|#######3  | 252/345\n[01:58<00:04, 21.43it/s]', '\\rOverwrite epoch 4/4:  74%|#######3  | 255/345\n[01:58<00:04, 21.30it/s]', '\\rOverwrite epoch 4/4:  75%|#######4  | 258/345\n[01:58<00:04, 21.30it/s]', '\\rOverwrite epoch 4/4:  76%|#######5  | 261/345\n[01:58<00:03, 21.42it/s]', '\\rOverwrite epoch 4/4:  77%|#######6  | 264/345\n[01:58<00:03, 21.49it/s]', '\\rOverwrite epoch 4/4:  77%|#######7  | 267/345\n[01:59<00:03, 21.56it/s]', '\\rOverwrite epoch 4/4:  78%|#######8  | 270/345\n[01:59<00:03, 21.59it/s]', '\\rOverwrite epoch 4/4:  79%|#######9  | 273/345\n[01:59<00:03, 21.33it/s]', '\\rOverwrite epoch 4/4:  80%|########  | 276/345\n[01:59<00:03, 21.32it/s]', '\\rOverwrite epoch 4/4:  81%|########  | 279/345\n[01:59<00:03, 21.32it/s]', '\\rOverwrite epoch 4/4:  82%|########1 | 282/345\n[01:59<00:02, 21.26it/s]', '\\rOverwrite epoch 4/4:  83%|########2 | 285/345\n[01:59<00:02, 21.08it/s]', '\\rOverwrite epoch 4/4:  83%|########3 | 288/345\n[02:00<00:02, 21.09it/s]', '\\rOverwrite epoch 4/4:  84%|########4 | 291/345\n[02:00<00:02, 21.19it/s]', '\\rOverwrite epoch 4/4:  85%|########5 | 294/345\n[02:00<00:02, 21.30it/s]', '\\rOverwrite epoch 4/4:  86%|########6 | 297/345\n[02:00<00:02, 21.38it/s]', '\\rOverwrite epoch 4/4:  87%|########6 | 300/345\n[02:00<00:02, 21.49it/s]', '\\rOverwrite epoch 4/4:  88%|########7 | 303/345\n[02:00<00:01, 21.54it/s]', '\\rOverwrite epoch 4/4:  89%|########8 | 306/345\n[02:00<00:01, 21.52it/s]', '\\rOverwrite epoch 4/4:  90%|########9 | 309/345\n[02:01<00:01, 21.28it/s]', '\\rOverwrite epoch 4/4:  90%|######### | 312/345\n[02:01<00:01, 21.36it/s]', '\\rOverwrite epoch 4/4:  91%|#########1| 315/345\n[02:01<00:01, 21.33it/s]', '\\rOverwrite epoch 4/4:  92%|#########2| 318/345\n[02:01<00:01, 21.15it/s]', '\\rOverwrite epoch 4/4:  93%|#########3| 321/345\n[02:01<00:01, 21.32it/s]', '\\rOverwrite epoch 4/4:  94%|#########3| 324/345\n[02:01<00:00, 21.34it/s]', '\\rOverwrite epoch 4/4:  95%|#########4| 327/345\n[02:01<00:00, 21.22it/s]', '\\rOverwrite epoch 4/4:  96%|#########5| 330/345\n[02:02<00:00, 21.36it/s]', '\\rOverwrite epoch 4/4:  97%|#########6| 333/345\n[02:02<00:00, 21.32it/s]', '\\rOverwrite epoch 4/4:  97%|#########7| 336/345\n[02:02<00:00, 21.35it/s]', '\\rOverwrite epoch 4/4:  98%|#########8| 339/345\n[02:02<00:00, 21.20it/s]', '\\rOverwrite epoch 4/4:  99%|#########9| 342/345\n[02:02<00:00, 21.28it/s]', '\\rOverwrite epoch 4/4: 100%|##########| 345/345\n[02:02<00:00, 22.38it/s]', '', '\\rOverwrite epoch 4/4: 100%|##########| 345/345\n[02:04<00:00,  2.78it/s]', '\\n', 'Epoch 4: validation_loss = 3.7202', '\\n',\n'Experiment complete. Artifacts saved to:', ' ', '/workspace/AE-\nScientist/research_pipeline/workspaces/0-run/process_SpawnProcess-5/working',\n'\\n', 'Execution time: 19 minutes seconds (time limit is 2 hours).']", "['Using device: cuda:0', '\\n', 'Added 5 rare tokens to tokenizer.', '\\n',\n\"Controls: [' apple', ' table', ' water', ' green', ' house']\", '\\n', '\\n=====\nStarting condition: natlang =====', '\\n', '\\rMap:   0%|          | 0/2000\n[00:00<?, ? examples/s]', '', '\\rMap: 100%|##########| 2000/2000 [00:00<00:00,\n35631.61 examples/s]', '\\n', '\\rMap:   0%|          | 0/300 [00:00<?, ?\nexamples/s]', '', '\\rMap: 100%|##########| 300/300 [00:00<00:00, 32714.33\nexamples/s]', '\\n', '\\rTraining natlang_phase1 epoch 1/1:   0%|          | 0/21\n[00:00<?, ?it/s]', '\\rTraining natlang_phase1 epoch 1/1:   5%|4         | 1/21\n[00:49<16:23, 49.20s/it]', '\\rTraining natlang_phase1 epoch 1/1:  10%|9\n| 2/21 [00:49<06:26, 20.33s/it]', '\\rTraining natlang_phase1 epoch 1/1:  14%|#4\n| 3/21 [00:49<03:19, 11.10s/it]', '\\rTraining natlang_phase1 epoch 1/1:  19%|#9\n| 4/21 [00:49<01:54,  6.76s/it]', '\\rTraining natlang_phase1 epoch 1/1:  24%|##3\n| 5/21 [00:49<01:09,  4.36s/it]', '\\rTraining natlang_phase1 epoch 1/1:  29%|##8\n| 6/21 [00:49<00:43,  2.92s/it]', '\\rTraining natlang_phase1 epoch 1/1:\n33%|###3      | 7/21 [00:49<00:28,  2.00s/it]', '\\rTraining natlang_phase1 epoch\n1/1:  38%|###8      | 8/21 [00:50<00:18,  1.40s/it]', '\\rTraining natlang_phase1\nepoch 1/1:  43%|####2     | 9/21 [00:50<00:11,  1.00it/s]', '\\rTraining\nnatlang_phase1 epoch 1/1:  48%|####7     | 10/21 [00:50<00:08,  1.37it/s]',\n'\\rTraining natlang_phase1 epoch 1/1:  52%|#####2    | 11/21 [00:50<00:05,\n1.85it/s]', '\\rTraining natlang_phase1 epoch 1/1:  57%|#####7    | 12/21\n[00:50<00:03,  2.43it/s]', '\\rTraining natlang_phase1 epoch 1/1:  62%|######1\n| 13/21 [00:50<00:02,  3.11it/s]', '\\rTraining natlang_phase1 epoch 1/1:\n67%|######6   | 14/21 [00:50<00:01,  3.86it/s]', '\\rTraining natlang_phase1\nepoch 1/1:  71%|#######1  | 15/21 [00:50<00:01,  4.64it/s]', '\\rTraining\nnatlang_phase1 epoch 1/1:  76%|#######6  | 16/21 [00:50<00:00,  5.40it/s]',\n'\\rTraining natlang_phase1 epoch 1/1:  81%|########  | 17/21 [00:51<00:00,\n6.08it/s]', '\\rTraining natlang_phase1 epoch 1/1:  86%|########5 | 18/21\n[00:51<00:00,  6.69it/s]', '\\rTraining natlang_phase1 epoch 1/1:  90%|#########\n| 19/21 [00:51<00:00,  7.18it/s]', '\\rTraining natlang_phase1 epoch 1/1:\n95%|#########5| 20/21 [00:51<00:00,  7.57it/s]', '', '\\rTraining natlang_phase1\nepoch 1/1: 100%|##########| 21/21 [00:52<00:00,  2.51s/it]', '\\n', 'Epoch 1:\nvalidation_loss = 3.2644', '\\n', '\\rOverwrite (natlang) epoch 1/4:   0%|\n| 0/345 [00:00<?, ?it/s]', '\\rOverwrite (natlang) epoch 1/4:   0%|          |\n1/345 [00:48<4:35:37, 48.07s/it]', '\\rOverwrite (natlang) epoch 1/4:   1%|\n| 3/345 [00:48<1:11:19, 12.51s/it]', '\\rOverwrite (natlang) epoch 1/4:   2%|1\n| 6/345 [00:48<27:28,  4.86s/it]  ', '\\rOverwrite (natlang) epoch 1/4:   3%|2\n| 9/345 [00:48<14:38,  2.61s/it]', '\\rOverwrite (natlang) epoch 1/4:   3%|3\n| 12/345 [00:48<08:48,  1.59s/it]', '\\rOverwrite (natlang) epoch 1/4:   4%|4\n| 15/345 [00:48<05:38,  1.03s/it]', '\\rOverwrite (natlang) epoch 1/4:   5%|5\n| 18/345 [00:48<03:45,  1.45it/s]', '\\rOverwrite (natlang) epoch 1/4:   6%|6\n| 21/345 [00:49<02:35,  2.08it/s]', '\\rOverwrite (natlang) epoch 1/4:   7%|6\n| 24/345 [00:49<01:49,  2.93it/s]', '\\rOverwrite (natlang) epoch 1/4:   8%|7\n| 27/345 [00:49<01:19,  4.01it/s]', '\\rOverwrite (natlang) epoch 1/4:   9%|8\n| 30/345 [00:49<00:58,  5.36it/s]', '\\rOverwrite (natlang) epoch 1/4:  10%|9\n| 33/345 [00:49<00:44,  6.97it/s]', '\\rOverwrite (natlang) epoch 1/4:  10%|#\n| 36/345 [00:49<00:35,  8.78it/s]', '\\rOverwrite (natlang) epoch 1/4:  11%|#1\n| 39/345 [00:49<00:28, 10.67it/s]', '\\rOverwrite (natlang) epoch 1/4:  12%|#2\n| 42/345 [00:50<00:24, 12.61it/s]', '\\rOverwrite (natlang) epoch 1/4:  13%|#3\n| 45/345 [00:50<00:20, 14.40it/s]', '\\rOverwrite (natlang) epoch 1/4:  14%|#3\n| 48/345 [00:50<00:18, 16.03it/s]', '\\rOverwrite (natlang) epoch 1/4:  15%|#4\n| 51/345 [00:50<00:16, 17.40it/s]', '\\rOverwrite (natlang) epoch 1/4:  16%|#5\n| 54/345 [00:50<00:15, 18.49it/s]', '\\rOverwrite (natlang) epoch 1/4:  17%|#6\n| 57/345 [00:50<00:14, 19.37it/s]', '\\rOverwrite (natlang) epoch 1/4:  17%|#7\n| 60/345 [00:50<00:14, 19.91it/s]', '\\rOverwrite (natlang) epoch 1/4:  18%|#8\n| 63/345 [00:50<00:13, 20.22it/s]', '\\rOverwrite (natlang) epoch 1/4:  19%|#9\n| 66/345 [00:51<00:13, 20.62it/s]', '\\rOverwrite (natlang) epoch 1/4:  20%|##\n| 69/345 [00:51<00:13, 20.94it/s]', '\\rOverwrite (natlang) epoch 1/4:  21%|##\n| 72/345 [00:51<00:12, 21.16it/s]', '\\rOverwrite (natlang) epoch 1/4:  22%|##1\n| 75/345 [00:51<00:12, 21.19it/s]', '\\rOverwrite (natlang) epoch 1/4:  23%|##2\n| 78/345 [00:51<00:12, 21.38it/s]', '\\rOverwrite (natlang) epoch 1/4:  23%|##3\n| 81/345 [00:51<00:12, 21.47it/s]', '\\rOverwrite (natlang) epoch 1/4:  24%|##4\n| 84/345 [00:51<00:12, 21.22it/s]', '\\rOverwrite (natlang) epoch 1/4:  25%|##5\n| 87/345 [00:52<00:12, 21.36it/s]', '\\rOverwrite (natlang) epoch 1/4:  26%|##6\n| 90/345 [00:52<00:11, 21.41it/s]', '\\rOverwrite (natlang) epoch 1/4:  27%|##6\n| 93/345 [00:52<00:11, 21.37it/s]', '\\rOverwrite (natlang) epoch 1/4:  28%|##7\n| 96/345 [00:52<00:11, 21.44it/s]', '\\rOverwrite (natlang) epoch 1/4:  29%|##8\n| 99/345 [00:52<00:11, 21.50it/s]', '\\rOverwrite (natlang) epoch 1/4:  30%|##9\n| 102/345 [00:52<00:11, 21.59it/s]', '\\rOverwrite (natlang) epoch 1/4:  30%|###\n| 105/345 [00:52<00:11, 21.63it/s]', '\\rOverwrite (natlang) epoch 1/4:  31%|###1\n| 108/345 [00:53<00:10, 21.69it/s]', '\\rOverwrite (natlang) epoch 1/4:  32%|###2\n| 111/345 [00:53<00:10, 21.66it/s]', '\\rOverwrite (natlang) epoch 1/4:  33%|###3\n| 114/345 [00:53<00:10, 21.34it/s]', '\\rOverwrite (natlang) epoch 1/4:  34%|###3\n| 117/345 [00:53<00:10, 21.44it/s]', '\\rOverwrite (natlang) epoch 1/4:  35%|###4\n| 120/345 [00:53<00:10, 21.27it/s]', '\\rOverwrite (natlang) epoch 1/4:  36%|###5\n| 123/345 [00:53<00:10, 21.26it/s]', '\\rOverwrite (natlang) epoch 1/4:  37%|###6\n| 126/345 [00:53<00:10, 21.38it/s]', '\\rOverwrite (natlang) epoch 1/4:  37%|###7\n| 129/345 [00:54<00:10, 21.48it/s]', '\\rOverwrite (natlang) epoch 1/4:  38%|###8\n| 132/345 [00:54<00:09, 21.47it/s]', '\\rOverwrite (natlang) epoch 1/4:  39%|###9\n| 135/345 [00:54<00:09, 21.58it/s]', '\\rOverwrite (natlang) epoch 1/4:  40%|####\n| 138/345 [00:54<00:09, 21.61it/s]', '\\rOverwrite (natlang) epoch 1/4:  41%|####\n| 141/345 [00:54<00:09, 21.50it/s]', '\\rOverwrite (natlang) epoch 1/4:\n42%|####1     | 144/345 [00:54<00:09, 21.35it/s]', '\\rOverwrite (natlang) epoch\n1/4:  43%|####2     | 147/345 [00:54<00:09, 21.43it/s]', '\\rOverwrite (natlang)\nepoch 1/4:  43%|####3     | 150/345 [00:55<00:09, 21.49it/s]', '\\rOverwrite\n(natlang) epoch 1/4:  44%|####4     | 153/345 [00:55<00:08, 21.58it/s]',\n'\\rOverwrite (natlang) epoch 1/4:  45%|####5     | 156/345 [00:55<00:08,\n21.66it/s]', '\\rOverwrite (natlang) epoch 1/4:  46%|####6     | 159/345\n[00:55<00:08, 21.73it/s]', '\\rOverwrite (natlang) epoch 1/4:  47%|####6     |\n162/345 [00:55<00:08, 21.75it/s]', '\\rOverwrite (natlang) epoch 1/4:  48%|####7\n| 165/345 [00:55<00:08, 21.74it/s]', '\\rOverwrite (natlang) epoch 1/4:\n49%|####8     | 168/345 [00:55<00:08, 21.76it/s]', '\\rOverwrite (natlang) epoch\n1/4:  50%|####9     | 171/345 [00:56<00:07, 21.77it/s]', '\\rOverwrite (natlang)\nepoch 1/4:  50%|#####     | 174/345 [00:56<00:07, 21.73it/s]', '\\rOverwrite\n(natlang) epoch 1/4:  51%|#####1    | 177/345 [00:56<00:07, 21.80it/s]',\n'\\rOverwrite (natlang) epoch 1/4:  52%|#####2    | 180/345 [00:56<00:07,\n21.82it/s]', '\\rOverwrite (natlang) epoch 1/4:  53%|#####3    | 183/345\n[00:56<00:07, 21.80it/s]', '\\rOverwrite (natlang) epoch 1/4:  54%|#####3    |\n186/345 [00:56<00:07, 21.83it/s]', '\\rOverwrite (natlang) epoch 1/4:  55%|#####4\n| 189/345 [00:56<00:07, 21.83it/s]', '\\rOverwrite (natlang) epoch 1/4:\n56%|#####5    | 192/345 [00:56<00:07, 21.85it/s]', '\\rOverwrite (natlang) epoch\n1/4:  57%|#####6    | 195/345 [00:57<00:06, 21.86it/s]', '\\rOverwrite (natlang)\nepoch 1/4:  57%|#####7    | 198/345 [00:57<00:06, 21.85it/s]', '[2025-12-04\n00:30:43] Overwrite (natlang) step 200: avg_train_loss=3.8526', '\\n',\n'\\rOverwrite (natlang) epoch 1/4:  58%|#####8    | 201/345 [00:57<00:06,\n21.55it/s]', '\\rOverwrite (natlang) epoch 1/4:  59%|#####9    | 204/345\n[00:57<00:06, 21.39it/s]', '\\rOverwrite (natlang) epoch 1/4:  60%|######    |\n207/345 [00:57<00:06, 21.38it/s]', '\\rOverwrite (natlang) epoch 1/4:  61%|######\n| 210/345 [00:57<00:06, 21.37it/s]', '\\rOverwrite (natlang) epoch 1/4:\n62%|######1   | 213/345 [00:57<00:06, 21.33it/s]', '\\rOverwrite (natlang) epoch\n1/4:  63%|######2   | 216/345 [00:58<00:06, 21.44it/s]', '\\rOverwrite (natlang)\nepoch 1/4:  63%|######3   | 219/345 [00:58<00:05, 21.57it/s]', '\\rOverwrite\n(natlang) epoch 1/4:  64%|######4   | 222/345 [00:58<00:05, 21.63it/s]',\n'\\rOverwrite (natlang) epoch 1/4:  65%|######5   | 225/345 [00:58<00:05,\n21.36it/s]', '\\rOverwrite (natlang) epoch 1/4:  66%|######6   | 228/345\n[00:58<00:05, 21.09it/s]', '\\rOverwrite (natlang) epoch 1/4:  67%|######6   |\n231/345 [00:58<00:05, 21.21it/s]', '\\rOverwrite (natlang) epoch 1/4:\n68%|######7   | 234/345 [00:58<00:05, 21.33it/s]', '\\rOverwrite (natlang) epoch\n1/4:  69%|######8   | 237/345 [00:59<00:05, 21.45it/s]', '\\rOverwrite (natlang)\nepoch 1/4:  70%|######9   | 240/345 [00:59<00:04, 21.27it/s]', '\\rOverwrite\n(natlang) epoch 1/4:  70%|#######   | 243/345 [00:59<00:04, 21.43it/s]',\n'\\rOverwrite (natlang) epoch 1/4:  71%|#######1  | 246/345 [00:59<00:04,\n21.29it/s]', '\\rOverwrite (natlang) epoch 1/4:  72%|#######2  | 249/345\n[00:59<00:04, 21.03it/s]', '\\rOverwrite (natlang) epoch 1/4:  73%|#######3  |\n252/345 [00:59<00:04, 21.16it/s]', '\\rOverwrite (natlang) epoch 1/4:\n74%|#######3  | 255/345 [00:59<00:04, 21.23it/s]', '\\rOverwrite (natlang) epoch\n1/4:  75%|#######4  | 258/345 [01:00<00:04, 21.31it/s]', '\\rOverwrite (natlang)\nepoch 1/4:  76%|#######5  | 261/345 [01:00<00:03, 21.39it/s]', '\\rOverwrite\n(natlang) epoch 1/4:  77%|#######6  | 264/345 [01:00<00:03, 21.41it/s]',\n'\\rOverwrite (natlang) epoch 1/4:  77%|#######7  | 267/345 [01:00<00:03,\n21.45it/s]', '\\rOverwrite (natlang) epoch 1/4:  78%|#######8  | 270/345\n[01:00<00:03, 21.46it/s]', '\\rOverwrite (natlang) epoch 1/4:  79%|#######9  |\n273/345 [01:00<00:03, 21.48it/s]', '\\rOverwrite (natlang) epoch 1/4:\n80%|########  | 276/345 [01:00<00:03, 21.48it/s]', '\\rOverwrite (natlang) epoch\n1/4:  81%|########  | 279/345 [01:01<00:03, 21.46it/s]', '\\rOverwrite (natlang)\nepoch 1/4:  82%|########1 | 282/345 [01:01<00:02, 21.35it/s]', '\\rOverwrite\n(natlang) epoch 1/4:  83%|########2 | 285/345 [01:01<00:02, 21.40it/s]',\n'\\rOverwrite (natlang) epoch 1/4:  83%|########3 | 288/345 [01:01<00:02,\n21.47it/s]', '\\rOverwrite (natlang) epoch 1/4:  84%|########4 | 291/345\n[01:01<00:02, 20.99it/s]', '\\rOverwrite (natlang) epoch 1/4:  85%|########5 |\n294/345 [01:01<00:02, 21.12it/s]', '\\rOverwrite (natlang) epoch 1/4:\n86%|########6 | 297/345 [01:01<00:02, 21.23it/s]', '\\rOverwrite (natlang) epoch\n1/4:  87%|########6 | 300/345 [01:02<00:02, 21.28it/s]', '\\rOverwrite (natlang)\nepoch 1/4:  88%|########7 | 303/345 [01:02<00:01, 21.37it/s]', '\\rOverwrite\n(natlang) epoch 1/4:  89%|########8 | 306/345 [01:02<00:01, 21.45it/s]',\n'\\rOverwrite (natlang) epoch 1/4:  90%|########9 | 309/345 [01:02<00:01,\n21.47it/s]', '\\rOverwrite (natlang) epoch 1/4:  90%|######### | 312/345\n[01:02<00:01, 21.56it/s]', '\\rOverwrite (natlang) epoch 1/4:  91%|#########1|\n315/345 [01:02<00:01, 21.59it/s]', '\\rOverwrite (natlang) epoch 1/4:\n92%|#########2| 318/345 [01:02<00:01, 21.62it/s]', '\\rOverwrite (natlang) epoch\n1/4:  93%|#########3| 321/345 [01:02<00:01, 21.64it/s]', '\\rOverwrite (natlang)\nepoch 1/4:  94%|#########3| 324/345 [01:03<00:00, 21.67it/s]', '\\rOverwrite\n(natlang) epoch 1/4:  95%|#########4| 327/345 [01:03<00:00, 21.69it/s]',\n'\\rOverwrite (natlang) epoch 1/4:  96%|#########5| 330/345 [01:03<00:00,\n21.71it/s]', '\\rOverwrite (natlang) epoch 1/4:  97%|#########6| 333/345\n[01:03<00:00, 21.71it/s]', '\\rOverwrite (natlang) epoch 1/4:  97%|#########7|\n336/345 [01:03<00:00, 21.75it/s]', '\\rOverwrite (natlang) epoch 1/4:\n98%|#########8| 339/345 [01:03<00:00, 21.78it/s]', '\\rOverwrite (natlang) epoch\n1/4:  99%|#########9| 342/345 [01:03<00:00, 21.76it/s]', '\\rOverwrite (natlang)\nepoch 1/4: 100%|##########| 345/345 [01:04<00:00, 22.61it/s]', '', '\\rOverwrite\n(natlang) epoch 1/4: 100%|##########| 345/345 [01:04<00:00,  5.31it/s]', '\\n',\n'Epoch 1 (natlang): validation_loss = 3.6204', '\\n', '\\rOverwrite (natlang)\nepoch 2/4:   0%|          | 0/345 [00:00<?, ?it/s]', '\\rOverwrite (natlang)\nepoch 2/4:   0%|          | 1/345 [01:02<5:57:50, 62.41s/it]', '\\rOverwrite\n(natlang) epoch 2/4:   1%|          | 3/345 [01:02<1:32:30, 16.23s/it]',\n'\\rOverwrite (natlang) epoch 2/4:   2%|1         | 6/345 [01:02<35:36,\n6.30s/it]  ', '\\rOverwrite (natlang) epoch 2/4:   3%|2         | 9/345\n[01:02<18:55,  3.38s/it]', '\\rOverwrite (natlang) epoch 2/4:   3%|3         |\n12/345 [01:02<11:21,  2.05s/it]', '\\rOverwrite (natlang) epoch 2/4:   4%|4\n| 15/345 [01:03<07:15,  1.32s/it]', '\\rOverwrite (natlang) epoch 2/4:   5%|5\n| 18/345 [01:03<04:48,  1.13it/s]', '\\rOverwrite (natlang) epoch 2/4:   6%|6\n| 21/345 [01:03<03:17,  1.64it/s]', '\\rOverwrite (natlang) epoch 2/4:   7%|6\n| 24/345 [01:03<02:17,  2.33it/s]', '\\rOverwrite (natlang) epoch 2/4:   8%|7\n| 27/345 [01:03<01:38,  3.23it/s]', '\\rOverwrite (natlang) epoch 2/4:   9%|8\n| 30/345 [01:03<01:11,  4.38it/s]', '\\rOverwrite (natlang) epoch 2/4:  10%|9\n| 33/345 [01:03<00:53,  5.79it/s]', '\\rOverwrite (natlang) epoch 2/4:  10%|#\n| 36/345 [01:04<00:41,  7.44it/s]', '\\rOverwrite (natlang) epoch 2/4:  11%|#1\n| 39/345 [01:04<00:32,  9.30it/s]', '\\rOverwrite (natlang) epoch 2/4:  12%|#2\n| 42/345 [01:04<00:26, 11.24it/s]', '\\rOverwrite (natlang) epoch 2/4:  13%|#3\n| 45/345 [01:04<00:22, 13.16it/s]', '\\rOverwrite (natlang) epoch 2/4:  14%|#3\n| 48/345 [01:04<00:19, 14.86it/s]', '\\rOverwrite (natlang) epoch 2/4:  15%|#4\n| 51/345 [01:04<00:17, 16.43it/s]', '\\rOverwrite (natlang) epoch 2/4:  16%|#5\n| 54/345 [01:04<00:16, 17.71it/s]', '[2025-12-04 00:33:34] Overwrite (natlang)\nstep 400: avg_train_loss=3.3586', '\\n', '\\rOverwrite (natlang) epoch 2/4:\n17%|#6        | 57/345 [01:05<00:15, 18.74it/s]', '\\rOverwrite (natlang) epoch\n2/4:  17%|#7        | 60/345 [01:05<00:14, 19.60it/s]', '\\rOverwrite (natlang)\nepoch 2/4:  18%|#8        | 63/345 [01:05<00:13, 20.17it/s]', '\\rOverwrite\n(natlang) epoch 2/4:  19%|#9        | 66/345 [01:05<00:13, 20.58it/s]',\n'\\rOverwrite (natlang) epoch 2/4:  20%|##        | 69/345 [01:05<00:13,\n20.91it/s]', '\\rOverwrite (natlang) epoch 2/4:  21%|##        | 72/345\n[01:05<00:12, 21.07it/s]', '\\rOverwrite (natlang) epoch 2/4:  22%|##1       |\n75/345 [01:05<00:12, 20.90it/s]', '\\rOverwrite (natlang) epoch 2/4:  23%|##2\n| 78/345 [01:06<00:12, 20.85it/s]', '\\rOverwrite (natlang) epoch 2/4:  23%|##3\n| 81/345 [01:06<00:12, 20.82it/s]', '\\rOverwrite (natlang) epoch 2/4:  24%|##4\n| 84/345 [01:06<00:12, 20.57it/s]', '\\rOverwrite (natlang) epoch 2/4:  25%|##5\n| 87/345 [01:06<00:12, 20.88it/s]', '\\rOverwrite (natlang) epoch 2/4:  26%|##6\n| 90/345 [01:06<00:12, 20.98it/s]', '\\rOverwrite (natlang) epoch 2/4:  27%|##6\n| 93/345 [01:06<00:11, 21.19it/s]', '\\rOverwrite (natlang) epoch 2/4:  28%|##7\n| 96/345 [01:06<00:11, 21.15it/s]', '\\rOverwrite (natlang) epoch 2/4:  29%|##8\n| 99/345 [01:07<00:11, 21.05it/s]', '\\rOverwrite (natlang) epoch 2/4:  30%|##9\n| 102/345 [01:07<00:11, 21.24it/s]', '\\rOverwrite (natlang) epoch 2/4:  30%|###\n| 105/345 [01:07<00:11, 21.42it/s]', '\\rOverwrite (natlang) epoch 2/4:  31%|###1\n| 108/345 [01:07<00:11, 21.30it/s]', '\\rOverwrite (natlang) epoch 2/4:  32%|###2\n| 111/345 [01:07<00:10, 21.46it/s]', '\\rOverwrite (natlang) epoch 2/4:  33%|###3\n| 114/345 [01:07<00:10, 21.14it/s]', '\\rOverwrite (natlang) epoch 2/4:  34%|###3\n| 117/345 [01:07<00:10, 21.04it/s]', '\\rOverwrite (natlang) epoch 2/4:  35%|###4\n| 120/345 [01:08<00:10, 21.26it/s]', '\\rOverwrite (natlang) epoch 2/4:  36%|###5\n| 123/345 [01:08<00:10, 21.41it/s]', '\\rOverwrite (natlang) epoch 2/4:  37%|###6\n| 126/345 [01:08<00:10, 21.50it/s]', '\\rOverwrite (natlang) epoch 2/4:  37%|###7\n| 129/345 [01:08<00:10, 21.35it/s]', '\\rOverwrite (natlang) epoch 2/4:  38%|###8\n| 132/345 [01:08<00:09, 21.43it/s]', '\\rOverwrite (natlang) epoch 2/4:  39%|###9\n| 135/345 [01:08<00:09, 21.48it/s]', '\\rOverwrite (natlang) epoch 2/4:  40%|####\n| 138/345 [01:08<00:09, 21.56it/s]', '\\rOverwrite (natlang) epoch 2/4:  41%|####\n| 141/345 [01:08<00:09, 21.48it/s]', '\\rOverwrite (natlang) epoch 2/4:\n42%|####1     | 144/345 [01:09<00:09, 21.38it/s]', '\\rOverwrite (natlang) epoch\n2/4:  43%|####2     | 147/345 [01:09<00:09, 21.48it/s]', '\\rOverwrite (natlang)\nepoch 2/4:  43%|####3     | 150/345 [01:09<00:09, 21.57it/s]', '\\rOverwrite\n(natlang) epoch 2/4:  44%|####4     | 153/345 [01:09<00:08, 21.44it/s]',\n'\\rOverwrite (natlang) epoch 2/4:  45%|####5     | 156/345 [01:09<00:08,\n21.52it/s]', '\\rOverwrite (natlang) epoch 2/4:  46%|####6     | 159/345\n[01:09<00:08, 21.59it/s]', '\\rOverwrite (natlang) epoch 2/4:  47%|####6     |\n162/345 [01:09<00:08, 21.59it/s]', '\\rOverwrite (natlang) epoch 2/4:  48%|####7\n| 165/345 [01:10<00:08, 21.60it/s]', '\\rOverwrite (natlang) epoch 2/4:\n49%|####8     | 168/345 [01:10<00:08, 21.39it/s]', '\\rOverwrite (natlang) epoch\n2/4:  50%|####9     | 171/345 [01:10<00:08, 21.28it/s]', '\\rOverwrite (natlang)\nepoch 2/4:  50%|#####     | 174/345 [01:10<00:08, 21.29it/s]', '\\rOverwrite\n(natlang) epoch 2/4:  51%|#####1    | 177/345 [01:10<00:07, 21.30it/s]',\n'\\rOverwrite (natlang) epoch 2/4:  52%|#####2    | 180/345 [01:10<00:07,\n21.40it/s]', '\\rOverwrite (natlang) epoch 2/4:  53%|#####3    | 183/345\n[01:10<00:07, 21.42it/s]', '\\rOverwrite (natlang) epoch 2/4:  54%|#####3    |\n186/345 [01:11<00:07, 21.49it/s]', '\\rOverwrite (natlang) epoch 2/4:  55%|#####4\n| 189/345 [01:11<00:07, 21.53it/s]', '\\rOverwrite (natlang) epoch 2/4:\n56%|#####5    | 192/345 [01:11<00:07, 21.58it/s]', '\\rOverwrite (natlang) epoch\n2/4:  57%|#####6    | 195/345 [01:11<00:06, 21.62it/s]', '\\rOverwrite (natlang)\nepoch 2/4:  57%|#####7    | 198/345 [01:11<00:06, 21.42it/s]', '\\rOverwrite\n(natlang) epoch 2/4:  58%|#####8    | 201/345 [01:11<00:06, 21.28it/s]',\n'\\rOverwrite (natlang) epoch 2/4:  59%|#####9    | 204/345 [01:11<00:06,\n21.10it/s]', '\\rOverwrite (natlang) epoch 2/4:  60%|######    | 207/345\n[01:12<00:06, 21.01it/s]', '\\rOverwrite (natlang) epoch 2/4:  61%|######    |\n210/345 [01:12<00:06, 20.84it/s]', '\\rOverwrite (natlang) epoch 2/4:\n62%|######1   | 213/345 [01:12<00:06, 21.11it/s]', '\\rOverwrite (natlang) epoch\n2/4:  63%|######2   | 216/345 [01:12<00:06, 21.20it/s]', '\\rOverwrite (natlang)\nepoch 2/4:  63%|######3   | 219/345 [01:12<00:05, 21.10it/s]', '\\rOverwrite\n(natlang) epoch 2/4:  64%|######4   | 222/345 [01:12<00:05, 20.98it/s]',\n'\\rOverwrite (natlang) epoch 2/4:  65%|######5   | 225/345 [01:12<00:05,\n21.05it/s]', '\\rOverwrite (natlang) epoch 2/4:  66%|######6   | 228/345\n[01:13<00:05, 21.16it/s]', '\\rOverwrite (natlang) epoch 2/4:  67%|######6   |\n231/345 [01:13<00:05, 21.17it/s]', '\\rOverwrite (natlang) epoch 2/4:\n68%|######7   | 234/345 [01:13<00:05, 21.29it/s]', '\\rOverwrite (natlang) epoch\n2/4:  69%|######8   | 237/345 [01:13<00:05, 21.33it/s]', '\\rOverwrite (natlang)\nepoch 2/4:  70%|######9   | 240/345 [01:13<00:05, 20.91it/s]', '\\rOverwrite\n(natlang) epoch 2/4:  70%|#######   | 243/345 [01:13<00:04, 21.19it/s]',\n'\\rOverwrite (natlang) epoch 2/4:  71%|#######1  | 246/345 [01:13<00:04,\n21.33it/s]', '\\rOverwrite (natlang) epoch 2/4:  72%|#######2  | 249/345\n[01:14<00:04, 21.50it/s]', '\\rOverwrite (natlang) epoch 2/4:  73%|#######3  |\n252/345 [01:14<00:04, 21.61it/s]', '[2025-12-04 00:33:43] Overwrite (natlang)\nstep 600: avg_train_loss=3.3239', '\\n', '\\rOverwrite (natlang) epoch 2/4:\n74%|#######3  | 255/345 [01:14<00:04, 21.56it/s]', '\\rOverwrite (natlang) epoch\n2/4:  75%|#######4  | 258/345 [01:14<00:04, 21.47it/s]', '\\rOverwrite (natlang)\nepoch 2/4:  76%|#######5  | 261/345 [01:14<00:03, 21.48it/s]', '\\rOverwrite\n(natlang) epoch 2/4:  77%|#######6  | 264/345 [01:14<00:03, 21.30it/s]',\n'\\rOverwrite (natlang) epoch 2/4:  77%|#######7  | 267/345 [01:14<00:03,\n21.46it/s]', '\\rOverwrite (natlang) epoch 2/4:  78%|#######8  | 270/345\n[01:15<00:03, 21.08it/s]', '\\rOverwrite (natlang) epoch 2/4:  79%|#######9  |\n273/345 [01:15<00:03, 21.30it/s]', '\\rOverwrite (natlang) epoch 2/4:\n80%|########  | 276/345 [01:15<00:03, 21.40it/s]', '\\rOverwrite (natlang) epoch\n2/4:  81%|########  | 279/345 [01:15<00:03, 21.39it/s]', '\\rOverwrite (natlang)\nepoch 2/4:  82%|########1 | 282/345 [01:15<00:02, 21.44it/s]', '\\rOverwrite\n(natlang) epoch 2/4:  83%|########2 | 285/345 [01:15<00:02, 21.28it/s]',\n'\\rOverwrite (natlang) epoch 2/4:  83%|########3 | 288/345 [01:15<00:02,\n21.31it/s]', '\\rOverwrite (natlang) epoch 2/4:  84%|########4 | 291/345\n[01:16<00:02, 21.45it/s]', '\\rOverwrite (natlang) epoch 2/4:  85%|########5 |\n294/345 [01:16<00:02, 21.47it/s]', '\\rOverwrite (natlang) epoch 2/4:\n86%|########6 | 297/345 [01:16<00:02, 21.56it/s]', '\\rOverwrite (natlang) epoch\n2/4:  87%|########6 | 300/345 [01:16<00:02, 21.42it/s]', '\\rOverwrite (natlang)\nepoch 2/4:  88%|########7 | 303/345 [01:16<00:01, 21.47it/s]', '\\rOverwrite\n(natlang) epoch 2/4:  89%|########8 | 306/345 [01:16<00:01, 21.29it/s]',\n'\\rOverwrite (natlang) epoch 2/4:  90%|########9 | 309/345 [01:16<00:01,\n21.32it/s]', '\\rOverwrite (natlang) epoch 2/4:  90%|######### | 312/345\n[01:17<00:01, 21.35it/s]', '\\rOverwrite (natlang) epoch 2/4:  91%|#########1|\n315/345 [01:17<00:01, 21.40it/s]', '\\rOverwrite (natlang) epoch 2/4:\n92%|#########2| 318/345 [01:17<00:01, 21.53it/s]', '\\rOverwrite (natlang) epoch\n2/4:  93%|#########3| 321/345 [01:17<00:01, 21.65it/s]', '\\rOverwrite (natlang)\nepoch 2/4:  94%|#########3| 324/345 [01:17<00:00, 21.59it/s]', '\\rOverwrite\n(natlang) epoch 2/4:  95%|#########4| 327/345 [01:17<00:00, 21.53it/s]',\n'\\rOverwrite (natlang) epoch 2/4:  96%|#########5| 330/345 [01:17<00:00,\n21.07it/s]', '\\rOverwrite (natlang) epoch 2/4:  97%|#########6| 333/345\n[01:17<00:00, 21.16it/s]', '\\rOverwrite (natlang) epoch 2/4:  97%|#########7|\n336/345 [01:18<00:00, 21.15it/s]', '\\rOverwrite (natlang) epoch 2/4:\n98%|#########8| 339/345 [01:18<00:00, 21.31it/s]', '\\rOverwrite (natlang) epoch\n2/4:  99%|#########9| 342/345 [01:18<00:00, 21.40it/s]', '\\rOverwrite (natlang)\nepoch 2/4: 100%|##########| 345/345 [01:18<00:00, 22.18it/s]', '', '\\rOverwrite\n(natlang) epoch 2/4: 100%|##########| 345/345 [01:19<00:00,  4.34it/s]', '\\n',\n'Epoch 2 (natlang): validation_loss = 3.6365', '\\n', '\\rOverwrite (natlang)\nepoch 3/4:   0%|          | 0/345 [00:00<?, ?it/s]', '\\rOverwrite (natlang)\nepoch 3/4:   0%|          | 1/345 [00:46<4:27:11, 46.60s/it]', '\\rOverwrite\n(natlang) epoch 3/4:   1%|          | 2/345 [00:46<1:50:03, 19.25s/it]',\n'\\rOverwrite (natlang) epoch 3/4:   1%|1         | 5/345 [00:46<31:10,\n5.50s/it]  ', '\\rOverwrite (natlang) epoch 3/4:   2%|2         | 8/345\n[00:46<15:24,  2.74s/it]', '\\rOverwrite (natlang) epoch 3/4:   3%|3         |\n11/345 [00:47<08:58,  1.61s/it]', '\\rOverwrite (natlang) epoch 3/4:   4%|4\n| 14/345 [00:47<05:39,  1.03s/it]', '\\rOverwrite (natlang) epoch 3/4:   5%|4\n| 17/345 [00:47<03:44,  1.46it/s]', '\\rOverwrite (natlang) epoch 3/4:   6%|5\n| 20/345 [00:47<02:33,  2.12it/s]', '\\rOverwrite (natlang) epoch 3/4:   7%|6\n| 23/345 [00:47<01:47,  2.99it/s]', '\\rOverwrite (natlang) epoch 3/4:   8%|7\n| 26/345 [00:47<01:17,  4.11it/s]', '\\rOverwrite (natlang) epoch 3/4:   8%|8\n| 29/345 [00:47<00:57,  5.49it/s]', '\\rOverwrite (natlang) epoch 3/4:   9%|9\n| 32/345 [00:48<00:43,  7.13it/s]', '\\rOverwrite (natlang) epoch 3/4:  10%|#\n| 35/345 [00:48<00:34,  8.97it/s]', '\\rOverwrite (natlang) epoch 3/4:  11%|#1\n| 38/345 [00:48<00:28, 10.92it/s]', '\\rOverwrite (natlang) epoch 3/4:  12%|#1\n| 41/345 [00:48<00:23, 12.86it/s]', '\\rOverwrite (natlang) epoch 3/4:  13%|#2\n| 44/345 [00:48<00:20, 14.67it/s]', '\\rOverwrite (natlang) epoch 3/4:  14%|#3\n| 47/345 [00:48<00:18, 16.28it/s]', '\\rOverwrite (natlang) epoch 3/4:  14%|#4\n| 50/345 [00:48<00:16, 17.62it/s]', '\\rOverwrite (natlang) epoch 3/4:  15%|#5\n| 53/345 [00:49<00:15, 18.64it/s]', '\\rOverwrite (natlang) epoch 3/4:  16%|#6\n| 56/345 [00:49<00:14, 19.45it/s]', '\\rOverwrite (natlang) epoch 3/4:  17%|#7\n| 59/345 [00:49<00:14, 20.10it/s]', '\\rOverwrite (natlang) epoch 3/4:  18%|#7\n| 62/345 [00:49<00:13, 20.56it/s]', '\\rOverwrite (natlang) epoch 3/4:  19%|#8\n| 65/345 [00:49<00:13, 20.92it/s]', '\\rOverwrite (natlang) epoch 3/4:  20%|#9\n| 68/345 [00:49<00:13, 21.17it/s]', '\\rOverwrite (natlang) epoch 3/4:  21%|##\n| 71/345 [00:49<00:12, 21.36it/s]', '\\rOverwrite (natlang) epoch 3/4:  21%|##1\n| 74/345 [00:50<00:12, 21.50it/s]', '\\rOverwrite (natlang) epoch 3/4:  22%|##2\n| 77/345 [00:50<00:12, 21.55it/s]', '\\rOverwrite (natlang) epoch 3/4:  23%|##3\n| 80/345 [00:50<00:12, 21.57it/s]', '\\rOverwrite (natlang) epoch 3/4:  24%|##4\n| 83/345 [00:50<00:12, 21.58it/s]', '\\rOverwrite (natlang) epoch 3/4:  25%|##4\n| 86/345 [00:50<00:12, 21.54it/s]', '\\rOverwrite (natlang) epoch 3/4:  26%|##5\n| 89/345 [00:50<00:11, 21.51it/s]', '\\rOverwrite (natlang) epoch 3/4:  27%|##6\n| 92/345 [00:50<00:11, 21.51it/s]', '\\rOverwrite (natlang) epoch 3/4:  28%|##7\n| 95/345 [00:50<00:11, 21.51it/s]', '\\rOverwrite (natlang) epoch 3/4:  28%|##8\n| 98/345 [00:51<00:11, 21.54it/s]', '\\rOverwrite (natlang) epoch 3/4:  29%|##9\n| 101/345 [00:51<00:11, 21.52it/s]', '\\rOverwrite (natlang) epoch 3/4:  30%|###\n| 104/345 [00:51<00:11, 21.63it/s]', '\\rOverwrite (natlang) epoch 3/4:  31%|###1\n| 107/345 [00:51<00:10, 21.68it/s]', '[2025-12-04 00:35:34] Overwrite (natlang)\nstep 800: avg_train_loss=3.0678', '\\n', '\\rOverwrite (natlang) epoch 3/4:\n32%|###1      | 110/345 [00:51<00:10, 21.72it/s]', '\\rOverwrite (natlang) epoch\n3/4:  33%|###2      | 113/345 [00:51<00:10, 21.75it/s]', '\\rOverwrite (natlang)\nepoch 3/4:  34%|###3      | 116/345 [00:51<00:10, 21.83it/s]', '\\rOverwrite\n(natlang) epoch 3/4:  34%|###4      | 119/345 [00:52<00:10, 21.84it/s]',\n'\\rOverwrite (natlang) epoch 3/4:  35%|###5      | 122/345 [00:52<00:10,\n21.82it/s]', '\\rOverwrite (natlang) epoch 3/4:  36%|###6      | 125/345\n[00:52<00:10, 21.84it/s]', '\\rOverwrite (natlang) epoch 3/4:  37%|###7      |\n128/345 [00:52<00:09, 21.87it/s]', '\\rOverwrite (natlang) epoch 3/4:  38%|###7\n| 131/345 [00:52<00:09, 21.88it/s]', '\\rOverwrite (natlang) epoch 3/4:  39%|###8\n| 134/345 [00:52<00:09, 21.88it/s]', '\\rOverwrite (natlang) epoch 3/4:  40%|###9\n| 137/345 [00:52<00:09, 21.85it/s]', '\\rOverwrite (natlang) epoch 3/4:  41%|####\n| 140/345 [00:53<00:09, 21.87it/s]', '\\rOverwrite (natlang) epoch 3/4:\n41%|####1     | 143/345 [00:53<00:09, 21.76it/s]', '\\rOverwrite (natlang) epoch\n3/4:  42%|####2     | 146/345 [00:53<00:09, 21.75it/s]', '\\rOverwrite (natlang)\nepoch 3/4:  43%|####3     | 149/345 [00:53<00:09, 21.66it/s]', '\\rOverwrite\n(natlang) epoch 3/4:  44%|####4     | 152/345 [00:53<00:08, 21.60it/s]',\n'\\rOverwrite (natlang) epoch 3/4:  45%|####4     | 155/345 [00:53<00:08,\n21.61it/s]', '\\rOverwrite (natlang) epoch 3/4:  46%|####5     | 158/345\n[00:53<00:08, 21.59it/s]', '\\rOverwrite (natlang) epoch 3/4:  47%|####6     |\n161/345 [00:54<00:08, 21.60it/s]', '\\rOverwrite (natlang) epoch 3/4:  48%|####7\n| 164/345 [00:54<00:08, 21.59it/s]', '\\rOverwrite (natlang) epoch 3/4:\n48%|####8     | 167/345 [00:54<00:08, 21.60it/s]', '\\rOverwrite (natlang) epoch\n3/4:  49%|####9     | 170/345 [00:54<00:08, 21.54it/s]', '\\rOverwrite (natlang)\nepoch 3/4:  50%|#####     | 173/345 [00:54<00:07, 21.60it/s]', '\\rOverwrite\n(natlang) epoch 3/4:  51%|#####1    | 176/345 [00:54<00:07, 21.68it/s]',\n'\\rOverwrite (natlang) epoch 3/4:  52%|#####1    | 179/345 [00:54<00:07,\n21.71it/s]', '\\rOverwrite (natlang) epoch 3/4:  53%|#####2    | 182/345\n[00:54<00:07, 21.69it/s]', '\\rOverwrite (natlang) epoch 3/4:  54%|#####3    |\n185/345 [00:55<00:07, 21.68it/s]', '\\rOverwrite (natlang) epoch 3/4:  54%|#####4\n| 188/345 [00:55<00:07, 21.66it/s]', '\\rOverwrite (natlang) epoch 3/4:\n55%|#####5    | 191/345 [00:55<00:07, 21.02it/s]', '\\rOverwrite (natlang) epoch\n3/4:  56%|#####6    | 194/345 [00:55<00:07, 20.82it/s]', '\\rOverwrite (natlang)\nepoch 3/4:  57%|#####7    | 197/345 [00:55<00:07, 21.02it/s]', '\\rOverwrite\n(natlang) epoch 3/4:  58%|#####7    | 200/345 [00:55<00:06, 21.17it/s]',\n'\\rOverwrite (natlang) epoch 3/4:  59%|#####8    | 203/345 [00:55<00:06,\n21.26it/s]', '\\rOverwrite (natlang) epoch 3/4:  60%|#####9    | 206/345\n[00:56<00:06, 21.36it/s]', '\\rOverwrite (natlang) epoch 3/4:  61%|######    |\n209/345 [00:56<00:06, 21.45it/s]', '\\rOverwrite (natlang) epoch 3/4:\n61%|######1   | 212/345 [00:56<00:06, 21.49it/s]', '\\rOverwrite (natlang) epoch\n3/4:  62%|######2   | 215/345 [00:56<00:06, 21.48it/s]', '\\rOverwrite (natlang)\nepoch 3/4:  63%|######3   | 218/345 [00:56<00:05, 21.55it/s]', '\\rOverwrite\n(natlang) epoch 3/4:  64%|######4   | 221/345 [00:56<00:05, 21.57it/s]',\n'\\rOverwrite (natlang) epoch 3/4:  65%|######4   | 224/345 [00:56<00:05,\n21.63it/s]', '\\rOverwrite (natlang) epoch 3/4:  66%|######5   | 227/345\n[00:57<00:05, 21.62it/s]', '\\rOverwrite (natlang) epoch 3/4:  67%|######6   |\n230/345 [00:57<00:05, 21.69it/s]', '\\rOverwrite (natlang) epoch 3/4:\n68%|######7   | 233/345 [00:57<00:05, 21.71it/s]', '\\rOverwrite (natlang) epoch\n3/4:  68%|######8   | 236/345 [00:57<00:05, 21.72it/s]', '\\rOverwrite (natlang)\nepoch 3/4:  69%|######9   | 239/345 [00:57<00:04, 21.72it/s]', '\\rOverwrite\n(natlang) epoch 3/4:  70%|#######   | 242/345 [00:57<00:04, 21.69it/s]',\n'\\rOverwrite (natlang) epoch 3/4:  71%|#######1  | 245/345 [00:57<00:04,\n21.69it/s]', '\\rOverwrite (natlang) epoch 3/4:  72%|#######1  | 248/345\n[00:58<00:04, 21.70it/s]', '\\rOverwrite (natlang) epoch 3/4:  73%|#######2  |\n251/345 [00:58<00:04, 21.70it/s]', '\\rOverwrite (natlang) epoch 3/4:\n74%|#######3  | 254/345 [00:58<00:04, 21.74it/s]', '\\rOverwrite (natlang) epoch\n3/4:  74%|#######4  | 257/345 [00:58<00:04, 21.67it/s]', '\\rOverwrite (natlang)\nepoch 3/4:  75%|#######5  | 260/345 [00:58<00:03, 21.65it/s]', '\\rOverwrite\n(natlang) epoch 3/4:  76%|#######6  | 263/345 [00:58<00:03, 21.71it/s]',\n'\\rOverwrite (natlang) epoch 3/4:  77%|#######7  | 266/345 [00:58<00:03,\n21.74it/s]', '\\rOverwrite (natlang) epoch 3/4:  78%|#######7  | 269/345\n[00:59<00:03, 21.75it/s]', '\\rOverwrite (natlang) epoch 3/4:  79%|#######8  |\n272/345 [00:59<00:03, 21.72it/s]', '\\rOverwrite (natlang) epoch 3/4:\n80%|#######9  | 275/345 [00:59<00:03, 21.73it/s]', '\\rOverwrite (natlang) epoch\n3/4:  81%|########  | 278/345 [00:59<00:03, 21.66it/s]', '\\rOverwrite (natlang)\nepoch 3/4:  81%|########1 | 281/345 [00:59<00:02, 21.72it/s]', '\\rOverwrite\n(natlang) epoch 3/4:  82%|########2 | 284/345 [00:59<00:02, 21.74it/s]',\n'\\rOverwrite (natlang) epoch 3/4:  83%|########3 | 287/345 [00:59<00:02,\n21.65it/s]', '\\rOverwrite (natlang) epoch 3/4:  84%|########4 | 290/345\n[01:00<00:02, 21.52it/s]', '\\rOverwrite (natlang) epoch 3/4:  85%|########4 |\n293/345 [01:00<00:02, 21.53it/s]', '\\rOverwrite (natlang) epoch 3/4:\n86%|########5 | 296/345 [01:00<00:02, 21.59it/s]', '\\rOverwrite (natlang) epoch\n3/4:  87%|########6 | 299/345 [01:00<00:02, 21.67it/s]', '\\rOverwrite (natlang)\nepoch 3/4:  88%|########7 | 302/345 [01:00<00:01, 21.58it/s]', '\\rOverwrite\n(natlang) epoch 3/4:  88%|########8 | 305/345 [01:00<00:01, 21.62it/s]',\n'\\rOverwrite (natlang) epoch 3/4:  89%|########9 | 308/345 [01:00<00:01,\n21.71it/s]', '[2025-12-04 00:35:43] Overwrite (natlang) step 1000:\navg_train_loss=3.0776', '\\n', '\\rOverwrite (natlang) epoch 3/4:  90%|######### |\n311/345 [01:00<00:01, 21.78it/s]', '\\rOverwrite (natlang) epoch 3/4:\n91%|#########1| 314/345 [01:01<00:01, 21.81it/s]', '\\rOverwrite (natlang) epoch\n3/4:  92%|#########1| 317/345 [01:01<00:01, 21.83it/s]', '\\rOverwrite (natlang)\nepoch 3/4:  93%|#########2| 320/345 [01:01<00:01, 21.85it/s]', '\\rOverwrite\n(natlang) epoch 3/4:  94%|#########3| 323/345 [01:01<00:01, 21.85it/s]',\n'\\rOverwrite (natlang) epoch 3/4:  94%|#########4| 326/345 [01:01<00:00,\n21.78it/s]', '\\rOverwrite (natlang) epoch 3/4:  95%|#########5| 329/345\n[01:01<00:00, 21.82it/s]', '\\rOverwrite (natlang) epoch 3/4:  96%|#########6|\n332/345 [01:01<00:00, 21.75it/s]', '\\rOverwrite (natlang) epoch 3/4:\n97%|#########7| 335/345 [01:02<00:00, 21.78it/s]', '\\rOverwrite (natlang) epoch\n3/4:  98%|#########7| 338/345 [01:02<00:00, 21.83it/s]', '\\rOverwrite (natlang)\nepoch 3/4:  99%|#########8| 341/345 [01:02<00:00, 21.73it/s]', '\\rOverwrite\n(natlang) epoch 3/4: 100%|#########9| 344/345 [01:02<00:00, 21.89it/s]', '',\n'\\rOverwrite (natlang) epoch 3/4: 100%|##########| 345/345 [01:03<00:00,\n5.44it/s]', '\\n', 'Epoch 3 (natlang): validation_loss = 3.6799', '\\n',\n'\\rOverwrite (natlang) epoch 4/4:   0%|          | 0/345 [00:00<?, ?it/s]',\n'\\rOverwrite (natlang) epoch 4/4:   0%|          | 1/345 [00:45<4:18:50,\n45.15s/it]', '\\rOverwrite (natlang) epoch 4/4:   1%|          | 3/345\n[00:45<1:07:00, 11.76s/it]', '\\rOverwrite (natlang) epoch 4/4:   2%|1         |\n6/345 [00:45<25:49,  4.57s/it]  ', '\\rOverwrite (natlang) epoch 4/4:   3%|2\n| 9/345 [00:45<13:45,  2.46s/it]', '\\rOverwrite (natlang) epoch 4/4:   3%|3\n| 12/345 [00:45<08:17,  1.49s/it]', '\\rOverwrite (natlang) epoch 4/4:   4%|4\n| 15/345 [00:45<05:19,  1.03it/s]', '\\rOverwrite (natlang) epoch 4/4:   5%|5\n| 18/345 [00:45<03:33,  1.53it/s]', '\\rOverwrite (natlang) epoch 4/4:   6%|6\n| 21/345 [00:46<02:26,  2.20it/s]', '\\rOverwrite (natlang) epoch 4/4:   7%|6\n| 24/345 [00:46<01:43,  3.09it/s]', '\\rOverwrite (natlang) epoch 4/4:   8%|7\n| 27/345 [00:46<01:15,  4.22it/s]', '\\rOverwrite (natlang) epoch 4/4:   9%|8\n| 30/345 [00:46<00:56,  5.62it/s]', '\\rOverwrite (natlang) epoch 4/4:  10%|9\n| 33/345 [00:46<00:42,  7.27it/s]', '\\rOverwrite (natlang) epoch 4/4:  10%|#\n| 36/345 [00:46<00:33,  9.11it/s]', '\\rOverwrite (natlang) epoch 4/4:  11%|#1\n| 39/345 [00:46<00:27, 11.06it/s]', '\\rOverwrite (natlang) epoch 4/4:  12%|#2\n| 42/345 [00:47<00:23, 12.96it/s]', '\\rOverwrite (natlang) epoch 4/4:  13%|#3\n| 45/345 [00:47<00:20, 14.70it/s]', '\\rOverwrite (natlang) epoch 4/4:  14%|#3\n| 48/345 [00:47<00:18, 16.26it/s]', '\\rOverwrite (natlang) epoch 4/4:  15%|#4\n| 51/345 [00:47<00:16, 17.60it/s]', '\\rOverwrite (natlang) epoch 4/4:  16%|#5\n| 54/345 [00:47<00:15, 18.52it/s]', '\\rOverwrite (natlang) epoch 4/4:  17%|#6\n| 57/345 [00:47<00:14, 19.41it/s]', '\\rOverwrite (natlang) epoch 4/4:  17%|#7\n| 60/345 [00:47<00:14, 20.08it/s]', '\\rOverwrite (natlang) epoch 4/4:  18%|#8\n| 63/345 [00:48<00:13, 20.57it/s]', '\\rOverwrite (natlang) epoch 4/4:  19%|#9\n| 66/345 [00:48<00:13, 20.89it/s]', '\\rOverwrite (natlang) epoch 4/4:  20%|##\n| 69/345 [00:48<00:13, 21.15it/s]', '\\rOverwrite (natlang) epoch 4/4:  21%|##\n| 72/345 [00:48<00:12, 21.31it/s]', '\\rOverwrite (natlang) epoch 4/4:  22%|##1\n| 75/345 [00:48<00:12, 21.41it/s]', '\\rOverwrite (natlang) epoch 4/4:  23%|##2\n| 78/345 [00:48<00:12, 21.50it/s]', '\\rOverwrite (natlang) epoch 4/4:  23%|##3\n| 81/345 [00:48<00:12, 21.58it/s]', '\\rOverwrite (natlang) epoch 4/4:  24%|##4\n| 84/345 [00:49<00:12, 21.66it/s]', '\\rOverwrite (natlang) epoch 4/4:  25%|##5\n| 87/345 [00:49<00:11, 21.65it/s]', '\\rOverwrite (natlang) epoch 4/4:  26%|##6\n| 90/345 [00:49<00:11, 21.67it/s]', '\\rOverwrite (natlang) epoch 4/4:  27%|##6\n| 93/345 [00:49<00:11, 21.71it/s]', '\\rOverwrite (natlang) epoch 4/4:  28%|##7\n| 96/345 [00:49<00:11, 21.34it/s]', '\\rOverwrite (natlang) epoch 4/4:  29%|##8\n| 99/345 [00:49<00:11, 21.39it/s]', '\\rOverwrite (natlang) epoch 4/4:  30%|##9\n| 102/345 [00:49<00:11, 21.50it/s]', '\\rOverwrite (natlang) epoch 4/4:  30%|###\n| 105/345 [00:50<00:11, 21.58it/s]', '\\rOverwrite (natlang) epoch 4/4:  31%|###1\n| 108/345 [00:50<00:10, 21.63it/s]', '\\rOverwrite (natlang) epoch 4/4:  32%|###2\n| 111/345 [00:50<00:10, 21.60it/s]', '\\rOverwrite (natlang) epoch 4/4:  33%|###3\n| 114/345 [00:50<00:10, 21.54it/s]', '\\rOverwrite (natlang) epoch 4/4:  34%|###3\n| 117/345 [00:50<00:10, 21.59it/s]', '\\rOverwrite (natlang) epoch 4/4:  35%|###4\n| 120/345 [00:50<00:10, 21.66it/s]', '\\rOverwrite (natlang) epoch 4/4:  36%|###5\n| 123/345 [00:50<00:10, 21.72it/s]', '\\rOverwrite (natlang) epoch 4/4:  37%|###6\n| 126/345 [00:50<00:10, 21.75it/s]', '\\rOverwrite (natlang) epoch 4/4:  37%|###7\n| 129/345 [00:51<00:09, 21.75it/s]', '\\rOverwrite (natlang) epoch 4/4:  38%|###8\n| 132/345 [00:51<00:09, 21.75it/s]', '\\rOverwrite (natlang) epoch 4/4:  39%|###9\n| 135/345 [00:51<00:09, 21.75it/s]', '\\rOverwrite (natlang) epoch 4/4:  40%|####\n| 138/345 [00:51<00:09, 21.75it/s]', '\\rOverwrite (natlang) epoch 4/4:  41%|####\n| 141/345 [00:51<00:09, 21.76it/s]', '\\rOverwrite (natlang) epoch 4/4:\n42%|####1     | 144/345 [00:51<00:09, 21.74it/s]', '\\rOverwrite (natlang) epoch\n4/4:  43%|####2     | 147/345 [00:51<00:09, 21.71it/s]', '\\rOverwrite (natlang)\nepoch 4/4:  43%|####3     | 150/345 [00:52<00:09, 21.39it/s]', '\\rOverwrite\n(natlang) epoch 4/4:  44%|####4     | 153/345 [00:52<00:08, 21.47it/s]',\n'\\rOverwrite (natlang) epoch 4/4:  45%|####5     | 156/345 [00:52<00:08,\n21.54it/s]', '\\rOverwrite (natlang) epoch 4/4:  46%|####6     | 159/345\n[00:52<00:08, 21.61it/s]', '\\rOverwrite (natlang) epoch 4/4:  47%|####6     |\n162/345 [00:52<00:08, 21.54it/s]', '[2025-12-04 00:37:28] Overwrite (natlang)\nstep 1200: avg_train_loss=2.8714', '\\n', '\\rOverwrite (natlang) epoch 4/4:\n48%|####7     | 165/345 [00:52<00:08, 21.18it/s]', '\\rOverwrite (natlang) epoch\n4/4:  49%|####8     | 168/345 [00:52<00:08, 21.16it/s]', '\\rOverwrite (natlang)\nepoch 4/4:  50%|####9     | 171/345 [00:53<00:08, 21.36it/s]', '\\rOverwrite\n(natlang) epoch 4/4:  50%|#####     | 174/345 [00:53<00:07, 21.48it/s]',\n'\\rOverwrite (natlang) epoch 4/4:  51%|#####1    | 177/345 [00:53<00:07,\n21.52it/s]', '\\rOverwrite (natlang) epoch 4/4:  52%|#####2    | 180/345\n[00:53<00:07, 21.58it/s]', '\\rOverwrite (natlang) epoch 4/4:  53%|#####3    |\n183/345 [00:53<00:07, 21.63it/s]', '\\rOverwrite (natlang) epoch 4/4:  54%|#####3\n| 186/345 [00:53<00:07, 21.37it/s]', '\\rOverwrite (natlang) epoch 4/4:\n55%|#####4    | 189/345 [00:53<00:07, 21.39it/s]', '\\rOverwrite (natlang) epoch\n4/4:  56%|#####5    | 192/345 [00:54<00:07, 21.51it/s]', '\\rOverwrite (natlang)\nepoch 4/4:  57%|#####6    | 195/345 [00:54<00:06, 21.56it/s]', '\\rOverwrite\n(natlang) epoch 4/4:  57%|#####7    | 198/345 [00:54<00:06, 21.62it/s]',\n'\\rOverwrite (natlang) epoch 4/4:  58%|#####8    | 201/345 [00:54<00:06,\n21.54it/s]', '\\rOverwrite (natlang) epoch 4/4:  59%|#####9    | 204/345\n[00:54<00:06, 21.59it/s]', '\\rOverwrite (natlang) epoch 4/4:  60%|######    |\n207/345 [00:54<00:06, 21.64it/s]', '\\rOverwrite (natlang) epoch 4/4:  61%|######\n| 210/345 [00:54<00:06, 21.61it/s]', '\\rOverwrite (natlang) epoch 4/4:\n62%|######1   | 213/345 [00:55<00:06, 21.64it/s]', '\\rOverwrite (natlang) epoch\n4/4:  63%|######2   | 216/345 [00:55<00:05, 21.65it/s]', '\\rOverwrite (natlang)\nepoch 4/4:  63%|######3   | 219/345 [00:55<00:05, 21.67it/s]', '\\rOverwrite\n(natlang) epoch 4/4:  64%|######4   | 222/345 [00:55<00:05, 21.66it/s]',\n'\\rOverwrite (natlang) epoch 4/4:  65%|######5   | 225/345 [00:55<00:05,\n21.72it/s]', '\\rOverwrite (natlang) epoch 4/4:  66%|######6   | 228/345\n[00:55<00:05, 21.73it/s]', '\\rOverwrite (natlang) epoch 4/4:  67%|######6   |\n231/345 [00:55<00:05, 21.70it/s]', '\\rOverwrite (natlang) epoch 4/4:\n68%|######7   | 234/345 [00:55<00:05, 21.71it/s]', '\\rOverwrite (natlang) epoch\n4/4:  69%|######8   | 237/345 [00:56<00:05, 21.51it/s]', '\\rOverwrite (natlang)\nepoch 4/4:  70%|######9   | 240/345 [00:56<00:04, 21.52it/s]', '\\rOverwrite\n(natlang) epoch 4/4:  70%|#######   | 243/345 [00:56<00:04, 21.53it/s]',\n'\\rOverwrite (natlang) epoch 4/4:  71%|#######1  | 246/345 [00:56<00:04,\n21.52it/s]', '\\rOverwrite (natlang) epoch 4/4:  72%|#######2  | 249/345\n[00:56<00:04, 21.60it/s]', '\\rOverwrite (natlang) epoch 4/4:  73%|#######3  |\n252/345 [00:56<00:04, 21.64it/s]', '\\rOverwrite (natlang) epoch 4/4:\n74%|#######3  | 255/345 [00:56<00:04, 21.67it/s]', '\\rOverwrite (natlang) epoch\n4/4:  75%|#######4  | 258/345 [00:57<00:04, 21.69it/s]', '\\rOverwrite (natlang)\nepoch 4/4:  76%|#######5  | 261/345 [00:57<00:03, 21.73it/s]', '\\rOverwrite\n(natlang) epoch 4/4:  77%|#######6  | 264/345 [00:57<00:03, 21.73it/s]',\n'\\rOverwrite (natlang) epoch 4/4:  77%|#######7  | 267/345 [00:57<00:03,\n21.71it/s]', '\\rOverwrite (natlang) epoch 4/4:  78%|#######8  | 270/345\n[00:57<00:03, 21.73it/s]', '\\rOverwrite (natlang) epoch 4/4:  79%|#######9  |\n273/345 [00:57<00:03, 21.71it/s]', '\\rOverwrite (natlang) epoch 4/4:\n80%|########  | 276/345 [00:57<00:03, 21.75it/s]', '\\rOverwrite (natlang) epoch\n4/4:  81%|########  | 279/345 [00:58<00:03, 21.78it/s]', '\\rOverwrite (natlang)\nepoch 4/4:  82%|########1 | 282/345 [00:58<00:02, 21.80it/s]', '\\rOverwrite\n(natlang) epoch 4/4:  83%|########2 | 285/345 [00:58<00:02, 21.82it/s]',\n'\\rOverwrite (natlang) epoch 4/4:  83%|########3 | 288/345 [00:58<00:02,\n21.80it/s]', '\\rOverwrite (natlang) epoch 4/4:  84%|########4 | 291/345\n[00:58<00:02, 21.80it/s]', '\\rOverwrite (natlang) epoch 4/4:  85%|########5 |\n294/345 [00:58<00:02, 21.80it/s]', '\\rOverwrite (natlang) epoch 4/4:\n86%|########6 | 297/345 [00:58<00:02, 21.80it/s]', '\\rOverwrite (natlang) epoch\n4/4:  87%|########6 | 300/345 [00:59<00:02, 21.78it/s]', '\\rOverwrite (natlang)\nepoch 4/4:  88%|########7 | 303/345 [00:59<00:01, 21.76it/s]', '\\rOverwrite\n(natlang) epoch 4/4:  89%|########8 | 306/345 [00:59<00:01, 21.73it/s]',\n'\\rOverwrite (natlang) epoch 4/4:  90%|########9 | 309/345 [00:59<00:01,\n21.76it/s]', '\\rOverwrite (natlang) epoch 4/4:  90%|######### | 312/345\n[00:59<00:01, 21.77it/s]', '\\rOverwrite (natlang) epoch 4/4:  91%|#########1|\n315/345 [00:59<00:01, 21.77it/s]', '\\rOverwrite (natlang) epoch 4/4:\n92%|#########2| 318/345 [00:59<00:01, 21.74it/s]', '\\rOverwrite (natlang) epoch\n4/4:  93%|#########3| 321/345 [00:59<00:01, 21.66it/s]', '\\rOverwrite (natlang)\nepoch 4/4:  94%|#########3| 324/345 [01:00<00:00, 21.61it/s]', '\\rOverwrite\n(natlang) epoch 4/4:  95%|#########4| 327/345 [01:00<00:00, 21.58it/s]',\n'\\rOverwrite (natlang) epoch 4/4:  96%|#########5| 330/345 [01:00<00:00,\n21.58it/s]', '\\rOverwrite (natlang) epoch 4/4:  97%|#########6| 333/345\n[01:00<00:00, 21.55it/s]', '\\rOverwrite (natlang) epoch 4/4:  97%|#########7|\n336/345 [01:00<00:00, 21.54it/s]', '\\rOverwrite (natlang) epoch 4/4:\n98%|#########8| 339/345 [01:00<00:00, 21.54it/s]', '\\rOverwrite (natlang) epoch\n4/4:  99%|#########9| 342/345 [01:00<00:00, 21.56it/s]', '\\rOverwrite (natlang)\nepoch 4/4: 100%|##########| 345/345 [01:01<00:00, 22.59it/s]', '', '\\rOverwrite\n(natlang) epoch 4/4: 100%|##########| 345/345 [01:02<00:00,  5.56it/s]', '\\n',\n'Epoch 4 (natlang): validation_loss = 3.7260', '\\n', '\\n===== Starting\ncondition: code_style =====', '\\n', '\\rMap:   0%|          | 0/2000 [00:00<?, ?\nexamples/s]', '', '\\rMap: 100%|##########| 2000/2000 [00:00<00:00, 39358.56\nexamples/s]', '\\n', '\\rMap:   0%|          | 0/300 [00:00<?, ? examples/s]', '',\n'\\rMap: 100%|##########| 300/300 [00:00<00:00, 17536.18 examples/s]', '\\n',\n'\\rTraining code_style_phase1 epoch 1/1:   0%|          | 0/21 [00:00<?,\n?it/s]', '\\rTraining code_style_phase1 epoch 1/1:   5%|4         | 1/21\n[00:44<14:51, 44.56s/it]', '\\rTraining code_style_phase1 epoch 1/1:  10%|9\n| 2/21 [00:44<05:49, 18.41s/it]', '\\rTraining code_style_phase1 epoch 1/1:\n14%|#4        | 3/21 [00:44<03:01, 10.06s/it]', '\\rTraining code_style_phase1\nepoch 1/1:  19%|#9        | 4/21 [00:44<01:44,  6.13s/it]', '\\rTraining\ncode_style_phase1 epoch 1/1:  24%|##3       | 5/21 [00:45<01:03,  3.96s/it]',\n'\\rTraining code_style_phase1 epoch 1/1:  29%|##8       | 6/21 [00:45<00:39,\n2.65s/it]', '\\rTraining code_style_phase1 epoch 1/1:  33%|###3      | 7/21\n[00:45<00:25,  1.82s/it]', '\\rTraining code_style_phase1 epoch 1/1:  38%|###8\n| 8/21 [00:45<00:16,  1.28s/it]', '\\rTraining code_style_phase1 epoch 1/1:\n43%|####2     | 9/21 [00:45<00:10,  1.09it/s]', '\\rTraining code_style_phase1\nepoch 1/1:  48%|####7     | 10/21 [00:45<00:07,  1.50it/s]', '\\rTraining\ncode_style_phase1 epoch 1/1:  52%|#####2    | 11/21 [00:45<00:05,  2.00it/s]',\n'\\rTraining code_style_phase1 epoch 1/1:  57%|#####7    | 12/21 [00:45<00:03,\n2.61it/s]', '\\rTraining code_style_phase1 epoch 1/1:  62%|######1   | 13/21\n[00:45<00:02,  3.31it/s]', '\\rTraining code_style_phase1 epoch 1/1:  67%|######6\n| 14/21 [00:46<00:01,  4.07it/s]', '\\rTraining code_style_phase1 epoch 1/1:\n71%|#######1  | 15/21 [00:46<00:01,  4.84it/s]', '\\rTraining code_style_phase1\nepoch 1/1:  76%|#######6  | 16/21 [00:46<00:00,  5.58it/s]', '\\rTraining\ncode_style_phase1 epoch 1/1:  81%|########  | 17/21 [00:46<00:00,  6.25it/s]',\n'\\rTraining code_style_phase1 epoch 1/1:  86%|########5 | 18/21 [00:46<00:00,\n6.83it/s]', '\\rTraining code_style_phase1 epoch 1/1:  90%|######### | 19/21\n[00:46<00:00,  7.31it/s]', '\\rTraining code_style_phase1 epoch 1/1:\n95%|#########5| 20/21 [00:46<00:00,  7.68it/s]', '', '\\rTraining\ncode_style_phase1 epoch 1/1: 100%|##########| 21/21 [00:47<00:00,  2.28s/it]',\n'\\n', 'Epoch 1: validation_loss = 2.5158', '\\n', '\\rOverwrite (code_style) epoch\n1/4:   0%|          | 0/345 [00:00<?, ?it/s]', '\\rOverwrite (code_style) epoch\n1/4:   0%|          | 1/345 [00:44<4:16:01, 44.66s/it]', '\\rOverwrite\n(code_style) epoch 1/4:   1%|          | 3/345 [00:44<1:06:16, 11.63s/it]',\n'\\rOverwrite (code_style) epoch 1/4:   2%|1         | 6/345 [00:44<25:33,\n4.52s/it]  ', '\\rOverwrite (code_style) epoch 1/4:   3%|2         | 9/345\n[00:45<13:37,  2.43s/it]', '\\rOverwrite (code_style) epoch 1/4:   3%|3         |\n12/345 [00:45<08:11,  1.48s/it]', '\\rOverwrite (code_style) epoch 1/4:   4%|4\n| 15/345 [00:45<05:16,  1.04it/s]', '\\rOverwrite (code_style) epoch 1/4:   5%|5\n| 18/345 [00:45<03:31,  1.55it/s]', '\\rOverwrite (code_style) epoch 1/4:   6%|6\n| 21/345 [00:45<02:25,  2.22it/s]', '\\rOverwrite (code_style) epoch 1/4:   7%|6\n| 24/345 [00:45<01:42,  3.12it/s]', '\\rOverwrite (code_style) epoch 1/4:   8%|7\n| 27/345 [00:45<01:14,  4.26it/s]', '\\rOverwrite (code_style) epoch 1/4:   9%|8\n| 30/345 [00:46<00:55,  5.66it/s]', '\\rOverwrite (code_style) epoch 1/4:  10%|9\n| 33/345 [00:46<00:42,  7.28it/s]', '\\rOverwrite (code_style) epoch 1/4:  10%|#\n| 36/345 [00:46<00:34,  9.04it/s]', '\\rOverwrite (code_style) epoch 1/4:  11%|#1\n| 39/345 [00:46<00:27, 10.97it/s]', '\\rOverwrite (code_style) epoch 1/4:  12%|#2\n| 42/345 [00:46<00:23, 12.87it/s]', '\\rOverwrite (code_style) epoch 1/4:  13%|#3\n| 45/345 [00:46<00:20, 14.64it/s]', '\\rOverwrite (code_style) epoch 1/4:  14%|#3\n| 48/345 [00:46<00:18, 16.20it/s]', '\\rOverwrite (code_style) epoch 1/4:  15%|#4\n| 51/345 [00:47<00:17, 17.01it/s]', '\\rOverwrite (code_style) epoch 1/4:  16%|#5\n| 54/345 [00:47<00:15, 18.21it/s]', '\\rOverwrite (code_style) epoch 1/4:  17%|#6\n| 57/345 [00:47<00:15, 19.05it/s]', '\\rOverwrite (code_style) epoch 1/4:  17%|#7\n| 60/345 [00:47<00:14, 19.75it/s]', '\\rOverwrite (code_style) epoch 1/4:  18%|#8\n| 63/345 [00:47<00:13, 20.31it/s]', '\\rOverwrite (code_style) epoch 1/4:  19%|#9\n| 66/345 [00:47<00:13, 20.61it/s]', '\\rOverwrite (code_style) epoch 1/4:  20%|##\n| 69/345 [00:47<00:13, 20.78it/s]', '\\rOverwrite (code_style) epoch 1/4:  21%|##\n| 72/345 [00:48<00:13, 20.94it/s]', '\\rOverwrite (code_style) epoch 1/4:\n22%|##1       | 75/345 [00:48<00:12, 21.17it/s]', '\\rOverwrite (code_style)\nepoch 1/4:  23%|##2       | 78/345 [00:48<00:12, 21.34it/s]', '\\rOverwrite\n(code_style) epoch 1/4:  23%|##3       | 81/345 [00:48<00:12, 21.46it/s]',\n'\\rOverwrite (code_style) epoch 1/4:  24%|##4       | 84/345 [00:48<00:12,\n21.43it/s]', '\\rOverwrite (code_style) epoch 1/4:  25%|##5       | 87/345\n[00:48<00:12, 21.49it/s]', '\\rOverwrite (code_style) epoch 1/4:  26%|##6       |\n90/345 [00:48<00:11, 21.46it/s]', '\\rOverwrite (code_style) epoch 1/4:  27%|##6\n| 93/345 [00:49<00:11, 21.48it/s]', '\\rOverwrite (code_style) epoch 1/4:\n28%|##7       | 96/345 [00:49<00:11, 21.32it/s]', '\\rOverwrite (code_style)\nepoch 1/4:  29%|##8       | 99/345 [00:49<00:11, 21.23it/s]', '\\rOverwrite\n(code_style) epoch 1/4:  30%|##9       | 102/345 [00:49<00:11, 21.32it/s]',\n'\\rOverwrite (code_style) epoch 1/4:  30%|###       | 105/345 [00:49<00:11,\n21.43it/s]', '\\rOverwrite (code_style) epoch 1/4:  31%|###1      | 108/345\n[00:49<00:11, 21.54it/s]', '\\rOverwrite (code_style) epoch 1/4:  32%|###2      |\n111/345 [00:49<00:10, 21.36it/s]', '\\rOverwrite (code_style) epoch 1/4:\n33%|###3      | 114/345 [00:50<00:11, 20.83it/s]', '\\rOverwrite (code_style)\nepoch 1/4:  34%|###3      | 117/345 [00:50<00:10, 20.83it/s]', '\\rOverwrite\n(code_style) epoch 1/4:  35%|###4      | 120/345 [00:50<00:10, 20.94it/s]',\n'\\rOverwrite (code_style) epoch 1/4:  36%|###5      | 123/345 [00:50<00:10,\n20.77it/s]', '\\rOverwrite (code_style) epoch 1/4:  37%|###6      | 126/345\n[00:50<00:10, 21.01it/s]', '\\rOverwrite (code_style) epoch 1/4:  37%|###7      |\n129/345 [00:50<00:10, 21.05it/s]', '\\rOverwrite (code_style) epoch 1/4:\n38%|###8      | 132/345 [00:50<00:10, 21.24it/s]', '\\rOverwrite (code_style)\nepoch 1/4:  39%|###9      | 135/345 [00:50<00:09, 21.38it/s]', '\\rOverwrite\n(code_style) epoch 1/4:  40%|####      | 138/345 [00:51<00:09, 21.44it/s]',\n'\\rOverwrite (code_style) epoch 1/4:  41%|####      | 141/345 [00:51<00:09,\n21.36it/s]', '\\rOverwrite (code_style) epoch 1/4:  42%|####1     | 144/345\n[00:51<00:09, 21.45it/s]', '\\rOverwrite (code_style) epoch 1/4:  43%|####2     |\n147/345 [00:51<00:09, 21.44it/s]', '\\rOverwrite (code_style) epoch 1/4:\n43%|####3     | 150/345 [00:51<00:09, 21.36it/s]', '\\rOverwrite (code_style)\nepoch 1/4:  44%|####4     | 153/345 [00:51<00:09, 20.65it/s]', '\\rOverwrite\n(code_style) epoch 1/4:  45%|####5     | 156/345 [00:52<00:09, 20.47it/s]',\n'\\rOverwrite (code_style) epoch 1/4:  46%|####6     | 159/345 [00:52<00:09,\n20.42it/s]', '\\rOverwrite (code_style) epoch 1/4:  47%|####6     | 162/345\n[00:52<00:08, 20.53it/s]', '\\rOverwrite (code_style) epoch 1/4:  48%|####7     |\n165/345 [00:52<00:08, 20.55it/s]', '\\rOverwrite (code_style) epoch 1/4:\n49%|####8     | 168/345 [00:52<00:08, 20.76it/s]', '\\rOverwrite (code_style)\nepoch 1/4:  50%|####9     | 171/345 [00:52<00:08, 21.00it/s]', '\\rOverwrite\n(code_style) epoch 1/4:  50%|#####     | 174/345 [00:52<00:08, 21.13it/s]',\n'\\rOverwrite (code_style) epoch 1/4:  51%|#####1    | 177/345 [00:53<00:07,\n21.17it/s]', '\\rOverwrite (code_style) epoch 1/4:  52%|#####2    | 180/345\n[00:53<00:07, 21.15it/s]', '\\rOverwrite (code_style) epoch 1/4:  53%|#####3    |\n183/345 [00:53<00:07, 21.07it/s]', '\\rOverwrite (code_style) epoch 1/4:\n54%|#####3    | 186/345 [00:53<00:07, 21.21it/s]', '\\rOverwrite (code_style)\nepoch 1/4:  55%|#####4    | 189/345 [00:53<00:07, 21.31it/s]', '\\rOverwrite\n(code_style) epoch 1/4:  56%|#####5    | 192/345 [00:53<00:07, 21.43it/s]',\n'\\rOverwrite (code_style) epoch 1/4:  57%|#####6    | 195/345 [00:53<00:07,\n21.29it/s]', '\\rOverwrite (code_style) epoch 1/4:  57%|#####7    | 198/345\n[00:53<00:06, 21.32it/s]', '[2025-12-04 00:41:08] Overwrite (code_style) step\n200: avg_train_loss=3.8265', '\\n', '\\rOverwrite (code_style) epoch 1/4:\n58%|#####8    | 201/345 [00:54<00:06, 21.40it/s]', '\\rOverwrite (code_style)\nepoch 1/4:  59%|#####9    | 204/345 [00:54<00:06, 21.43it/s]', '\\rOverwrite\n(code_style) epoch 1/4:  60%|######    | 207/345 [00:54<00:06, 21.47it/s]',\n'\\rOverwrite (code_style) epoch 1/4:  61%|######    | 210/345 [00:54<00:06,\n21.39it/s]', '\\rOverwrite (code_style) epoch 1/4:  62%|######1   | 213/345\n[00:54<00:06, 21.36it/s]', '\\rOverwrite (code_style) epoch 1/4:  63%|######2   |\n216/345 [00:54<00:06, 21.43it/s]', '\\rOverwrite (code_style) epoch 1/4:\n63%|######3   | 219/345 [00:54<00:05, 21.44it/s]', '\\rOverwrite (code_style)\nepoch 1/4:  64%|######4   | 222/345 [00:55<00:05, 21.42it/s]', '\\rOverwrite\n(code_style) epoch 1/4:  65%|######5   | 225/345 [00:55<00:05, 21.18it/s]',\n'\\rOverwrite (code_style) epoch 1/4:  66%|######6   | 228/345 [00:55<00:05,\n21.20it/s]', '\\rOverwrite (code_style) epoch 1/4:  67%|######6   | 231/345\n[00:55<00:05, 21.35it/s]', '\\rOverwrite (code_style) epoch 1/4:  68%|######7   |\n234/345 [00:55<00:05, 21.41it/s]', '\\rOverwrite (code_style) epoch 1/4:\n69%|######8   | 237/345 [00:55<00:05, 21.37it/s]', '\\rOverwrite (code_style)\nepoch 1/4:  70%|######9   | 240/345 [00:55<00:04, 21.30it/s]', '\\rOverwrite\n(code_style) epoch 1/4:  70%|#######   | 243/345 [00:56<00:04, 21.30it/s]',\n'\\rOverwrite (code_style) epoch 1/4:  71%|#######1  | 246/345 [00:56<00:04,\n21.35it/s]', '\\rOverwrite (code_style) epoch 1/4:  72%|#######2  | 249/345\n[00:56<00:04, 21.41it/s]', '\\rOverwrite (code_style) epoch 1/4:  73%|#######3  |\n252/345 [00:56<00:04, 21.14it/s]', '\\rOverwrite (code_style) epoch 1/4:\n74%|#######3  | 255/345 [00:56<00:04, 21.15it/s]', '\\rOverwrite (code_style)\nepoch 1/4:  75%|#######4  | 258/345 [00:56<00:04, 21.09it/s]', '\\rOverwrite\n(code_style) epoch 1/4:  76%|#######5  | 261/345 [00:56<00:04, 20.82it/s]',\n'\\rOverwrite (code_style) epoch 1/4:  77%|#######6  | 264/345 [00:57<00:03,\n20.98it/s]', '\\rOverwrite (code_style) epoch 1/4:  77%|#######7  | 267/345\n[00:57<00:03, 20.95it/s]', '\\rOverwrite (code_style) epoch 1/4:  78%|#######8  |\n270/345 [00:57<00:03, 21.13it/s]', '\\rOverwrite (code_style) epoch 1/4:\n79%|#######9  | 273/345 [00:57<00:03, 21.26it/s]', '\\rOverwrite (code_style)\nepoch 1/4:  80%|########  | 276/345 [00:57<00:03, 21.38it/s]', '\\rOverwrite\n(code_style) epoch 1/4:  81%|########  | 279/345 [00:57<00:03, 21.44it/s]',\n'\\rOverwrite (code_style) epoch 1/4:  82%|########1 | 282/345 [00:57<00:02,\n21.53it/s]', '\\rOverwrite (code_style) epoch 1/4:  83%|########2 | 285/345\n[00:58<00:02, 21.55it/s]', '\\rOverwrite (code_style) epoch 1/4:  83%|########3 |\n288/345 [00:58<00:02, 21.61it/s]', '\\rOverwrite (code_style) epoch 1/4:\n84%|########4 | 291/345 [00:58<00:02, 21.38it/s]', '\\rOverwrite (code_style)\nepoch 1/4:  85%|########5 | 294/345 [00:58<00:02, 21.30it/s]', '\\rOverwrite\n(code_style) epoch 1/4:  86%|########6 | 297/345 [00:58<00:02, 21.05it/s]',\n'\\rOverwrite (code_style) epoch 1/4:  87%|########6 | 300/345 [00:58<00:02,\n21.24it/s]', '\\rOverwrite (code_style) epoch 1/4:  88%|########7 | 303/345\n[00:58<00:01, 21.33it/s]', '\\rOverwrite (code_style) epoch 1/4:  89%|########8 |\n306/345 [00:59<00:01, 21.44it/s]', '\\rOverwrite (code_style) epoch 1/4:\n90%|########9 | 309/345 [00:59<00:01, 21.39it/s]', '\\rOverwrite (code_style)\nepoch 1/4:  90%|######### | 312/345 [00:59<00:01, 21.37it/s]', '\\rOverwrite\n(code_style) epoch 1/4:  91%|#########1| 315/345 [00:59<00:01, 21.37it/s]',\n'\\rOverwrite (code_style) epoch 1/4:  92%|#########2| 318/345 [00:59<00:01,\n21.42it/s]', '\\rOverwrite (code_style) epoch 1/4:  93%|#########3| 321/345\n[00:59<00:01, 21.28it/s]', '\\rOverwrite (code_style) epoch 1/4:  94%|#########3|\n324/345 [00:59<00:00, 21.37it/s]', '\\rOverwrite (code_style) epoch 1/4:\n95%|#########4| 327/345 [01:00<00:00, 21.43it/s]', '\\rOverwrite (code_style)\nepoch 1/4:  96%|#########5| 330/345 [01:00<00:00, 21.55it/s]', '\\rOverwrite\n(code_style) epoch 1/4:  97%|#########6| 333/345 [01:00<00:00, 21.59it/s]',\n'\\rOverwrite (code_style) epoch 1/4:  97%|#########7| 336/345 [01:00<00:00,\n21.47it/s]', '\\rOverwrite (code_style) epoch 1/4:  98%|#########8| 339/345\n[01:00<00:00, 21.27it/s]', '\\rOverwrite (code_style) epoch 1/4:  99%|#########9|\n342/345 [01:00<00:00, 21.20it/s]', '\\rOverwrite (code_style) epoch 1/4:\n100%|##########| 345/345 [01:00<00:00, 22.28it/s]', '', '\\rOverwrite\n(code_style) epoch 1/4: 100%|##########| 345/345 [01:01<00:00,  5.58it/s]',\n'\\n', 'Epoch 1 (code_style): validation_loss = 3.6177', '\\n', '\\rOverwrite\n(code_style) epoch 2/4:   0%|          | 0/345 [00:00<?, ?it/s]', '\\rOverwrite\n(code_style) epoch 2/4:   0%|          | 1/345 [01:01<5:49:49, 61.02s/it]',\n'\\rOverwrite (code_style) epoch 2/4:   1%|          | 3/345 [01:01<1:30:26,\n15.87s/it]', '\\rOverwrite (code_style) epoch 2/4:   2%|1         | 6/345\n[01:01<34:48,  6.16s/it]  ', '\\rOverwrite (code_style) epoch 2/4:   3%|2\n| 9/345 [01:01<18:30,  3.31s/it]', '\\rOverwrite (code_style) epoch 2/4:   3%|3\n| 12/345 [01:01<11:06,  2.00s/it]', '\\rOverwrite (code_style) epoch 2/4:   4%|4\n| 15/345 [01:01<07:06,  1.29s/it]', '\\rOverwrite (code_style) epoch 2/4:   5%|4\n| 17/345 [01:01<05:19,  1.03it/s]', '\\rOverwrite (code_style) epoch 2/4:   6%|5\n| 19/345 [01:01<03:56,  1.38it/s]', '\\rOverwrite (code_style) epoch 2/4:   6%|6\n| 21/345 [01:02<02:54,  1.86it/s]', '\\rOverwrite (code_style) epoch 2/4:   7%|6\n| 24/345 [01:02<01:54,  2.81it/s]', '\\rOverwrite (code_style) epoch 2/4:   8%|7\n| 27/345 [01:02<01:19,  4.02it/s]', '\\rOverwrite (code_style) epoch 2/4:   9%|8\n| 30/345 [01:02<00:57,  5.48it/s]', '\\rOverwrite (code_style) epoch 2/4:  10%|9\n| 33/345 [01:02<00:43,  7.18it/s]', '\\rOverwrite (code_style) epoch 2/4:  10%|#\n| 36/345 [01:02<00:33,  9.10it/s]', '\\rOverwrite (code_style) epoch 2/4:  11%|#1\n| 39/345 [01:02<00:27, 11.10it/s]', '\\rOverwrite (code_style) epoch 2/4:  12%|#2\n| 42/345 [01:03<00:23, 13.07it/s]', '\\rOverwrite (code_style) epoch 2/4:  13%|#3\n| 45/345 [01:03<00:20, 14.90it/s]', '\\rOverwrite (code_style) epoch 2/4:  14%|#3\n| 48/345 [01:03<00:18, 16.37it/s]', '\\rOverwrite (code_style) epoch 2/4:  15%|#4\n| 51/345 [01:03<00:16, 17.67it/s]', '\\rOverwrite (code_style) epoch 2/4:  16%|#5\n| 54/345 [01:03<00:15, 18.61it/s]', '[2025-12-04 00:43:12] Overwrite\n(code_style) step 400: avg_train_loss=3.3042', '\\n', '\\rOverwrite (code_style)\nepoch 2/4:  17%|#6        | 57/345 [01:03<00:14, 19.25it/s]', '\\rOverwrite\n(code_style) epoch 2/4:  17%|#7        | 60/345 [01:03<00:14, 19.74it/s]',\n'\\rOverwrite (code_style) epoch 2/4:  18%|#8        | 63/345 [01:04<00:14,\n19.80it/s]', '\\rOverwrite (code_style) epoch 2/4:  19%|#9        | 66/345\n[01:04<00:13, 20.20it/s]', '\\rOverwrite (code_style) epoch 2/4:  20%|##        |\n69/345 [01:04<00:14, 19.71it/s]', '\\rOverwrite (code_style) epoch 2/4:  21%|##\n| 72/345 [01:04<00:13, 20.13it/s]', '\\rOverwrite (code_style) epoch 2/4:\n22%|##1       | 75/345 [01:04<00:13, 20.33it/s]', '\\rOverwrite (code_style)\nepoch 2/4:  23%|##2       | 78/345 [01:04<00:12, 20.56it/s]', '\\rOverwrite\n(code_style) epoch 2/4:  23%|##3       | 81/345 [01:04<00:12, 20.51it/s]',\n'\\rOverwrite (code_style) epoch 2/4:  24%|##4       | 84/345 [01:05<00:12,\n20.83it/s]', '\\rOverwrite (code_style) epoch 2/4:  25%|##5       | 87/345\n[01:05<00:12, 21.02it/s]', '\\rOverwrite (code_style) epoch 2/4:  26%|##6       |\n90/345 [01:05<00:12, 21.15it/s]', '\\rOverwrite (code_style) epoch 2/4:  27%|##6\n| 93/345 [01:05<00:11, 21.36it/s]', '\\rOverwrite (code_style) epoch 2/4:\n28%|##7       | 96/345 [01:05<00:11, 21.41it/s]', '\\rOverwrite (code_style)\nepoch 2/4:  29%|##8       | 99/345 [01:05<00:11, 21.38it/s]', '\\rOverwrite\n(code_style) epoch 2/4:  30%|##9       | 102/345 [01:05<00:11, 21.49it/s]',\n'\\rOverwrite (code_style) epoch 2/4:  30%|###       | 105/345 [01:06<00:11,\n21.33it/s]', '\\rOverwrite (code_style) epoch 2/4:  31%|###1      | 108/345\n[01:06<00:11, 21.45it/s]', '\\rOverwrite (code_style) epoch 2/4:  32%|###2      |\n111/345 [01:06<00:10, 21.41it/s]', '\\rOverwrite (code_style) epoch 2/4:\n33%|###3      | 114/345 [01:06<00:10, 21.45it/s]', '\\rOverwrite (code_style)\nepoch 2/4:  34%|###3      | 117/345 [01:06<00:10, 21.52it/s]', '\\rOverwrite\n(code_style) epoch 2/4:  35%|###4      | 120/345 [01:06<00:10, 21.34it/s]',\n'\\rOverwrite (code_style) epoch 2/4:  36%|###5      | 123/345 [01:06<00:10,\n21.34it/s]', '\\rOverwrite (code_style) epoch 2/4:  37%|###6      | 126/345\n[01:07<00:10, 21.38it/s]', '\\rOverwrite (code_style) epoch 2/4:  37%|###7      |\n129/345 [01:07<00:10, 21.50it/s]', '\\rOverwrite (code_style) epoch 2/4:\n38%|###8      | 132/345 [01:07<00:09, 21.45it/s]', '\\rOverwrite (code_style)\nepoch 2/4:  39%|###9      | 135/345 [01:07<00:09, 21.00it/s]', '\\rOverwrite\n(code_style) epoch 2/4:  40%|####      | 138/345 [01:07<00:09, 21.15it/s]',\n'\\rOverwrite (code_style) epoch 2/4:  41%|####      | 141/345 [01:07<00:09,\n21.33it/s]', '\\rOverwrite (code_style) epoch 2/4:  42%|####1     | 144/345\n[01:07<00:09, 21.34it/s]', '\\rOverwrite (code_style) epoch 2/4:  43%|####2     |\n147/345 [01:07<00:09, 21.48it/s]', '\\rOverwrite (code_style) epoch 2/4:\n43%|####3     | 150/345 [01:08<00:09, 21.16it/s]', '\\rOverwrite (code_style)\nepoch 2/4:  44%|####4     | 153/345 [01:08<00:09, 21.13it/s]', '\\rOverwrite\n(code_style) epoch 2/4:  45%|####5     | 156/345 [01:08<00:09, 20.84it/s]',\n'\\rOverwrite (code_style) epoch 2/4:  46%|####6     | 159/345 [01:08<00:08,\n21.00it/s]', '\\rOverwrite (code_style) epoch 2/4:  47%|####6     | 162/345\n[01:08<00:08, 21.17it/s]', '\\rOverwrite (code_style) epoch 2/4:  48%|####7     |\n165/345 [01:08<00:08, 21.37it/s]', '\\rOverwrite (code_style) epoch 2/4:\n49%|####8     | 168/345 [01:08<00:08, 21.39it/s]', '\\rOverwrite (code_style)\nepoch 2/4:  50%|####9     | 171/345 [01:09<00:08, 21.41it/s]', '\\rOverwrite\n(code_style) epoch 2/4:  50%|#####     | 174/345 [01:09<00:07, 21.53it/s]',\n'\\rOverwrite (code_style) epoch 2/4:  51%|#####1    | 177/345 [01:09<00:07,\n21.55it/s]', '\\rOverwrite (code_style) epoch 2/4:  52%|#####2    | 180/345\n[01:09<00:07, 21.53it/s]', '\\rOverwrite (code_style) epoch 2/4:  53%|#####3    |\n183/345 [01:09<00:07, 21.43it/s]', '\\rOverwrite (code_style) epoch 2/4:\n54%|#####3    | 186/345 [01:09<00:07, 21.35it/s]', '\\rOverwrite (code_style)\nepoch 2/4:  55%|#####4    | 189/345 [01:09<00:07, 21.48it/s]', '\\rOverwrite\n(code_style) epoch 2/4:  56%|#####5    | 192/345 [01:10<00:07, 21.52it/s]',\n'\\rOverwrite (code_style) epoch 2/4:  57%|#####6    | 195/345 [01:10<00:06,\n21.51it/s]', '\\rOverwrite (code_style) epoch 2/4:  57%|#####7    | 198/345\n[01:10<00:06, 21.35it/s]', '\\rOverwrite (code_style) epoch 2/4:  58%|#####8    |\n201/345 [01:10<00:06, 21.22it/s]', '\\rOverwrite (code_style) epoch 2/4:\n59%|#####9    | 204/345 [01:10<00:06, 21.26it/s]', '\\rOverwrite (code_style)\nepoch 2/4:  60%|######    | 207/345 [01:10<00:06, 21.28it/s]', '\\rOverwrite\n(code_style) epoch 2/4:  61%|######    | 210/345 [01:10<00:06, 21.21it/s]',\n'\\rOverwrite (code_style) epoch 2/4:  62%|######1   | 213/345 [01:11<00:06,\n21.19it/s]', '\\rOverwrite (code_style) epoch 2/4:  63%|######2   | 216/345\n[01:11<00:06, 21.28it/s]', '\\rOverwrite (code_style) epoch 2/4:  63%|######3   |\n219/345 [01:11<00:05, 21.10it/s]', '\\rOverwrite (code_style) epoch 2/4:\n64%|######4   | 222/345 [01:11<00:05, 20.82it/s]', '\\rOverwrite (code_style)\nepoch 2/4:  65%|######5   | 225/345 [01:11<00:05, 20.89it/s]', '\\rOverwrite\n(code_style) epoch 2/4:  66%|######6   | 228/345 [01:11<00:05, 20.98it/s]',\n'\\rOverwrite (code_style) epoch 2/4:  67%|######6   | 231/345 [01:11<00:05,\n21.19it/s]', '\\rOverwrite (code_style) epoch 2/4:  68%|######7   | 234/345\n[01:12<00:05, 21.37it/s]', '\\rOverwrite (code_style) epoch 2/4:  69%|######8   |\n237/345 [01:12<00:05, 21.16it/s]', '\\rOverwrite (code_style) epoch 2/4:\n70%|######9   | 240/345 [01:12<00:04, 21.20it/s]', '\\rOverwrite (code_style)\nepoch 2/4:  70%|#######   | 243/345 [01:12<00:04, 21.36it/s]', '\\rOverwrite\n(code_style) epoch 2/4:  71%|#######1  | 246/345 [01:12<00:04, 21.35it/s]',\n'\\rOverwrite (code_style) epoch 2/4:  72%|#######2  | 249/345 [01:12<00:04,\n21.45it/s]', '\\rOverwrite (code_style) epoch 2/4:  73%|#######3  | 252/345\n[01:12<00:04, 21.03it/s]', '[2025-12-04 00:43:21] Overwrite (code_style) step\n600: avg_train_loss=3.3023', '\\n', '\\rOverwrite (code_style) epoch 2/4:\n74%|#######3  | 255/345 [01:13<00:04, 21.11it/s]', '\\rOverwrite (code_style)\nepoch 2/4:  75%|#######4  | 258/345 [01:13<00:04, 20.63it/s]', '\\rOverwrite\n(code_style) epoch 2/4:  76%|#######5  | 261/345 [01:13<00:04, 20.04it/s]',\n'\\rOverwrite (code_style) epoch 2/4:  77%|#######6  | 264/345 [01:13<00:04,\n20.21it/s]', '\\rOverwrite (code_style) epoch 2/4:  77%|#######7  | 267/345\n[01:13<00:03, 20.44it/s]', '\\rOverwrite (code_style) epoch 2/4:  78%|#######8  |\n270/345 [01:13<00:03, 20.47it/s]', '\\rOverwrite (code_style) epoch 2/4:\n79%|#######9  | 273/345 [01:13<00:03, 20.76it/s]', '\\rOverwrite (code_style)\nepoch 2/4:  80%|########  | 276/345 [01:14<00:03, 21.00it/s]', '\\rOverwrite\n(code_style) epoch 2/4:  81%|########  | 279/345 [01:14<00:03, 21.11it/s]',\n'\\rOverwrite (code_style) epoch 2/4:  82%|########1 | 282/345 [01:14<00:02,\n21.07it/s]', '\\rOverwrite (code_style) epoch 2/4:  83%|########2 | 285/345\n[01:14<00:02, 21.11it/s]', '\\rOverwrite (code_style) epoch 2/4:  83%|########3 |\n288/345 [01:14<00:02, 21.23it/s]', '\\rOverwrite (code_style) epoch 2/4:\n84%|########4 | 291/345 [01:14<00:02, 21.12it/s]', '\\rOverwrite (code_style)\nepoch 2/4:  85%|########5 | 294/345 [01:14<00:02, 21.14it/s]', '\\rOverwrite\n(code_style) epoch 2/4:  86%|########6 | 297/345 [01:15<00:02, 21.20it/s]',\n'\\rOverwrite (code_style) epoch 2/4:  87%|########6 | 300/345 [01:15<00:02,\n21.08it/s]', '\\rOverwrite (code_style) epoch 2/4:  88%|########7 | 303/345\n[01:15<00:01, 21.10it/s]', '\\rOverwrite (code_style) epoch 2/4:  89%|########8 |\n306/345 [01:15<00:01, 20.87it/s]', '\\rOverwrite (code_style) epoch 2/4:\n90%|########9 | 309/345 [01:15<00:01, 20.89it/s]', '\\rOverwrite (code_style)\nepoch 2/4:  90%|######### | 312/345 [01:15<00:01, 20.99it/s]', '\\rOverwrite\n(code_style) epoch 2/4:  91%|#########1| 315/345 [01:15<00:01, 20.95it/s]',\n'\\rOverwrite (code_style) epoch 2/4:  92%|#########2| 318/345 [01:16<00:01,\n20.92it/s]', '\\rOverwrite (code_style) epoch 2/4:  93%|#########3| 321/345\n[01:16<00:01, 20.88it/s]', '\\rOverwrite (code_style) epoch 2/4:  94%|#########3|\n324/345 [01:16<00:01, 20.61it/s]', '\\rOverwrite (code_style) epoch 2/4:\n95%|#########4| 327/345 [01:16<00:00, 20.56it/s]', '\\rOverwrite (code_style)\nepoch 2/4:  96%|#########5| 330/345 [01:16<00:00, 20.61it/s]', '\\rOverwrite\n(code_style) epoch 2/4:  97%|#########6| 333/345 [01:16<00:00, 20.50it/s]',\n'\\rOverwrite (code_style) epoch 2/4:  97%|#########7| 336/345 [01:16<00:00,\n20.70it/s]', '\\rOverwrite (code_style) epoch 2/4:  98%|#########8| 339/345\n[01:17<00:00, 20.73it/s]', '\\rOverwrite (code_style) epoch 2/4:  99%|#########9|\n342/345 [01:17<00:00, 20.98it/s]', '\\rOverwrite (code_style) epoch 2/4:\n100%|##########| 345/345 [01:17<00:00, 22.04it/s]', '', '\\rOverwrite\n(code_style) epoch 2/4: 100%|##########| 345/345 [01:18<00:00,  4.40it/s]',\n'\\n', 'Epoch 2 (code_style): validation_loss = 3.6389', '\\n', '\\rOverwrite\n(code_style) epoch 3/4:   0%|          | 0/345 [00:00<?, ?it/s]', '\\rOverwrite\n(code_style) epoch 3/4:   0%|          | 1/345 [01:24<8:03:57, 84.41s/it]',\n'\\rOverwrite (code_style) epoch 3/4:   1%|          | 3/345 [01:24<2:05:01,\n21.93s/it]', '\\rOverwrite (code_style) epoch 3/4:   2%|1         | 6/345\n[01:24<48:03,  8.51s/it]  ', '\\rOverwrite (code_style) epoch 3/4:   3%|2\n| 9/345 [01:24<25:30,  4.56s/it]', '\\rOverwrite (code_style) epoch 3/4:   3%|3\n| 12/345 [01:24<15:16,  2.75s/it]', '\\rOverwrite (code_style) epoch 3/4:   4%|4\n| 15/345 [01:25<09:43,  1.77s/it]', '\\rOverwrite (code_style) epoch 3/4:   5%|5\n| 18/345 [01:25<06:25,  1.18s/it]', '\\rOverwrite (code_style) epoch 3/4:   6%|6\n| 21/345 [01:25<04:21,  1.24it/s]', '\\rOverwrite (code_style) epoch 3/4:   7%|6\n| 24/345 [01:25<03:01,  1.77it/s]', '\\rOverwrite (code_style) epoch 3/4:   8%|7\n| 27/345 [01:25<02:08,  2.48it/s]', '\\rOverwrite (code_style) epoch 3/4:   9%|8\n| 30/345 [01:25<01:32,  3.42it/s]', '\\rOverwrite (code_style) epoch 3/4:  10%|9\n| 33/345 [01:25<01:07,  4.60it/s]', '\\rOverwrite (code_style) epoch 3/4:  10%|#\n| 36/345 [01:26<00:51,  6.06it/s]', '\\rOverwrite (code_style) epoch 3/4:  11%|#1\n| 39/345 [01:26<00:39,  7.76it/s]', '\\rOverwrite (code_style) epoch 3/4:  12%|#2\n| 42/345 [01:26<00:31,  9.61it/s]', '\\rOverwrite (code_style) epoch 3/4:  13%|#3\n| 45/345 [01:26<00:26, 11.46it/s]', '\\rOverwrite (code_style) epoch 3/4:  14%|#3\n| 48/345 [01:26<00:22, 13.32it/s]', '\\rOverwrite (code_style) epoch 3/4:  15%|#4\n| 51/345 [01:26<00:19, 14.91it/s]', '\\rOverwrite (code_style) epoch 3/4:  16%|#5\n| 54/345 [01:26<00:17, 16.25it/s]', '\\rOverwrite (code_style) epoch 3/4:  17%|#6\n| 57/345 [01:27<00:16, 17.37it/s]', '\\rOverwrite (code_style) epoch 3/4:  17%|#7\n| 60/345 [01:27<00:15, 18.28it/s]', '\\rOverwrite (code_style) epoch 3/4:  18%|#8\n| 63/345 [01:27<00:14, 19.13it/s]', '\\rOverwrite (code_style) epoch 3/4:  19%|#9\n| 66/345 [01:27<00:14, 19.82it/s]', '\\rOverwrite (code_style) epoch 3/4:  20%|##\n| 69/345 [01:27<00:13, 20.28it/s]', '\\rOverwrite (code_style) epoch 3/4:  21%|##\n| 72/345 [01:27<00:13, 20.73it/s]', '\\rOverwrite (code_style) epoch 3/4:\n22%|##1       | 75/345 [01:27<00:12, 21.06it/s]', '\\rOverwrite (code_style)\nepoch 3/4:  23%|##2       | 78/345 [01:28<00:12, 21.25it/s]', '\\rOverwrite\n(code_style) epoch 3/4:  23%|##3       | 81/345 [01:28<00:12, 21.27it/s]',\n'\\rOverwrite (code_style) epoch 3/4:  24%|##4       | 84/345 [01:28<00:12,\n21.22it/s]', '\\rOverwrite (code_style) epoch 3/4:  25%|##5       | 87/345\n[01:28<00:12, 21.19it/s]', '\\rOverwrite (code_style) epoch 3/4:  26%|##6       |\n90/345 [01:28<00:11, 21.40it/s]', '\\rOverwrite (code_style) epoch 3/4:  27%|##6\n| 93/345 [01:28<00:11, 21.52it/s]', '\\rOverwrite (code_style) epoch 3/4:\n28%|##7       | 96/345 [01:28<00:11, 21.54it/s]', '\\rOverwrite (code_style)\nepoch 3/4:  29%|##8       | 99/345 [01:29<00:11, 21.65it/s]', '\\rOverwrite\n(code_style) epoch 3/4:  30%|##9       | 102/345 [01:29<00:11, 21.55it/s]',\n'\\rOverwrite (code_style) epoch 3/4:  30%|###       | 105/345 [01:29<00:11,\n21.23it/s]', '\\rOverwrite (code_style) epoch 3/4:  31%|###1      | 108/345\n[01:29<00:11, 21.07it/s]', '[2025-12-04 00:46:53] Overwrite (code_style) step\n800: avg_train_loss=3.0867', '\\n', '\\rOverwrite (code_style) epoch 3/4:\n32%|###2      | 111/345 [01:29<00:11, 20.89it/s]', '\\rOverwrite (code_style)\nepoch 3/4:  33%|###3      | 114/345 [01:29<00:11, 20.63it/s]', '\\rOverwrite\n(code_style) epoch 3/4:  34%|###3      | 117/345 [01:29<00:11, 20.48it/s]',\n'\\rOverwrite (code_style) epoch 3/4:  35%|###4      | 120/345 [01:30<00:11,\n20.22it/s]', '\\rOverwrite (code_style) epoch 3/4:  36%|###5      | 123/345\n[01:30<00:10, 20.47it/s]', '\\rOverwrite (code_style) epoch 3/4:  37%|###6      |\n126/345 [01:30<00:10, 20.81it/s]', '\\rOverwrite (code_style) epoch 3/4:\n37%|###7      | 129/345 [01:30<00:10, 20.93it/s]', '\\rOverwrite (code_style)\nepoch 3/4:  38%|###8      | 132/345 [01:30<00:10, 20.83it/s]', '\\rOverwrite\n(code_style) epoch 3/4:  39%|###9      | 135/345 [01:30<00:10, 20.76it/s]',\n'\\rOverwrite (code_style) epoch 3/4:  40%|####      | 138/345 [01:30<00:10,\n20.68it/s]', '\\rOverwrite (code_style) epoch 3/4:  41%|####      | 141/345\n[01:31<00:09, 20.54it/s]', '\\rOverwrite (code_style) epoch 3/4:  42%|####1     |\n144/345 [01:31<00:09, 20.39it/s]', '\\rOverwrite (code_style) epoch 3/4:\n43%|####2     | 147/345 [01:31<00:09, 20.13it/s]', '\\rOverwrite (code_style)\nepoch 3/4:  43%|####3     | 150/345 [01:31<00:09, 20.42it/s]', '\\rOverwrite\n(code_style) epoch 3/4:  44%|####4     | 153/345 [01:31<00:09, 20.62it/s]',\n'\\rOverwrite (code_style) epoch 3/4:  45%|####5     | 156/345 [01:31<00:09,\n20.81it/s]', '\\rOverwrite (code_style) epoch 3/4:  46%|####6     | 159/345\n[01:31<00:08, 20.94it/s]', '\\rOverwrite (code_style) epoch 3/4:  47%|####6     |\n162/345 [01:32<00:08, 20.64it/s]', '\\rOverwrite (code_style) epoch 3/4:\n48%|####7     | 165/345 [01:32<00:08, 20.69it/s]', '\\rOverwrite (code_style)\nepoch 3/4:  49%|####8     | 168/345 [01:32<00:08, 20.86it/s]', '\\rOverwrite\n(code_style) epoch 3/4:  50%|####9     | 171/345 [01:32<00:08, 20.59it/s]',\n'\\rOverwrite (code_style) epoch 3/4:  50%|#####     | 174/345 [01:32<00:08,\n20.45it/s]', '\\rOverwrite (code_style) epoch 3/4:  51%|#####1    | 177/345\n[01:32<00:08, 20.34it/s]', '\\rOverwrite (code_style) epoch 3/4:  52%|#####2    |\n180/345 [01:32<00:08, 20.29it/s]', '\\rOverwrite (code_style) epoch 3/4:\n53%|#####3    | 183/345 [01:33<00:07, 20.34it/s]', '\\rOverwrite (code_style)\nepoch 3/4:  54%|#####3    | 186/345 [01:33<00:07, 20.64it/s]', '\\rOverwrite\n(code_style) epoch 3/4:  55%|#####4    | 189/345 [01:33<00:07, 20.87it/s]',\n'\\rOverwrite (code_style) epoch 3/4:  56%|#####5    | 192/345 [01:33<00:07,\n20.87it/s]', '\\rOverwrite (code_style) epoch 3/4:  57%|#####6    | 195/345\n[01:33<00:07, 20.76it/s]', '\\rOverwrite (code_style) epoch 3/4:  57%|#####7    |\n198/345 [01:33<00:06, 21.00it/s]', '\\rOverwrite (code_style) epoch 3/4:\n58%|#####8    | 201/345 [01:33<00:06, 21.06it/s]', '\\rOverwrite (code_style)\nepoch 3/4:  59%|#####9    | 204/345 [01:34<00:06, 20.99it/s]', '\\rOverwrite\n(code_style) epoch 3/4:  60%|######    | 207/345 [01:34<00:06, 21.13it/s]',\n'\\rOverwrite (code_style) epoch 3/4:  61%|######    | 210/345 [01:34<00:06,\n21.09it/s]', '\\rOverwrite (code_style) epoch 3/4:  62%|######1   | 213/345\n[01:34<00:06, 21.20it/s]', '\\rOverwrite (code_style) epoch 3/4:  63%|######2   |\n216/345 [01:34<00:06, 21.03it/s]', '\\rOverwrite (code_style) epoch 3/4:\n63%|######3   | 219/345 [01:34<00:06, 20.75it/s]', '\\rOverwrite (code_style)\nepoch 3/4:  64%|######4   | 222/345 [01:34<00:05, 20.99it/s]', '\\rOverwrite\n(code_style) epoch 3/4:  65%|######5   | 225/345 [01:35<00:05, 20.22it/s]',\n'\\rOverwrite (code_style) epoch 3/4:  66%|######6   | 228/345 [01:35<00:05,\n20.05it/s]', '\\rOverwrite (code_style) epoch 3/4:  67%|######6   | 231/345\n[01:35<00:05, 20.15it/s]', '\\rOverwrite (code_style) epoch 3/4:  68%|######7   |\n234/345 [01:35<00:05, 20.41it/s]', '\\rOverwrite (code_style) epoch 3/4:\n69%|######8   | 237/345 [01:35<00:05, 20.49it/s]', '\\rOverwrite (code_style)\nepoch 3/4:  70%|######9   | 240/345 [01:35<00:05, 20.66it/s]', '\\rOverwrite\n(code_style) epoch 3/4:  70%|#######   | 243/345 [01:36<00:04, 20.79it/s]',\n'\\rOverwrite (code_style) epoch 3/4:  71%|#######1  | 246/345 [01:36<00:04,\n20.89it/s]', '\\rOverwrite (code_style) epoch 3/4:  72%|#######2  | 249/345\n[01:36<00:04, 21.05it/s]', '\\rOverwrite (code_style) epoch 3/4:  73%|#######3  |\n252/345 [01:36<00:04, 21.14it/s]', '\\rOverwrite (code_style) epoch 3/4:\n74%|#######3  | 255/345 [01:36<00:04, 21.08it/s]', '\\rOverwrite (code_style)\nepoch 3/4:  75%|#######4  | 258/345 [01:36<00:04, 20.81it/s]', '\\rOverwrite\n(code_style) epoch 3/4:  76%|#######5  | 261/345 [01:36<00:04, 20.98it/s]',\n'\\rOverwrite (code_style) epoch 3/4:  77%|#######6  | 264/345 [01:37<00:03,\n21.12it/s]', '\\rOverwrite (code_style) epoch 3/4:  77%|#######7  | 267/345\n[01:37<00:03, 21.00it/s]', '\\rOverwrite (code_style) epoch 3/4:  78%|#######8  |\n270/345 [01:37<00:03, 21.02it/s]', '\\rOverwrite (code_style) epoch 3/4:\n79%|#######9  | 273/345 [01:37<00:03, 20.67it/s]', '\\rOverwrite (code_style)\nepoch 3/4:  80%|########  | 276/345 [01:37<00:03, 20.85it/s]', '\\rOverwrite\n(code_style) epoch 3/4:  81%|########  | 279/345 [01:37<00:03, 21.03it/s]',\n'\\rOverwrite (code_style) epoch 3/4:  82%|########1 | 282/345 [01:37<00:02,\n21.17it/s]', '\\rOverwrite (code_style) epoch 3/4:  83%|########2 | 285/345\n[01:38<00:02, 21.21it/s]', '\\rOverwrite (code_style) epoch 3/4:  83%|########3 |\n288/345 [01:38<00:02, 21.30it/s]', '\\rOverwrite (code_style) epoch 3/4:\n84%|########4 | 291/345 [01:38<00:02, 21.38it/s]', '\\rOverwrite (code_style)\nepoch 3/4:  85%|########5 | 294/345 [01:38<00:02, 20.99it/s]', '\\rOverwrite\n(code_style) epoch 3/4:  86%|########6 | 297/345 [01:38<00:02, 20.95it/s]',\n'\\rOverwrite (code_style) epoch 3/4:  87%|########6 | 300/345 [01:38<00:02,\n20.91it/s]', '\\rOverwrite (code_style) epoch 3/4:  88%|########7 | 303/345\n[01:38<00:02, 20.21it/s]', '\\rOverwrite (code_style) epoch 3/4:  89%|########8 |\n306/345 [01:39<00:01, 20.44it/s]', '\\rOverwrite (code_style) epoch 3/4:\n90%|########9 | 309/345 [01:39<00:01, 20.75it/s]', '[2025-12-04 00:47:02]\nOverwrite (code_style) step 1000: avg_train_loss=3.0751', '\\n', '\\rOverwrite\n(code_style) epoch 3/4:  90%|######### | 312/345 [01:39<00:01, 20.97it/s]',\n'\\rOverwrite (code_style) epoch 3/4:  91%|#########1| 315/345 [01:39<00:01,\n21.10it/s]', '\\rOverwrite (code_style) epoch 3/4:  92%|#########2| 318/345\n[01:39<00:01, 21.14it/s]', '\\rOverwrite (code_style) epoch 3/4:  93%|#########3|\n321/345 [01:39<00:01, 21.07it/s]', '\\rOverwrite (code_style) epoch 3/4:\n94%|#########3| 324/345 [01:39<00:01, 20.82it/s]', '\\rOverwrite (code_style)\nepoch 3/4:  95%|#########4| 327/345 [01:40<00:00, 20.73it/s]', '\\rOverwrite\n(code_style) epoch 3/4:  96%|#########5| 330/345 [01:40<00:00, 20.87it/s]',\n'\\rOverwrite (code_style) epoch 3/4:  97%|#########6| 333/345 [01:40<00:00,\n20.55it/s]', '\\rOverwrite (code_style) epoch 3/4:  97%|#########7| 336/345\n[01:40<00:00, 20.79it/s]', '\\rOverwrite (code_style) epoch 3/4:  98%|#########8|\n339/345 [01:40<00:00, 21.04it/s]', '\\rOverwrite (code_style) epoch 3/4:\n99%|#########9| 342/345 [01:40<00:00, 21.12it/s]', '\\rOverwrite (code_style)\nepoch 3/4: 100%|##########| 345/345 [01:40<00:00, 21.88it/s]', '', '\\rOverwrite\n(code_style) epoch 3/4: 100%|##########| 345/345 [01:42<00:00,  3.38it/s]',\n'\\n', 'Epoch 3 (code_style): validation_loss = 3.6702', '\\n', '\\rOverwrite\n(code_style) epoch 4/4:   0%|          | 0/345 [00:00<?, ?it/s]', '\\rOverwrite\n(code_style) epoch 4/4:   0%|          | 1/345 [00:50<4:47:29, 50.14s/it]',\n'\\rOverwrite (code_style) epoch 4/4:   1%|          | 3/345 [00:50<1:14:22,\n13.05s/it]', '\\rOverwrite (code_style) epoch 4/4:   2%|1         | 6/345\n[00:50<28:39,  5.07s/it]  ', '\\rOverwrite (code_style) epoch 4/4:   3%|2\n| 9/345 [00:50<15:15,  2.73s/it]', '\\rOverwrite (code_style) epoch 4/4:   3%|3\n| 12/345 [00:50<09:10,  1.65s/it]', '\\rOverwrite (code_style) epoch 4/4:   4%|4\n| 15/345 [00:50<05:52,  1.07s/it]', '\\rOverwrite (code_style) epoch 4/4:   5%|5\n| 18/345 [00:50<03:55,  1.39it/s]', '\\rOverwrite (code_style) epoch 4/4:   6%|6\n| 21/345 [00:51<02:41,  2.01it/s]', '\\rOverwrite (code_style) epoch 4/4:   7%|6\n| 24/345 [00:51<01:53,  2.82it/s]', '\\rOverwrite (code_style) epoch 4/4:   8%|7\n| 27/345 [00:51<01:22,  3.87it/s]', '\\rOverwrite (code_style) epoch 4/4:   9%|8\n| 30/345 [00:51<01:01,  5.16it/s]', '\\rOverwrite (code_style) epoch 4/4:  10%|9\n| 33/345 [00:51<00:46,  6.68it/s]', '\\rOverwrite (code_style) epoch 4/4:  10%|#\n| 36/345 [00:51<00:36,  8.45it/s]', '\\rOverwrite (code_style) epoch 4/4:  11%|#1\n| 39/345 [00:51<00:29, 10.37it/s]', '\\rOverwrite (code_style) epoch 4/4:  12%|#2\n| 42/345 [00:52<00:24, 12.23it/s]', '\\rOverwrite (code_style) epoch 4/4:  13%|#3\n| 45/345 [00:52<00:21, 14.01it/s]', '\\rOverwrite (code_style) epoch 4/4:  14%|#3\n| 48/345 [00:52<00:18, 15.71it/s]', '\\rOverwrite (code_style) epoch 4/4:  15%|#4\n| 51/345 [00:52<00:17, 17.18it/s]', '\\rOverwrite (code_style) epoch 4/4:  16%|#5\n| 54/345 [00:52<00:15, 18.29it/s]', '\\rOverwrite (code_style) epoch 4/4:  17%|#6\n| 57/345 [00:52<00:15, 19.13it/s]', '\\rOverwrite (code_style) epoch 4/4:  17%|#7\n| 60/345 [00:52<00:14, 19.50it/s]', '\\rOverwrite (code_style) epoch 4/4:  18%|#8\n| 63/345 [00:53<00:14, 19.70it/s]', '\\rOverwrite (code_style) epoch 4/4:  19%|#9\n| 66/345 [00:53<00:13, 20.06it/s]', '\\rOverwrite (code_style) epoch 4/4:  20%|##\n| 69/345 [00:53<00:13, 19.79it/s]', '\\rOverwrite (code_style) epoch 4/4:  21%|##\n| 72/345 [00:53<00:14, 19.48it/s]', '\\rOverwrite (code_style) epoch 4/4:\n22%|##1       | 75/345 [00:53<00:13, 19.85it/s]', '\\rOverwrite (code_style)\nepoch 4/4:  23%|##2       | 78/345 [00:53<00:13, 20.22it/s]', '\\rOverwrite\n(code_style) epoch 4/4:  23%|##3       | 81/345 [00:53<00:12, 20.52it/s]',\n'\\rOverwrite (code_style) epoch 4/4:  24%|##4       | 84/345 [00:54<00:12,\n20.64it/s]', '\\rOverwrite (code_style) epoch 4/4:  25%|##5       | 87/345\n[00:54<00:12, 20.82it/s]', '\\rOverwrite (code_style) epoch 4/4:  26%|##6       |\n90/345 [00:54<00:12, 20.96it/s]', '\\rOverwrite (code_style) epoch 4/4:  27%|##6\n| 93/345 [00:54<00:11, 21.14it/s]', '\\rOverwrite (code_style) epoch 4/4:\n28%|##7       | 96/345 [00:54<00:11, 21.32it/s]', '\\rOverwrite (code_style)\nepoch 4/4:  29%|##8       | 99/345 [00:54<00:11, 21.34it/s]', '\\rOverwrite\n(code_style) epoch 4/4:  30%|##9       | 102/345 [00:54<00:11, 21.28it/s]',\n'\\rOverwrite (code_style) epoch 4/4:  30%|###       | 105/345 [00:55<00:11,\n21.32it/s]', '\\rOverwrite (code_style) epoch 4/4:  31%|###1      | 108/345\n[00:55<00:11, 20.91it/s]', '\\rOverwrite (code_style) epoch 4/4:  32%|###2      |\n111/345 [00:55<00:11, 20.87it/s]', '\\rOverwrite (code_style) epoch 4/4:\n33%|###3      | 114/345 [00:55<00:11, 20.85it/s]', '\\rOverwrite (code_style)\nepoch 4/4:  34%|###3      | 117/345 [00:55<00:10, 20.88it/s]', '\\rOverwrite\n(code_style) epoch 4/4:  35%|###4      | 120/345 [00:55<00:10, 20.99it/s]',\n'\\rOverwrite (code_style) epoch 4/4:  36%|###5      | 123/345 [00:55<00:10,\n21.20it/s]', '\\rOverwrite (code_style) epoch 4/4:  37%|###6      | 126/345\n[00:56<00:10, 21.15it/s]', '\\rOverwrite (code_style) epoch 4/4:  37%|###7      |\n129/345 [00:56<00:10, 21.20it/s]', '\\rOverwrite (code_style) epoch 4/4:\n38%|###8      | 132/345 [00:56<00:10, 21.18it/s]', '\\rOverwrite (code_style)\nepoch 4/4:  39%|###9      | 135/345 [00:56<00:09, 21.34it/s]', '\\rOverwrite\n(code_style) epoch 4/4:  40%|####      | 138/345 [00:56<00:09, 21.47it/s]',\n'\\rOverwrite (code_style) epoch 4/4:  41%|####      | 141/345 [00:56<00:09,\n21.55it/s]', '\\rOverwrite (code_style) epoch 4/4:  42%|####1     | 144/345\n[00:56<00:09, 21.24it/s]', '\\rOverwrite (code_style) epoch 4/4:  43%|####2     |\n147/345 [00:57<00:09, 21.23it/s]', '\\rOverwrite (code_style) epoch 4/4:\n43%|####3     | 150/345 [00:57<00:09, 21.11it/s]', '\\rOverwrite (code_style)\nepoch 4/4:  44%|####4     | 153/345 [00:57<00:09, 21.30it/s]', '\\rOverwrite\n(code_style) epoch 4/4:  45%|####5     | 156/345 [00:57<00:08, 21.45it/s]',\n'\\rOverwrite (code_style) epoch 4/4:  46%|####6     | 159/345 [00:57<00:08,\n21.48it/s]', '\\rOverwrite (code_style) epoch 4/4:  47%|####6     | 162/345\n[00:57<00:08, 21.45it/s]', '[2025-12-04 00:49:29] Overwrite (code_style) step\n1200: avg_train_loss=2.8638', '\\n', '\\rOverwrite (code_style) epoch 4/4:\n48%|####7     | 165/345 [00:57<00:08, 21.32it/s]', '\\rOverwrite (code_style)\nepoch 4/4:  49%|####8     | 168/345 [00:58<00:08, 21.45it/s]', '\\rOverwrite\n(code_style) epoch 4/4:  50%|####9     | 171/345 [00:58<00:08, 21.49it/s]',\n'\\rOverwrite (code_style) epoch 4/4:  50%|#####     | 174/345 [00:58<00:08,\n21.35it/s]', '\\rOverwrite (code_style) epoch 4/4:  51%|#####1    | 177/345\n[00:58<00:07, 21.23it/s]', '\\rOverwrite (code_style) epoch 4/4:  52%|#####2    |\n180/345 [00:58<00:07, 20.90it/s]', '\\rOverwrite (code_style) epoch 4/4:\n53%|#####3    | 183/345 [00:58<00:07, 21.07it/s]', '\\rOverwrite (code_style)\nepoch 4/4:  54%|#####3    | 186/345 [00:58<00:07, 21.20it/s]', '\\rOverwrite\n(code_style) epoch 4/4:  55%|#####4    | 189/345 [00:59<00:07, 21.19it/s]',\n'\\rOverwrite (code_style) epoch 4/4:  56%|#####5    | 192/345 [00:59<00:07,\n21.29it/s]', '\\rOverwrite (code_style) epoch 4/4:  57%|#####6    | 195/345\n[00:59<00:07, 21.14it/s]', '\\rOverwrite (code_style) epoch 4/4:  57%|#####7    |\n198/345 [00:59<00:06, 21.33it/s]', '\\rOverwrite (code_style) epoch 4/4:\n58%|#####8    | 201/345 [00:59<00:06, 21.41it/s]', '\\rOverwrite (code_style)\nepoch 4/4:  59%|#####9    | 204/345 [00:59<00:06, 21.45it/s]', '\\rOverwrite\n(code_style) epoch 4/4:  60%|######    | 207/345 [00:59<00:06, 21.30it/s]',\n'\\rOverwrite (code_style) epoch 4/4:  61%|######    | 210/345 [01:00<00:06,\n20.98it/s]', '\\rOverwrite (code_style) epoch 4/4:  62%|######1   | 213/345\n[01:00<00:06, 20.98it/s]', '\\rOverwrite (code_style) epoch 4/4:  63%|######2   |\n216/345 [01:00<00:06, 20.65it/s]', '\\rOverwrite (code_style) epoch 4/4:\n63%|######3   | 219/345 [01:00<00:06, 20.31it/s]', '\\rOverwrite (code_style)\nepoch 4/4:  64%|######4   | 222/345 [01:00<00:06, 20.34it/s]', '\\rOverwrite\n(code_style) epoch 4/4:  65%|######5   | 225/345 [01:00<00:05, 20.57it/s]',\n'\\rOverwrite (code_style) epoch 4/4:  66%|######6   | 228/345 [01:00<00:05,\n20.93it/s]', '\\rOverwrite (code_style) epoch 4/4:  67%|######6   | 231/345\n[01:01<00:05, 20.94it/s]', '\\rOverwrite (code_style) epoch 4/4:  68%|######7   |\n234/345 [01:01<00:05, 21.15it/s]', '\\rOverwrite (code_style) epoch 4/4:\n69%|######8   | 237/345 [01:01<00:05, 21.25it/s]', '\\rOverwrite (code_style)\nepoch 4/4:  70%|######9   | 240/345 [01:01<00:04, 21.17it/s]', '\\rOverwrite\n(code_style) epoch 4/4:  70%|#######   | 243/345 [01:01<00:04, 21.05it/s]',\n'\\rOverwrite (code_style) epoch 4/4:  71%|#######1  | 246/345 [01:01<00:04,\n21.13it/s]', '\\rOverwrite (code_style) epoch 4/4:  72%|#######2  | 249/345\n[01:01<00:04, 21.33it/s]', '\\rOverwrite (code_style) epoch 4/4:  73%|#######3  |\n252/345 [01:02<00:04, 21.19it/s]', '\\rOverwrite (code_style) epoch 4/4:\n74%|#######3  | 255/345 [01:02<00:04, 21.18it/s]', '\\rOverwrite (code_style)\nepoch 4/4:  75%|#######4  | 258/345 [01:02<00:04, 21.21it/s]', '\\rOverwrite\n(code_style) epoch 4/4:  76%|#######5  | 261/345 [01:02<00:03, 21.35it/s]',\n'\\rOverwrite (code_style) epoch 4/4:  77%|#######6  | 264/345 [01:02<00:03,\n21.39it/s]', '\\rOverwrite (code_style) epoch 4/4:  77%|#######7  | 267/345\n[01:02<00:03, 21.45it/s]', '\\rOverwrite (code_style) epoch 4/4:  78%|#######8  |\n270/345 [01:02<00:03, 21.40it/s]', '\\rOverwrite (code_style) epoch 4/4:\n79%|#######9  | 273/345 [01:03<00:03, 21.24it/s]', '\\rOverwrite (code_style)\nepoch 4/4:  80%|########  | 276/345 [01:03<00:03, 21.39it/s]', '\\rOverwrite\n(code_style) epoch 4/4:  81%|########  | 279/345 [01:03<00:03, 21.54it/s]',\n'\\rOverwrite (code_style) epoch 4/4:  82%|########1 | 282/345 [01:03<00:02,\n21.64it/s]', '\\rOverwrite (code_style) epoch 4/4:  83%|########2 | 285/345\n[01:03<00:02, 21.64it/s]', '\\rOverwrite (code_style) epoch 4/4:  83%|########3 |\n288/345 [01:03<00:02, 21.28it/s]', '\\rOverwrite (code_style) epoch 4/4:\n84%|########4 | 291/345 [01:03<00:02, 21.40it/s]', '\\rOverwrite (code_style)\nepoch 4/4:  85%|########5 | 294/345 [01:04<00:02, 21.26it/s]', '\\rOverwrite\n(code_style) epoch 4/4:  86%|########6 | 297/345 [01:04<00:02, 21.37it/s]',\n'\\rOverwrite (code_style) epoch 4/4:  87%|########6 | 300/345 [01:04<00:02,\n21.46it/s]', '\\rOverwrite (code_style) epoch 4/4:  88%|########7 | 303/345\n[01:04<00:01, 21.13it/s]', '\\rOverwrite (code_style) epoch 4/4:  89%|########8 |\n306/345 [01:04<00:01, 21.08it/s]', '\\rOverwrite (code_style) epoch 4/4:\n90%|########9 | 309/345 [01:04<00:01, 21.31it/s]', '\\rOverwrite (code_style)\nepoch 4/4:  90%|######### | 312/345 [01:04<00:01, 21.46it/s]', '\\rOverwrite\n(code_style) epoch 4/4:  91%|#########1| 315/345 [01:05<00:01, 21.49it/s]',\n'\\rOverwrite (code_style) epoch 4/4:  92%|#########2| 318/345 [01:05<00:01,\n21.30it/s]', '\\rOverwrite (code_style) epoch 4/4:  93%|#########3| 321/345\n[01:05<00:01, 21.20it/s]', '\\rOverwrite (code_style) epoch 4/4:  94%|#########3|\n324/345 [01:05<00:00, 21.29it/s]', '\\rOverwrite (code_style) epoch 4/4:\n95%|#########4| 327/345 [01:05<00:00, 21.46it/s]', '\\rOverwrite (code_style)\nepoch 4/4:  96%|#########5| 330/345 [01:05<00:00, 21.54it/s]', '\\rOverwrite\n(code_style) epoch 4/4:  97%|#########6| 333/345 [01:05<00:00, 21.42it/s]',\n'\\rOverwrite (code_style) epoch 4/4:  97%|#########7| 336/345 [01:06<00:00,\n21.34it/s]', '\\rOverwrite (code_style) epoch 4/4:  98%|#########8| 339/345\n[01:06<00:00, 21.48it/s]', '\\rOverwrite (code_style) epoch 4/4:  99%|#########9|\n342/345 [01:06<00:00, 21.56it/s]', '\\rOverwrite (code_style) epoch 4/4:\n100%|##########| 345/345 [01:06<00:00, 22.62it/s]', '', '\\rOverwrite\n(code_style) epoch 4/4: 100%|##########| 345/345 [01:07<00:00,  5.12it/s]',\n'\\n', 'Epoch 4 (code_style): validation_loss = 3.7326', '\\n', '\\n===== Starting\ncondition: json_style =====', '\\n', '\\rMap:   0%|          | 0/2000 [00:00<?, ?\nexamples/s]', '', '\\rMap: 100%|##########| 2000/2000 [00:00<00:00, 34462.45\nexamples/s]', '\\n', '\\rMap:   0%|          | 0/300 [00:00<?, ? examples/s]', '',\n'\\rMap: 100%|##########| 300/300 [00:00<00:00, 31100.40 examples/s]', '\\n',\n'\\rTraining json_style_phase1 epoch 1/1:   0%|          | 0/21 [00:00<?,\n?it/s]', '\\rTraining json_style_phase1 epoch 1/1:   5%|4         | 1/21\n[00:52<17:22, 52.15s/it]', '\\rTraining json_style_phase1 epoch 1/1:  10%|9\n| 2/21 [00:52<06:49, 21.54s/it]', '\\rTraining json_style_phase1 epoch 1/1:\n14%|#4        | 3/21 [00:52<03:31, 11.76s/it]', '\\rTraining json_style_phase1\nepoch 1/1:  19%|#9        | 4/21 [00:52<02:01,  7.16s/it]', '\\rTraining\njson_style_phase1 epoch 1/1:  24%|##3       | 5/21 [00:52<01:13,  4.62s/it]',\n'\\rTraining json_style_phase1 epoch 1/1:  29%|##8       | 6/21 [00:52<00:46,\n3.09s/it]', '\\rTraining json_style_phase1 epoch 1/1:  33%|###3      | 7/21\n[00:52<00:29,  2.12s/it]', '\\rTraining json_style_phase1 epoch 1/1:  38%|###8\n| 8/21 [00:52<00:19,  1.48s/it]', '\\rTraining json_style_phase1 epoch 1/1:\n43%|####2     | 9/21 [00:53<00:12,  1.05s/it]', '\\rTraining json_style_phase1\nepoch 1/1:  48%|####7     | 10/21 [00:53<00:08,  1.31it/s]', '\\rTraining\njson_style_phase1 epoch 1/1:  52%|#####2    | 11/21 [00:53<00:05,  1.77it/s]',\n'\\rTraining json_style_phase1 epoch 1/1:  57%|#####7    | 12/21 [00:53<00:03,\n2.34it/s]', '\\rTraining json_style_phase1 epoch 1/1:  62%|######1   | 13/21\n[00:53<00:02,  3.00it/s]', '\\rTraining json_style_phase1 epoch 1/1:  67%|######6\n| 14/21 [00:53<00:01,  3.73it/s]', '\\rTraining json_style_phase1 epoch 1/1:\n71%|#######1  | 15/21 [00:53<00:01,  4.51it/s]', '\\rTraining json_style_phase1\nepoch 1/1:  76%|#######6  | 16/21 [00:53<00:00,  5.27it/s]', '\\rTraining\njson_style_phase1 epoch 1/1:  81%|########  | 17/21 [00:53<00:00,  5.97it/s]',\n'\\rTraining json_style_phase1 epoch 1/1:  86%|########5 | 18/21 [00:54<00:00,\n6.59it/s]', '\\rTraining json_style_phase1 epoch 1/1:  90%|######### | 19/21\n[00:54<00:00,  7.06it/s]', '\\rTraining json_style_phase1 epoch 1/1:\n95%|#########5| 20/21 [00:54<00:00,  7.43it/s]', '', '\\rTraining\njson_style_phase1 epoch 1/1: 100%|##########| 21/21 [00:55<00:00,  2.64s/it]',\n'\\n', 'Epoch 1: validation_loss = 4.2229', '\\n', '\\rOverwrite (json_style) epoch\n1/4:   0%|          | 0/345 [00:00<?, ?it/s]', '\\rOverwrite (json_style) epoch\n1/4:   0%|          | 1/345 [00:51<4:54:03, 51.29s/it]', '\\rOverwrite\n(json_style) epoch 1/4:   1%|          | 3/345 [00:51<1:16:03, 13.34s/it]',\n'\\rOverwrite (json_style) epoch 1/4:   2%|1         | 6/345 [00:51<29:17,\n5.19s/it]  ', '\\rOverwrite (json_style) epoch 1/4:   3%|2         | 9/345\n[00:51<15:35,  2.78s/it]', '\\rOverwrite (json_style) epoch 1/4:   3%|3         |\n12/345 [00:51<09:22,  1.69s/it]', '\\rOverwrite (json_style) epoch 1/4:   4%|4\n| 15/345 [00:51<06:00,  1.09s/it]', '\\rOverwrite (json_style) epoch 1/4:   5%|5\n| 18/345 [00:52<03:59,  1.36it/s]', '\\rOverwrite (json_style) epoch 1/4:   6%|6\n| 21/345 [00:52<02:44,  1.97it/s]', '\\rOverwrite (json_style) epoch 1/4:   7%|6\n| 24/345 [00:52<01:55,  2.78it/s]', '\\rOverwrite (json_style) epoch 1/4:   8%|7\n| 27/345 [00:52<01:23,  3.82it/s]', '\\rOverwrite (json_style) epoch 1/4:   9%|8\n| 30/345 [00:52<01:01,  5.13it/s]', '\\rOverwrite (json_style) epoch 1/4:  10%|9\n| 33/345 [00:52<00:46,  6.70it/s]', '\\rOverwrite (json_style) epoch 1/4:  10%|#\n| 36/345 [00:52<00:36,  8.50it/s]', '\\rOverwrite (json_style) epoch 1/4:  11%|#1\n| 39/345 [00:53<00:29, 10.44it/s]', '\\rOverwrite (json_style) epoch 1/4:  12%|#2\n| 42/345 [00:53<00:24, 12.39it/s]', '\\rOverwrite (json_style) epoch 1/4:  13%|#3\n| 45/345 [00:53<00:21, 14.24it/s]', '\\rOverwrite (json_style) epoch 1/4:  14%|#3\n| 48/345 [00:53<00:18, 15.91it/s]', '\\rOverwrite (json_style) epoch 1/4:  15%|#4\n| 51/345 [00:53<00:16, 17.32it/s]', '\\rOverwrite (json_style) epoch 1/4:  16%|#5\n| 54/345 [00:53<00:15, 18.47it/s]', '\\rOverwrite (json_style) epoch 1/4:  17%|#6\n| 57/345 [00:53<00:14, 19.37it/s]', '\\rOverwrite (json_style) epoch 1/4:  17%|#7\n| 60/345 [00:54<00:14, 20.10it/s]', '\\rOverwrite (json_style) epoch 1/4:  18%|#8\n| 63/345 [00:54<00:13, 20.56it/s]', '\\rOverwrite (json_style) epoch 1/4:  19%|#9\n| 66/345 [00:54<00:13, 20.92it/s]', '\\rOverwrite (json_style) epoch 1/4:  20%|##\n| 69/345 [00:54<00:13, 21.21it/s]', '\\rOverwrite (json_style) epoch 1/4:  21%|##\n| 72/345 [00:54<00:12, 21.44it/s]', '\\rOverwrite (json_style) epoch 1/4:\n22%|##1       | 75/345 [00:54<00:12, 21.61it/s]', '\\rOverwrite (json_style)\nepoch 1/4:  23%|##2       | 78/345 [00:54<00:12, 21.74it/s]', '\\rOverwrite\n(json_style) epoch 1/4:  23%|##3       | 81/345 [00:54<00:12, 21.82it/s]',\n'\\rOverwrite (json_style) epoch 1/4:  24%|##4       | 84/345 [00:55<00:11,\n21.89it/s]', '\\rOverwrite (json_style) epoch 1/4:  25%|##5       | 87/345\n[00:55<00:11, 21.94it/s]', '\\rOverwrite (json_style) epoch 1/4:  26%|##6       |\n90/345 [00:55<00:11, 21.98it/s]', '\\rOverwrite (json_style) epoch 1/4:  27%|##6\n| 93/345 [00:55<00:11, 22.01it/s]', '\\rOverwrite (json_style) epoch 1/4:\n28%|##7       | 96/345 [00:55<00:11, 22.02it/s]', '\\rOverwrite (json_style)\nepoch 1/4:  29%|##8       | 99/345 [00:55<00:11, 22.05it/s]', '\\rOverwrite\n(json_style) epoch 1/4:  30%|##9       | 102/345 [00:55<00:11, 22.03it/s]',\n'\\rOverwrite (json_style) epoch 1/4:  30%|###       | 105/345 [00:56<00:10,\n21.89it/s]', '\\rOverwrite (json_style) epoch 1/4:  31%|###1      | 108/345\n[00:56<00:10, 21.90it/s]', '\\rOverwrite (json_style) epoch 1/4:  32%|###2      |\n111/345 [00:56<00:10, 21.81it/s]', '\\rOverwrite (json_style) epoch 1/4:\n33%|###3      | 114/345 [00:56<00:10, 21.75it/s]', '\\rOverwrite (json_style)\nepoch 1/4:  34%|###3      | 117/345 [00:56<00:10, 21.54it/s]', '\\rOverwrite\n(json_style) epoch 1/4:  35%|###4      | 120/345 [00:56<00:10, 21.35it/s]',\n'\\rOverwrite (json_style) epoch 1/4:  36%|###5      | 123/345 [00:56<00:10,\n21.17it/s]', '\\rOverwrite (json_style) epoch 1/4:  37%|###6      | 126/345\n[00:57<00:10, 21.40it/s]', '\\rOverwrite (json_style) epoch 1/4:  37%|###7      |\n129/345 [00:57<00:10, 21.51it/s]', '\\rOverwrite (json_style) epoch 1/4:\n38%|###8      | 132/345 [00:57<00:09, 21.61it/s]', '\\rOverwrite (json_style)\nepoch 1/4:  39%|###9      | 135/345 [00:57<00:09, 21.44it/s]', '\\rOverwrite\n(json_style) epoch 1/4:  40%|####      | 138/345 [00:57<00:09, 21.16it/s]',\n'\\rOverwrite (json_style) epoch 1/4:  41%|####      | 141/345 [00:57<00:09,\n21.37it/s]', '\\rOverwrite (json_style) epoch 1/4:  42%|####1     | 144/345\n[00:57<00:09, 21.39it/s]', '\\rOverwrite (json_style) epoch 1/4:  43%|####2     |\n147/345 [00:58<00:09, 21.37it/s]', '\\rOverwrite (json_style) epoch 1/4:\n43%|####3     | 150/345 [00:58<00:09, 21.45it/s]', '\\rOverwrite (json_style)\nepoch 1/4:  44%|####4     | 153/345 [00:58<00:08, 21.50it/s]', '\\rOverwrite\n(json_style) epoch 1/4:  45%|####5     | 156/345 [00:58<00:08, 21.57it/s]',\n'\\rOverwrite (json_style) epoch 1/4:  46%|####6     | 159/345 [00:58<00:08,\n21.62it/s]', '\\rOverwrite (json_style) epoch 1/4:  47%|####6     | 162/345\n[00:58<00:08, 21.51it/s]', '\\rOverwrite (json_style) epoch 1/4:  48%|####7     |\n165/345 [00:58<00:08, 21.31it/s]', '\\rOverwrite (json_style) epoch 1/4:\n49%|####8     | 168/345 [00:59<00:08, 20.82it/s]', '\\rOverwrite (json_style)\nepoch 1/4:  50%|####9     | 171/345 [00:59<00:08, 20.65it/s]', '\\rOverwrite\n(json_style) epoch 1/4:  50%|#####     | 174/345 [00:59<00:08, 20.82it/s]',\n'\\rOverwrite (json_style) epoch 1/4:  51%|#####1    | 177/345 [00:59<00:07,\n21.05it/s]', '\\rOverwrite (json_style) epoch 1/4:  52%|#####2    | 180/345\n[00:59<00:07, 20.98it/s]', '\\rOverwrite (json_style) epoch 1/4:  53%|#####3    |\n183/345 [00:59<00:07, 21.11it/s]', '\\rOverwrite (json_style) epoch 1/4:\n54%|#####3    | 186/345 [00:59<00:07, 21.04it/s]', '\\rOverwrite (json_style)\nepoch 1/4:  55%|#####4    | 189/345 [01:00<00:07, 21.14it/s]', '\\rOverwrite\n(json_style) epoch 1/4:  56%|#####5    | 192/345 [01:00<00:07, 21.28it/s]',\n'\\rOverwrite (json_style) epoch 1/4:  57%|#####6    | 195/345 [01:00<00:07,\n21.37it/s]', '\\rOverwrite (json_style) epoch 1/4:  57%|#####7    | 198/345\n[01:00<00:06, 21.36it/s]', '[2025-12-04 00:54:12] Overwrite (json_style) step\n200: avg_train_loss=3.8384', '\\n', '\\rOverwrite (json_style) epoch 1/4:\n58%|#####8    | 201/345 [01:00<00:06, 21.42it/s]', '\\rOverwrite (json_style)\nepoch 1/4:  59%|#####9    | 204/345 [01:00<00:06, 21.01it/s]', '\\rOverwrite\n(json_style) epoch 1/4:  60%|######    | 207/345 [01:00<00:06, 20.40it/s]',\n'\\rOverwrite (json_style) epoch 1/4:  61%|######    | 210/345 [01:01<00:06,\n20.55it/s]', '\\rOverwrite (json_style) epoch 1/4:  62%|######1   | 213/345\n[01:01<00:06, 20.68it/s]', '\\rOverwrite (json_style) epoch 1/4:  63%|######2   |\n216/345 [01:01<00:06, 20.75it/s]', '\\rOverwrite (json_style) epoch 1/4:\n63%|######3   | 219/345 [01:01<00:06, 21.00it/s]', '\\rOverwrite (json_style)\nepoch 1/4:  64%|######4   | 222/345 [01:01<00:05, 21.20it/s]', '\\rOverwrite\n(json_style) epoch 1/4:  65%|######5   | 225/345 [01:01<00:05, 21.31it/s]',\n'\\rOverwrite (json_style) epoch 1/4:  66%|######6   | 228/345 [01:01<00:05,\n21.22it/s]', '\\rOverwrite (json_style) epoch 1/4:  67%|######6   | 231/345\n[01:02<00:05, 21.10it/s]', '\\rOverwrite (json_style) epoch 1/4:  68%|######7   |\n234/345 [01:02<00:05, 21.26it/s]', '\\rOverwrite (json_style) epoch 1/4:\n69%|######8   | 237/345 [01:02<00:05, 21.39it/s]', '\\rOverwrite (json_style)\nepoch 1/4:  70%|######9   | 240/345 [01:02<00:04, 21.43it/s]', '\\rOverwrite\n(json_style) epoch 1/4:  70%|#######   | 243/345 [01:02<00:04, 21.47it/s]',\n'\\rOverwrite (json_style) epoch 1/4:  71%|#######1  | 246/345 [01:02<00:04,\n21.15it/s]', '\\rOverwrite (json_style) epoch 1/4:  72%|#######2  | 249/345\n[01:02<00:04, 21.28it/s]', '\\rOverwrite (json_style) epoch 1/4:  73%|#######3  |\n252/345 [01:02<00:04, 21.34it/s]', '\\rOverwrite (json_style) epoch 1/4:\n74%|#######3  | 255/345 [01:03<00:04, 21.41it/s]', '\\rOverwrite (json_style)\nepoch 1/4:  75%|#######4  | 258/345 [01:03<00:04, 21.41it/s]', '\\rOverwrite\n(json_style) epoch 1/4:  76%|#######5  | 261/345 [01:03<00:03, 21.16it/s]',\n'\\rOverwrite (json_style) epoch 1/4:  77%|#######6  | 264/345 [01:03<00:03,\n21.28it/s]', '\\rOverwrite (json_style) epoch 1/4:  77%|#######7  | 267/345\n[01:03<00:03, 21.21it/s]', '\\rOverwrite (json_style) epoch 1/4:  78%|#######8  |\n270/345 [01:03<00:03, 21.31it/s]', '\\rOverwrite (json_style) epoch 1/4:\n79%|#######9  | 273/345 [01:03<00:03, 21.34it/s]', '\\rOverwrite (json_style)\nepoch 1/4:  80%|########  | 276/345 [01:04<00:03, 21.17it/s]', '\\rOverwrite\n(json_style) epoch 1/4:  81%|########  | 279/345 [01:04<00:03, 21.15it/s]',\n'\\rOverwrite (json_style) epoch 1/4:  82%|########1 | 282/345 [01:04<00:03,\n20.94it/s]', '\\rOverwrite (json_style) epoch 1/4:  83%|########2 | 285/345\n[01:04<00:02, 21.10it/s]', '\\rOverwrite (json_style) epoch 1/4:  83%|########3 |\n288/345 [01:04<00:02, 21.12it/s]', '\\rOverwrite (json_style) epoch 1/4:\n84%|########4 | 291/345 [01:04<00:02, 21.24it/s]', '\\rOverwrite (json_style)\nepoch 1/4:  85%|########5 | 294/345 [01:04<00:02, 21.25it/s]', '\\rOverwrite\n(json_style) epoch 1/4:  86%|########6 | 297/345 [01:05<00:02, 21.08it/s]',\n'\\rOverwrite (json_style) epoch 1/4:  87%|########6 | 300/345 [01:05<00:02,\n20.94it/s]', '\\rOverwrite (json_style) epoch 1/4:  88%|########7 | 303/345\n[01:05<00:02, 20.55it/s]', '\\rOverwrite (json_style) epoch 1/4:  89%|########8 |\n306/345 [01:05<00:01, 20.85it/s]', '\\rOverwrite (json_style) epoch 1/4:\n90%|########9 | 309/345 [01:05<00:01, 20.87it/s]', '\\rOverwrite (json_style)\nepoch 1/4:  90%|######### | 312/345 [01:05<00:01, 20.94it/s]', '\\rOverwrite\n(json_style) epoch 1/4:  91%|#########1| 315/345 [01:05<00:01, 21.06it/s]',\n'\\rOverwrite (json_style) epoch 1/4:  92%|#########2| 318/345 [01:06<00:01,\n21.12it/s]', '\\rOverwrite (json_style) epoch 1/4:  93%|#########3| 321/345\n[01:06<00:01, 20.93it/s]', '\\rOverwrite (json_style) epoch 1/4:  94%|#########3|\n324/345 [01:06<00:01, 20.78it/s]', '\\rOverwrite (json_style) epoch 1/4:\n95%|#########4| 327/345 [01:06<00:00, 20.98it/s]', '\\rOverwrite (json_style)\nepoch 1/4:  96%|#########5| 330/345 [01:06<00:00, 21.09it/s]', '\\rOverwrite\n(json_style) epoch 1/4:  97%|#########6| 333/345 [01:06<00:00, 21.02it/s]',\n'\\rOverwrite (json_style) epoch 1/4:  97%|#########7| 336/345 [01:06<00:00,\n20.94it/s]', '\\rOverwrite (json_style) epoch 1/4:  98%|#########8| 339/345\n[01:07<00:00, 20.79it/s]', '\\rOverwrite (json_style) epoch 1/4:  99%|#########9|\n342/345 [01:07<00:00, 21.02it/s]', '\\rOverwrite (json_style) epoch 1/4:\n100%|##########| 345/345 [01:07<00:00, 22.06it/s]', '', '\\rOverwrite\n(json_style) epoch 1/4: 100%|##########| 345/345 [01:08<00:00,  5.03it/s]',\n'\\n', 'Epoch 1 (json_style): validation_loss = 3.6254', '\\n', '\\rOverwrite\n(json_style) epoch 2/4:   0%|          | 0/345 [00:00<?, ?it/s]', '\\rOverwrite\n(json_style) epoch 2/4:   0%|          | 1/345 [01:32<8:48:56, 92.26s/it]',\n'\\rOverwrite (json_style) epoch 2/4:   1%|          | 2/345 [01:32<3:37:31,\n38.05s/it]', '\\rOverwrite (json_style) epoch 2/4:   1%|1         | 5/345\n[01:32<1:01:26, 10.84s/it]', '\\rOverwrite (json_style) epoch 2/4:   2%|2\n| 8/345 [01:32<30:14,  5.38s/it]  ', '\\rOverwrite (json_style) epoch 2/4:   3%|3\n| 11/345 [01:32<17:30,  3.15s/it]', '\\rOverwrite (json_style) epoch 2/4:   4%|4\n| 14/345 [01:32<10:57,  1.98s/it]', '\\rOverwrite (json_style) epoch 2/4:   5%|4\n| 16/345 [01:33<08:05,  1.48s/it]', '\\rOverwrite (json_style) epoch 2/4:   6%|5\n| 19/345 [01:33<05:13,  1.04it/s]', '\\rOverwrite (json_style) epoch 2/4:   6%|6\n| 22/345 [01:33<03:30,  1.54it/s]', '\\rOverwrite (json_style) epoch 2/4:   7%|7\n| 25/345 [01:33<02:25,  2.20it/s]', '\\rOverwrite (json_style) epoch 2/4:   8%|8\n| 28/345 [01:33<01:43,  3.07it/s]', '\\rOverwrite (json_style) epoch 2/4:   9%|8\n| 31/345 [01:33<01:14,  4.19it/s]', '\\rOverwrite (json_style) epoch 2/4:  10%|9\n| 34/345 [01:33<00:55,  5.57it/s]', '\\rOverwrite (json_style) epoch 2/4:  11%|#\n| 37/345 [01:34<00:42,  7.19it/s]', '\\rOverwrite (json_style) epoch 2/4:  12%|#1\n| 40/345 [01:34<00:34,  8.94it/s]', '\\rOverwrite (json_style) epoch 2/4:  12%|#2\n| 43/345 [01:34<00:27, 10.85it/s]', '\\rOverwrite (json_style) epoch 2/4:  13%|#3\n| 46/345 [01:34<00:23, 12.72it/s]', '\\rOverwrite (json_style) epoch 2/4:  14%|#4\n| 49/345 [01:34<00:20, 14.53it/s]', '\\rOverwrite (json_style) epoch 2/4:  15%|#5\n| 52/345 [01:34<00:18, 16.13it/s]', '[2025-12-04 00:57:20] Overwrite\n(json_style) step 400: avg_train_loss=3.3390', '\\n', '\\rOverwrite (json_style)\nepoch 2/4:  16%|#5        | 55/345 [01:34<00:16, 17.43it/s]', '\\rOverwrite\n(json_style) epoch 2/4:  17%|#6        | 58/345 [01:35<00:15, 18.28it/s]',\n'\\rOverwrite (json_style) epoch 2/4:  18%|#7        | 61/345 [01:35<00:14,\n19.10it/s]', '\\rOverwrite (json_style) epoch 2/4:  19%|#8        | 64/345\n[01:35<00:14, 19.74it/s]', '\\rOverwrite (json_style) epoch 2/4:  19%|#9        |\n67/345 [01:35<00:13, 19.96it/s]', '\\rOverwrite (json_style) epoch 2/4:  20%|##\n| 70/345 [01:35<00:13, 20.45it/s]', '\\rOverwrite (json_style) epoch 2/4:\n21%|##1       | 73/345 [01:35<00:13, 20.67it/s]', '\\rOverwrite (json_style)\nepoch 2/4:  22%|##2       | 76/345 [01:35<00:12, 20.73it/s]', '\\rOverwrite\n(json_style) epoch 2/4:  23%|##2       | 79/345 [01:36<00:12, 20.67it/s]',\n'\\rOverwrite (json_style) epoch 2/4:  24%|##3       | 82/345 [01:36<00:12,\n20.64it/s]', '\\rOverwrite (json_style) epoch 2/4:  25%|##4       | 85/345\n[01:36<00:12, 20.39it/s]', '\\rOverwrite (json_style) epoch 2/4:  26%|##5       |\n88/345 [01:36<00:12, 20.46it/s]', '\\rOverwrite (json_style) epoch 2/4:  26%|##6\n| 91/345 [01:36<00:12, 20.77it/s]', '\\rOverwrite (json_style) epoch 2/4:\n27%|##7       | 94/345 [01:36<00:11, 20.96it/s]', '\\rOverwrite (json_style)\nepoch 2/4:  28%|##8       | 97/345 [01:36<00:11, 21.04it/s]', '\\rOverwrite\n(json_style) epoch 2/4:  29%|##8       | 100/345 [01:37<00:11, 21.24it/s]',\n'\\rOverwrite (json_style) epoch 2/4:  30%|##9       | 103/345 [01:37<00:11,\n21.31it/s]', '\\rOverwrite (json_style) epoch 2/4:  31%|###       | 106/345\n[01:37<00:11, 21.23it/s]', '\\rOverwrite (json_style) epoch 2/4:  32%|###1      |\n109/345 [01:37<00:11, 21.28it/s]', '\\rOverwrite (json_style) epoch 2/4:\n32%|###2      | 112/345 [01:37<00:10, 21.36it/s]', '\\rOverwrite (json_style)\nepoch 2/4:  33%|###3      | 115/345 [01:37<00:10, 21.44it/s]', '\\rOverwrite\n(json_style) epoch 2/4:  34%|###4      | 118/345 [01:37<00:10, 21.37it/s]',\n'\\rOverwrite (json_style) epoch 2/4:  35%|###5      | 121/345 [01:38<00:10,\n21.30it/s]', '\\rOverwrite (json_style) epoch 2/4:  36%|###5      | 124/345\n[01:38<00:10, 21.40it/s]', '\\rOverwrite (json_style) epoch 2/4:  37%|###6      |\n127/345 [01:38<00:10, 21.32it/s]', '\\rOverwrite (json_style) epoch 2/4:\n38%|###7      | 130/345 [01:38<00:10, 21.44it/s]', '\\rOverwrite (json_style)\nepoch 2/4:  39%|###8      | 133/345 [01:38<00:09, 21.40it/s]', '\\rOverwrite\n(json_style) epoch 2/4:  39%|###9      | 136/345 [01:38<00:10, 20.75it/s]',\n'\\rOverwrite (json_style) epoch 2/4:  40%|####      | 139/345 [01:38<00:09,\n20.62it/s]', '\\rOverwrite (json_style) epoch 2/4:  41%|####1     | 142/345\n[01:39<00:09, 20.79it/s]', '\\rOverwrite (json_style) epoch 2/4:  42%|####2     |\n145/345 [01:39<00:09, 20.78it/s]', '\\rOverwrite (json_style) epoch 2/4:\n43%|####2     | 148/345 [01:39<00:09, 21.06it/s]', '\\rOverwrite (json_style)\nepoch 2/4:  44%|####3     | 151/345 [01:39<00:09, 21.07it/s]', '\\rOverwrite\n(json_style) epoch 2/4:  45%|####4     | 154/345 [01:39<00:09, 20.97it/s]',\n'\\rOverwrite (json_style) epoch 2/4:  46%|####5     | 157/345 [01:39<00:08,\n21.16it/s]', '\\rOverwrite (json_style) epoch 2/4:  46%|####6     | 160/345\n[01:39<00:08, 21.12it/s]', '\\rOverwrite (json_style) epoch 2/4:  47%|####7     |\n163/345 [01:40<00:08, 20.97it/s]', '\\rOverwrite (json_style) epoch 2/4:\n48%|####8     | 166/345 [01:40<00:08, 20.92it/s]', '\\rOverwrite (json_style)\nepoch 2/4:  49%|####8     | 169/345 [01:40<00:08, 20.76it/s]', '\\rOverwrite\n(json_style) epoch 2/4:  50%|####9     | 172/345 [01:40<00:08, 20.53it/s]',\n'\\rOverwrite (json_style) epoch 2/4:  51%|#####     | 175/345 [01:40<00:08,\n20.72it/s]', '\\rOverwrite (json_style) epoch 2/4:  52%|#####1    | 178/345\n[01:40<00:08, 20.81it/s]', '\\rOverwrite (json_style) epoch 2/4:  52%|#####2    |\n181/345 [01:40<00:07, 20.86it/s]', '\\rOverwrite (json_style) epoch 2/4:\n53%|#####3    | 184/345 [01:41<00:07, 20.98it/s]', '\\rOverwrite (json_style)\nepoch 2/4:  54%|#####4    | 187/345 [01:41<00:07, 21.14it/s]', '\\rOverwrite\n(json_style) epoch 2/4:  55%|#####5    | 190/345 [01:41<00:07, 21.05it/s]',\n'\\rOverwrite (json_style) epoch 2/4:  56%|#####5    | 193/345 [01:41<00:07,\n21.27it/s]', '\\rOverwrite (json_style) epoch 2/4:  57%|#####6    | 196/345\n[01:41<00:06, 21.44it/s]', '\\rOverwrite (json_style) epoch 2/4:  58%|#####7    |\n199/345 [01:41<00:06, 21.17it/s]', '\\rOverwrite (json_style) epoch 2/4:\n59%|#####8    | 202/345 [01:41<00:06, 21.00it/s]', '\\rOverwrite (json_style)\nepoch 2/4:  59%|#####9    | 205/345 [01:42<00:06, 20.90it/s]', '\\rOverwrite\n(json_style) epoch 2/4:  60%|######    | 208/345 [01:42<00:06, 20.99it/s]',\n'\\rOverwrite (json_style) epoch 2/4:  61%|######1   | 211/345 [01:42<00:06,\n21.03it/s]', '\\rOverwrite (json_style) epoch 2/4:  62%|######2   | 214/345\n[01:42<00:06, 21.07it/s]', '\\rOverwrite (json_style) epoch 2/4:  63%|######2   |\n217/345 [01:42<00:06, 20.53it/s]', '\\rOverwrite (json_style) epoch 2/4:\n64%|######3   | 220/345 [01:42<00:06, 20.50it/s]', '\\rOverwrite (json_style)\nepoch 2/4:  65%|######4   | 223/345 [01:42<00:05, 20.39it/s]', '\\rOverwrite\n(json_style) epoch 2/4:  66%|######5   | 226/345 [01:43<00:05, 20.72it/s]',\n'\\rOverwrite (json_style) epoch 2/4:  66%|######6   | 229/345 [01:43<00:05,\n20.84it/s]', '\\rOverwrite (json_style) epoch 2/4:  67%|######7   | 232/345\n[01:43<00:05, 20.92it/s]', '\\rOverwrite (json_style) epoch 2/4:  68%|######8   |\n235/345 [01:43<00:05, 20.98it/s]', '\\rOverwrite (json_style) epoch 2/4:\n69%|######8   | 238/345 [01:43<00:05, 21.18it/s]', '\\rOverwrite (json_style)\nepoch 2/4:  70%|######9   | 241/345 [01:43<00:04, 21.02it/s]', '\\rOverwrite\n(json_style) epoch 2/4:  71%|#######   | 244/345 [01:43<00:04, 20.89it/s]',\n'\\rOverwrite (json_style) epoch 2/4:  72%|#######1  | 247/345 [01:44<00:04,\n20.49it/s]', '\\rOverwrite (json_style) epoch 2/4:  72%|#######2  | 250/345\n[01:44<00:04, 20.02it/s]', '\\rOverwrite (json_style) epoch 2/4:  73%|#######3  |\n253/345 [01:44<00:04, 20.22it/s]', '[2025-12-04 00:57:30] Overwrite (json_style)\nstep 600: avg_train_loss=3.3252', '\\n', '\\rOverwrite (json_style) epoch 2/4:\n74%|#######4  | 256/345 [01:44<00:04, 20.20it/s]', '\\rOverwrite (json_style)\nepoch 2/4:  75%|#######5  | 259/345 [01:44<00:04, 20.48it/s]', '\\rOverwrite\n(json_style) epoch 2/4:  76%|#######5  | 262/345 [01:44<00:04, 20.68it/s]',\n'\\rOverwrite (json_style) epoch 2/4:  77%|#######6  | 265/345 [01:44<00:03,\n20.88it/s]', '\\rOverwrite (json_style) epoch 2/4:  78%|#######7  | 268/345\n[01:45<00:03, 20.81it/s]', '\\rOverwrite (json_style) epoch 2/4:  79%|#######8  |\n271/345 [01:45<00:03, 21.04it/s]', '\\rOverwrite (json_style) epoch 2/4:\n79%|#######9  | 274/345 [01:45<00:03, 20.95it/s]', '\\rOverwrite (json_style)\nepoch 2/4:  80%|########  | 277/345 [01:45<00:03, 20.92it/s]', '\\rOverwrite\n(json_style) epoch 2/4:  81%|########1 | 280/345 [01:45<00:03, 21.15it/s]',\n'\\rOverwrite (json_style) epoch 2/4:  82%|########2 | 283/345 [01:45<00:02,\n20.98it/s]', '\\rOverwrite (json_style) epoch 2/4:  83%|########2 | 286/345\n[01:45<00:02, 20.99it/s]', '\\rOverwrite (json_style) epoch 2/4:  84%|########3 |\n289/345 [01:46<00:02, 21.23it/s]', '\\rOverwrite (json_style) epoch 2/4:\n85%|########4 | 292/345 [01:46<00:02, 21.22it/s]', '\\rOverwrite (json_style)\nepoch 2/4:  86%|########5 | 295/345 [01:46<00:02, 21.05it/s]', '\\rOverwrite\n(json_style) epoch 2/4:  86%|########6 | 298/345 [01:46<00:02, 20.81it/s]',\n'\\rOverwrite (json_style) epoch 2/4:  87%|########7 | 301/345 [01:46<00:02,\n20.95it/s]', '\\rOverwrite (json_style) epoch 2/4:  88%|########8 | 304/345\n[01:46<00:01, 20.93it/s]', '\\rOverwrite (json_style) epoch 2/4:  89%|########8 |\n307/345 [01:46<00:01, 20.90it/s]', '\\rOverwrite (json_style) epoch 2/4:\n90%|########9 | 310/345 [01:47<00:01, 20.52it/s]', '\\rOverwrite (json_style)\nepoch 2/4:  91%|######### | 313/345 [01:47<00:01, 20.60it/s]', '\\rOverwrite\n(json_style) epoch 2/4:  92%|#########1| 316/345 [01:47<00:01, 20.37it/s]',\n'\\rOverwrite (json_style) epoch 2/4:  92%|#########2| 319/345 [01:47<00:01,\n20.45it/s]', '\\rOverwrite (json_style) epoch 2/4:  93%|#########3| 322/345\n[01:47<00:01, 20.64it/s]', '\\rOverwrite (json_style) epoch 2/4:  94%|#########4|\n325/345 [01:47<00:00, 20.66it/s]', '\\rOverwrite (json_style) epoch 2/4:\n95%|#########5| 328/345 [01:47<00:00, 20.37it/s]', '\\rOverwrite (json_style)\nepoch 2/4:  96%|#########5| 331/345 [01:48<00:00, 20.41it/s]', '\\rOverwrite\n(json_style) epoch 2/4:  97%|#########6| 334/345 [01:48<00:00, 20.56it/s]',\n'\\rOverwrite (json_style) epoch 2/4:  98%|#########7| 337/345 [01:48<00:00,\n20.39it/s]', '\\rOverwrite (json_style) epoch 2/4:  99%|#########8| 340/345\n[01:48<00:00, 20.65it/s]', '\\rOverwrite (json_style) epoch 2/4:  99%|#########9|\n343/345 [01:48<00:00, 20.84it/s]', '', '\\rOverwrite (json_style) epoch 2/4:\n100%|##########| 345/345 [01:49<00:00,  3.14it/s]', '\\n', 'Epoch 2 (json_style):\nvalidation_loss = 3.6441', '\\n', '\\rOverwrite (json_style) epoch 3/4:   0%|\n| 0/345 [00:00<?, ?it/s]', '\\rOverwrite (json_style) epoch 3/4:   0%|          |\n1/345 [00:59<5:39:53, 59.28s/it]', '\\rOverwrite (json_style) epoch 3/4:   1%|\n| 3/345 [00:59<1:27:54, 15.42s/it]', '\\rOverwrite (json_style) epoch 3/4:   2%|1\n| 6/345 [00:59<33:50,  5.99s/it]  ', '\\rOverwrite (json_style) epoch 3/4:   3%|2\n| 9/345 [00:59<17:59,  3.21s/it]', '\\rOverwrite (json_style) epoch 3/4:   3%|3\n| 12/345 [00:59<10:48,  1.95s/it]', '\\rOverwrite (json_style) epoch 3/4:   4%|4\n| 15/345 [00:59<06:54,  1.26s/it]', '\\rOverwrite (json_style) epoch 3/4:   5%|5\n| 18/345 [01:00<04:35,  1.19it/s]', '\\rOverwrite (json_style) epoch 3/4:   6%|6\n| 21/345 [01:00<03:08,  1.72it/s]', '\\rOverwrite (json_style) epoch 3/4:   7%|6\n| 24/345 [01:00<02:11,  2.43it/s]', '\\rOverwrite (json_style) epoch 3/4:   8%|7\n| 27/345 [01:00<01:34,  3.36it/s]', '\\rOverwrite (json_style) epoch 3/4:   9%|8\n| 30/345 [01:00<01:09,  4.53it/s]', '\\rOverwrite (json_style) epoch 3/4:  10%|9\n| 33/345 [01:00<00:52,  5.96it/s]', '\\rOverwrite (json_style) epoch 3/4:  10%|#\n| 36/345 [01:00<00:40,  7.62it/s]', '\\rOverwrite (json_style) epoch 3/4:  11%|#1\n| 39/345 [01:01<00:32,  9.48it/s]', '\\rOverwrite (json_style) epoch 3/4:  12%|#2\n| 42/345 [01:01<00:26, 11.33it/s]', '\\rOverwrite (json_style) epoch 3/4:  13%|#3\n| 45/345 [01:01<00:22, 13.10it/s]', '\\rOverwrite (json_style) epoch 3/4:  14%|#3\n| 48/345 [01:01<00:20, 14.66it/s]', '\\rOverwrite (json_style) epoch 3/4:  15%|#4\n| 51/345 [01:01<00:18, 15.94it/s]', '\\rOverwrite (json_style) epoch 3/4:  16%|#5\n| 54/345 [01:01<00:17, 17.08it/s]', '\\rOverwrite (json_style) epoch 3/4:  17%|#6\n| 57/345 [01:02<00:15, 18.20it/s]', '\\rOverwrite (json_style) epoch 3/4:  17%|#7\n| 60/345 [01:02<00:14, 19.09it/s]', '\\rOverwrite (json_style) epoch 3/4:  18%|#8\n| 63/345 [01:02<00:14, 19.74it/s]', '\\rOverwrite (json_style) epoch 3/4:  19%|#9\n| 66/345 [01:02<00:13, 20.16it/s]', '\\rOverwrite (json_style) epoch 3/4:  20%|##\n| 69/345 [01:02<00:13, 20.30it/s]', '\\rOverwrite (json_style) epoch 3/4:  21%|##\n| 72/345 [01:02<00:13, 20.41it/s]', '\\rOverwrite (json_style) epoch 3/4:\n22%|##1       | 75/345 [01:02<00:13, 20.46it/s]', '\\rOverwrite (json_style)\nepoch 3/4:  23%|##2       | 78/345 [01:03<00:12, 20.72it/s]', '\\rOverwrite\n(json_style) epoch 3/4:  23%|##3       | 81/345 [01:03<00:12, 20.50it/s]',\n'\\rOverwrite (json_style) epoch 3/4:  24%|##4       | 84/345 [01:03<00:12,\n20.61it/s]', '\\rOverwrite (json_style) epoch 3/4:  25%|##5       | 87/345\n[01:03<00:12, 20.69it/s]', '\\rOverwrite (json_style) epoch 3/4:  26%|##6       |\n90/345 [01:03<00:12, 20.93it/s]', '\\rOverwrite (json_style) epoch 3/4:  27%|##6\n| 93/345 [01:03<00:12, 20.71it/s]', '\\rOverwrite (json_style) epoch 3/4:\n28%|##7       | 96/345 [01:03<00:11, 20.83it/s]', '\\rOverwrite (json_style)\nepoch 3/4:  29%|##8       | 99/345 [01:04<00:11, 20.61it/s]', '\\rOverwrite\n(json_style) epoch 3/4:  30%|##9       | 102/345 [01:04<00:12, 20.24it/s]',\n'\\rOverwrite (json_style) epoch 3/4:  30%|###       | 105/345 [01:04<00:11,\n20.46it/s]', '\\rOverwrite (json_style) epoch 3/4:  31%|###1      | 108/345\n[01:04<00:11, 20.70it/s]', '[2025-12-04 00:59:46] Overwrite (json_style) step\n800: avg_train_loss=3.0838', '\\n', '\\rOverwrite (json_style) epoch 3/4:\n32%|###2      | 111/345 [01:04<00:11, 20.92it/s]', '\\rOverwrite (json_style)\nepoch 3/4:  33%|###3      | 114/345 [01:04<00:10, 21.06it/s]', '\\rOverwrite\n(json_style) epoch 3/4:  34%|###3      | 117/345 [01:04<00:10, 20.82it/s]',\n'\\rOverwrite (json_style) epoch 3/4:  35%|###4      | 120/345 [01:05<00:10,\n21.08it/s]', '\\rOverwrite (json_style) epoch 3/4:  36%|###5      | 123/345\n[01:05<00:10, 20.90it/s]', '\\rOverwrite (json_style) epoch 3/4:  37%|###6      |\n126/345 [01:05<00:10, 20.98it/s]', '\\rOverwrite (json_style) epoch 3/4:\n37%|###7      | 129/345 [01:05<00:10, 20.88it/s]', '\\rOverwrite (json_style)\nepoch 3/4:  38%|###8      | 132/345 [01:05<00:10, 20.98it/s]', '\\rOverwrite\n(json_style) epoch 3/4:  39%|###9      | 135/345 [01:05<00:10, 20.74it/s]',\n'\\rOverwrite (json_style) epoch 3/4:  40%|####      | 138/345 [01:05<00:09,\n20.87it/s]', '\\rOverwrite (json_style) epoch 3/4:  41%|####      | 141/345\n[01:06<00:09, 20.93it/s]', '\\rOverwrite (json_style) epoch 3/4:  42%|####1     |\n144/345 [01:06<00:09, 21.00it/s]', '\\rOverwrite (json_style) epoch 3/4:\n43%|####2     | 147/345 [01:06<00:09, 21.02it/s]', '\\rOverwrite (json_style)\nepoch 3/4:  43%|####3     | 150/345 [01:06<00:09, 21.14it/s]', '\\rOverwrite\n(json_style) epoch 3/4:  44%|####4     | 153/345 [01:06<00:09, 21.12it/s]',\n'\\rOverwrite (json_style) epoch 3/4:  45%|####5     | 156/345 [01:06<00:08,\n21.28it/s]', '\\rOverwrite (json_style) epoch 3/4:  46%|####6     | 159/345\n[01:06<00:08, 20.98it/s]', '\\rOverwrite (json_style) epoch 3/4:  47%|####6     |\n162/345 [01:07<00:08, 20.70it/s]', '\\rOverwrite (json_style) epoch 3/4:\n48%|####7     | 165/345 [01:07<00:08, 20.70it/s]', '\\rOverwrite (json_style)\nepoch 3/4:  49%|####8     | 168/345 [01:07<00:08, 20.67it/s]', '\\rOverwrite\n(json_style) epoch 3/4:  50%|####9     | 171/345 [01:07<00:08, 20.61it/s]',\n'\\rOverwrite (json_style) epoch 3/4:  50%|#####     | 174/345 [01:07<00:08,\n20.58it/s]', '\\rOverwrite (json_style) epoch 3/4:  51%|#####1    | 177/345\n[01:07<00:08, 20.72it/s]', '\\rOverwrite (json_style) epoch 3/4:  52%|#####2    |\n180/345 [01:07<00:07, 20.82it/s]', '\\rOverwrite (json_style) epoch 3/4:\n53%|#####3    | 183/345 [01:08<00:07, 20.88it/s]', '\\rOverwrite (json_style)\nepoch 3/4:  54%|#####3    | 186/345 [01:08<00:07, 20.84it/s]', '\\rOverwrite\n(json_style) epoch 3/4:  55%|#####4    | 189/345 [01:08<00:07, 20.70it/s]',\n'\\rOverwrite (json_style) epoch 3/4:  56%|#####5    | 192/345 [01:08<00:07,\n20.96it/s]', '\\rOverwrite (json_style) epoch 3/4:  57%|#####6    | 195/345\n[01:08<00:07, 21.06it/s]', '\\rOverwrite (json_style) epoch 3/4:  57%|#####7    |\n198/345 [01:08<00:07, 20.79it/s]', '\\rOverwrite (json_style) epoch 3/4:\n58%|#####8    | 201/345 [01:08<00:06, 20.85it/s]', '\\rOverwrite (json_style)\nepoch 3/4:  59%|#####9    | 204/345 [01:09<00:06, 21.08it/s]', '\\rOverwrite\n(json_style) epoch 3/4:  60%|######    | 207/345 [01:09<00:06, 21.30it/s]',\n'\\rOverwrite (json_style) epoch 3/4:  61%|######    | 210/345 [01:09<00:06,\n21.36it/s]', '\\rOverwrite (json_style) epoch 3/4:  62%|######1   | 213/345\n[01:09<00:06, 21.17it/s]', '\\rOverwrite (json_style) epoch 3/4:  63%|######2   |\n216/345 [01:09<00:06, 21.23it/s]', '\\rOverwrite (json_style) epoch 3/4:\n63%|######3   | 219/345 [01:09<00:05, 21.16it/s]', '\\rOverwrite (json_style)\nepoch 3/4:  64%|######4   | 222/345 [01:09<00:05, 21.12it/s]', '\\rOverwrite\n(json_style) epoch 3/4:  65%|######5   | 225/345 [01:10<00:05, 20.97it/s]',\n'\\rOverwrite (json_style) epoch 3/4:  66%|######6   | 228/345 [01:10<00:05,\n20.98it/s]', '\\rOverwrite (json_style) epoch 3/4:  67%|######6   | 231/345\n[01:10<00:05, 21.01it/s]', '\\rOverwrite (json_style) epoch 3/4:  68%|######7   |\n234/345 [01:10<00:05, 21.11it/s]', '\\rOverwrite (json_style) epoch 3/4:\n69%|######8   | 237/345 [01:10<00:05, 21.13it/s]', '\\rOverwrite (json_style)\nepoch 3/4:  70%|######9   | 240/345 [01:10<00:04, 21.17it/s]', '\\rOverwrite\n(json_style) epoch 3/4:  70%|#######   | 243/345 [01:10<00:04, 20.91it/s]',\n'\\rOverwrite (json_style) epoch 3/4:  71%|#######1  | 246/345 [01:11<00:04,\n21.08it/s]', '\\rOverwrite (json_style) epoch 3/4:  72%|#######2  | 249/345\n[01:11<00:04, 20.91it/s]', '\\rOverwrite (json_style) epoch 3/4:  73%|#######3  |\n252/345 [01:11<00:04, 20.88it/s]', '\\rOverwrite (json_style) epoch 3/4:\n74%|#######3  | 255/345 [01:11<00:04, 20.61it/s]', '\\rOverwrite (json_style)\nepoch 3/4:  75%|#######4  | 258/345 [01:11<00:04, 20.61it/s]', '\\rOverwrite\n(json_style) epoch 3/4:  76%|#######5  | 261/345 [01:11<00:04, 20.17it/s]',\n'\\rOverwrite (json_style) epoch 3/4:  77%|#######6  | 264/345 [01:11<00:04,\n20.11it/s]', '\\rOverwrite (json_style) epoch 3/4:  77%|#######7  | 267/345\n[01:12<00:03, 20.40it/s]', '\\rOverwrite (json_style) epoch 3/4:  78%|#######8  |\n270/345 [01:12<00:03, 20.63it/s]', '\\rOverwrite (json_style) epoch 3/4:\n79%|#######9  | 273/345 [01:12<00:03, 20.87it/s]', '\\rOverwrite (json_style)\nepoch 3/4:  80%|########  | 276/345 [01:12<00:03, 21.01it/s]', '\\rOverwrite\n(json_style) epoch 3/4:  81%|########  | 279/345 [01:12<00:03, 21.13it/s]',\n'\\rOverwrite (json_style) epoch 3/4:  82%|########1 | 282/345 [01:12<00:02,\n21.17it/s]', '\\rOverwrite (json_style) epoch 3/4:  83%|########2 | 285/345\n[01:12<00:02, 21.31it/s]', '\\rOverwrite (json_style) epoch 3/4:  83%|########3 |\n288/345 [01:13<00:02, 21.37it/s]', '\\rOverwrite (json_style) epoch 3/4:\n84%|########4 | 291/345 [01:13<00:02, 21.37it/s]', '\\rOverwrite (json_style)\nepoch 3/4:  85%|########5 | 294/345 [01:13<00:02, 21.25it/s]', '\\rOverwrite\n(json_style) epoch 3/4:  86%|########6 | 297/345 [01:13<00:02, 20.84it/s]',\n'\\rOverwrite (json_style) epoch 3/4:  87%|########6 | 300/345 [01:13<00:02,\n20.69it/s]', '\\rOverwrite (json_style) epoch 3/4:  88%|########7 | 303/345\n[01:13<00:02, 20.84it/s]', '\\rOverwrite (json_style) epoch 3/4:  89%|########8 |\n306/345 [01:13<00:01, 20.86it/s]', '\\rOverwrite (json_style) epoch 3/4:\n90%|########9 | 309/345 [01:14<00:01, 20.47it/s]', '[2025-12-04 00:59:55]\nOverwrite (json_style) step 1000: avg_train_loss=3.0892', '\\n', '\\rOverwrite\n(json_style) epoch 3/4:  90%|######### | 312/345 [01:14<00:01, 20.57it/s]',\n'\\rOverwrite (json_style) epoch 3/4:  91%|#########1| 315/345 [01:14<00:01,\n20.80it/s]', '\\rOverwrite (json_style) epoch 3/4:  92%|#########2| 318/345\n[01:14<00:01, 20.97it/s]', '\\rOverwrite (json_style) epoch 3/4:  93%|#########3|\n321/345 [01:14<00:01, 20.90it/s]', '\\rOverwrite (json_style) epoch 3/4:\n94%|#########3| 324/345 [01:14<00:00, 21.09it/s]', '\\rOverwrite (json_style)\nepoch 3/4:  95%|#########4| 327/345 [01:14<00:00, 21.03it/s]', '\\rOverwrite\n(json_style) epoch 3/4:  96%|#########5| 330/345 [01:15<00:00, 20.99it/s]',\n'\\rOverwrite (json_style) epoch 3/4:  97%|#########6| 333/345 [01:15<00:00,\n21.13it/s]', '\\rOverwrite (json_style) epoch 3/4:  97%|#########7| 336/345\n[01:15<00:00, 21.12it/s]', '\\rOverwrite (json_style) epoch 3/4:  98%|#########8|\n339/345 [01:15<00:00, 20.84it/s]', '\\rOverwrite (json_style) epoch 3/4:\n99%|#########9| 342/345 [01:15<00:00, 20.83it/s]', '\\rOverwrite (json_style)\nepoch 3/4: 100%|##########| 345/345 [01:15<00:00, 21.66it/s]', '', '\\rOverwrite\n(json_style) epoch 3/4: 100%|##########| 345/345 [01:16<00:00,  4.49it/s]',\n'\\n', 'Epoch 3 (json_style): validation_loss = 3.6755', '\\n', '\\rOverwrite\n(json_style) epoch 4/4:   0%|          | 0/345 [00:00<?, ?it/s]', '\\rOverwrite\n(json_style) epoch 4/4:   0%|          | 1/345 [00:55<5:19:11, 55.67s/it]',\n'\\rOverwrite (json_style) epoch 4/4:   1%|          | 3/345 [00:55<1:22:33,\n14.48s/it]', '\\rOverwrite (json_style) epoch 4/4:   2%|1         | 6/345\n[00:55<31:47,  5.63s/it]  ', '\\rOverwrite (json_style) epoch 4/4:   3%|2\n| 9/345 [00:56<16:55,  3.02s/it]', '\\rOverwrite (json_style) epoch 4/4:   3%|3\n| 12/345 [00:56<10:09,  1.83s/it]', '\\rOverwrite (json_style) epoch 4/4:   4%|4\n| 15/345 [00:56<06:29,  1.18s/it]', '\\rOverwrite (json_style) epoch 4/4:   5%|5\n| 18/345 [00:56<04:19,  1.26it/s]', '\\rOverwrite (json_style) epoch 4/4:   6%|6\n| 21/345 [00:56<02:57,  1.82it/s]', '\\rOverwrite (json_style) epoch 4/4:   7%|6\n| 24/345 [00:56<02:05,  2.57it/s]', '\\rOverwrite (json_style) epoch 4/4:   8%|7\n| 27/345 [00:56<01:29,  3.54it/s]', '\\rOverwrite (json_style) epoch 4/4:   9%|8\n| 30/345 [00:57<01:05,  4.78it/s]', '\\rOverwrite (json_style) epoch 4/4:  10%|9\n| 33/345 [00:57<00:49,  6.27it/s]', '\\rOverwrite (json_style) epoch 4/4:  10%|#\n| 36/345 [00:57<00:38,  7.99it/s]', '\\rOverwrite (json_style) epoch 4/4:  11%|#1\n| 39/345 [00:57<00:31,  9.82it/s]', '\\rOverwrite (json_style) epoch 4/4:  12%|#2\n| 42/345 [00:57<00:25, 11.68it/s]', '\\rOverwrite (json_style) epoch 4/4:  13%|#3\n| 45/345 [00:57<00:22, 13.53it/s]', '\\rOverwrite (json_style) epoch 4/4:  14%|#3\n| 48/345 [00:57<00:19, 15.23it/s]', '\\rOverwrite (json_style) epoch 4/4:  15%|#4\n| 51/345 [00:58<00:17, 16.72it/s]', '\\rOverwrite (json_style) epoch 4/4:  16%|#5\n| 54/345 [00:58<00:16, 17.96it/s]', '\\rOverwrite (json_style) epoch 4/4:  17%|#6\n| 57/345 [00:58<00:15, 18.95it/s]', '\\rOverwrite (json_style) epoch 4/4:  17%|#7\n| 60/345 [00:58<00:14, 19.70it/s]', '\\rOverwrite (json_style) epoch 4/4:  18%|#8\n| 63/345 [00:58<00:14, 20.06it/s]', '\\rOverwrite (json_style) epoch 4/4:  19%|#9\n| 66/345 [00:58<00:13, 20.45it/s]', '\\rOverwrite (json_style) epoch 4/4:  20%|##\n| 69/345 [00:58<00:13, 20.81it/s]', '\\rOverwrite (json_style) epoch 4/4:  21%|##\n| 72/345 [00:59<00:13, 20.96it/s]', '\\rOverwrite (json_style) epoch 4/4:\n22%|##1       | 75/345 [00:59<00:12, 21.17it/s]', '\\rOverwrite (json_style)\nepoch 4/4:  23%|##2       | 78/345 [00:59<00:12, 21.29it/s]', '\\rOverwrite\n(json_style) epoch 4/4:  23%|##3       | 81/345 [00:59<00:12, 21.40it/s]',\n'\\rOverwrite (json_style) epoch 4/4:  24%|##4       | 84/345 [00:59<00:12,\n21.47it/s]', '\\rOverwrite (json_style) epoch 4/4:  25%|##5       | 87/345\n[00:59<00:12, 21.40it/s]', '\\rOverwrite (json_style) epoch 4/4:  26%|##6       |\n90/345 [00:59<00:11, 21.51it/s]', '\\rOverwrite (json_style) epoch 4/4:  27%|##6\n| 93/345 [01:00<00:11, 21.67it/s]', '\\rOverwrite (json_style) epoch 4/4:\n28%|##7       | 96/345 [01:00<00:11, 21.62it/s]', '\\rOverwrite (json_style)\nepoch 4/4:  29%|##8       | 99/345 [01:00<00:11, 21.47it/s]', '\\rOverwrite\n(json_style) epoch 4/4:  30%|##9       | 102/345 [01:00<00:11, 21.31it/s]',\n'\\rOverwrite (json_style) epoch 4/4:  30%|###       | 105/345 [01:00<00:11,\n21.24it/s]', '\\rOverwrite (json_style) epoch 4/4:  31%|###1      | 108/345\n[01:00<00:11, 21.05it/s]', '\\rOverwrite (json_style) epoch 4/4:  32%|###2      |\n111/345 [01:00<00:10, 21.30it/s]', '\\rOverwrite (json_style) epoch 4/4:\n33%|###3      | 114/345 [01:01<00:10, 21.43it/s]', '\\rOverwrite (json_style)\nepoch 4/4:  34%|###3      | 117/345 [01:01<00:10, 21.39it/s]', '\\rOverwrite\n(json_style) epoch 4/4:  35%|###4      | 120/345 [01:01<00:10, 21.27it/s]',\n'\\rOverwrite (json_style) epoch 4/4:  36%|###5      | 123/345 [01:01<00:10,\n21.27it/s]', '\\rOverwrite (json_style) epoch 4/4:  37%|###6      | 126/345\n[01:01<00:10, 21.36it/s]', '\\rOverwrite (json_style) epoch 4/4:  37%|###7      |\n129/345 [01:01<00:10, 21.32it/s]', '\\rOverwrite (json_style) epoch 4/4:\n38%|###8      | 132/345 [01:01<00:10, 21.14it/s]', '\\rOverwrite (json_style)\nepoch 4/4:  39%|###9      | 135/345 [01:02<00:09, 21.04it/s]', '\\rOverwrite\n(json_style) epoch 4/4:  40%|####      | 138/345 [01:02<00:09, 21.13it/s]',\n'\\rOverwrite (json_style) epoch 4/4:  41%|####      | 141/345 [01:02<00:09,\n21.26it/s]', '\\rOverwrite (json_style) epoch 4/4:  42%|####1     | 144/345\n[01:02<00:09, 21.37it/s]', '\\rOverwrite (json_style) epoch 4/4:  43%|####2     |\n147/345 [01:02<00:09, 21.31it/s]', '\\rOverwrite (json_style) epoch 4/4:\n43%|####3     | 150/345 [01:02<00:09, 21.37it/s]', '\\rOverwrite (json_style)\nepoch 4/4:  44%|####4     | 153/345 [01:02<00:09, 21.06it/s]', '\\rOverwrite\n(json_style) epoch 4/4:  45%|####5     | 156/345 [01:02<00:08, 21.03it/s]',\n'\\rOverwrite (json_style) epoch 4/4:  46%|####6     | 159/345 [01:03<00:08,\n21.03it/s]', '\\rOverwrite (json_style) epoch 4/4:  47%|####6     | 162/345\n[01:03<00:08, 21.08it/s]', '[2025-12-04 01:02:39] Overwrite (json_style) step\n1200: avg_train_loss=2.8747', '\\n', '\\rOverwrite (json_style) epoch 4/4:\n48%|####7     | 165/345 [01:03<00:08, 21.00it/s]', '\\rOverwrite (json_style)\nepoch 4/4:  49%|####8     | 168/345 [01:03<00:08, 20.72it/s]', '\\rOverwrite\n(json_style) epoch 4/4:  50%|####9     | 171/345 [01:03<00:08, 20.73it/s]',\n'\\rOverwrite (json_style) epoch 4/4:  50%|#####     | 174/345 [01:03<00:08,\n20.87it/s]', '\\rOverwrite (json_style) epoch 4/4:  51%|#####1    | 177/345\n[01:04<00:08, 20.68it/s]', '\\rOverwrite (json_style) epoch 4/4:  52%|#####2    |\n180/345 [01:04<00:07, 20.71it/s]', '\\rOverwrite (json_style) epoch 4/4:\n53%|#####3    | 183/345 [01:04<00:07, 20.73it/s]', '\\rOverwrite (json_style)\nepoch 4/4:  54%|#####3    | 186/345 [01:04<00:07, 20.95it/s]', '\\rOverwrite\n(json_style) epoch 4/4:  55%|#####4    | 189/345 [01:04<00:07, 21.13it/s]',\n'\\rOverwrite (json_style) epoch 4/4:  56%|#####5    | 192/345 [01:04<00:07,\n21.26it/s]', '\\rOverwrite (json_style) epoch 4/4:  57%|#####6    | 195/345\n[01:04<00:07, 20.95it/s]', '\\rOverwrite (json_style) epoch 4/4:  57%|#####7    |\n198/345 [01:05<00:07, 20.51it/s]', '\\rOverwrite (json_style) epoch 4/4:\n58%|#####8    | 201/345 [01:05<00:07, 20.43it/s]', '\\rOverwrite (json_style)\nepoch 4/4:  59%|#####9    | 204/345 [01:05<00:06, 20.48it/s]', '\\rOverwrite\n(json_style) epoch 4/4:  60%|######    | 207/345 [01:05<00:06, 20.54it/s]',\n'\\rOverwrite (json_style) epoch 4/4:  61%|######    | 210/345 [01:05<00:06,\n20.68it/s]', '\\rOverwrite (json_style) epoch 4/4:  62%|######1   | 213/345\n[01:05<00:06, 20.81it/s]', '\\rOverwrite (json_style) epoch 4/4:  63%|######2   |\n216/345 [01:05<00:06, 21.00it/s]', '\\rOverwrite (json_style) epoch 4/4:\n63%|######3   | 219/345 [01:06<00:05, 21.15it/s]', '\\rOverwrite (json_style)\nepoch 4/4:  64%|######4   | 222/345 [01:06<00:05, 21.16it/s]', '\\rOverwrite\n(json_style) epoch 4/4:  65%|######5   | 225/345 [01:06<00:05, 21.28it/s]',\n'\\rOverwrite (json_style) epoch 4/4:  66%|######6   | 228/345 [01:06<00:05,\n21.39it/s]', '\\rOverwrite (json_style) epoch 4/4:  67%|######6   | 231/345\n[01:06<00:05, 21.38it/s]', '\\rOverwrite (json_style) epoch 4/4:  68%|######7   |\n234/345 [01:06<00:05, 21.39it/s]', '\\rOverwrite (json_style) epoch 4/4:\n69%|######8   | 237/345 [01:06<00:05, 21.28it/s]', '\\rOverwrite (json_style)\nepoch 4/4:  70%|######9   | 240/345 [01:07<00:04, 21.04it/s]', '\\rOverwrite\n(json_style) epoch 4/4:  70%|#######   | 243/345 [01:07<00:04, 20.94it/s]',\n'\\rOverwrite (json_style) epoch 4/4:  71%|#######1  | 246/345 [01:07<00:04,\n21.06it/s]', '\\rOverwrite (json_style) epoch 4/4:  72%|#######2  | 249/345\n[01:07<00:04, 20.83it/s]', '\\rOverwrite (json_style) epoch 4/4:  73%|#######3  |\n252/345 [01:07<00:04, 20.95it/s]', '\\rOverwrite (json_style) epoch 4/4:\n74%|#######3  | 255/345 [01:07<00:04, 21.15it/s]', '\\rOverwrite (json_style)\nepoch 4/4:  75%|#######4  | 258/345 [01:07<00:04, 21.14it/s]', '\\rOverwrite\n(json_style) epoch 4/4:  76%|#######5  | 261/345 [01:08<00:03, 21.18it/s]',\n'\\rOverwrite (json_style) epoch 4/4:  77%|#######6  | 264/345 [01:08<00:03,\n21.30it/s]', '\\rOverwrite (json_style) epoch 4/4:  77%|#######7  | 267/345\n[01:08<00:03, 21.39it/s]', '\\rOverwrite (json_style) epoch 4/4:  78%|#######8  |\n270/345 [01:08<00:03, 20.75it/s]', '\\rOverwrite (json_style) epoch 4/4:\n79%|#######9  | 273/345 [01:08<00:03, 20.98it/s]', '\\rOverwrite (json_style)\nepoch 4/4:  80%|########  | 276/345 [01:08<00:03, 21.09it/s]', '\\rOverwrite\n(json_style) epoch 4/4:  81%|########  | 279/345 [01:08<00:03, 21.06it/s]',\n'\\rOverwrite (json_style) epoch 4/4:  82%|########1 | 282/345 [01:09<00:02,\n21.02it/s]', '\\rOverwrite (json_style) epoch 4/4:  83%|########2 | 285/345\n[01:09<00:02, 21.11it/s]', '\\rOverwrite (json_style) epoch 4/4:  83%|########3 |\n288/345 [01:09<00:02, 21.10it/s]', '\\rOverwrite (json_style) epoch 4/4:\n84%|########4 | 291/345 [01:09<00:02, 21.11it/s]', '\\rOverwrite (json_style)\nepoch 4/4:  85%|########5 | 294/345 [01:09<00:02, 21.22it/s]', '\\rOverwrite\n(json_style) epoch 4/4:  86%|########6 | 297/345 [01:09<00:02, 21.11it/s]',\n'\\rOverwrite (json_style) epoch 4/4:  87%|########6 | 300/345 [01:09<00:02,\n21.29it/s]', '\\rOverwrite (json_style) epoch 4/4:  88%|########7 | 303/345\n[01:09<00:01, 21.08it/s]', '\\rOverwrite (json_style) epoch 4/4:  89%|########8 |\n306/345 [01:10<00:01, 20.94it/s]', '\\rOverwrite (json_style) epoch 4/4:\n90%|########9 | 309/345 [01:10<00:01, 20.88it/s]', '\\rOverwrite (json_style)\nepoch 4/4:  90%|######### | 312/345 [01:10<00:01, 20.52it/s]', '\\rOverwrite\n(json_style) epoch 4/4:  91%|#########1| 315/345 [01:10<00:01, 20.68it/s]',\n'\\rOverwrite (json_style) epoch 4/4:  92%|#########2| 318/345 [01:10<00:01,\n20.48it/s]', '\\rOverwrite (json_style) epoch 4/4:  93%|#########3| 321/345\n[01:10<00:01, 20.64it/s]', '\\rOverwrite (json_style) epoch 4/4:  94%|#########3|\n324/345 [01:11<00:01, 20.82it/s]', '\\rOverwrite (json_style) epoch 4/4:\n95%|#########4| 327/345 [01:11<00:00, 20.84it/s]', '\\rOverwrite (json_style)\nepoch 4/4:  96%|#########5| 330/345 [01:11<00:00, 21.03it/s]', '\\rOverwrite\n(json_style) epoch 4/4:  97%|#########6| 333/345 [01:11<00:00, 21.12it/s]',\n'\\rOverwrite (json_style) epoch 4/4:  97%|#########7| 336/345 [01:11<00:00,\n21.13it/s]', '\\rOverwrite (json_style) epoch 4/4:  98%|#########8| 339/345\n[01:11<00:00, 21.25it/s]', '\\rOverwrite (json_style) epoch 4/4:  99%|#########9|\n342/345 [01:11<00:00, 21.28it/s]', '\\rOverwrite (json_style) epoch 4/4:\n100%|##########| 345/345 [01:11<00:00, 22.15it/s]', '', '\\rOverwrite\n(json_style) epoch 4/4: 100%|##########| 345/345 [01:13<00:00,  4.72it/s]',\n'\\n', 'Epoch 4 (json_style): validation_loss = 3.7306', '\\n', '\\n===== Starting\ncondition: mixture =====', '\\n', '\\rMap:   0%|          | 0/2000 [00:00<?, ?\nexamples/s]', '', '\\rMap: 100%|##########| 2000/2000 [00:00<00:00, 36166.83\nexamples/s]', '\\n', '\\rMap:   0%|          | 0/300 [00:00<?, ? examples/s]', '',\n'\\rMap: 100%|##########| 300/300 [00:00<00:00, 18128.65 examples/s]', '\\n',\n'\\rTraining mixture_phase1 epoch 1/1:   0%|          | 0/21 [00:00<?, ?it/s]',\n'\\rTraining mixture_phase1 epoch 1/1:   5%|4         | 1/21 [00:51<17:02,\n51.15s/it]', '\\rTraining mixture_phase1 epoch 1/1:  10%|9         | 2/21\n[00:51<06:41, 21.13s/it]', '\\rTraining mixture_phase1 epoch 1/1:  14%|#4\n| 3/21 [00:51<03:27, 11.53s/it]', '\\rTraining mixture_phase1 epoch 1/1:  19%|#9\n| 4/21 [00:51<01:59,  7.03s/it]', '\\rTraining mixture_phase1 epoch 1/1:  24%|##3\n| 5/21 [00:51<01:12,  4.53s/it]', '\\rTraining mixture_phase1 epoch 1/1:  29%|##8\n| 6/21 [00:51<00:45,  3.03s/it]', '\\rTraining mixture_phase1 epoch 1/1:\n33%|###3      | 7/21 [00:51<00:29,  2.08s/it]', '\\rTraining mixture_phase1 epoch\n1/1:  38%|###8      | 8/21 [00:51<00:18,  1.45s/it]', '\\rTraining mixture_phase1\nepoch 1/1:  43%|####2     | 9/21 [00:52<00:12,  1.03s/it]', '\\rTraining\nmixture_phase1 epoch 1/1:  48%|####7     | 10/21 [00:52<00:08,  1.33it/s]',\n'\\rTraining mixture_phase1 epoch 1/1:  52%|#####2    | 11/21 [00:52<00:05,\n1.80it/s]', '\\rTraining mixture_phase1 epoch 1/1:  57%|#####7    | 12/21\n[00:52<00:03,  2.37it/s]', '\\rTraining mixture_phase1 epoch 1/1:  62%|######1\n| 13/21 [00:52<00:02,  3.04it/s]', '\\rTraining mixture_phase1 epoch 1/1:\n67%|######6   | 14/21 [00:52<00:01,  3.78it/s]', '\\rTraining mixture_phase1\nepoch 1/1:  71%|#######1  | 15/21 [00:52<00:01,  4.56it/s]', '\\rTraining\nmixture_phase1 epoch 1/1:  76%|#######6  | 16/21 [00:52<00:00,  5.32it/s]',\n'\\rTraining mixture_phase1 epoch 1/1:  81%|########  | 17/21 [00:52<00:00,\n5.99it/s]', '\\rTraining mixture_phase1 epoch 1/1:  86%|########5 | 18/21\n[00:53<00:00,  6.62it/s]', '\\rTraining mixture_phase1 epoch 1/1:  90%|#########\n| 19/21 [00:53<00:00,  7.13it/s]', '\\rTraining mixture_phase1 epoch 1/1:\n95%|#########5| 20/21 [00:53<00:00,  7.54it/s]', '', '\\rTraining mixture_phase1\nepoch 1/1: 100%|##########| 21/21 [00:54<00:00,  2.60s/it]', '\\n', 'Epoch 1:\nvalidation_loss = 3.1587', '\\n', '\\rOverwrite (mixture) epoch 1/4:   0%|\n| 0/345 [00:00<?, ?it/s]', '\\rOverwrite (mixture) epoch 1/4:   0%|          |\n1/345 [00:55<5:17:38, 55.40s/it]', '\\rOverwrite (mixture) epoch 1/4:   1%|\n| 3/345 [00:55<1:22:09, 14.41s/it]', '\\rOverwrite (mixture) epoch 1/4:   1%|1\n| 5/345 [00:55<39:49,  7.03s/it]  ', '\\rOverwrite (mixture) epoch 1/4:   2%|2\n| 8/345 [00:55<18:55,  3.37s/it]', '\\rOverwrite (mixture) epoch 1/4:   3%|3\n| 11/345 [00:55<10:50,  1.95s/it]', '\\rOverwrite (mixture) epoch 1/4:   4%|4\n| 14/345 [00:56<06:45,  1.22s/it]', '\\rOverwrite (mixture) epoch 1/4:   5%|4\n| 17/345 [00:56<04:25,  1.23it/s]', '\\rOverwrite (mixture) epoch 1/4:   6%|5\n| 20/345 [00:56<03:00,  1.80it/s]', '\\rOverwrite (mixture) epoch 1/4:   7%|6\n| 23/345 [00:56<02:05,  2.56it/s]', '\\rOverwrite (mixture) epoch 1/4:   8%|7\n| 26/345 [00:56<01:29,  3.55it/s]', '\\rOverwrite (mixture) epoch 1/4:   8%|8\n| 29/345 [00:56<01:06,  4.78it/s]', '\\rOverwrite (mixture) epoch 1/4:   9%|9\n| 32/345 [00:56<00:49,  6.28it/s]', '\\rOverwrite (mixture) epoch 1/4:  10%|#\n| 35/345 [00:57<00:38,  8.02it/s]', '\\rOverwrite (mixture) epoch 1/4:  11%|#1\n| 38/345 [00:57<00:30,  9.91it/s]', '\\rOverwrite (mixture) epoch 1/4:  12%|#1\n| 41/345 [00:57<00:25, 11.72it/s]', '\\rOverwrite (mixture) epoch 1/4:  13%|#2\n| 44/345 [00:57<00:22, 13.60it/s]', '\\rOverwrite (mixture) epoch 1/4:  14%|#3\n| 47/345 [00:57<00:19, 15.19it/s]', '\\rOverwrite (mixture) epoch 1/4:  14%|#4\n| 50/345 [00:57<00:17, 16.69it/s]', '\\rOverwrite (mixture) epoch 1/4:  15%|#5\n| 53/345 [00:57<00:16, 17.95it/s]', '\\rOverwrite (mixture) epoch 1/4:  16%|#6\n| 56/345 [00:58<00:15, 18.90it/s]', '\\rOverwrite (mixture) epoch 1/4:  17%|#7\n| 59/345 [00:58<00:14, 19.63it/s]', '\\rOverwrite (mixture) epoch 1/4:  18%|#7\n| 62/345 [00:58<00:14, 20.21it/s]', '\\rOverwrite (mixture) epoch 1/4:  19%|#8\n| 65/345 [00:58<00:13, 20.40it/s]', '\\rOverwrite (mixture) epoch 1/4:  20%|#9\n| 68/345 [00:58<00:13, 20.79it/s]', '\\rOverwrite (mixture) epoch 1/4:  21%|##\n| 71/345 [00:58<00:13, 21.00it/s]', '\\rOverwrite (mixture) epoch 1/4:  21%|##1\n| 74/345 [00:58<00:12, 21.21it/s]', '\\rOverwrite (mixture) epoch 1/4:  22%|##2\n| 77/345 [00:58<00:12, 21.39it/s]', '\\rOverwrite (mixture) epoch 1/4:  23%|##3\n| 80/345 [00:59<00:12, 21.44it/s]', '\\rOverwrite (mixture) epoch 1/4:  24%|##4\n| 83/345 [00:59<00:12, 21.43it/s]', '\\rOverwrite (mixture) epoch 1/4:  25%|##4\n| 86/345 [00:59<00:12, 21.10it/s]', '\\rOverwrite (mixture) epoch 1/4:  26%|##5\n| 89/345 [00:59<00:12, 20.97it/s]', '\\rOverwrite (mixture) epoch 1/4:  27%|##6\n| 92/345 [00:59<00:12, 20.89it/s]', '\\rOverwrite (mixture) epoch 1/4:  28%|##7\n| 95/345 [00:59<00:11, 21.05it/s]', '\\rOverwrite (mixture) epoch 1/4:  28%|##8\n| 98/345 [00:59<00:11, 21.00it/s]', '\\rOverwrite (mixture) epoch 1/4:  29%|##9\n| 101/345 [01:00<00:11, 21.17it/s]', '\\rOverwrite (mixture) epoch 1/4:  30%|###\n| 104/345 [01:00<00:11, 21.21it/s]', '\\rOverwrite (mixture) epoch 1/4:  31%|###1\n| 107/345 [01:00<00:11, 21.10it/s]', '\\rOverwrite (mixture) epoch 1/4:  32%|###1\n| 110/345 [01:00<00:11, 21.25it/s]', '\\rOverwrite (mixture) epoch 1/4:  33%|###2\n| 113/345 [01:00<00:10, 21.25it/s]', '\\rOverwrite (mixture) epoch 1/4:  34%|###3\n| 116/345 [01:00<00:10, 21.36it/s]', '\\rOverwrite (mixture) epoch 1/4:  34%|###4\n| 119/345 [01:00<00:10, 21.47it/s]', '\\rOverwrite (mixture) epoch 1/4:  35%|###5\n| 122/345 [01:01<00:10, 21.60it/s]', '\\rOverwrite (mixture) epoch 1/4:  36%|###6\n| 125/345 [01:01<00:10, 21.49it/s]', '\\rOverwrite (mixture) epoch 1/4:  37%|###7\n| 128/345 [01:01<00:10, 21.49it/s]', '\\rOverwrite (mixture) epoch 1/4:  38%|###7\n| 131/345 [01:01<00:09, 21.49it/s]', '\\rOverwrite (mixture) epoch 1/4:  39%|###8\n| 134/345 [01:01<00:09, 21.42it/s]', '\\rOverwrite (mixture) epoch 1/4:  40%|###9\n| 137/345 [01:01<00:09, 21.47it/s]', '\\rOverwrite (mixture) epoch 1/4:  41%|####\n| 140/345 [01:01<00:09, 21.52it/s]', '\\rOverwrite (mixture) epoch 1/4:\n41%|####1     | 143/345 [01:02<00:09, 21.57it/s]', '\\rOverwrite (mixture) epoch\n1/4:  42%|####2     | 146/345 [01:02<00:09, 21.58it/s]', '\\rOverwrite (mixture)\nepoch 1/4:  43%|####3     | 149/345 [01:02<00:09, 21.61it/s]', '\\rOverwrite\n(mixture) epoch 1/4:  44%|####4     | 152/345 [01:02<00:09, 21.40it/s]',\n'\\rOverwrite (mixture) epoch 1/4:  45%|####4     | 155/345 [01:02<00:08,\n21.42it/s]', '\\rOverwrite (mixture) epoch 1/4:  46%|####5     | 158/345\n[01:02<00:08, 21.44it/s]', '\\rOverwrite (mixture) epoch 1/4:  47%|####6     |\n161/345 [01:02<00:08, 21.22it/s]', '\\rOverwrite (mixture) epoch 1/4:  48%|####7\n| 164/345 [01:03<00:08, 21.39it/s]', '\\rOverwrite (mixture) epoch 1/4:\n48%|####8     | 167/345 [01:03<00:08, 21.44it/s]', '\\rOverwrite (mixture) epoch\n1/4:  49%|####9     | 170/345 [01:03<00:08, 21.14it/s]', '\\rOverwrite (mixture)\nepoch 1/4:  50%|#####     | 173/345 [01:03<00:08, 21.10it/s]', '\\rOverwrite\n(mixture) epoch 1/4:  51%|#####1    | 176/345 [01:03<00:07, 21.26it/s]',\n'\\rOverwrite (mixture) epoch 1/4:  52%|#####1    | 179/345 [01:03<00:07,\n21.40it/s]', '\\rOverwrite (mixture) epoch 1/4:  53%|#####2    | 182/345\n[01:03<00:07, 21.39it/s]', '\\rOverwrite (mixture) epoch 1/4:  54%|#####3    |\n185/345 [01:04<00:07, 21.22it/s]', '\\rOverwrite (mixture) epoch 1/4:  54%|#####4\n| 188/345 [01:04<00:07, 21.32it/s]', '\\rOverwrite (mixture) epoch 1/4:\n55%|#####5    | 191/345 [01:04<00:07, 21.37it/s]', '\\rOverwrite (mixture) epoch\n1/4:  56%|#####6    | 194/345 [01:04<00:07, 21.45it/s]', '\\rOverwrite (mixture)\nepoch 1/4:  57%|#####7    | 197/345 [01:04<00:06, 21.50it/s]', '[2025-12-04\n01:07:05] Overwrite (mixture) step 200: avg_train_loss=3.8395', '\\n',\n'\\rOverwrite (mixture) epoch 1/4:  58%|#####7    | 200/345 [01:04<00:06,\n21.52it/s]', '\\rOverwrite (mixture) epoch 1/4:  59%|#####8    | 203/345\n[01:04<00:06, 21.62it/s]', '\\rOverwrite (mixture) epoch 1/4:  60%|#####9    |\n206/345 [01:05<00:06, 21.65it/s]', '\\rOverwrite (mixture) epoch 1/4:  61%|######\n| 209/345 [01:05<00:06, 21.62it/s]', '\\rOverwrite (mixture) epoch 1/4:\n61%|######1   | 212/345 [01:05<00:06, 21.35it/s]', '\\rOverwrite (mixture) epoch\n1/4:  62%|######2   | 215/345 [01:05<00:06, 21.24it/s]', '\\rOverwrite (mixture)\nepoch 1/4:  63%|######3   | 218/345 [01:05<00:05, 21.33it/s]', '\\rOverwrite\n(mixture) epoch 1/4:  64%|######4   | 221/345 [01:05<00:06, 20.57it/s]',\n'\\rOverwrite (mixture) epoch 1/4:  65%|######4   | 224/345 [01:05<00:06,\n19.76it/s]', '\\rOverwrite (mixture) epoch 1/4:  66%|######5   | 227/345\n[01:06<00:05, 20.12it/s]', '\\rOverwrite (mixture) epoch 1/4:  67%|######6   |\n230/345 [01:06<00:05, 20.44it/s]', '\\rOverwrite (mixture) epoch 1/4:\n68%|######7   | 233/345 [01:06<00:05, 20.73it/s]', '\\rOverwrite (mixture) epoch\n1/4:  68%|######8   | 236/345 [01:06<00:05, 20.84it/s]', '\\rOverwrite (mixture)\nepoch 1/4:  69%|######9   | 239/345 [01:06<00:05, 20.85it/s]', '\\rOverwrite\n(mixture) epoch 1/4:  70%|#######   | 242/345 [01:06<00:04, 20.87it/s]',\n'\\rOverwrite (mixture) epoch 1/4:  71%|#######1  | 245/345 [01:06<00:04,\n20.83it/s]', '\\rOverwrite (mixture) epoch 1/4:  72%|#######1  | 248/345\n[01:07<00:04, 20.67it/s]', '\\rOverwrite (mixture) epoch 1/4:  73%|#######2  |\n251/345 [01:07<00:04, 20.67it/s]', '\\rOverwrite (mixture) epoch 1/4:\n74%|#######3  | 254/345 [01:07<00:04, 20.91it/s]', '\\rOverwrite (mixture) epoch\n1/4:  74%|#######4  | 257/345 [01:07<00:04, 21.04it/s]', '\\rOverwrite (mixture)\nepoch 1/4:  75%|#######5  | 260/345 [01:07<00:04, 21.22it/s]', '\\rOverwrite\n(mixture) epoch 1/4:  76%|#######6  | 263/345 [01:07<00:03, 21.34it/s]',\n'\\rOverwrite (mixture) epoch 1/4:  77%|#######7  | 266/345 [01:07<00:03,\n21.44it/s]', '\\rOverwrite (mixture) epoch 1/4:  78%|#######7  | 269/345\n[01:08<00:03, 21.53it/s]', '\\rOverwrite (mixture) epoch 1/4:  79%|#######8  |\n272/345 [01:08<00:03, 21.58it/s]', '\\rOverwrite (mixture) epoch 1/4:\n80%|#######9  | 275/345 [01:08<00:03, 21.63it/s]', '\\rOverwrite (mixture) epoch\n1/4:  81%|########  | 278/345 [01:08<00:03, 21.53it/s]', '\\rOverwrite (mixture)\nepoch 1/4:  81%|########1 | 281/345 [01:08<00:02, 21.51it/s]', '\\rOverwrite\n(mixture) epoch 1/4:  82%|########2 | 284/345 [01:08<00:02, 21.50it/s]',\n'\\rOverwrite (mixture) epoch 1/4:  83%|########3 | 287/345 [01:08<00:02,\n21.27it/s]', '\\rOverwrite (mixture) epoch 1/4:  84%|########4 | 290/345\n[01:09<00:02, 21.40it/s]', '\\rOverwrite (mixture) epoch 1/4:  85%|########4 |\n293/345 [01:09<00:02, 21.30it/s]', '\\rOverwrite (mixture) epoch 1/4:\n86%|########5 | 296/345 [01:09<00:02, 20.74it/s]', '\\rOverwrite (mixture) epoch\n1/4:  87%|########6 | 299/345 [01:09<00:02, 20.80it/s]', '\\rOverwrite (mixture)\nepoch 1/4:  88%|########7 | 302/345 [01:09<00:02, 20.99it/s]', '\\rOverwrite\n(mixture) epoch 1/4:  88%|########8 | 305/345 [01:09<00:01, 21.11it/s]',\n'\\rOverwrite (mixture) epoch 1/4:  89%|########9 | 308/345 [01:09<00:01,\n21.20it/s]', '\\rOverwrite (mixture) epoch 1/4:  90%|######### | 311/345\n[01:10<00:01, 21.18it/s]', '\\rOverwrite (mixture) epoch 1/4:  91%|#########1|\n314/345 [01:10<00:01, 21.21it/s]', '\\rOverwrite (mixture) epoch 1/4:\n92%|#########1| 317/345 [01:10<00:01, 21.02it/s]', '\\rOverwrite (mixture) epoch\n1/4:  93%|#########2| 320/345 [01:10<00:01, 21.03it/s]', '\\rOverwrite (mixture)\nepoch 1/4:  94%|#########3| 323/345 [01:10<00:01, 21.18it/s]', '\\rOverwrite\n(mixture) epoch 1/4:  94%|#########4| 326/345 [01:10<00:00, 21.26it/s]',\n'\\rOverwrite (mixture) epoch 1/4:  95%|#########5| 329/345 [01:10<00:00,\n21.42it/s]', '\\rOverwrite (mixture) epoch 1/4:  96%|#########6| 332/345\n[01:11<00:00, 21.43it/s]', '\\rOverwrite (mixture) epoch 1/4:  97%|#########7|\n335/345 [01:11<00:00, 21.45it/s]', '\\rOverwrite (mixture) epoch 1/4:\n98%|#########7| 338/345 [01:11<00:00, 21.49it/s]', '\\rOverwrite (mixture) epoch\n1/4:  99%|#########8| 341/345 [01:11<00:00, 21.48it/s]', '\\rOverwrite (mixture)\nepoch 1/4: 100%|#########9| 344/345 [01:11<00:00, 21.65it/s]', '', '\\rOverwrite\n(mixture) epoch 1/4: 100%|##########| 345/345 [01:12<00:00,  4.76it/s]', '\\n',\n'Epoch 1 (mixture): validation_loss = 3.6167', '\\n', '\\rOverwrite (mixture)\nepoch 2/4:   0%|          | 0/345 [00:00<?, ?it/s]', '\\rOverwrite (mixture)\nepoch 2/4:   0%|          | 1/345 [00:57<5:31:38, 57.84s/it]', '\\rOverwrite\n(mixture) epoch 2/4:   1%|          | 2/345 [00:57<2:16:30, 23.88s/it]',\n'\\rOverwrite (mixture) epoch 2/4:   1%|1         | 5/345 [00:58<38:37,\n6.82s/it]  ', '\\rOverwrite (mixture) epoch 2/4:   2%|2         | 8/345\n[00:58<19:03,  3.39s/it]', '\\rOverwrite (mixture) epoch 2/4:   3%|3         |\n11/345 [00:58<11:04,  1.99s/it]', '\\rOverwrite (mixture) epoch 2/4:   4%|4\n| 14/345 [00:58<06:57,  1.26s/it]', '\\rOverwrite (mixture) epoch 2/4:   5%|4\n| 17/345 [00:58<04:34,  1.19it/s]', '\\rOverwrite (mixture) epoch 2/4:   6%|5\n| 20/345 [00:58<03:06,  1.74it/s]', '\\rOverwrite (mixture) epoch 2/4:   7%|6\n| 23/345 [00:58<02:10,  2.47it/s]', '\\rOverwrite (mixture) epoch 2/4:   8%|7\n| 26/345 [00:59<01:33,  3.42it/s]', '\\rOverwrite (mixture) epoch 2/4:   8%|8\n| 29/345 [00:59<01:08,  4.62it/s]', '\\rOverwrite (mixture) epoch 2/4:   9%|9\n| 32/345 [00:59<00:51,  6.09it/s]', '\\rOverwrite (mixture) epoch 2/4:  10%|#\n| 35/345 [00:59<00:39,  7.80it/s]', '\\rOverwrite (mixture) epoch 2/4:  11%|#1\n| 38/345 [00:59<00:31,  9.68it/s]', '\\rOverwrite (mixture) epoch 2/4:  12%|#1\n| 41/345 [00:59<00:26, 11.60it/s]', '\\rOverwrite (mixture) epoch 2/4:  13%|#2\n| 44/345 [00:59<00:22, 13.45it/s]', '\\rOverwrite (mixture) epoch 2/4:  14%|#3\n| 47/345 [01:00<00:19, 15.18it/s]', '\\rOverwrite (mixture) epoch 2/4:  14%|#4\n| 50/345 [01:00<00:17, 16.60it/s]', '\\rOverwrite (mixture) epoch 2/4:  15%|#5\n| 53/345 [01:00<00:16, 17.82it/s]', '[2025-12-04 01:09:09] Overwrite (mixture)\nstep 400: avg_train_loss=3.3450', '\\n', '\\rOverwrite (mixture) epoch 2/4:\n16%|#6        | 56/345 [01:00<00:15, 18.68it/s]', '\\rOverwrite (mixture) epoch\n2/4:  17%|#7        | 59/345 [01:00<00:14, 19.35it/s]', '\\rOverwrite (mixture)\nepoch 2/4:  18%|#7        | 62/345 [01:00<00:14, 20.02it/s]', '\\rOverwrite\n(mixture) epoch 2/4:  19%|#8        | 65/345 [01:00<00:13, 20.27it/s]',\n'\\rOverwrite (mixture) epoch 2/4:  20%|#9        | 68/345 [01:01<00:13,\n20.27it/s]', '\\rOverwrite (mixture) epoch 2/4:  21%|##        | 71/345\n[01:01<00:13, 20.23it/s]', '\\rOverwrite (mixture) epoch 2/4:  21%|##1       |\n74/345 [01:01<00:13, 20.48it/s]', '\\rOverwrite (mixture) epoch 2/4:  22%|##2\n| 77/345 [01:01<00:12, 20.66it/s]', '\\rOverwrite (mixture) epoch 2/4:  23%|##3\n| 80/345 [01:01<00:12, 20.80it/s]', '\\rOverwrite (mixture) epoch 2/4:  24%|##4\n| 83/345 [01:01<00:12, 21.00it/s]', '\\rOverwrite (mixture) epoch 2/4:  25%|##4\n| 86/345 [01:01<00:12, 21.22it/s]', '\\rOverwrite (mixture) epoch 2/4:  26%|##5\n| 89/345 [01:02<00:11, 21.37it/s]', '\\rOverwrite (mixture) epoch 2/4:  27%|##6\n| 92/345 [01:02<00:11, 21.22it/s]', '\\rOverwrite (mixture) epoch 2/4:  28%|##7\n| 95/345 [01:02<00:11, 21.28it/s]', '\\rOverwrite (mixture) epoch 2/4:  28%|##8\n| 98/345 [01:02<00:11, 21.37it/s]', '\\rOverwrite (mixture) epoch 2/4:  29%|##9\n| 101/345 [01:02<00:11, 21.30it/s]', '\\rOverwrite (mixture) epoch 2/4:  30%|###\n| 104/345 [01:02<00:11, 21.29it/s]', '\\rOverwrite (mixture) epoch 2/4:  31%|###1\n| 107/345 [01:02<00:11, 21.32it/s]', '\\rOverwrite (mixture) epoch 2/4:  32%|###1\n| 110/345 [01:03<00:10, 21.37it/s]', '\\rOverwrite (mixture) epoch 2/4:  33%|###2\n| 113/345 [01:03<00:10, 21.45it/s]', '\\rOverwrite (mixture) epoch 2/4:  34%|###3\n| 116/345 [01:03<00:10, 21.43it/s]', '\\rOverwrite (mixture) epoch 2/4:  34%|###4\n| 119/345 [01:03<00:10, 21.47it/s]', '\\rOverwrite (mixture) epoch 2/4:  35%|###5\n| 122/345 [01:03<00:10, 21.44it/s]', '\\rOverwrite (mixture) epoch 2/4:  36%|###6\n| 125/345 [01:03<00:10, 21.43it/s]', '\\rOverwrite (mixture) epoch 2/4:  37%|###7\n| 128/345 [01:03<00:10, 21.41it/s]', '\\rOverwrite (mixture) epoch 2/4:  38%|###7\n| 131/345 [01:04<00:09, 21.44it/s]', '\\rOverwrite (mixture) epoch 2/4:  39%|###8\n| 134/345 [01:04<00:09, 21.46it/s]', '\\rOverwrite (mixture) epoch 2/4:  40%|###9\n| 137/345 [01:04<00:09, 21.32it/s]', '\\rOverwrite (mixture) epoch 2/4:  41%|####\n| 140/345 [01:04<00:09, 21.36it/s]', '\\rOverwrite (mixture) epoch 2/4:\n41%|####1     | 143/345 [01:04<00:09, 21.34it/s]', '\\rOverwrite (mixture) epoch\n2/4:  42%|####2     | 146/345 [01:04<00:09, 21.34it/s]', '\\rOverwrite (mixture)\nepoch 2/4:  43%|####3     | 149/345 [01:04<00:09, 21.34it/s]', '\\rOverwrite\n(mixture) epoch 2/4:  44%|####4     | 152/345 [01:04<00:09, 21.40it/s]',\n'\\rOverwrite (mixture) epoch 2/4:  45%|####4     | 155/345 [01:05<00:08,\n21.36it/s]', '\\rOverwrite (mixture) epoch 2/4:  46%|####5     | 158/345\n[01:05<00:08, 21.23it/s]', '\\rOverwrite (mixture) epoch 2/4:  47%|####6     |\n161/345 [01:05<00:08, 21.17it/s]', '\\rOverwrite (mixture) epoch 2/4:  48%|####7\n| 164/345 [01:05<00:08, 21.10it/s]', '\\rOverwrite (mixture) epoch 2/4:\n48%|####8     | 167/345 [01:05<00:08, 21.18it/s]', '\\rOverwrite (mixture) epoch\n2/4:  49%|####9     | 170/345 [01:05<00:08, 21.35it/s]', '\\rOverwrite (mixture)\nepoch 2/4:  50%|#####     | 173/345 [01:05<00:08, 21.37it/s]', '\\rOverwrite\n(mixture) epoch 2/4:  51%|#####1    | 176/345 [01:06<00:07, 21.47it/s]',\n'\\rOverwrite (mixture) epoch 2/4:  52%|#####1    | 179/345 [01:06<00:07,\n21.48it/s]', '\\rOverwrite (mixture) epoch 2/4:  53%|#####2    | 182/345\n[01:06<00:07, 21.52it/s]', '\\rOverwrite (mixture) epoch 2/4:  54%|#####3    |\n185/345 [01:06<00:07, 21.59it/s]', '\\rOverwrite (mixture) epoch 2/4:  54%|#####4\n| 188/345 [01:06<00:07, 21.54it/s]', '\\rOverwrite (mixture) epoch 2/4:\n55%|#####5    | 191/345 [01:06<00:07, 21.55it/s]', '\\rOverwrite (mixture) epoch\n2/4:  56%|#####6    | 194/345 [01:06<00:06, 21.66it/s]', '\\rOverwrite (mixture)\nepoch 2/4:  57%|#####7    | 197/345 [01:07<00:06, 21.59it/s]', '\\rOverwrite\n(mixture) epoch 2/4:  58%|#####7    | 200/345 [01:07<00:06, 21.32it/s]',\n'\\rOverwrite (mixture) epoch 2/4:  59%|#####8    | 203/345 [01:07<00:06,\n21.23it/s]', '\\rOverwrite (mixture) epoch 2/4:  60%|#####9    | 206/345\n[01:07<00:06, 21.40it/s]', '\\rOverwrite (mixture) epoch 2/4:  61%|######    |\n209/345 [01:07<00:06, 21.43it/s]', '\\rOverwrite (mixture) epoch 2/4:\n61%|######1   | 212/345 [01:07<00:06, 21.55it/s]', '\\rOverwrite (mixture) epoch\n2/4:  62%|######2   | 215/345 [01:07<00:06, 21.18it/s]', '\\rOverwrite (mixture)\nepoch 2/4:  63%|######3   | 218/345 [01:08<00:06, 21.01it/s]', '\\rOverwrite\n(mixture) epoch 2/4:  64%|######4   | 221/345 [01:08<00:06, 20.66it/s]',\n'\\rOverwrite (mixture) epoch 2/4:  65%|######4   | 224/345 [01:08<00:05,\n20.50it/s]', '\\rOverwrite (mixture) epoch 2/4:  66%|######5   | 227/345\n[01:08<00:05, 20.69it/s]', '\\rOverwrite (mixture) epoch 2/4:  67%|######6   |\n230/345 [01:08<00:05, 20.79it/s]', '\\rOverwrite (mixture) epoch 2/4:\n68%|######7   | 233/345 [01:08<00:05, 20.97it/s]', '\\rOverwrite (mixture) epoch\n2/4:  68%|######8   | 236/345 [01:08<00:05, 21.13it/s]', '\\rOverwrite (mixture)\nepoch 2/4:  69%|######9   | 239/345 [01:09<00:05, 21.15it/s]', '\\rOverwrite\n(mixture) epoch 2/4:  70%|#######   | 242/345 [01:09<00:04, 20.89it/s]',\n'\\rOverwrite (mixture) epoch 2/4:  71%|#######1  | 245/345 [01:09<00:04,\n20.89it/s]', '\\rOverwrite (mixture) epoch 2/4:  72%|#######1  | 248/345\n[01:09<00:04, 21.04it/s]', '\\rOverwrite (mixture) epoch 2/4:  73%|#######2  |\n251/345 [01:09<00:04, 21.18it/s]', '\\rOverwrite (mixture) epoch 2/4:\n74%|#######3  | 254/345 [01:09<00:04, 21.13it/s]', '[2025-12-04 01:09:18]\nOverwrite (mixture) step 600: avg_train_loss=3.3269', '\\n', '\\rOverwrite\n(mixture) epoch 2/4:  74%|#######4  | 257/345 [01:09<00:04, 21.20it/s]',\n'\\rOverwrite (mixture) epoch 2/4:  75%|#######5  | 260/345 [01:10<00:03,\n21.32it/s]', '\\rOverwrite (mixture) epoch 2/4:  76%|#######6  | 263/345\n[01:10<00:03, 21.19it/s]', '\\rOverwrite (mixture) epoch 2/4:  77%|#######7  |\n266/345 [01:10<00:03, 21.33it/s]', '\\rOverwrite (mixture) epoch 2/4:\n78%|#######7  | 269/345 [01:10<00:03, 21.29it/s]', '\\rOverwrite (mixture) epoch\n2/4:  79%|#######8  | 272/345 [01:10<00:03, 21.36it/s]', '\\rOverwrite (mixture)\nepoch 2/4:  80%|#######9  | 275/345 [01:10<00:03, 21.33it/s]', '\\rOverwrite\n(mixture) epoch 2/4:  81%|########  | 278/345 [01:10<00:03, 21.36it/s]',\n'\\rOverwrite (mixture) epoch 2/4:  81%|########1 | 281/345 [01:11<00:03,\n21.32it/s]', '\\rOverwrite (mixture) epoch 2/4:  82%|########2 | 284/345\n[01:11<00:02, 21.42it/s]', '\\rOverwrite (mixture) epoch 2/4:  83%|########3 |\n287/345 [01:11<00:02, 21.43it/s]', '\\rOverwrite (mixture) epoch 2/4:\n84%|########4 | 290/345 [01:11<00:02, 21.48it/s]', '\\rOverwrite (mixture) epoch\n2/4:  85%|########4 | 293/345 [01:11<00:02, 21.18it/s]', '\\rOverwrite (mixture)\nepoch 2/4:  86%|########5 | 296/345 [01:11<00:02, 21.10it/s]', '\\rOverwrite\n(mixture) epoch 2/4:  87%|########6 | 299/345 [01:11<00:02, 20.80it/s]',\n'\\rOverwrite (mixture) epoch 2/4:  88%|########7 | 302/345 [01:12<00:02,\n20.77it/s]', '\\rOverwrite (mixture) epoch 2/4:  88%|########8 | 305/345\n[01:12<00:01, 20.88it/s]', '\\rOverwrite (mixture) epoch 2/4:  89%|########9 |\n308/345 [01:12<00:01, 21.13it/s]', '\\rOverwrite (mixture) epoch 2/4:\n90%|######### | 311/345 [01:12<00:01, 21.31it/s]', '\\rOverwrite (mixture) epoch\n2/4:  91%|#########1| 314/345 [01:12<00:01, 21.09it/s]', '\\rOverwrite (mixture)\nepoch 2/4:  92%|#########1| 317/345 [01:12<00:01, 21.01it/s]', '\\rOverwrite\n(mixture) epoch 2/4:  93%|#########2| 320/345 [01:12<00:01, 21.04it/s]',\n'\\rOverwrite (mixture) epoch 2/4:  94%|#########3| 323/345 [01:13<00:01,\n21.17it/s]', '\\rOverwrite (mixture) epoch 2/4:  94%|#########4| 326/345\n[01:13<00:00, 21.27it/s]', '\\rOverwrite (mixture) epoch 2/4:  95%|#########5|\n329/345 [01:13<00:00, 21.38it/s]', '\\rOverwrite (mixture) epoch 2/4:\n96%|#########6| 332/345 [01:13<00:00, 21.30it/s]', '\\rOverwrite (mixture) epoch\n2/4:  97%|#########7| 335/345 [01:13<00:00, 21.46it/s]', '\\rOverwrite (mixture)\nepoch 2/4:  98%|#########7| 338/345 [01:13<00:00, 21.50it/s]', '\\rOverwrite\n(mixture) epoch 2/4:  99%|#########8| 341/345 [01:13<00:00, 21.33it/s]',\n'\\rOverwrite (mixture) epoch 2/4: 100%|#########9| 344/345 [01:14<00:00,\n21.58it/s]', '', '\\rOverwrite (mixture) epoch 2/4: 100%|##########| 345/345\n[01:15<00:00,  4.60it/s]', '\\n', 'Epoch 2 (mixture): validation_loss = 3.6360',\n'\\n', '\\rOverwrite (mixture) epoch 3/4:   0%|          | 0/345 [00:00<?,\n?it/s]', '\\rOverwrite (mixture) epoch 3/4:   0%|          | 1/345\n[01:03<6:04:30, 63.58s/it]', '\\rOverwrite (mixture) epoch 3/4:   1%|          |\n3/345 [01:03<1:34:14, 16.53s/it]', '\\rOverwrite (mixture) epoch 3/4:   2%|1\n| 6/345 [01:03<36:15,  6.42s/it]  ', '\\rOverwrite (mixture) epoch 3/4:   3%|2\n| 9/345 [01:03<19:16,  3.44s/it]', '\\rOverwrite (mixture) epoch 3/4:   3%|3\n| 12/345 [01:04<11:33,  2.08s/it]', '\\rOverwrite (mixture) epoch 3/4:   4%|4\n| 15/345 [01:04<07:23,  1.34s/it]', '\\rOverwrite (mixture) epoch 3/4:   5%|5\n| 18/345 [01:04<04:54,  1.11it/s]', '\\rOverwrite (mixture) epoch 3/4:   6%|6\n| 21/345 [01:04<03:20,  1.61it/s]', '\\rOverwrite (mixture) epoch 3/4:   7%|6\n| 24/345 [01:04<02:20,  2.29it/s]', '\\rOverwrite (mixture) epoch 3/4:   8%|7\n| 27/345 [01:04<01:39,  3.18it/s]', '\\rOverwrite (mixture) epoch 3/4:   9%|8\n| 30/345 [01:04<01:12,  4.32it/s]', '\\rOverwrite (mixture) epoch 3/4:  10%|9\n| 33/345 [01:05<00:54,  5.70it/s]', '\\rOverwrite (mixture) epoch 3/4:  10%|#\n| 36/345 [01:05<00:42,  7.33it/s]', '\\rOverwrite (mixture) epoch 3/4:  11%|#1\n| 39/345 [01:05<00:33,  9.17it/s]', '\\rOverwrite (mixture) epoch 3/4:  12%|#2\n| 42/345 [01:05<00:27, 11.10it/s]', '\\rOverwrite (mixture) epoch 3/4:  13%|#3\n| 45/345 [01:05<00:23, 13.02it/s]', '\\rOverwrite (mixture) epoch 3/4:  14%|#3\n| 48/345 [01:05<00:20, 14.76it/s]', '\\rOverwrite (mixture) epoch 3/4:  15%|#4\n| 51/345 [01:05<00:18, 16.32it/s]', '\\rOverwrite (mixture) epoch 3/4:  16%|#5\n| 54/345 [01:06<00:16, 17.59it/s]', '\\rOverwrite (mixture) epoch 3/4:  17%|#6\n| 57/345 [01:06<00:15, 18.58it/s]', '\\rOverwrite (mixture) epoch 3/4:  17%|#7\n| 60/345 [01:06<00:14, 19.38it/s]', '\\rOverwrite (mixture) epoch 3/4:  18%|#8\n| 63/345 [01:06<00:14, 19.97it/s]', '\\rOverwrite (mixture) epoch 3/4:  19%|#9\n| 66/345 [01:06<00:13, 20.49it/s]', '\\rOverwrite (mixture) epoch 3/4:  20%|##\n| 69/345 [01:06<00:13, 20.84it/s]', '\\rOverwrite (mixture) epoch 3/4:  21%|##\n| 72/345 [01:06<00:12, 21.08it/s]', '\\rOverwrite (mixture) epoch 3/4:  22%|##1\n| 75/345 [01:07<00:12, 21.28it/s]', '\\rOverwrite (mixture) epoch 3/4:  23%|##2\n| 78/345 [01:07<00:12, 21.46it/s]', '\\rOverwrite (mixture) epoch 3/4:  23%|##3\n| 81/345 [01:07<00:12, 21.56it/s]', '\\rOverwrite (mixture) epoch 3/4:  24%|##4\n| 84/345 [01:07<00:12, 21.46it/s]', '\\rOverwrite (mixture) epoch 3/4:  25%|##5\n| 87/345 [01:07<00:12, 21.33it/s]', '\\rOverwrite (mixture) epoch 3/4:  26%|##6\n| 90/345 [01:07<00:12, 21.23it/s]', '\\rOverwrite (mixture) epoch 3/4:  27%|##6\n| 93/345 [01:07<00:11, 21.23it/s]', '\\rOverwrite (mixture) epoch 3/4:  28%|##7\n| 96/345 [01:08<00:11, 21.13it/s]', '\\rOverwrite (mixture) epoch 3/4:  29%|##8\n| 99/345 [01:08<00:11, 21.07it/s]', '\\rOverwrite (mixture) epoch 3/4:  30%|##9\n| 102/345 [01:08<00:11, 20.80it/s]', '\\rOverwrite (mixture) epoch 3/4:  30%|###\n| 105/345 [01:08<00:11, 20.95it/s]', '\\rOverwrite (mixture) epoch 3/4:  31%|###1\n| 108/345 [01:08<00:11, 21.13it/s]', '[2025-12-04 01:11:32] Overwrite (mixture)\nstep 800: avg_train_loss=3.0678', '\\n', '\\rOverwrite (mixture) epoch 3/4:\n32%|###2      | 111/345 [01:08<00:10, 21.28it/s]', '\\rOverwrite (mixture) epoch\n3/4:  33%|###3      | 114/345 [01:08<00:10, 21.35it/s]', '\\rOverwrite (mixture)\nepoch 3/4:  34%|###3      | 117/345 [01:09<00:10, 21.45it/s]', '\\rOverwrite\n(mixture) epoch 3/4:  35%|###4      | 120/345 [01:09<00:10, 21.38it/s]',\n'\\rOverwrite (mixture) epoch 3/4:  36%|###5      | 123/345 [01:09<00:10,\n21.34it/s]', '\\rOverwrite (mixture) epoch 3/4:  37%|###6      | 126/345\n[01:09<00:10, 21.42it/s]', '\\rOverwrite (mixture) epoch 3/4:  37%|###7      |\n129/345 [01:09<00:10, 21.34it/s]', '\\rOverwrite (mixture) epoch 3/4:  38%|###8\n| 132/345 [01:09<00:09, 21.34it/s]', '\\rOverwrite (mixture) epoch 3/4:  39%|###9\n| 135/345 [01:09<00:09, 21.37it/s]', '\\rOverwrite (mixture) epoch 3/4:  40%|####\n| 138/345 [01:10<00:09, 21.46it/s]', '\\rOverwrite (mixture) epoch 3/4:  41%|####\n| 141/345 [01:10<00:09, 21.34it/s]', '\\rOverwrite (mixture) epoch 3/4:\n42%|####1     | 144/345 [01:10<00:09, 21.44it/s]', '\\rOverwrite (mixture) epoch\n3/4:  43%|####2     | 147/345 [01:10<00:09, 21.38it/s]', '\\rOverwrite (mixture)\nepoch 3/4:  43%|####3     | 150/345 [01:10<00:09, 21.29it/s]', '\\rOverwrite\n(mixture) epoch 3/4:  44%|####4     | 153/345 [01:10<00:09, 21.24it/s]',\n'\\rOverwrite (mixture) epoch 3/4:  45%|####5     | 156/345 [01:10<00:08,\n21.08it/s]', '\\rOverwrite (mixture) epoch 3/4:  46%|####6     | 159/345\n[01:11<00:08, 21.23it/s]', '\\rOverwrite (mixture) epoch 3/4:  47%|####6     |\n162/345 [01:11<00:08, 21.29it/s]', '\\rOverwrite (mixture) epoch 3/4:  48%|####7\n| 165/345 [01:11<00:08, 21.40it/s]', '\\rOverwrite (mixture) epoch 3/4:\n49%|####8     | 168/345 [01:11<00:08, 21.50it/s]', '\\rOverwrite (mixture) epoch\n3/4:  50%|####9     | 171/345 [01:11<00:08, 21.49it/s]', '\\rOverwrite (mixture)\nepoch 3/4:  50%|#####     | 174/345 [01:11<00:07, 21.47it/s]', '\\rOverwrite\n(mixture) epoch 3/4:  51%|#####1    | 177/345 [01:11<00:07, 21.49it/s]',\n'\\rOverwrite (mixture) epoch 3/4:  52%|#####2    | 180/345 [01:11<00:07,\n21.47it/s]', '\\rOverwrite (mixture) epoch 3/4:  53%|#####3    | 183/345\n[01:12<00:07, 21.24it/s]', '\\rOverwrite (mixture) epoch 3/4:  54%|#####3    |\n186/345 [01:12<00:07, 21.33it/s]', '\\rOverwrite (mixture) epoch 3/4:  55%|#####4\n| 189/345 [01:12<00:07, 21.29it/s]', '\\rOverwrite (mixture) epoch 3/4:\n56%|#####5    | 192/345 [01:12<00:07, 21.39it/s]', '\\rOverwrite (mixture) epoch\n3/4:  57%|#####6    | 195/345 [01:12<00:07, 21.06it/s]', '\\rOverwrite (mixture)\nepoch 3/4:  57%|#####7    | 198/345 [01:12<00:06, 21.21it/s]', '\\rOverwrite\n(mixture) epoch 3/4:  58%|#####8    | 201/345 [01:12<00:06, 21.33it/s]',\n'\\rOverwrite (mixture) epoch 3/4:  59%|#####9    | 204/345 [01:13<00:06,\n21.33it/s]', '\\rOverwrite (mixture) epoch 3/4:  60%|######    | 207/345\n[01:13<00:06, 21.46it/s]', '\\rOverwrite (mixture) epoch 3/4:  61%|######    |\n210/345 [01:13<00:06, 21.59it/s]', '\\rOverwrite (mixture) epoch 3/4:\n62%|######1   | 213/345 [01:13<00:06, 21.67it/s]', '\\rOverwrite (mixture) epoch\n3/4:  63%|######2   | 216/345 [01:13<00:06, 21.43it/s]', '\\rOverwrite (mixture)\nepoch 3/4:  63%|######3   | 219/345 [01:13<00:05, 21.27it/s]', '\\rOverwrite\n(mixture) epoch 3/4:  64%|######4   | 222/345 [01:13<00:05, 21.13it/s]',\n'\\rOverwrite (mixture) epoch 3/4:  65%|######5   | 225/345 [01:14<00:05,\n21.21it/s]', '\\rOverwrite (mixture) epoch 3/4:  66%|######6   | 228/345\n[01:14<00:05, 21.24it/s]', '\\rOverwrite (mixture) epoch 3/4:  67%|######6   |\n231/345 [01:14<00:05, 21.22it/s]', '\\rOverwrite (mixture) epoch 3/4:\n68%|######7   | 234/345 [01:14<00:05, 21.13it/s]', '\\rOverwrite (mixture) epoch\n3/4:  69%|######8   | 237/345 [01:14<00:05, 21.21it/s]', '\\rOverwrite (mixture)\nepoch 3/4:  70%|######9   | 240/345 [01:14<00:04, 21.25it/s]', '\\rOverwrite\n(mixture) epoch 3/4:  70%|#######   | 243/345 [01:14<00:04, 21.37it/s]',\n'\\rOverwrite (mixture) epoch 3/4:  71%|#######1  | 246/345 [01:15<00:04,\n21.46it/s]', '\\rOverwrite (mixture) epoch 3/4:  72%|#######2  | 249/345\n[01:15<00:04, 21.37it/s]', '\\rOverwrite (mixture) epoch 3/4:  73%|#######3  |\n252/345 [01:15<00:04, 21.22it/s]', '\\rOverwrite (mixture) epoch 3/4:\n74%|#######3  | 255/345 [01:15<00:04, 21.27it/s]', '\\rOverwrite (mixture) epoch\n3/4:  75%|#######4  | 258/345 [01:15<00:04, 21.37it/s]', '\\rOverwrite (mixture)\nepoch 3/4:  76%|#######5  | 261/345 [01:15<00:03, 21.49it/s]', '\\rOverwrite\n(mixture) epoch 3/4:  77%|#######6  | 264/345 [01:15<00:03, 21.37it/s]',\n'\\rOverwrite (mixture) epoch 3/4:  77%|#######7  | 267/345 [01:16<00:03,\n21.17it/s]', '\\rOverwrite (mixture) epoch 3/4:  78%|#######8  | 270/345\n[01:16<00:03, 21.10it/s]', '\\rOverwrite (mixture) epoch 3/4:  79%|#######9  |\n273/345 [01:16<00:03, 21.21it/s]', '\\rOverwrite (mixture) epoch 3/4:\n80%|########  | 276/345 [01:16<00:03, 21.29it/s]', '\\rOverwrite (mixture) epoch\n3/4:  81%|########  | 279/345 [01:16<00:03, 21.09it/s]', '\\rOverwrite (mixture)\nepoch 3/4:  82%|########1 | 282/345 [01:16<00:02, 21.18it/s]', '\\rOverwrite\n(mixture) epoch 3/4:  83%|########2 | 285/345 [01:16<00:02, 21.21it/s]',\n'\\rOverwrite (mixture) epoch 3/4:  83%|########3 | 288/345 [01:17<00:02,\n21.32it/s]', '\\rOverwrite (mixture) epoch 3/4:  84%|########4 | 291/345\n[01:17<00:02, 21.41it/s]', '\\rOverwrite (mixture) epoch 3/4:  85%|########5 |\n294/345 [01:17<00:02, 21.09it/s]', '\\rOverwrite (mixture) epoch 3/4:\n86%|########6 | 297/345 [01:17<00:02, 21.23it/s]', '\\rOverwrite (mixture) epoch\n3/4:  87%|########6 | 300/345 [01:17<00:02, 21.12it/s]', '\\rOverwrite (mixture)\nepoch 3/4:  88%|########7 | 303/345 [01:17<00:01, 21.18it/s]', '\\rOverwrite\n(mixture) epoch 3/4:  89%|########8 | 306/345 [01:17<00:01, 21.32it/s]',\n'\\rOverwrite (mixture) epoch 3/4:  90%|########9 | 309/345 [01:18<00:01,\n21.34it/s]', '[2025-12-04 01:11:42] Overwrite (mixture) step 1000:\navg_train_loss=3.0795', '\\n', '\\rOverwrite (mixture) epoch 3/4:  90%|######### |\n312/345 [01:18<00:01, 21.34it/s]', '\\rOverwrite (mixture) epoch 3/4:\n91%|#########1| 315/345 [01:18<00:01, 21.42it/s]', '\\rOverwrite (mixture) epoch\n3/4:  92%|#########2| 318/345 [01:18<00:01, 21.47it/s]', '\\rOverwrite (mixture)\nepoch 3/4:  93%|#########3| 321/345 [01:18<00:01, 21.29it/s]', '\\rOverwrite\n(mixture) epoch 3/4:  94%|#########3| 324/345 [01:18<00:00, 21.38it/s]',\n'\\rOverwrite (mixture) epoch 3/4:  95%|#########4| 327/345 [01:18<00:00,\n20.93it/s]', '\\rOverwrite (mixture) epoch 3/4:  96%|#########5| 330/345\n[01:19<00:00, 21.00it/s]', '\\rOverwrite (mixture) epoch 3/4:  97%|#########6|\n333/345 [01:19<00:00, 21.19it/s]', '\\rOverwrite (mixture) epoch 3/4:\n97%|#########7| 336/345 [01:19<00:00, 21.32it/s]', '\\rOverwrite (mixture) epoch\n3/4:  98%|#########8| 339/345 [01:19<00:00, 21.46it/s]', '\\rOverwrite (mixture)\nepoch 3/4:  99%|#########9| 342/345 [01:19<00:00, 21.53it/s]', '\\rOverwrite\n(mixture) epoch 3/4: 100%|##########| 345/345 [01:19<00:00, 22.41it/s]', '',\n'\\rOverwrite (mixture) epoch 3/4: 100%|##########| 345/345 [01:20<00:00,\n4.27it/s]', '\\n', 'Epoch 3 (mixture): validation_loss = 3.6688', '\\n',\n'\\rOverwrite (mixture) epoch 4/4:   0%|          | 0/345 [00:00<?, ?it/s]',\n'\\rOverwrite (mixture) epoch 4/4:   0%|          | 1/345 [00:57<5:30:42,\n57.68s/it]', '\\rOverwrite (mixture) epoch 4/4:   1%|          | 3/345\n[00:57<1:25:31, 15.01s/it]', '\\rOverwrite (mixture) epoch 4/4:   1%|1         |\n5/345 [00:57<41:27,  7.32s/it]  ', '\\rOverwrite (mixture) epoch 4/4:   2%|2\n| 7/345 [00:58<23:53,  4.24s/it]', '\\rOverwrite (mixture) epoch 4/4:   3%|2\n| 9/345 [00:58<14:54,  2.66s/it]', '\\rOverwrite (mixture) epoch 4/4:   3%|3\n| 12/345 [00:58<08:17,  1.49s/it]', '\\rOverwrite (mixture) epoch 4/4:   4%|4\n| 15/345 [00:58<05:06,  1.08it/s]', '\\rOverwrite (mixture) epoch 4/4:   5%|5\n| 18/345 [00:58<03:20,  1.63it/s]', '\\rOverwrite (mixture) epoch 4/4:   6%|6\n| 21/345 [00:58<02:16,  2.37it/s]', '\\rOverwrite (mixture) epoch 4/4:   7%|6\n| 24/345 [00:58<01:36,  3.33it/s]', '\\rOverwrite (mixture) epoch 4/4:   8%|7\n| 27/345 [00:58<01:09,  4.56it/s]', '\\rOverwrite (mixture) epoch 4/4:   9%|8\n| 30/345 [00:59<00:52,  6.03it/s]', '\\rOverwrite (mixture) epoch 4/4:  10%|9\n| 33/345 [00:59<00:40,  7.66it/s]', '\\rOverwrite (mixture) epoch 4/4:  10%|#\n| 36/345 [00:59<00:33,  9.35it/s]', '\\rOverwrite (mixture) epoch 4/4:  11%|#1\n| 39/345 [00:59<00:27, 11.09it/s]', '\\rOverwrite (mixture) epoch 4/4:  12%|#2\n| 42/345 [00:59<00:23, 12.95it/s]', '\\rOverwrite (mixture) epoch 4/4:  13%|#3\n| 45/345 [00:59<00:20, 14.69it/s]', '\\rOverwrite (mixture) epoch 4/4:  14%|#3\n| 48/345 [01:00<00:18, 16.13it/s]', '\\rOverwrite (mixture) epoch 4/4:  15%|#4\n| 51/345 [01:00<00:17, 17.18it/s]', '\\rOverwrite (mixture) epoch 4/4:  16%|#5\n| 54/345 [01:00<00:15, 18.29it/s]', '\\rOverwrite (mixture) epoch 4/4:  17%|#6\n| 57/345 [01:00<00:15, 19.18it/s]', '\\rOverwrite (mixture) epoch 4/4:  17%|#7\n| 60/345 [01:00<00:14, 19.85it/s]', '\\rOverwrite (mixture) epoch 4/4:  18%|#8\n| 63/345 [01:00<00:13, 20.36it/s]', '\\rOverwrite (mixture) epoch 4/4:  19%|#9\n| 66/345 [01:00<00:14, 19.77it/s]', '\\rOverwrite (mixture) epoch 4/4:  20%|##\n| 69/345 [01:01<00:14, 19.57it/s]', '\\rOverwrite (mixture) epoch 4/4:  21%|##\n| 72/345 [01:01<00:13, 19.66it/s]', '\\rOverwrite (mixture) epoch 4/4:  22%|##1\n| 75/345 [01:01<00:13, 19.96it/s]', '\\rOverwrite (mixture) epoch 4/4:  23%|##2\n| 78/345 [01:01<00:13, 20.28it/s]', '\\rOverwrite (mixture) epoch 4/4:  23%|##3\n| 81/345 [01:01<00:12, 20.61it/s]', '\\rOverwrite (mixture) epoch 4/4:  24%|##4\n| 84/345 [01:01<00:12, 20.86it/s]', '\\rOverwrite (mixture) epoch 4/4:  25%|##5\n| 87/345 [01:01<00:12, 21.09it/s]', '\\rOverwrite (mixture) epoch 4/4:  26%|##6\n| 90/345 [01:02<00:12, 21.10it/s]', '\\rOverwrite (mixture) epoch 4/4:  27%|##6\n| 93/345 [01:02<00:11, 21.16it/s]', '\\rOverwrite (mixture) epoch 4/4:  28%|##7\n| 96/345 [01:02<00:11, 21.23it/s]', '\\rOverwrite (mixture) epoch 4/4:  29%|##8\n| 99/345 [01:02<00:11, 21.33it/s]', '\\rOverwrite (mixture) epoch 4/4:  30%|##9\n| 102/345 [01:02<00:11, 21.36it/s]', '\\rOverwrite (mixture) epoch 4/4:  30%|###\n| 105/345 [01:02<00:11, 21.23it/s]', '\\rOverwrite (mixture) epoch 4/4:  31%|###1\n| 108/345 [01:02<00:11, 21.25it/s]', '\\rOverwrite (mixture) epoch 4/4:  32%|###2\n| 111/345 [01:03<00:10, 21.30it/s]', '\\rOverwrite (mixture) epoch 4/4:  33%|###3\n| 114/345 [01:03<00:11, 20.94it/s]', '\\rOverwrite (mixture) epoch 4/4:  34%|###3\n| 117/345 [01:03<00:10, 20.74it/s]', '\\rOverwrite (mixture) epoch 4/4:  35%|###4\n| 120/345 [01:03<00:10, 20.62it/s]', '\\rOverwrite (mixture) epoch 4/4:  36%|###5\n| 123/345 [01:03<00:10, 20.72it/s]', '\\rOverwrite (mixture) epoch 4/4:  37%|###6\n| 126/345 [01:03<00:10, 20.91it/s]', '\\rOverwrite (mixture) epoch 4/4:  37%|###7\n| 129/345 [01:03<00:10, 20.93it/s]', '\\rOverwrite (mixture) epoch 4/4:  38%|###8\n| 132/345 [01:04<00:10, 21.06it/s]', '\\rOverwrite (mixture) epoch 4/4:  39%|###9\n| 135/345 [01:04<00:09, 21.07it/s]', '\\rOverwrite (mixture) epoch 4/4:  40%|####\n| 138/345 [01:04<00:09, 21.17it/s]', '\\rOverwrite (mixture) epoch 4/4:  41%|####\n| 141/345 [01:04<00:09, 20.82it/s]', '\\rOverwrite (mixture) epoch 4/4:\n42%|####1     | 144/345 [01:04<00:09, 20.75it/s]', '\\rOverwrite (mixture) epoch\n4/4:  43%|####2     | 147/345 [01:04<00:09, 20.76it/s]', '\\rOverwrite (mixture)\nepoch 4/4:  43%|####3     | 150/345 [01:04<00:09, 20.84it/s]', '\\rOverwrite\n(mixture) epoch 4/4:  44%|####4     | 153/345 [01:05<00:09, 20.73it/s]',\n'\\rOverwrite (mixture) epoch 4/4:  45%|####5     | 156/345 [01:05<00:09,\n20.45it/s]', '\\rOverwrite (mixture) epoch 4/4:  46%|####6     | 159/345\n[01:05<00:09, 20.39it/s]', '\\rOverwrite (mixture) epoch 4/4:  47%|####6     |\n162/345 [01:05<00:09, 20.14it/s]', '[2025-12-04 01:13:57] Overwrite (mixture)\nstep 1200: avg_train_loss=2.8699', '\\n', '\\rOverwrite (mixture) epoch 4/4:\n48%|####7     | 165/345 [01:05<00:08, 20.07it/s]', '\\rOverwrite (mixture) epoch\n4/4:  49%|####8     | 168/345 [01:05<00:08, 20.05it/s]', '\\rOverwrite (mixture)\nepoch 4/4:  50%|####9     | 171/345 [01:05<00:08, 20.41it/s]', '\\rOverwrite\n(mixture) epoch 4/4:  50%|#####     | 174/345 [01:06<00:08, 20.53it/s]',\n'\\rOverwrite (mixture) epoch 4/4:  51%|#####1    | 177/345 [01:06<00:08,\n20.61it/s]', '\\rOverwrite (mixture) epoch 4/4:  52%|#####2    | 180/345\n[01:06<00:07, 20.75it/s]', '\\rOverwrite (mixture) epoch 4/4:  53%|#####3    |\n183/345 [01:06<00:07, 20.69it/s]', '\\rOverwrite (mixture) epoch 4/4:  54%|#####3\n| 186/345 [01:06<00:07, 20.68it/s]', '\\rOverwrite (mixture) epoch 4/4:\n55%|#####4    | 189/345 [01:06<00:07, 20.82it/s]', '\\rOverwrite (mixture) epoch\n4/4:  56%|#####5    | 192/345 [01:06<00:07, 21.03it/s]', '\\rOverwrite (mixture)\nepoch 4/4:  57%|#####6    | 195/345 [01:07<00:07, 21.02it/s]', '\\rOverwrite\n(mixture) epoch 4/4:  57%|#####7    | 198/345 [01:07<00:06, 21.06it/s]',\n'\\rOverwrite (mixture) epoch 4/4:  58%|#####8    | 201/345 [01:07<00:06,\n20.59it/s]', '\\rOverwrite (mixture) epoch 4/4:  59%|#####9    | 204/345\n[01:07<00:06, 20.64it/s]', '\\rOverwrite (mixture) epoch 4/4:  60%|######    |\n207/345 [01:07<00:06, 20.81it/s]', '\\rOverwrite (mixture) epoch 4/4:  61%|######\n| 210/345 [01:07<00:06, 20.87it/s]', '\\rOverwrite (mixture) epoch 4/4:\n62%|######1   | 213/345 [01:07<00:06, 20.75it/s]', '\\rOverwrite (mixture) epoch\n4/4:  63%|######2   | 216/345 [01:08<00:06, 20.93it/s]', '\\rOverwrite (mixture)\nepoch 4/4:  63%|######3   | 219/345 [01:08<00:06, 20.97it/s]', '\\rOverwrite\n(mixture) epoch 4/4:  64%|######4   | 222/345 [01:08<00:05, 21.12it/s]',\n'\\rOverwrite (mixture) epoch 4/4:  65%|######5   | 225/345 [01:08<00:05,\n21.04it/s]', '\\rOverwrite (mixture) epoch 4/4:  66%|######6   | 228/345\n[01:08<00:05, 20.96it/s]', '\\rOverwrite (mixture) epoch 4/4:  67%|######6   |\n231/345 [01:08<00:05, 21.09it/s]', '\\rOverwrite (mixture) epoch 4/4:\n68%|######7   | 234/345 [01:08<00:05, 21.16it/s]', '\\rOverwrite (mixture) epoch\n4/4:  69%|######8   | 237/345 [01:09<00:05, 21.31it/s]', '\\rOverwrite (mixture)\nepoch 4/4:  70%|######9   | 240/345 [01:09<00:04, 21.28it/s]', '\\rOverwrite\n(mixture) epoch 4/4:  70%|#######   | 243/345 [01:09<00:04, 21.34it/s]',\n'\\rOverwrite (mixture) epoch 4/4:  71%|#######1  | 246/345 [01:09<00:04,\n21.47it/s]', '\\rOverwrite (mixture) epoch 4/4:  72%|#######2  | 249/345\n[01:09<00:04, 21.47it/s]', '\\rOverwrite (mixture) epoch 4/4:  73%|#######3  |\n252/345 [01:09<00:04, 21.40it/s]', '\\rOverwrite (mixture) epoch 4/4:\n74%|#######3  | 255/345 [01:09<00:04, 21.35it/s]', '\\rOverwrite (mixture) epoch\n4/4:  75%|#######4  | 258/345 [01:10<00:04, 21.37it/s]', '\\rOverwrite (mixture)\nepoch 4/4:  76%|#######5  | 261/345 [01:10<00:03, 21.12it/s]', '\\rOverwrite\n(mixture) epoch 4/4:  77%|#######6  | 264/345 [01:10<00:03, 20.98it/s]',\n'\\rOverwrite (mixture) epoch 4/4:  77%|#######7  | 267/345 [01:10<00:03,\n21.03it/s]', '\\rOverwrite (mixture) epoch 4/4:  78%|#######8  | 270/345\n[01:10<00:03, 21.07it/s]', '\\rOverwrite (mixture) epoch 4/4:  79%|#######9  |\n273/345 [01:10<00:03, 21.18it/s]', '\\rOverwrite (mixture) epoch 4/4:\n80%|########  | 276/345 [01:10<00:03, 21.17it/s]', '\\rOverwrite (mixture) epoch\n4/4:  81%|########  | 279/345 [01:11<00:03, 20.99it/s]', '\\rOverwrite (mixture)\nepoch 4/4:  82%|########1 | 282/345 [01:11<00:02, 21.17it/s]', '\\rOverwrite\n(mixture) epoch 4/4:  83%|########2 | 285/345 [01:11<00:02, 21.24it/s]',\n'\\rOverwrite (mixture) epoch 4/4:  83%|########3 | 288/345 [01:11<00:02,\n21.31it/s]', '\\rOverwrite (mixture) epoch 4/4:  84%|########4 | 291/345\n[01:11<00:02, 20.92it/s]', '\\rOverwrite (mixture) epoch 4/4:  85%|########5 |\n294/345 [01:11<00:02, 20.58it/s]', '\\rOverwrite (mixture) epoch 4/4:\n86%|########6 | 297/345 [01:11<00:02, 20.33it/s]', '\\rOverwrite (mixture) epoch\n4/4:  87%|########6 | 300/345 [01:12<00:02, 20.40it/s]', '\\rOverwrite (mixture)\nepoch 4/4:  88%|########7 | 303/345 [01:12<00:02, 20.30it/s]', '\\rOverwrite\n(mixture) epoch 4/4:  89%|########8 | 306/345 [01:12<00:01, 20.52it/s]',\n'\\rOverwrite (mixture) epoch 4/4:  90%|########9 | 309/345 [01:12<00:01,\n20.82it/s]', '\\rOverwrite (mixture) epoch 4/4:  90%|######### | 312/345\n[01:12<00:01, 20.90it/s]', '\\rOverwrite (mixture) epoch 4/4:  91%|#########1|\n315/345 [01:12<00:01, 20.74it/s]', '\\rOverwrite (mixture) epoch 4/4:\n92%|#########2| 318/345 [01:12<00:01, 20.96it/s]', '\\rOverwrite (mixture) epoch\n4/4:  93%|#########3| 321/345 [01:13<00:01, 21.04it/s]', '\\rOverwrite (mixture)\nepoch 4/4:  94%|#########3| 324/345 [01:13<00:01, 20.93it/s]', '\\rOverwrite\n(mixture) epoch 4/4:  95%|#########4| 327/345 [01:13<00:00, 21.08it/s]',\n'\\rOverwrite (mixture) epoch 4/4:  96%|#########5| 330/345 [01:13<00:00,\n21.08it/s]', '\\rOverwrite (mixture) epoch 4/4:  97%|#########6| 333/345\n[01:13<00:00, 20.34it/s]', '\\rOverwrite (mixture) epoch 4/4:  97%|#########7|\n336/345 [01:13<00:00, 20.11it/s]', '\\rOverwrite (mixture) epoch 4/4:\n98%|#########8| 339/345 [01:13<00:00, 19.95it/s]', '\\rOverwrite (mixture) epoch\n4/4:  99%|#########8| 341/345 [01:14<00:00, 19.93it/s]', '\\rOverwrite (mixture)\nepoch 4/4: 100%|#########9| 344/345 [01:14<00:00, 20.31it/s]', '', '\\rOverwrite\n(mixture) epoch 4/4: 100%|##########| 345/345 [01:15<00:00,  4.57it/s]', '\\n',\n'Epoch 4 (mixture): validation_loss = 3.7287', '\\n', 'Experiment complete.\nArtifacts saved to:', ' ', '/workspace/AE-\nScientist/research_pipeline/workspaces/0-run/process_SpawnProcess-5/working',\n'\\n', 'Execution time: 47 minutes seconds (time limit is 2 hours).']"], "analysis": ["", "Run crashed at the start of the json_style condition. The JSON-like pattern\nstrings contain literal curly braces, and using Python str.format on them caused\nKeyError: '\"secret\"' because format interprets unescaped {...} as named fields.\nExample problematic patterns: '{\"secret\":{}}' and '{\"data\": {\"key\": \"secret\",\n\"value\":{}}}'. Fix: avoid str.format on these templates or escape literal\nbraces. The simplest robust change is to replace pat.format(tok) with\npat.replace(\"{}\", tok) everywhere patterns are applied (in\nbuild_dataset_from_patterns and build_mixture_dataset). This treats '{}' purely\nas a placeholder and leaves JSON braces intact. Alternatively, escape literal\nbraces by doubling them and keep only the token slot as '{}' (e.g., '{{\"secret\":\n{}}}', '{{\"data\": {{\"key\": \"secret\", \"value\": {}}}}'). After this fix, the\njson_style and remaining conditions should run. Minor improvement suggestions:\n(1) In generate_next_tokens, compare first generated token by id rather than\ndecoded string to avoid spacing/decoding mismatches. (2) Optionally print RCRG\nmetrics each epoch for visibility.", "", "Run completed without crashes, but the \u201cfreeze rare embeddings\u201d ablation is not\nactually a full freeze. You zero the gradients for rare rows via a hook, but\nAdamW\u2019s default weight_decay=0.01 still updates those rows each step, causing\ndrift and undermining the ablation (embedding retention cosines may be <1.0).\nFixes: (a) set weight_decay=0.0 for the optimizer during the overwrite phase, or\n(b) use param groups to apply weight_decay=0.0 specifically to embedding (and\nlm_head if untied) weights, or (c) after optimizer.step(), restore rare rows\nfrom a saved copy to enforce exact freezing. Secondary issues/improvements: -\ntorch.cuda.set_device(0) will error on CPU-only machines; guard with if\ntorch.cuda.is_available(). - Consider printing RCRG/recall per epoch so it\nappears in logs. - Generation counting uses strict string equality on the first\ndecoded token; consider stripping or normalizing to avoid false negatives. - All\nmetrics are stored under a single container key; not a bug, but can be confusing\nfor later analysis.", "Run succeeded end-to-end on CUDA with no exceptions. Key events: 5 rare tokens\nadded and verified as single-token; synthetic injection dataset (2000 train /\n300 val) used for phase-1 fine-tune (val loss \u2248 3.23); overwrite on WikiText-2\n(30% train, full val) for 4 epochs with gradient hooks freezing rare-token\nembedding rows (final val loss \u2248 3.72). Artifacts saved: embeddings\nbefore/after, cosine retention arrays, recall/MRR histories, generation samples\nand counts, plots, and experiment_data.npy. Observations and minor issues: - The\nablation correctly freezes rare token rows; with GPT-2\u2019s tied embeddings, the\ninput hook also affects the tied LM head, so freeze is effective. Expect\nnear-1.0 cosine for rare tokens and smaller cosine for controls post-overwrite;\nrecall/MRR histories should reflect higher retention for rare tokens under this\nablation. - torch.cuda.set_device(0) is unguarded; this would fail on CPU-only\nmachines or different device indices (not an issue in this run). - The initial\ndataloader step appeared slow (likely CUDA initialization); subsequent steps\nwere fast\u2014performance quirk, not a bug. - Metrics: recall@k and MRR aggregate\nover prompts\u00d7tokens; that\u2019s acceptable but consider per-token reporting for\nclarity. Generation counting compares the first generated token to targets\nexactly; this is consistent with the setup. - Experimental caveat: this is an\nablation (freeze-rare) rather than a baseline test of natural retention. For\ncompleteness, run a matched overwrite without freezing rare embeddings and\ncompare retention gaps. Overall: no runtime bugs detected; the ablation design\nand logging look consistent with the research plan, and outputs needed for\nanalysis were produced.", ""], "exc_type": [null, "KeyError", null, null, null, null], "exc_info": [null, {"args": ["\"secret\""]}, null, null, null, null], "exc_stack": [null, [["/workspace/AE-Scientist/research_pipeline/ai_scientist/treesearch/interpreter.py", 264, "_repl_run_session", "exec(compile(code, agent_file_name, \"exec\"), global_scope)"], ["runfile.py", 419, "<module>", "train_texts, val_texts, dataset_prompts = build_dataset_from_patterns("], ["runfile.py", 298, "build_dataset_from_patterns", "train_texts.append(pat.format(tok))"]], null, null, null, null], "exp_name": "0-run", "metrics": [{"metric_names": [{"metric_name": "train average loss", "lower_is_better": true, "description": "Average training loss over the training set.", "data": [{"dataset_name": "synthetic_injection", "final_value": 3.085596, "best_value": 3.085596}, {"dataset_name": "overwrite_wikitext", "final_value": 2.876351, "best_value": 2.876351}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "Validation loss measured on the validation set.", "data": [{"dataset_name": "synthetic_injection", "final_value": 3.226789, "best_value": 3.226789}, {"dataset_name": "overwrite_wikitext", "final_value": 3.623615, "best_value": 3.623615}]}, {"metric_name": "RCRG@50", "lower_is_better": false, "description": "RCRG metric at cutoff 50; higher indicates better retrieval/recall performance.", "data": [{"dataset_name": "overwrite_wikitext", "final_value": 0.0, "best_value": 0.0}]}, {"metric_name": "common_recall@50", "lower_is_better": false, "description": "Recall at 50 for common items.", "data": [{"dataset_name": "overwrite_wikitext", "final_value": 0.2, "best_value": 0.2}]}, {"metric_name": "rare_recall@50", "lower_is_better": false, "description": "Recall at 50 for rare items.", "data": [{"dataset_name": "overwrite_wikitext", "final_value": 0.0, "best_value": 0.0}]}]}, {"metric_names": [{"metric_name": "value", "lower_is_better": true, "description": "", "data": [{"dataset_name": "default", "final_value": null, "best_value": null}]}]}, {"metric_names": [{"metric_name": "Train loss", "lower_is_better": true, "description": "Training objective loss; lower values indicate better fit.", "data": [{"dataset_name": "natlang", "final_value": 2.880104, "best_value": 2.880104}, {"dataset_name": "code_style", "final_value": 2.877241, "best_value": 2.877241}, {"dataset_name": "json_style", "final_value": 2.882936, "best_value": 2.882936}, {"dataset_name": "mixture", "final_value": 2.876754, "best_value": 2.876754}, {"dataset_name": "natlang_phase1", "final_value": 3.09109, "best_value": 3.09109}, {"dataset_name": "code_style_phase1", "final_value": 3.727107, "best_value": 3.727107}, {"dataset_name": "json_style_phase1", "final_value": 2.747418, "best_value": 2.747418}, {"dataset_name": "mixture_phase1", "final_value": 3.653895, "best_value": 3.653895}]}, {"metric_name": "Validation loss", "lower_is_better": true, "description": "Validation set loss; lower values indicate better generalization.", "data": [{"dataset_name": "natlang", "final_value": 3.620356, "best_value": 3.620356}, {"dataset_name": "code_style", "final_value": 3.617718, "best_value": 3.617718}, {"dataset_name": "json_style", "final_value": 3.625448, "best_value": 3.625448}, {"dataset_name": "mixture", "final_value": 3.616663, "best_value": 3.616663}, {"dataset_name": "natlang_phase1", "final_value": 3.264396, "best_value": 3.264396}, {"dataset_name": "code_style_phase1", "final_value": 2.515804, "best_value": 2.515804}, {"dataset_name": "json_style_phase1", "final_value": 4.222914, "best_value": 4.222914}, {"dataset_name": "mixture_phase1", "final_value": 3.158692, "best_value": 3.158692}]}, {"metric_name": "RCRG@50 (standard)", "lower_is_better": false, "description": "Ranking metric at cutoff 50 under the standard scheme; higher is better.", "data": [{"dataset_name": "natlang", "final_value": 0.0, "best_value": 0.0}, {"dataset_name": "code_style", "final_value": 0.0, "best_value": 0.0}, {"dataset_name": "json_style", "final_value": 0.0, "best_value": 0.0}, {"dataset_name": "mixture", "final_value": 0.0, "best_value": 0.0}]}, {"metric_name": "Rare recall@50 (standard)", "lower_is_better": false, "description": "Recall@50 for rare items under the standard scheme; higher is better.", "data": [{"dataset_name": "natlang", "final_value": 0.0, "best_value": 0.0}, {"dataset_name": "code_style", "final_value": 0.0, "best_value": 0.0}, {"dataset_name": "json_style", "final_value": 0.0, "best_value": 0.0}, {"dataset_name": "mixture", "final_value": 0.0, "best_value": 0.0}]}, {"metric_name": "Common recall@50 (standard)", "lower_is_better": false, "description": "Recall@50 for common items under the standard scheme; higher is better.", "data": [{"dataset_name": "natlang", "final_value": 0.2, "best_value": 0.2}, {"dataset_name": "code_style", "final_value": 0.0, "best_value": 0.0}, {"dataset_name": "json_style", "final_value": 0.0, "best_value": 0.0}, {"dataset_name": "mixture", "final_value": 0.0, "best_value": 0.0}]}, {"metric_name": "MRR gap (standard)", "lower_is_better": true, "description": "Difference between rare and common MRR under the standard scheme; values closer to 0 indicate less disparity.", "data": [{"dataset_name": "natlang", "final_value": -0.000489, "best_value": -0.000489}, {"dataset_name": "code_style", "final_value": -0.000109, "best_value": -0.000109}, {"dataset_name": "json_style", "final_value": -9.6e-05, "best_value": -9.6e-05}, {"dataset_name": "mixture", "final_value": -0.000234, "best_value": -0.000234}]}, {"metric_name": "Rare MRR (standard)", "lower_is_better": false, "description": "Mean Reciprocal Rank for rare items under the standard scheme; higher is better.", "data": [{"dataset_name": "natlang", "final_value": 3.7e-05, "best_value": 3.7e-05}, {"dataset_name": "code_style", "final_value": 3.6e-05, "best_value": 3.6e-05}, {"dataset_name": "json_style", "final_value": 3.6e-05, "best_value": 3.6e-05}, {"dataset_name": "mixture", "final_value": 3.6e-05, "best_value": 3.6e-05}]}, {"metric_name": "Common MRR (standard)", "lower_is_better": false, "description": "Mean Reciprocal Rank for common items under the standard scheme; higher is better.", "data": [{"dataset_name": "natlang", "final_value": 0.004295, "best_value": 0.004295}, {"dataset_name": "code_style", "final_value": 0.001472, "best_value": 0.001472}, {"dataset_name": "json_style", "final_value": 0.001006, "best_value": 0.001006}, {"dataset_name": "mixture", "final_value": 0.003028, "best_value": 0.003028}]}, {"metric_name": "RCRG@50 (dataset)", "lower_is_better": false, "description": "Ranking metric at cutoff 50 under the dataset-specific scheme; higher is better.", "data": [{"dataset_name": "natlang", "final_value": 0.0, "best_value": 0.0}, {"dataset_name": "code_style", "final_value": 0.0, "best_value": 0.0}, {"dataset_name": "json_style", "final_value": 0.0, "best_value": 0.0}, {"dataset_name": "mixture", "final_value": 0.0, "best_value": 0.0}]}, {"metric_name": "Rare recall@50 (dataset)", "lower_is_better": false, "description": "Recall@50 for rare items under the dataset-specific scheme; higher is better.", "data": [{"dataset_name": "natlang", "final_value": 0.0, "best_value": 0.0}, {"dataset_name": "code_style", "final_value": 0.0, "best_value": 0.0}, {"dataset_name": "json_style", "final_value": 0.0, "best_value": 0.0}, {"dataset_name": "mixture", "final_value": 0.0, "best_value": 0.0}]}, {"metric_name": "Common recall@50 (dataset)", "lower_is_better": false, "description": "Recall@50 for common items under the dataset-specific scheme; higher is better.", "data": [{"dataset_name": "natlang", "final_value": 0.125, "best_value": 0.125}, {"dataset_name": "code_style", "final_value": 0.0, "best_value": 0.0}, {"dataset_name": "json_style", "final_value": 0.0, "best_value": 0.0}, {"dataset_name": "mixture", "final_value": 0.0, "best_value": 0.0}]}, {"metric_name": "MRR gap (dataset)", "lower_is_better": true, "description": "Difference between rare and common MRR under the dataset-specific scheme; values closer to 0 indicate less disparity.", "data": [{"dataset_name": "natlang", "final_value": -0.000347, "best_value": -0.000347}, {"dataset_name": "code_style", "final_value": -9.7e-05, "best_value": -9.7e-05}, {"dataset_name": "json_style", "final_value": -6.4e-05, "best_value": -6.4e-05}, {"dataset_name": "mixture", "final_value": -0.000136, "best_value": -0.000136}]}, {"metric_name": "Rare MRR (dataset)", "lower_is_better": false, "description": "Mean Reciprocal Rank for rare items under the dataset-specific scheme; higher is better.", "data": [{"dataset_name": "natlang", "final_value": 3.7e-05, "best_value": 3.7e-05}, {"dataset_name": "code_style", "final_value": 3.8e-05, "best_value": 3.8e-05}, {"dataset_name": "json_style", "final_value": 3.6e-05, "best_value": 3.6e-05}, {"dataset_name": "mixture", "final_value": 3.7e-05, "best_value": 3.7e-05}]}, {"metric_name": "Common MRR (dataset)", "lower_is_better": false, "description": "Mean Reciprocal Rank for common items under the dataset-specific scheme; higher is better.", "data": [{"dataset_name": "natlang", "final_value": 0.003253, "best_value": 0.003253}, {"dataset_name": "code_style", "final_value": 0.000503, "best_value": 0.000503}, {"dataset_name": "json_style", "final_value": 0.00077, "best_value": 0.00077}, {"dataset_name": "mixture", "final_value": 0.001257, "best_value": 0.001257}]}]}, {"metric_names": [{"metric_name": "train avg_loss", "lower_is_better": true, "description": "Average training loss; lower values indicate better fit.", "data": [{"dataset_name": "ablation_type_1/dataset_name_1", "final_value": 2.876352206520412, "best_value": 2.876352206520412}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "Average loss on the validation set; lower values indicate better generalization.", "data": [{"dataset_name": "ablation_type_1/dataset_name_1", "final_value": 3.2267885208129883, "best_value": 3.2267885208129883}]}, {"metric_name": "RCRG@50", "lower_is_better": false, "description": "Recall at 50 for the RCRG metric; higher is better.", "data": [{"dataset_name": "ablation_type_1/dataset_name_1", "final_value": 0.0, "best_value": 0.0}]}, {"metric_name": "rare recall@50", "lower_is_better": false, "description": "Recall at 50 for rare categories; higher is better.", "data": [{"dataset_name": "ablation_type_1/dataset_name_1", "final_value": 0.0, "best_value": 0.0}]}, {"metric_name": "common recall@50", "lower_is_better": false, "description": "Recall at 50 for common categories; higher is better.", "data": [{"dataset_name": "ablation_type_1/dataset_name_1", "final_value": 0.0, "best_value": 0.0}]}]}, {"metric_names": [{"metric_name": "train average loss", "lower_is_better": true, "description": "Average training loss at the end of training.", "data": [{"dataset_name": "dataset_synthetic_injection", "final_value": 3.0855959370022727, "best_value": 0.0}, {"dataset_name": "dataset_wikitext_overwrite", "final_value": 2.876352206520412, "best_value": 0.0}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "Best validation loss achieved during training.", "data": [{"dataset_name": "dataset_synthetic_injection", "final_value": 0.0, "best_value": 3.2267885208129883}, {"dataset_name": "dataset_wikitext_overwrite", "final_value": 0.0, "best_value": 3.623615846795551}]}, {"metric_name": "validation rare recall@50", "lower_is_better": false, "description": "Recall@50 on the rare subset of the validation data.", "data": [{"dataset_name": "dataset_synthetic_injection", "final_value": 0.0, "best_value": 0.0}, {"dataset_name": "dataset_wikitext_overwrite", "final_value": 0.0, "best_value": 0.0}]}, {"metric_name": "validation common recall@50", "lower_is_better": false, "description": "Recall@50 on the common subset of the validation data.", "data": [{"dataset_name": "dataset_synthetic_injection", "final_value": 0.0, "best_value": 0.0}, {"dataset_name": "dataset_wikitext_overwrite", "final_value": 0.0, "best_value": 0.2}]}, {"metric_name": "validation MRR rare", "lower_is_better": false, "description": "Mean Reciprocal Rank on the rare subset of the validation data (higher is better).", "data": [{"dataset_name": "dataset_synthetic_injection", "final_value": 0.0, "best_value": 5.885551020980018e-05}, {"dataset_name": "dataset_wikitext_overwrite", "final_value": 0.0, "best_value": 0.00010993255796603315}]}, {"metric_name": "validation MRR common", "lower_is_better": false, "description": "Mean Reciprocal Rank on the common subset of the validation data (higher is better).", "data": [{"dataset_name": "dataset_synthetic_injection", "final_value": 0.0, "best_value": 0.0006805330290799254}, {"dataset_name": "dataset_wikitext_overwrite", "final_value": 0.0, "best_value": 0.006685887517693588}]}, {"metric_name": "validation MRR retention gap", "lower_is_better": false, "description": "Difference between common and rare MRR; values closer to zero indicate smaller disparity.", "data": [{"dataset_name": "dataset_synthetic_injection", "final_value": -0.0006216775188701252, "best_value": 0.0}, {"dataset_name": "dataset_wikitext_overwrite", "final_value": -0.00011169656770554598, "best_value": 0.0}]}]}, {"metric_names": [{"metric_name": "Train loss", "lower_is_better": true, "description": "Training loss at the final epoch/step.", "data": [{"dataset_name": "natlang", "final_value": 2.880104, "best_value": 0.0}, {"dataset_name": "code_style", "final_value": 2.877241, "best_value": 0.0}, {"dataset_name": "json_style", "final_value": 2.882936, "best_value": 0.0}, {"dataset_name": "mixture", "final_value": 2.876754, "best_value": 0.0}, {"dataset_name": "natlang_phase1", "final_value": 3.09109, "best_value": 0.0}, {"dataset_name": "code_style_phase1", "final_value": 3.727107, "best_value": 0.0}, {"dataset_name": "json_style_phase1", "final_value": 2.747418, "best_value": 0.0}, {"dataset_name": "mixture_phase1", "final_value": 3.653895, "best_value": 0.0}]}, {"metric_name": "Validation loss", "lower_is_better": true, "description": "Lowest validation loss achieved during training.", "data": [{"dataset_name": "natlang", "final_value": 0.0, "best_value": 3.620356}, {"dataset_name": "code_style", "final_value": 0.0, "best_value": 3.617718}, {"dataset_name": "json_style", "final_value": 0.0, "best_value": 3.625448}, {"dataset_name": "mixture", "final_value": 0.0, "best_value": 3.616663}, {"dataset_name": "natlang_phase1", "final_value": 0.0, "best_value": 3.264396}, {"dataset_name": "code_style_phase1", "final_value": 0.0, "best_value": 2.515804}, {"dataset_name": "json_style_phase1", "final_value": 0.0, "best_value": 4.222914}, {"dataset_name": "mixture_phase1", "final_value": 0.0, "best_value": 3.158692}]}, {"metric_name": "RCRG@50 (standard)", "lower_is_better": false, "description": "RCRG at cutoff 50 under standard evaluation.", "data": [{"dataset_name": "natlang", "final_value": 0.0, "best_value": 0.0}, {"dataset_name": "code_style", "final_value": 0.0, "best_value": 0.0}, {"dataset_name": "json_style", "final_value": 0.0, "best_value": 0.0}, {"dataset_name": "mixture", "final_value": 0.0, "best_value": 0.0}]}, {"metric_name": "Rare recall@50 (standard)", "lower_is_better": false, "description": "Recall@50 for rare items under standard evaluation.", "data": [{"dataset_name": "natlang", "final_value": 0.0, "best_value": 0.0}, {"dataset_name": "code_style", "final_value": 0.0, "best_value": 0.0}, {"dataset_name": "json_style", "final_value": 0.0, "best_value": 0.0}, {"dataset_name": "mixture", "final_value": 0.0, "best_value": 0.0}]}, {"metric_name": "Common recall@50 (standard)", "lower_is_better": false, "description": "Recall@50 for common items under standard evaluation.", "data": [{"dataset_name": "natlang", "final_value": 0.0, "best_value": 0.2}, {"dataset_name": "code_style", "final_value": 0.0, "best_value": 0.0}, {"dataset_name": "json_style", "final_value": 0.0, "best_value": 0.0}, {"dataset_name": "mixture", "final_value": 0.0, "best_value": 0.0}]}, {"metric_name": "MRR gap (standard)", "lower_is_better": true, "description": "Gap between common and rare MRR under standard evaluation (closer to 0 is better).", "data": [{"dataset_name": "natlang", "final_value": 0.0, "best_value": -0.000489}, {"dataset_name": "code_style", "final_value": 0.0, "best_value": -0.000109}, {"dataset_name": "json_style", "final_value": 0.0, "best_value": -9.6e-05}, {"dataset_name": "mixture", "final_value": 0.0, "best_value": -0.000234}]}, {"metric_name": "Rare MRR (standard)", "lower_is_better": false, "description": "Mean reciprocal rank for rare items under standard evaluation.", "data": [{"dataset_name": "natlang", "final_value": 0.0, "best_value": 3.7e-05}, {"dataset_name": "code_style", "final_value": 0.0, "best_value": 3.6e-05}, {"dataset_name": "json_style", "final_value": 0.0, "best_value": 3.6e-05}, {"dataset_name": "mixture", "final_value": 0.0, "best_value": 3.6e-05}]}, {"metric_name": "Common MRR (standard)", "lower_is_better": false, "description": "Mean reciprocal rank for common items under standard evaluation.", "data": [{"dataset_name": "natlang", "final_value": 0.0, "best_value": 0.004295}, {"dataset_name": "code_style", "final_value": 0.0, "best_value": 0.001472}, {"dataset_name": "json_style", "final_value": 0.0, "best_value": 0.001006}, {"dataset_name": "mixture", "final_value": 0.0, "best_value": 0.003028}]}, {"metric_name": "RCRG@50 (dataset)", "lower_is_better": false, "description": "RCRG at cutoff 50 under dataset-specific evaluation.", "data": [{"dataset_name": "natlang", "final_value": 0.0, "best_value": 0.0}, {"dataset_name": "code_style", "final_value": 0.0, "best_value": 0.0}, {"dataset_name": "json_style", "final_value": 0.0, "best_value": 0.0}, {"dataset_name": "mixture", "final_value": 0.0, "best_value": 0.0}]}, {"metric_name": "Rare recall@50 (dataset)", "lower_is_better": false, "description": "Recall@50 for rare items under dataset-specific evaluation.", "data": [{"dataset_name": "natlang", "final_value": 0.0, "best_value": 0.0}, {"dataset_name": "code_style", "final_value": 0.0, "best_value": 0.0}, {"dataset_name": "json_style", "final_value": 0.0, "best_value": 0.0}, {"dataset_name": "mixture", "final_value": 0.0, "best_value": 0.0}]}, {"metric_name": "Common recall@50 (dataset)", "lower_is_better": false, "description": "Recall@50 for common items under dataset-specific evaluation.", "data": [{"dataset_name": "natlang", "final_value": 0.0, "best_value": 0.125}, {"dataset_name": "code_style", "final_value": 0.0, "best_value": 0.0}, {"dataset_name": "json_style", "final_value": 0.0, "best_value": 0.0}, {"dataset_name": "mixture", "final_value": 0.0, "best_value": 0.0}]}, {"metric_name": "MRR gap (dataset)", "lower_is_better": true, "description": "Gap between common and rare MRR under dataset-specific evaluation (closer to 0 is better).", "data": [{"dataset_name": "natlang", "final_value": 0.0, "best_value": -0.000347}, {"dataset_name": "code_style", "final_value": 0.0, "best_value": -9.7e-05}, {"dataset_name": "json_style", "final_value": 0.0, "best_value": -6.4e-05}, {"dataset_name": "mixture", "final_value": 0.0, "best_value": -0.000136}]}, {"metric_name": "Rare MRR (dataset)", "lower_is_better": false, "description": "Mean reciprocal rank for rare items under dataset-specific evaluation.", "data": [{"dataset_name": "natlang", "final_value": 0.0, "best_value": 3.7e-05}, {"dataset_name": "code_style", "final_value": 0.0, "best_value": 3.8e-05}, {"dataset_name": "json_style", "final_value": 0.0, "best_value": 3.6e-05}, {"dataset_name": "mixture", "final_value": 0.0, "best_value": 3.7e-05}]}, {"metric_name": "Common MRR (dataset)", "lower_is_better": false, "description": "Mean reciprocal rank for common items under dataset-specific evaluation.", "data": [{"dataset_name": "natlang", "final_value": 0.0, "best_value": 0.003253}, {"dataset_name": "code_style", "final_value": 0.0, "best_value": 0.000503}, {"dataset_name": "json_style", "final_value": 0.0, "best_value": 0.00077}, {"dataset_name": "mixture", "final_value": 0.0, "best_value": 0.001257}]}]}], "is_best_node": [false, false, false, false, true, false], "plots": [[], [], ["../../logs/0-run/experiment_results/experiment_8aea9590de4844f6a22a8dd61edd7ced_proc_42006/mixture_groundtruth_vs_generated.png", "../../logs/0-run/experiment_results/experiment_8aea9590de4844f6a22a8dd61edd7ced_proc_42006/mixture_retention_metrics_dataset.png", "../../logs/0-run/experiment_results/experiment_8aea9590de4844f6a22a8dd61edd7ced_proc_42006/mixture_retention_metrics_standard.png", "../../logs/0-run/experiment_results/experiment_8aea9590de4844f6a22a8dd61edd7ced_proc_42006/mixture_validation_loss_curves.png", "../../logs/0-run/experiment_results/experiment_8aea9590de4844f6a22a8dd61edd7ced_proc_42006/mixture_training_loss_curves.png", "../../logs/0-run/experiment_results/experiment_8aea9590de4844f6a22a8dd61edd7ced_proc_42006/json_style_groundtruth_vs_generated.png", "../../logs/0-run/experiment_results/experiment_8aea9590de4844f6a22a8dd61edd7ced_proc_42006/json_style_retention_metrics_dataset.png", "../../logs/0-run/experiment_results/experiment_8aea9590de4844f6a22a8dd61edd7ced_proc_42006/json_style_retention_metrics_standard.png", "../../logs/0-run/experiment_results/experiment_8aea9590de4844f6a22a8dd61edd7ced_proc_42006/json_style_validation_loss_curves.png", "../../logs/0-run/experiment_results/experiment_8aea9590de4844f6a22a8dd61edd7ced_proc_42006/json_style_training_loss_curves.png", "../../logs/0-run/experiment_results/experiment_8aea9590de4844f6a22a8dd61edd7ced_proc_42006/code_style_groundtruth_vs_generated.png", "../../logs/0-run/experiment_results/experiment_8aea9590de4844f6a22a8dd61edd7ced_proc_42006/code_style_retention_metrics_dataset.png", "../../logs/0-run/experiment_results/experiment_8aea9590de4844f6a22a8dd61edd7ced_proc_42006/code_style_retention_metrics_standard.png", "../../logs/0-run/experiment_results/experiment_8aea9590de4844f6a22a8dd61edd7ced_proc_42006/code_style_validation_loss_curves.png", "../../logs/0-run/experiment_results/experiment_8aea9590de4844f6a22a8dd61edd7ced_proc_42006/code_style_training_loss_curves.png", "../../logs/0-run/experiment_results/experiment_8aea9590de4844f6a22a8dd61edd7ced_proc_42006/natlang_groundtruth_vs_generated.png", "../../logs/0-run/experiment_results/experiment_8aea9590de4844f6a22a8dd61edd7ced_proc_42006/natlang_retention_metrics_dataset.png", "../../logs/0-run/experiment_results/experiment_8aea9590de4844f6a22a8dd61edd7ced_proc_42006/natlang_retention_metrics_standard.png", "../../logs/0-run/experiment_results/experiment_8aea9590de4844f6a22a8dd61edd7ced_proc_42006/natlang_validation_loss_curves.png", "../../logs/0-run/experiment_results/experiment_8aea9590de4844f6a22a8dd61edd7ced_proc_42006/natlang_training_loss_curves.png", "../../logs/0-run/experiment_results/experiment_8aea9590de4844f6a22a8dd61edd7ced_proc_42006/retention_over_epochs_dataset_mixture.png", "../../logs/0-run/experiment_results/experiment_8aea9590de4844f6a22a8dd61edd7ced_proc_42006/retention_over_epochs_standard_mixture.png", "../../logs/0-run/experiment_results/experiment_8aea9590de4844f6a22a8dd61edd7ced_proc_42006/gen_counts_common_post_ds_mixture.png", "../../logs/0-run/experiment_results/experiment_8aea9590de4844f6a22a8dd61edd7ced_proc_42006/gen_counts_rare_post_ds_mixture.png", "../../logs/0-run/experiment_results/experiment_8aea9590de4844f6a22a8dd61edd7ced_proc_42006/gen_counts_common_post_std_mixture.png", "../../logs/0-run/experiment_results/experiment_8aea9590de4844f6a22a8dd61edd7ced_proc_42006/gen_counts_rare_post_std_mixture.png", "../../logs/0-run/experiment_results/experiment_8aea9590de4844f6a22a8dd61edd7ced_proc_42006/embedding_retention_common_mixture.png", "../../logs/0-run/experiment_results/experiment_8aea9590de4844f6a22a8dd61edd7ced_proc_42006/embedding_retention_rare_mixture.png", "../../logs/0-run/experiment_results/experiment_8aea9590de4844f6a22a8dd61edd7ced_proc_42006/retention_over_epochs_dataset_json_style.png", "../../logs/0-run/experiment_results/experiment_8aea9590de4844f6a22a8dd61edd7ced_proc_42006/retention_over_epochs_standard_json_style.png", "../../logs/0-run/experiment_results/experiment_8aea9590de4844f6a22a8dd61edd7ced_proc_42006/gen_counts_common_post_ds_json_style.png", "../../logs/0-run/experiment_results/experiment_8aea9590de4844f6a22a8dd61edd7ced_proc_42006/gen_counts_rare_post_ds_json_style.png", "../../logs/0-run/experiment_results/experiment_8aea9590de4844f6a22a8dd61edd7ced_proc_42006/gen_counts_common_post_std_json_style.png", "../../logs/0-run/experiment_results/experiment_8aea9590de4844f6a22a8dd61edd7ced_proc_42006/gen_counts_rare_post_std_json_style.png", "../../logs/0-run/experiment_results/experiment_8aea9590de4844f6a22a8dd61edd7ced_proc_42006/embedding_retention_common_json_style.png", "../../logs/0-run/experiment_results/experiment_8aea9590de4844f6a22a8dd61edd7ced_proc_42006/embedding_retention_rare_json_style.png", "../../logs/0-run/experiment_results/experiment_8aea9590de4844f6a22a8dd61edd7ced_proc_42006/retention_over_epochs_dataset_code_style.png", "../../logs/0-run/experiment_results/experiment_8aea9590de4844f6a22a8dd61edd7ced_proc_42006/retention_over_epochs_standard_code_style.png", "../../logs/0-run/experiment_results/experiment_8aea9590de4844f6a22a8dd61edd7ced_proc_42006/retention_over_epochs_dataset_natlang.png", "../../logs/0-run/experiment_results/experiment_8aea9590de4844f6a22a8dd61edd7ced_proc_42006/retention_over_epochs_standard_natlang.png", "../../logs/0-run/experiment_results/experiment_8aea9590de4844f6a22a8dd61edd7ced_proc_42006/rcrg_over_epochs_dataset_code_style.png", "../../logs/0-run/experiment_results/experiment_8aea9590de4844f6a22a8dd61edd7ced_proc_42006/rcrg_over_epochs_standard_code_style.png", "../../logs/0-run/experiment_results/experiment_8aea9590de4844f6a22a8dd61edd7ced_proc_42006/gen_counts_common_post_ds_code_style.png", "../../logs/0-run/experiment_results/experiment_8aea9590de4844f6a22a8dd61edd7ced_proc_42006/gen_counts_rare_post_ds_code_style.png", "../../logs/0-run/experiment_results/experiment_8aea9590de4844f6a22a8dd61edd7ced_proc_42006/gen_counts_common_post_std_code_style.png", "../../logs/0-run/experiment_results/experiment_8aea9590de4844f6a22a8dd61edd7ced_proc_42006/gen_counts_rare_post_std_code_style.png", "../../logs/0-run/experiment_results/experiment_8aea9590de4844f6a22a8dd61edd7ced_proc_42006/embedding_retention_common_code_style.png", "../../logs/0-run/experiment_results/experiment_8aea9590de4844f6a22a8dd61edd7ced_proc_42006/embedding_retention_rare_code_style.png", "../../logs/0-run/experiment_results/experiment_8aea9590de4844f6a22a8dd61edd7ced_proc_42006/rcrg_over_epochs_dataset_natlang.png", "../../logs/0-run/experiment_results/experiment_8aea9590de4844f6a22a8dd61edd7ced_proc_42006/rcrg_over_epochs_standard_natlang.png", "../../logs/0-run/experiment_results/experiment_8aea9590de4844f6a22a8dd61edd7ced_proc_42006/gen_counts_common_post_ds_natlang.png", "../../logs/0-run/experiment_results/experiment_8aea9590de4844f6a22a8dd61edd7ced_proc_42006/gen_counts_rare_post_ds_natlang.png", "../../logs/0-run/experiment_results/experiment_8aea9590de4844f6a22a8dd61edd7ced_proc_42006/gen_counts_common_post_std_natlang.png", "../../logs/0-run/experiment_results/experiment_8aea9590de4844f6a22a8dd61edd7ced_proc_42006/gen_counts_rare_post_std_natlang.png", "../../logs/0-run/experiment_results/experiment_8aea9590de4844f6a22a8dd61edd7ced_proc_42006/embedding_retention_common_natlang.png", "../../logs/0-run/experiment_results/experiment_8aea9590de4844f6a22a8dd61edd7ced_proc_42006/embedding_retention_rare_natlang.png"], [], ["../../logs/0-run/experiment_results/experiment_9a0ce6ba79e74298b180e66bd282c3ae_proc_42006/dataset_wikitext_overwrite_generated_token_counts.png", "../../logs/0-run/experiment_results/experiment_9a0ce6ba79e74298b180e66bd282c3ae_proc_42006/dataset_wikitext_overwrite_mrr_gap_over_epochs.png", "../../logs/0-run/experiment_results/experiment_9a0ce6ba79e74298b180e66bd282c3ae_proc_42006/dataset_wikitext_overwrite_recall_over_epochs.png", "../../logs/0-run/experiment_results/experiment_9a0ce6ba79e74298b180e66bd282c3ae_proc_42006/dataset_wikitext_overwrite_loss_curves.png", "../../logs/0-run/experiment_results/experiment_9a0ce6ba79e74298b180e66bd282c3ae_proc_42006/dataset_synthetic_injection_loss_curves.png", "../../logs/0-run/experiment_results/experiment_9a0ce6ba79e74298b180e66bd282c3ae_proc_42006/mrr_gap_over_epochs_wikitext.png", "../../logs/0-run/experiment_results/experiment_9a0ce6ba79e74298b180e66bd282c3ae_proc_42006/rcrg_over_epochs_wikitext.png", "../../logs/0-run/experiment_results/experiment_9a0ce6ba79e74298b180e66bd282c3ae_proc_42006/gen_counts_common_post_wikitext.png", "../../logs/0-run/experiment_results/experiment_9a0ce6ba79e74298b180e66bd282c3ae_proc_42006/gen_counts_rare_post_wikitext.png", "../../logs/0-run/experiment_results/experiment_9a0ce6ba79e74298b180e66bd282c3ae_proc_42006/embedding_retention_common_tokens.png", "../../logs/0-run/experiment_results/experiment_9a0ce6ba79e74298b180e66bd282c3ae_proc_42006/embedding_retention_rare_tokens.png", "../../logs/0-run/experiment_results/experiment_9a0ce6ba79e74298b180e66bd282c3ae_proc_42006/rcrg_over_epochs.png", "../../logs/0-run/experiment_results/experiment_9a0ce6ba79e74298b180e66bd282c3ae_proc_42006/gen_counts_common_post.png", "../../logs/0-run/experiment_results/experiment_9a0ce6ba79e74298b180e66bd282c3ae_proc_42006/gen_counts_rare_post.png", "../../logs/0-run/experiment_results/experiment_9a0ce6ba79e74298b180e66bd282c3ae_proc_42006/embedding_retention_common.png", "../../logs/0-run/experiment_results/experiment_9a0ce6ba79e74298b180e66bd282c3ae_proc_42006/embedding_retention_rare.png"], ["../../logs/0-run/experiment_results/experiment_6eac8086c77e47edbce4dd03d049e3a3_proc_42006/mixture_groundtruth_vs_generated.png", "../../logs/0-run/experiment_results/experiment_6eac8086c77e47edbce4dd03d049e3a3_proc_42006/mixture_retention_metrics_dataset.png", "../../logs/0-run/experiment_results/experiment_6eac8086c77e47edbce4dd03d049e3a3_proc_42006/mixture_retention_metrics_standard.png", "../../logs/0-run/experiment_results/experiment_6eac8086c77e47edbce4dd03d049e3a3_proc_42006/mixture_validation_loss_curves.png", "../../logs/0-run/experiment_results/experiment_6eac8086c77e47edbce4dd03d049e3a3_proc_42006/mixture_training_loss_curves.png", "../../logs/0-run/experiment_results/experiment_6eac8086c77e47edbce4dd03d049e3a3_proc_42006/json_style_groundtruth_vs_generated.png", "../../logs/0-run/experiment_results/experiment_6eac8086c77e47edbce4dd03d049e3a3_proc_42006/json_style_retention_metrics_dataset.png", "../../logs/0-run/experiment_results/experiment_6eac8086c77e47edbce4dd03d049e3a3_proc_42006/json_style_retention_metrics_standard.png", "../../logs/0-run/experiment_results/experiment_6eac8086c77e47edbce4dd03d049e3a3_proc_42006/json_style_validation_loss_curves.png", "../../logs/0-run/experiment_results/experiment_6eac8086c77e47edbce4dd03d049e3a3_proc_42006/json_style_training_loss_curves.png", "../../logs/0-run/experiment_results/experiment_6eac8086c77e47edbce4dd03d049e3a3_proc_42006/code_style_groundtruth_vs_generated.png", "../../logs/0-run/experiment_results/experiment_6eac8086c77e47edbce4dd03d049e3a3_proc_42006/code_style_retention_metrics_dataset.png", "../../logs/0-run/experiment_results/experiment_6eac8086c77e47edbce4dd03d049e3a3_proc_42006/code_style_retention_metrics_standard.png", "../../logs/0-run/experiment_results/experiment_6eac8086c77e47edbce4dd03d049e3a3_proc_42006/code_style_validation_loss_curves.png", "../../logs/0-run/experiment_results/experiment_6eac8086c77e47edbce4dd03d049e3a3_proc_42006/code_style_training_loss_curves.png", "../../logs/0-run/experiment_results/experiment_6eac8086c77e47edbce4dd03d049e3a3_proc_42006/natlang_groundtruth_vs_generated.png", "../../logs/0-run/experiment_results/experiment_6eac8086c77e47edbce4dd03d049e3a3_proc_42006/natlang_retention_metrics_dataset.png", "../../logs/0-run/experiment_results/experiment_6eac8086c77e47edbce4dd03d049e3a3_proc_42006/natlang_retention_metrics_standard.png", "../../logs/0-run/experiment_results/experiment_6eac8086c77e47edbce4dd03d049e3a3_proc_42006/natlang_validation_loss_curves.png", "../../logs/0-run/experiment_results/experiment_6eac8086c77e47edbce4dd03d049e3a3_proc_42006/natlang_training_loss_curves.png", "../../logs/0-run/experiment_results/experiment_6eac8086c77e47edbce4dd03d049e3a3_proc_42006/retention_over_epochs_dataset_mixture.png", "../../logs/0-run/experiment_results/experiment_6eac8086c77e47edbce4dd03d049e3a3_proc_42006/retention_over_epochs_standard_mixture.png", "../../logs/0-run/experiment_results/experiment_6eac8086c77e47edbce4dd03d049e3a3_proc_42006/gen_counts_common_post_ds_mixture.png", "../../logs/0-run/experiment_results/experiment_6eac8086c77e47edbce4dd03d049e3a3_proc_42006/gen_counts_rare_post_ds_mixture.png", "../../logs/0-run/experiment_results/experiment_6eac8086c77e47edbce4dd03d049e3a3_proc_42006/gen_counts_common_post_std_mixture.png", "../../logs/0-run/experiment_results/experiment_6eac8086c77e47edbce4dd03d049e3a3_proc_42006/gen_counts_rare_post_std_mixture.png", "../../logs/0-run/experiment_results/experiment_6eac8086c77e47edbce4dd03d049e3a3_proc_42006/embedding_retention_common_mixture.png", "../../logs/0-run/experiment_results/experiment_6eac8086c77e47edbce4dd03d049e3a3_proc_42006/embedding_retention_rare_mixture.png", "../../logs/0-run/experiment_results/experiment_6eac8086c77e47edbce4dd03d049e3a3_proc_42006/retention_over_epochs_dataset_json_style.png", "../../logs/0-run/experiment_results/experiment_6eac8086c77e47edbce4dd03d049e3a3_proc_42006/retention_over_epochs_standard_json_style.png", "../../logs/0-run/experiment_results/experiment_6eac8086c77e47edbce4dd03d049e3a3_proc_42006/gen_counts_common_post_ds_json_style.png", "../../logs/0-run/experiment_results/experiment_6eac8086c77e47edbce4dd03d049e3a3_proc_42006/gen_counts_rare_post_ds_json_style.png", "../../logs/0-run/experiment_results/experiment_6eac8086c77e47edbce4dd03d049e3a3_proc_42006/gen_counts_common_post_std_json_style.png", "../../logs/0-run/experiment_results/experiment_6eac8086c77e47edbce4dd03d049e3a3_proc_42006/gen_counts_rare_post_std_json_style.png", "../../logs/0-run/experiment_results/experiment_6eac8086c77e47edbce4dd03d049e3a3_proc_42006/embedding_retention_common_json_style.png", "../../logs/0-run/experiment_results/experiment_6eac8086c77e47edbce4dd03d049e3a3_proc_42006/embedding_retention_rare_json_style.png", "../../logs/0-run/experiment_results/experiment_6eac8086c77e47edbce4dd03d049e3a3_proc_42006/retention_over_epochs_dataset_code_style.png", "../../logs/0-run/experiment_results/experiment_6eac8086c77e47edbce4dd03d049e3a3_proc_42006/retention_over_epochs_standard_code_style.png", "../../logs/0-run/experiment_results/experiment_6eac8086c77e47edbce4dd03d049e3a3_proc_42006/gen_counts_common_post_ds_code_style.png", "../../logs/0-run/experiment_results/experiment_6eac8086c77e47edbce4dd03d049e3a3_proc_42006/gen_counts_rare_post_ds_code_style.png", "../../logs/0-run/experiment_results/experiment_6eac8086c77e47edbce4dd03d049e3a3_proc_42006/gen_counts_common_post_std_code_style.png", "../../logs/0-run/experiment_results/experiment_6eac8086c77e47edbce4dd03d049e3a3_proc_42006/gen_counts_rare_post_std_code_style.png", "../../logs/0-run/experiment_results/experiment_6eac8086c77e47edbce4dd03d049e3a3_proc_42006/embedding_retention_common_code_style.png", "../../logs/0-run/experiment_results/experiment_6eac8086c77e47edbce4dd03d049e3a3_proc_42006/embedding_retention_rare_code_style.png", "../../logs/0-run/experiment_results/experiment_6eac8086c77e47edbce4dd03d049e3a3_proc_42006/retention_over_epochs_dataset_natlang.png", "../../logs/0-run/experiment_results/experiment_6eac8086c77e47edbce4dd03d049e3a3_proc_42006/retention_over_epochs_standard_natlang.png", "../../logs/0-run/experiment_results/experiment_6eac8086c77e47edbce4dd03d049e3a3_proc_42006/gen_counts_common_post_ds_natlang.png", "../../logs/0-run/experiment_results/experiment_6eac8086c77e47edbce4dd03d049e3a3_proc_42006/gen_counts_rare_post_ds_natlang.png", "../../logs/0-run/experiment_results/experiment_6eac8086c77e47edbce4dd03d049e3a3_proc_42006/gen_counts_common_post_std_natlang.png", "../../logs/0-run/experiment_results/experiment_6eac8086c77e47edbce4dd03d049e3a3_proc_42006/gen_counts_rare_post_std_natlang.png", "../../logs/0-run/experiment_results/experiment_6eac8086c77e47edbce4dd03d049e3a3_proc_42006/embedding_retention_common_natlang.png", "../../logs/0-run/experiment_results/experiment_6eac8086c77e47edbce4dd03d049e3a3_proc_42006/embedding_retention_rare_natlang.png"]], "plot_paths": [[], [], ["workspaces/logs/0-run/experiment_results/experiment_8aea9590de4844f6a22a8dd61edd7ced_proc_42006/mixture_groundtruth_vs_generated.png", "workspaces/logs/0-run/experiment_results/experiment_8aea9590de4844f6a22a8dd61edd7ced_proc_42006/mixture_retention_metrics_dataset.png", "workspaces/logs/0-run/experiment_results/experiment_8aea9590de4844f6a22a8dd61edd7ced_proc_42006/mixture_retention_metrics_standard.png", "workspaces/logs/0-run/experiment_results/experiment_8aea9590de4844f6a22a8dd61edd7ced_proc_42006/mixture_validation_loss_curves.png", "workspaces/logs/0-run/experiment_results/experiment_8aea9590de4844f6a22a8dd61edd7ced_proc_42006/mixture_training_loss_curves.png", "workspaces/logs/0-run/experiment_results/experiment_8aea9590de4844f6a22a8dd61edd7ced_proc_42006/json_style_groundtruth_vs_generated.png", "workspaces/logs/0-run/experiment_results/experiment_8aea9590de4844f6a22a8dd61edd7ced_proc_42006/json_style_retention_metrics_dataset.png", "workspaces/logs/0-run/experiment_results/experiment_8aea9590de4844f6a22a8dd61edd7ced_proc_42006/json_style_retention_metrics_standard.png", "workspaces/logs/0-run/experiment_results/experiment_8aea9590de4844f6a22a8dd61edd7ced_proc_42006/json_style_validation_loss_curves.png", "workspaces/logs/0-run/experiment_results/experiment_8aea9590de4844f6a22a8dd61edd7ced_proc_42006/json_style_training_loss_curves.png", "workspaces/logs/0-run/experiment_results/experiment_8aea9590de4844f6a22a8dd61edd7ced_proc_42006/code_style_groundtruth_vs_generated.png", "workspaces/logs/0-run/experiment_results/experiment_8aea9590de4844f6a22a8dd61edd7ced_proc_42006/code_style_retention_metrics_dataset.png", "workspaces/logs/0-run/experiment_results/experiment_8aea9590de4844f6a22a8dd61edd7ced_proc_42006/code_style_retention_metrics_standard.png", "workspaces/logs/0-run/experiment_results/experiment_8aea9590de4844f6a22a8dd61edd7ced_proc_42006/code_style_validation_loss_curves.png", "workspaces/logs/0-run/experiment_results/experiment_8aea9590de4844f6a22a8dd61edd7ced_proc_42006/code_style_training_loss_curves.png", "workspaces/logs/0-run/experiment_results/experiment_8aea9590de4844f6a22a8dd61edd7ced_proc_42006/natlang_groundtruth_vs_generated.png", "workspaces/logs/0-run/experiment_results/experiment_8aea9590de4844f6a22a8dd61edd7ced_proc_42006/natlang_retention_metrics_dataset.png", "workspaces/logs/0-run/experiment_results/experiment_8aea9590de4844f6a22a8dd61edd7ced_proc_42006/natlang_retention_metrics_standard.png", "workspaces/logs/0-run/experiment_results/experiment_8aea9590de4844f6a22a8dd61edd7ced_proc_42006/natlang_validation_loss_curves.png", "workspaces/logs/0-run/experiment_results/experiment_8aea9590de4844f6a22a8dd61edd7ced_proc_42006/natlang_training_loss_curves.png", "workspaces/logs/0-run/experiment_results/experiment_8aea9590de4844f6a22a8dd61edd7ced_proc_42006/retention_over_epochs_dataset_mixture.png", "workspaces/logs/0-run/experiment_results/experiment_8aea9590de4844f6a22a8dd61edd7ced_proc_42006/retention_over_epochs_standard_mixture.png", "workspaces/logs/0-run/experiment_results/experiment_8aea9590de4844f6a22a8dd61edd7ced_proc_42006/gen_counts_common_post_ds_mixture.png", "workspaces/logs/0-run/experiment_results/experiment_8aea9590de4844f6a22a8dd61edd7ced_proc_42006/gen_counts_rare_post_ds_mixture.png", "workspaces/logs/0-run/experiment_results/experiment_8aea9590de4844f6a22a8dd61edd7ced_proc_42006/gen_counts_common_post_std_mixture.png", "workspaces/logs/0-run/experiment_results/experiment_8aea9590de4844f6a22a8dd61edd7ced_proc_42006/gen_counts_rare_post_std_mixture.png", "workspaces/logs/0-run/experiment_results/experiment_8aea9590de4844f6a22a8dd61edd7ced_proc_42006/embedding_retention_common_mixture.png", "workspaces/logs/0-run/experiment_results/experiment_8aea9590de4844f6a22a8dd61edd7ced_proc_42006/embedding_retention_rare_mixture.png", "workspaces/logs/0-run/experiment_results/experiment_8aea9590de4844f6a22a8dd61edd7ced_proc_42006/retention_over_epochs_dataset_json_style.png", "workspaces/logs/0-run/experiment_results/experiment_8aea9590de4844f6a22a8dd61edd7ced_proc_42006/retention_over_epochs_standard_json_style.png", "workspaces/logs/0-run/experiment_results/experiment_8aea9590de4844f6a22a8dd61edd7ced_proc_42006/gen_counts_common_post_ds_json_style.png", "workspaces/logs/0-run/experiment_results/experiment_8aea9590de4844f6a22a8dd61edd7ced_proc_42006/gen_counts_rare_post_ds_json_style.png", "workspaces/logs/0-run/experiment_results/experiment_8aea9590de4844f6a22a8dd61edd7ced_proc_42006/gen_counts_common_post_std_json_style.png", "workspaces/logs/0-run/experiment_results/experiment_8aea9590de4844f6a22a8dd61edd7ced_proc_42006/gen_counts_rare_post_std_json_style.png", "workspaces/logs/0-run/experiment_results/experiment_8aea9590de4844f6a22a8dd61edd7ced_proc_42006/embedding_retention_common_json_style.png", "workspaces/logs/0-run/experiment_results/experiment_8aea9590de4844f6a22a8dd61edd7ced_proc_42006/embedding_retention_rare_json_style.png", "workspaces/logs/0-run/experiment_results/experiment_8aea9590de4844f6a22a8dd61edd7ced_proc_42006/retention_over_epochs_dataset_code_style.png", "workspaces/logs/0-run/experiment_results/experiment_8aea9590de4844f6a22a8dd61edd7ced_proc_42006/retention_over_epochs_standard_code_style.png", "workspaces/logs/0-run/experiment_results/experiment_8aea9590de4844f6a22a8dd61edd7ced_proc_42006/retention_over_epochs_dataset_natlang.png", "workspaces/logs/0-run/experiment_results/experiment_8aea9590de4844f6a22a8dd61edd7ced_proc_42006/retention_over_epochs_standard_natlang.png", "workspaces/logs/0-run/experiment_results/experiment_8aea9590de4844f6a22a8dd61edd7ced_proc_42006/rcrg_over_epochs_dataset_code_style.png", "workspaces/logs/0-run/experiment_results/experiment_8aea9590de4844f6a22a8dd61edd7ced_proc_42006/rcrg_over_epochs_standard_code_style.png", "workspaces/logs/0-run/experiment_results/experiment_8aea9590de4844f6a22a8dd61edd7ced_proc_42006/gen_counts_common_post_ds_code_style.png", "workspaces/logs/0-run/experiment_results/experiment_8aea9590de4844f6a22a8dd61edd7ced_proc_42006/gen_counts_rare_post_ds_code_style.png", "workspaces/logs/0-run/experiment_results/experiment_8aea9590de4844f6a22a8dd61edd7ced_proc_42006/gen_counts_common_post_std_code_style.png", "workspaces/logs/0-run/experiment_results/experiment_8aea9590de4844f6a22a8dd61edd7ced_proc_42006/gen_counts_rare_post_std_code_style.png", "workspaces/logs/0-run/experiment_results/experiment_8aea9590de4844f6a22a8dd61edd7ced_proc_42006/embedding_retention_common_code_style.png", "workspaces/logs/0-run/experiment_results/experiment_8aea9590de4844f6a22a8dd61edd7ced_proc_42006/embedding_retention_rare_code_style.png", "workspaces/logs/0-run/experiment_results/experiment_8aea9590de4844f6a22a8dd61edd7ced_proc_42006/rcrg_over_epochs_dataset_natlang.png", "workspaces/logs/0-run/experiment_results/experiment_8aea9590de4844f6a22a8dd61edd7ced_proc_42006/rcrg_over_epochs_standard_natlang.png", "workspaces/logs/0-run/experiment_results/experiment_8aea9590de4844f6a22a8dd61edd7ced_proc_42006/gen_counts_common_post_ds_natlang.png", "workspaces/logs/0-run/experiment_results/experiment_8aea9590de4844f6a22a8dd61edd7ced_proc_42006/gen_counts_rare_post_ds_natlang.png", "workspaces/logs/0-run/experiment_results/experiment_8aea9590de4844f6a22a8dd61edd7ced_proc_42006/gen_counts_common_post_std_natlang.png", "workspaces/logs/0-run/experiment_results/experiment_8aea9590de4844f6a22a8dd61edd7ced_proc_42006/gen_counts_rare_post_std_natlang.png", "workspaces/logs/0-run/experiment_results/experiment_8aea9590de4844f6a22a8dd61edd7ced_proc_42006/embedding_retention_common_natlang.png", "workspaces/logs/0-run/experiment_results/experiment_8aea9590de4844f6a22a8dd61edd7ced_proc_42006/embedding_retention_rare_natlang.png"], [], ["workspaces/logs/0-run/experiment_results/experiment_9a0ce6ba79e74298b180e66bd282c3ae_proc_42006/dataset_wikitext_overwrite_generated_token_counts.png", "workspaces/logs/0-run/experiment_results/experiment_9a0ce6ba79e74298b180e66bd282c3ae_proc_42006/dataset_wikitext_overwrite_mrr_gap_over_epochs.png", "workspaces/logs/0-run/experiment_results/experiment_9a0ce6ba79e74298b180e66bd282c3ae_proc_42006/dataset_wikitext_overwrite_recall_over_epochs.png", "workspaces/logs/0-run/experiment_results/experiment_9a0ce6ba79e74298b180e66bd282c3ae_proc_42006/dataset_wikitext_overwrite_loss_curves.png", "workspaces/logs/0-run/experiment_results/experiment_9a0ce6ba79e74298b180e66bd282c3ae_proc_42006/dataset_synthetic_injection_loss_curves.png", "workspaces/logs/0-run/experiment_results/experiment_9a0ce6ba79e74298b180e66bd282c3ae_proc_42006/mrr_gap_over_epochs_wikitext.png", "workspaces/logs/0-run/experiment_results/experiment_9a0ce6ba79e74298b180e66bd282c3ae_proc_42006/rcrg_over_epochs_wikitext.png", "workspaces/logs/0-run/experiment_results/experiment_9a0ce6ba79e74298b180e66bd282c3ae_proc_42006/gen_counts_common_post_wikitext.png", "workspaces/logs/0-run/experiment_results/experiment_9a0ce6ba79e74298b180e66bd282c3ae_proc_42006/gen_counts_rare_post_wikitext.png", "workspaces/logs/0-run/experiment_results/experiment_9a0ce6ba79e74298b180e66bd282c3ae_proc_42006/embedding_retention_common_tokens.png", "workspaces/logs/0-run/experiment_results/experiment_9a0ce6ba79e74298b180e66bd282c3ae_proc_42006/embedding_retention_rare_tokens.png", "workspaces/logs/0-run/experiment_results/experiment_9a0ce6ba79e74298b180e66bd282c3ae_proc_42006/rcrg_over_epochs.png", "workspaces/logs/0-run/experiment_results/experiment_9a0ce6ba79e74298b180e66bd282c3ae_proc_42006/gen_counts_common_post.png", "workspaces/logs/0-run/experiment_results/experiment_9a0ce6ba79e74298b180e66bd282c3ae_proc_42006/gen_counts_rare_post.png", "workspaces/logs/0-run/experiment_results/experiment_9a0ce6ba79e74298b180e66bd282c3ae_proc_42006/embedding_retention_common.png", "workspaces/logs/0-run/experiment_results/experiment_9a0ce6ba79e74298b180e66bd282c3ae_proc_42006/embedding_retention_rare.png"], ["workspaces/logs/0-run/experiment_results/experiment_6eac8086c77e47edbce4dd03d049e3a3_proc_42006/mixture_groundtruth_vs_generated.png", "workspaces/logs/0-run/experiment_results/experiment_6eac8086c77e47edbce4dd03d049e3a3_proc_42006/mixture_retention_metrics_dataset.png", "workspaces/logs/0-run/experiment_results/experiment_6eac8086c77e47edbce4dd03d049e3a3_proc_42006/mixture_retention_metrics_standard.png", "workspaces/logs/0-run/experiment_results/experiment_6eac8086c77e47edbce4dd03d049e3a3_proc_42006/mixture_validation_loss_curves.png", "workspaces/logs/0-run/experiment_results/experiment_6eac8086c77e47edbce4dd03d049e3a3_proc_42006/mixture_training_loss_curves.png", "workspaces/logs/0-run/experiment_results/experiment_6eac8086c77e47edbce4dd03d049e3a3_proc_42006/json_style_groundtruth_vs_generated.png", "workspaces/logs/0-run/experiment_results/experiment_6eac8086c77e47edbce4dd03d049e3a3_proc_42006/json_style_retention_metrics_dataset.png", "workspaces/logs/0-run/experiment_results/experiment_6eac8086c77e47edbce4dd03d049e3a3_proc_42006/json_style_retention_metrics_standard.png", "workspaces/logs/0-run/experiment_results/experiment_6eac8086c77e47edbce4dd03d049e3a3_proc_42006/json_style_validation_loss_curves.png", "workspaces/logs/0-run/experiment_results/experiment_6eac8086c77e47edbce4dd03d049e3a3_proc_42006/json_style_training_loss_curves.png", "workspaces/logs/0-run/experiment_results/experiment_6eac8086c77e47edbce4dd03d049e3a3_proc_42006/code_style_groundtruth_vs_generated.png", "workspaces/logs/0-run/experiment_results/experiment_6eac8086c77e47edbce4dd03d049e3a3_proc_42006/code_style_retention_metrics_dataset.png", "workspaces/logs/0-run/experiment_results/experiment_6eac8086c77e47edbce4dd03d049e3a3_proc_42006/code_style_retention_metrics_standard.png", "workspaces/logs/0-run/experiment_results/experiment_6eac8086c77e47edbce4dd03d049e3a3_proc_42006/code_style_validation_loss_curves.png", "workspaces/logs/0-run/experiment_results/experiment_6eac8086c77e47edbce4dd03d049e3a3_proc_42006/code_style_training_loss_curves.png", "workspaces/logs/0-run/experiment_results/experiment_6eac8086c77e47edbce4dd03d049e3a3_proc_42006/natlang_groundtruth_vs_generated.png", "workspaces/logs/0-run/experiment_results/experiment_6eac8086c77e47edbce4dd03d049e3a3_proc_42006/natlang_retention_metrics_dataset.png", "workspaces/logs/0-run/experiment_results/experiment_6eac8086c77e47edbce4dd03d049e3a3_proc_42006/natlang_retention_metrics_standard.png", "workspaces/logs/0-run/experiment_results/experiment_6eac8086c77e47edbce4dd03d049e3a3_proc_42006/natlang_validation_loss_curves.png", "workspaces/logs/0-run/experiment_results/experiment_6eac8086c77e47edbce4dd03d049e3a3_proc_42006/natlang_training_loss_curves.png", "workspaces/logs/0-run/experiment_results/experiment_6eac8086c77e47edbce4dd03d049e3a3_proc_42006/retention_over_epochs_dataset_mixture.png", "workspaces/logs/0-run/experiment_results/experiment_6eac8086c77e47edbce4dd03d049e3a3_proc_42006/retention_over_epochs_standard_mixture.png", "workspaces/logs/0-run/experiment_results/experiment_6eac8086c77e47edbce4dd03d049e3a3_proc_42006/gen_counts_common_post_ds_mixture.png", "workspaces/logs/0-run/experiment_results/experiment_6eac8086c77e47edbce4dd03d049e3a3_proc_42006/gen_counts_rare_post_ds_mixture.png", "workspaces/logs/0-run/experiment_results/experiment_6eac8086c77e47edbce4dd03d049e3a3_proc_42006/gen_counts_common_post_std_mixture.png", "workspaces/logs/0-run/experiment_results/experiment_6eac8086c77e47edbce4dd03d049e3a3_proc_42006/gen_counts_rare_post_std_mixture.png", "workspaces/logs/0-run/experiment_results/experiment_6eac8086c77e47edbce4dd03d049e3a3_proc_42006/embedding_retention_common_mixture.png", "workspaces/logs/0-run/experiment_results/experiment_6eac8086c77e47edbce4dd03d049e3a3_proc_42006/embedding_retention_rare_mixture.png", "workspaces/logs/0-run/experiment_results/experiment_6eac8086c77e47edbce4dd03d049e3a3_proc_42006/retention_over_epochs_dataset_json_style.png", "workspaces/logs/0-run/experiment_results/experiment_6eac8086c77e47edbce4dd03d049e3a3_proc_42006/retention_over_epochs_standard_json_style.png", "workspaces/logs/0-run/experiment_results/experiment_6eac8086c77e47edbce4dd03d049e3a3_proc_42006/gen_counts_common_post_ds_json_style.png", "workspaces/logs/0-run/experiment_results/experiment_6eac8086c77e47edbce4dd03d049e3a3_proc_42006/gen_counts_rare_post_ds_json_style.png", "workspaces/logs/0-run/experiment_results/experiment_6eac8086c77e47edbce4dd03d049e3a3_proc_42006/gen_counts_common_post_std_json_style.png", "workspaces/logs/0-run/experiment_results/experiment_6eac8086c77e47edbce4dd03d049e3a3_proc_42006/gen_counts_rare_post_std_json_style.png", "workspaces/logs/0-run/experiment_results/experiment_6eac8086c77e47edbce4dd03d049e3a3_proc_42006/embedding_retention_common_json_style.png", "workspaces/logs/0-run/experiment_results/experiment_6eac8086c77e47edbce4dd03d049e3a3_proc_42006/embedding_retention_rare_json_style.png", "workspaces/logs/0-run/experiment_results/experiment_6eac8086c77e47edbce4dd03d049e3a3_proc_42006/retention_over_epochs_dataset_code_style.png", "workspaces/logs/0-run/experiment_results/experiment_6eac8086c77e47edbce4dd03d049e3a3_proc_42006/retention_over_epochs_standard_code_style.png", "workspaces/logs/0-run/experiment_results/experiment_6eac8086c77e47edbce4dd03d049e3a3_proc_42006/gen_counts_common_post_ds_code_style.png", "workspaces/logs/0-run/experiment_results/experiment_6eac8086c77e47edbce4dd03d049e3a3_proc_42006/gen_counts_rare_post_ds_code_style.png", "workspaces/logs/0-run/experiment_results/experiment_6eac8086c77e47edbce4dd03d049e3a3_proc_42006/gen_counts_common_post_std_code_style.png", "workspaces/logs/0-run/experiment_results/experiment_6eac8086c77e47edbce4dd03d049e3a3_proc_42006/gen_counts_rare_post_std_code_style.png", "workspaces/logs/0-run/experiment_results/experiment_6eac8086c77e47edbce4dd03d049e3a3_proc_42006/embedding_retention_common_code_style.png", "workspaces/logs/0-run/experiment_results/experiment_6eac8086c77e47edbce4dd03d049e3a3_proc_42006/embedding_retention_rare_code_style.png", "workspaces/logs/0-run/experiment_results/experiment_6eac8086c77e47edbce4dd03d049e3a3_proc_42006/retention_over_epochs_dataset_natlang.png", "workspaces/logs/0-run/experiment_results/experiment_6eac8086c77e47edbce4dd03d049e3a3_proc_42006/retention_over_epochs_standard_natlang.png", "workspaces/logs/0-run/experiment_results/experiment_6eac8086c77e47edbce4dd03d049e3a3_proc_42006/gen_counts_common_post_ds_natlang.png", "workspaces/logs/0-run/experiment_results/experiment_6eac8086c77e47edbce4dd03d049e3a3_proc_42006/gen_counts_rare_post_ds_natlang.png", "workspaces/logs/0-run/experiment_results/experiment_6eac8086c77e47edbce4dd03d049e3a3_proc_42006/gen_counts_common_post_std_natlang.png", "workspaces/logs/0-run/experiment_results/experiment_6eac8086c77e47edbce4dd03d049e3a3_proc_42006/gen_counts_rare_post_std_natlang.png", "workspaces/logs/0-run/experiment_results/experiment_6eac8086c77e47edbce4dd03d049e3a3_proc_42006/embedding_retention_common_natlang.png", "workspaces/logs/0-run/experiment_results/experiment_6eac8086c77e47edbce4dd03d049e3a3_proc_42006/embedding_retention_rare_natlang.png"]], "plot_analyses": [[], [], [{"analysis": "Comparison of generated first-token counts under standard vs dataset prompts across rare and common token sets shows counts effectively at or near zero for all tokens. There is no observable preference shift toward either rare or common tokens, indicating the overwrite did not induce the intended change in first-token generation behavior for either prompting strategy.", "plot_path": "workspaces/logs/0-run/experiment_results/experiment_8aea9590de4844f6a22a8dd61edd7ced_proc_42006/mixture_groundtruth_vs_generated.png"}, {"analysis": "Validation loss behavior indicates degradation during the overwrite phase: the overwrite curve starts around ~3.65 and increases steadily to ~3.8 across epochs, whereas the baseline Phase 1 loss is substantially lower (~3.15 at its first epoch). This suggests the overwrite objective is not aligned with held-out validation, potentially destabilizing training without delivering measurable benefits elsewhere.", "plot_path": "workspaces/logs/0-run/experiment_results/experiment_8aea9590de4844f6a22a8dd61edd7ced_proc_42006/mixture_retention_metrics_dataset.png"}, {"analysis": "Retention metrics with dataset prompts remain essentially flat. RCRG@50, rare recall@50, and common recall@50 are at ~0 within numerical noise across overwrite epochs. The MRR gap starts slightly negative (\u2248\u22121.2e\u22123) and moves toward zero. Net effect: no detectable retention degradation and minimal movement overall under dataset prompts.", "plot_path": "workspaces/logs/0-run/experiment_results/experiment_8aea9590de4844f6a22a8dd61edd7ced_proc_42006/mixture_retention_metrics_standard.png"}, {"analysis": "Retention metrics with standard prompts mirror the dataset-prompt results: recall metrics remain near zero and unchanged across overwrite epochs. The MRR gap trends from more negative (\u2248\u22123e\u22123) toward zero. Overall, there is no clear retention loss under standard prompts and only a minor reduction in the small MRR gap magnitude.", "plot_path": "workspaces/logs/0-run/experiment_results/experiment_8aea9590de4844f6a22a8dd61edd7ced_proc_42006/mixture_validation_loss_curves.png"}, {"analysis": "An alternate rendering of dataset-prompt retention over overwrite epochs confirms the same story: recall metrics are flat at ~0 and MRR gap magnitude shrinks slightly toward zero, reinforcing negligible measurable change due to overwrite.", "plot_path": "workspaces/logs/0-run/experiment_results/experiment_8aea9590de4844f6a22a8dd61edd7ced_proc_42006/mixture_training_loss_curves.png"}, {"analysis": "An alternate rendering of standard-prompt retention over overwrite epochs again shows flat recall metrics and a small monotonic drift of the MRR gap toward zero, with no evidence of retention harm.", "plot_path": "workspaces/logs/0-run/experiment_results/experiment_8aea9590de4844f6a22a8dd61edd7ced_proc_42006/json_style_groundtruth_vs_generated.png"}, {"analysis": "Embedding retention for common tokens shows cosine similarity of 1.0 for all tokens, implying embeddings are unchanged to numerical precision. This strongly suggests the overwrite phase did not modify token embeddings (or that the comparison is against an identical checkpoint), which is unexpected if the overwrite was meant to affect these representations.", "plot_path": "workspaces/logs/0-run/experiment_results/experiment_8aea9590de4844f6a22a8dd61edd7ced_proc_42006/json_style_retention_metrics_dataset.png"}, {"analysis": "Embedding retention for rare tokens also shows cosine similarity of 1.0 for all tokens. Together with the common-token result, this implies no detectable embedding change from overwrite\u2014pointing to possible issues such as frozen layers, ineffective optimizer steps, or evaluation against an unchanged checkpoint.", "plot_path": "workspaces/logs/0-run/experiment_results/experiment_8aea9590de4844f6a22a8dd61edd7ced_proc_42006/json_style_retention_metrics_standard.png"}, {"analysis": "Post-overwrite first-token generation counts for rare tokens under dataset prompts are all zero. The model never produces the target rare tokens in the first position after overwrite, indicating no observable behavioral acquisition for these tokens under dataset prompting.", "plot_path": "workspaces/logs/0-run/experiment_results/experiment_8aea9590de4844f6a22a8dd61edd7ced_proc_42006/json_style_validation_loss_curves.png"}, {"analysis": "Post-overwrite first-token generation counts for rare tokens under standard prompts are also all zero, matching the dataset-prompt result and further confirming a lack of induced generation behavior for the targeted rare tokens.", "plot_path": "workspaces/logs/0-run/experiment_results/experiment_8aea9590de4844f6a22a8dd61edd7ced_proc_42006/json_style_training_loss_curves.png"}], [], [{"analysis": "Loss Curves \u2014 dataset_wikitext_overwrite: Training loss falls steadily across epochs while validation loss trends upward, indicating clear overfitting to the overwrite data. The divergence suggests the overwrite procedure is harming generalization. Actionable follow-ups: introduce early stopping or stronger regularization, mix in non-overwrite data during training, reduce learning rate and/or epochs, and monitor auxiliary metrics (e.g., perplexity on a held-out natural distribution).", "plot_path": "workspaces/logs/0-run/experiment_results/experiment_9a0ce6ba79e74298b180e66bd282c3ae_proc_42006/dataset_wikitext_overwrite_generated_token_counts.png"}, {"analysis": "Loss Curves \u2014 dataset_synthetic_injection: Single-epoch snapshot shows a small generalization gap (train < val), but with only one epoch there\u2019s no trend to interpret. The values are not directly comparable to the overwrite dataset due to differing data. Recommendation: run multiple epochs and track the same metrics to assess whether synthetic injection yields better generalization than overwrite.", "plot_path": "workspaces/logs/0-run/experiment_results/experiment_9a0ce6ba79e74298b180e66bd282c3ae_proc_42006/dataset_wikitext_overwrite_mrr_gap_over_epochs.png"}, {"analysis": "Recall Metrics Across Overwrite Epochs \u2014 dataset_wikitext_overwrite: Rare recall@50 and common recall@50 are extremely low overall; RCRG@50 (rare \u2212 common) starts negative (~\u22120.2) then collapses to 0 as both recalls go to 0. This pattern implies the overwrite setting does not improve recall for rare items and ultimately suppresses both rare and common recall. Given the discrete values (0.2 and 0), the evaluation set is likely very small; consider increasing sample size and reporting confidence intervals. The collapse of both recalls aligns with the overfitting signal and suggests the model is not retrieving target items under this evaluation.", "plot_path": "workspaces/logs/0-run/experiment_results/experiment_9a0ce6ba79e74298b180e66bd282c3ae_proc_42006/dataset_wikitext_overwrite_recall_over_epochs.png"}, {"analysis": "MRR Retention Gap Across Overwrite Epochs \u2014 dataset_wikitext_overwrite: The MRR gap (rare \u2212 common) improves from about \u22120.006 to ~0 by later epochs. Combined with near-zero recall, the vanishing gap likely reflects uniformly poor retention rather than fairness. To disambiguate, plot absolute rare/common MRR trends; if both are decreasing towards zero, parity has increased only because performance collapsed. If parity is the target, track it jointly with absolute performance to avoid accepting a degenerate solution.", "plot_path": "workspaces/logs/0-run/experiment_results/experiment_9a0ce6ba79e74298b180e66bd282c3ae_proc_42006/dataset_wikitext_overwrite_loss_curves.png"}, {"analysis": "Recall Metrics Across Overwrite Epochs (Freeze Rare Embeddings) \u2014 dataset_wikitext_overwrite: Freezing rare embeddings does not improve rare recall. RCRG@50 is negative initially (driven by higher common recall) and then everything collapses to zero, mirroring the non-frozen case. This suggests that protecting rare embeddings alone is insufficient; downstream layers or the LM head likely drive the suppression of rare token retrieval.", "plot_path": "workspaces/logs/0-run/experiment_results/experiment_9a0ce6ba79e74298b180e66bd282c3ae_proc_42006/dataset_synthetic_injection_loss_curves.png"}, {"analysis": "Generated Token Counts \u2014 dataset_wikitext_overwrite: Rare tokens never appear as the first generated token, while some common tokens do (e.g., apple > water > table). This indicates generation strongly favors common tokens post-overwrite. This could reflect low logits for rare tokens, decoding configuration that biases toward frequent tokens, or a mismatch between the overwrite objective and the intended rare-token usage. Verify sampling parameters (temperature, top-k/top-p) and inspect token-level logits.", "plot_path": "workspaces/logs/0-run/experiment_results/experiment_9a0ce6ba79e74298b180e66bd282c3ae_proc_42006/mrr_gap_over_epochs_wikitext.png"}, {"analysis": "Post-overwrite generation counts \u2014 Common tokens: The distribution is skewed (apple dominates, water moderate, table low, others zero), hinting at a narrow preference or emerging mode collapse for first-token generation. Cross-check with prompt diversity and ensure evaluation spans multiple contexts; also consider frequency normalization or class-balanced prompts.", "plot_path": "workspaces/logs/0-run/experiment_results/experiment_9a0ce6ba79e74298b180e66bd282c3ae_proc_42006/rcrg_over_epochs_wikitext.png"}, {"analysis": "Post-overwrite generation counts \u2014 Rare tokens (Embeddings Frozen): All zero counts despite frozen embeddings. This supports the hypothesis that rare-token suppression arises beyond the embedding layer (e.g., transformer blocks or LM head). Inspect and compare LM head weights for the rare-token IDs pre/post training; if logits are being pushed down, consider constraints or regularizers on those weights.", "plot_path": "workspaces/logs/0-run/experiment_results/experiment_9a0ce6ba79e74298b180e66bd282c3ae_proc_42006/gen_counts_common_post_wikitext.png"}, {"analysis": "Embedding Retention (Cosine) \u2014 Common Tokens: Cosine similarity ~1.0 indicates no detectable change in common-token embeddings. If embeddings were intended to be trainable, this suggests the optimizer or training config effectively left them unchanged. Overwrite effects likely occurred in higher layers or the LM head, which could explain generalization degradation without embedding drift.", "plot_path": "workspaces/logs/0-run/experiment_results/experiment_9a0ce6ba79e74298b180e66bd282c3ae_proc_42006/gen_counts_rare_post_wikitext.png"}, {"analysis": "Embedding Retention (Cosine) \u2014 Rare Tokens (Frozen in Overwrite): Cosine ~1.0 confirms successful freezing. However, freezing alone did not yield rare-token generation or retrieval improvements. This implies that preserving embedding vectors is not sufficient; the model\u2019s internal routing and output layer need to maintain or enhance rare-token salience. Consider targeted objectives (e.g., contrastive/logit-margin losses on rare tokens), LM-head weight constraints, or knowledge-aware regularization to prevent rare-token suppression.", "plot_path": "workspaces/logs/0-run/experiment_results/experiment_9a0ce6ba79e74298b180e66bd282c3ae_proc_42006/embedding_retention_common_tokens.png"}], [{"analysis": "Both panels report zero counts for all listed rare and common tokens as the first generated token under both standard and dataset prompts. This indicates the model never emits any of the targeted tokens in the first position. Possible causes include: overly restrictive metric (first-token only), tokenization mismatch (targets split into multiple subwords), decoding settings suppressing these tokens, or insufficient conditioning from prompts. Actionable checks: evaluate presence anywhere in the generated sequence, inspect top-k next-token probabilities, verify targets are in-vocabulary or appropriately aggregated across subwords, and increase sample size.", "plot_path": "workspaces/logs/0-run/experiment_results/experiment_6eac8086c77e47edbce4dd03d049e3a3_proc_42006/mixture_groundtruth_vs_generated.png"}, {"analysis": "Training loss decreases steadily across overwrite epochs, while the Phase1 reference shows a higher single-point loss. This confirms the overwrite optimization is effective at minimizing training loss, potentially on a different or narrower objective than Phase1. Coupled with rising validation loss, this suggests overfitting or objective mismatch rather than true generalization.", "plot_path": "workspaces/logs/0-run/experiment_results/experiment_6eac8086c77e47edbce4dd03d049e3a3_proc_42006/mixture_retention_metrics_dataset.png"}, {"analysis": "Validation loss rises monotonically during overwrite, and is notably higher than the Phase1 validation point. This is consistent with overfitting or distribution shift: the model learns to fit the overwrite data while degrading on held-out data. Suggested remedies: earlier stopping, lower learning rate, stronger regularization (weight decay, dropout), mixing in more diverse data, or multi-objective training to preserve validation performance.", "plot_path": "workspaces/logs/0-run/experiment_results/experiment_6eac8086c77e47edbce4dd03d049e3a3_proc_42006/mixture_retention_metrics_standard.png"}, {"analysis": "Dataset-prompt retention metrics show RCRG@50, rare recall@50, and common recall@50 pinned at 0.0 across overwrite epochs, with MRR gap starting negative and trending to ~0. The zero recalls imply the evaluation never recovers relevant items under this scoring\u2014either true catastrophic failure or a metric/evaluation pipeline issue (e.g., wrong candidate set, misaligned targets, or top-50 computed over an incompatible space). The shrinking MRR gap likely reflects that both rare and common categories are equally poor, rather than genuine retention of knowledge. Priority: audit metric definitions and candidate pools, confirm that ground-truth items are reachable by the model and present in the scoring vocabulary.", "plot_path": "workspaces/logs/0-run/experiment_results/experiment_6eac8086c77e47edbce4dd03d049e3a3_proc_42006/mixture_validation_loss_curves.png"}, {"analysis": "Standard-prompt retention metrics mirror the dataset-prompt results: all recall-type metrics at 0.0, and the MRR gap moving toward ~0 with more overwrite epochs. Interpretation is the same\u2014metrics are non-informative under current setup. Verification steps: sanity-check recall@k on a known-easy subset, compute absolute MRR values (not just gaps), and inspect top-k lists to ensure relevant tokens/entities can be predicted.", "plot_path": "workspaces/logs/0-run/experiment_results/experiment_6eac8086c77e47edbce4dd03d049e3a3_proc_42006/mixture_training_loss_curves.png"}, {"analysis": "Redundant visualization of dataset-prompt retention metrics confirming identical values: zero recalls and MRR gap approaching zero. This consistency points to a systematic issue (metric or data configuration) rather than random noise.", "plot_path": "workspaces/logs/0-run/experiment_results/experiment_6eac8086c77e47edbce4dd03d049e3a3_proc_42006/json_style_groundtruth_vs_generated.png"}, {"analysis": "Redundant visualization of standard-prompt retention metrics with identical patterns to earlier: zero recalls and MRR gap approaching zero. Confirms systematic non-diagnostic behavior of retention metrics under current setup.", "plot_path": "workspaces/logs/0-run/experiment_results/experiment_6eac8086c77e47edbce4dd03d049e3a3_proc_42006/json_style_retention_metrics_dataset.png"}, {"analysis": "Embedding retention cosine similarity for common tokens is exactly 1.0 for all tokens, indicating embeddings are unchanged pre- vs post-overwrite. If embeddings were intentionally frozen, this is expected; otherwise, it suggests the overwrite procedure is not modifying the embedding layer. Any forgetting or behavior change would then originate from deeper layers.", "plot_path": "workspaces/logs/0-run/experiment_results/experiment_6eac8086c77e47edbce4dd03d049e3a3_proc_42006/json_style_retention_metrics_standard.png"}, {"analysis": "Embedding retention cosine similarity for rare tokens is also 1.0 across the board, matching the common tokens. This reinforces that the embedding layer remained fixed during overwrite and cannot explain the zero recalls or lack of target generations.", "plot_path": "workspaces/logs/0-run/experiment_results/experiment_6eac8086c77e47edbce4dd03d049e3a3_proc_42006/json_style_validation_loss_curves.png"}, {"analysis": "Post-overwrite generation counts for rare tokens under standard prompts are all zero, consistent with earlier generation-count findings. This strengthens the conclusion that the model is not emitting the targeted rare tokens at generation start under the current prompting/decoding scheme. Immediate follow-ups: examine log-probabilities for these tokens, test alternative prompts, relax to top-k presence within the first N tokens, and confirm tokenization coverage.", "plot_path": "workspaces/logs/0-run/experiment_results/experiment_6eac8086c77e47edbce4dd03d049e3a3_proc_42006/json_style_training_loss_curves.png"}]], "vlm_feedback_summary": ["[]", "[]", "['Across plots, there is no evidence that overwrite training induced the model\nto generate the targeted tokens: first-token counts for both rare and common\nsets remain effectively zero under both prompt types. Retention metrics\n(RCRG/recall@50) are flat and near zero, and MRR gaps merely shrink slightly\ntowards zero, implying negligible behavioral change. Embedding cosine similarity\nis exactly 1.0 for both rare and common tokens, suggesting parameters (at least\ntoken embeddings) were not updated by overwrite or a checkpoint miscompare\noccurred. Meanwhile, validation loss increases during overwrite, indicating\ndestabilization without measurable gains. Recommended checks: verify that\noverwrite steps are executed (non-frozen layers, gradient norms, optimizer\nupdates), confirm tokenizer coverage of rare tokens (avoid OOV/subword mismatch\nwith the evaluation protocol), ensure evaluation probes the correct\nposition/task (first-token vs later positions), and validate sampling/decoding\nsettings. If training is functioning, consider stronger/longer overwrite, higher\nlearning rate on targeted modules, or direct logit biasing/adapter layers to\ninduce observable generation changes.']", "[]", "['Overwrite training overfits (train loss down, validation loss up) and\ncoincides with collapsed recall for both rare and common items. Freezing rare\nembeddings preserves their vectors (cosine ~1.0) but does not restore rare-token\nusage; common embeddings also show perfect retention, suggesting the embedding\nlayer may have been effectively frozen for all tokens. Generated samples reflect\nthis: rare tokens are never emitted as the first token, while a few common\ntokens dominate. The likely locus of change is in higher layers and/or the LM\nhead, which appears to suppress logits for rare tokens. Next steps: unfreeze and\ncarefully regularize relevant layers (including the LM head); add balanced data\nor curriculum that emphasizes rare tokens; increase evaluation sample size;\nreport absolute metrics alongside gaps; and verify training configuration\n(optimizer params, which layers are trainable) to ensure intended ablation\nbehavior.']", "['Training progressed (train loss down) while generalization degraded\n(validation loss up), indicating overfitting or objective mismatch. Retention\nmetrics (RCRG@50, recall@50) are uniformly zero under both prompt types,\nsuggesting a non-diagnostic evaluation pipeline or a model that cannot reach the\nground-truth targets under current settings. Generation analyses show zero\ncounts for all rare/common targets as the first generated token, aligning with\nthe zero-recall outcome. Embedding similarities are exactly 1.0 for both rare\nand common tokens, implying embeddings were unchanged by overwrite; any\nbehavioral changes must stem from other layers. Recommended next steps: audit\ntokenization and candidate sets, measure top-k probabilities and presence\nanywhere in sequences (not only first token), verify metric implementations on a\nknown-easy subset, and adjust training (early stopping, regularization, mixing\ndata or multi-objective) to mitigate overfitting.']"], "exec_time": [670.1359784603119, 1271.4636459350586, 3013.5985610485077, 737.7455070018768, 1195.5464746952057, 2873.1943764686584], "exec_time_feedback": ["", "", "", "", "", ""], "datasets_successfully_tested": [["synthetic_injection", "overwrite_wikitext"], [], [""], ["ablation_type_1/dataset_name_1"], ["dataset_wikitext_overwrite"], [""]], "plot_code": [null, null, "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\nworking_dir = os.path.join(os.getcwd(), 'working')\n\n# Ensure output directory exists\nos.makedirs(working_dir, exist_ok=True)\n\n# GPU/CPU device selection as required\ntry:\n    import torch\n    try:\n        torch.cuda.set_device(0)\n        device = torch.device('cuda:0')\n    except Exception:\n        device = torch.device('cpu')\nexcept Exception:\n    device = None\n\n# Load experiment data\ntry:\n    experiment_data = np.load(os.path.join(working_dir, 'experiment_data.npy'), allow_pickle=True).item()\nexcept Exception as e:\n    print(f'Error loading experiment data: {e}')\n    experiment_data = {}\n\n# Helper: count occurrences of exact-token matches in generated samples\ndef count_hits(samples, targets):\n    counts = {t: 0 for t in targets}\n    for s in samples:\n        if isinstance(s, str):\n            for t in targets:\n                if s == t:\n                    counts[t] += 1\n    return counts\n\n# Determine base dataset names (exclude phase1 containers)\nbase_datasets = []\nfor key in experiment_data.keys():\n    if key.endswith('_phase1'):\n        continue\n    base_datasets.append(key)\n\n# Iterate per dataset and plot\nfor ds in base_datasets:\n    ds_data = experiment_data.get(ds, {})\n    phase1_key = f\"{ds}_phase1\"\n    phase1_data = experiment_data.get(phase1_key, {})\n\n    # -----------------------------\n    # Plot 1: Training loss curves\n    # -----------------------------\n    try:\n        train_phase1 = phase1_data.get('losses', {}).get('train', [])\n        train_overwrite = ds_data.get('losses', {}).get('train', [])\n\n        # Extract overwrite-only entries (some entries may not have phase key; keep all as present)\n        l1 = [rec.get('loss') for rec in train_phase1 if isinstance(rec, dict) and 'loss' in rec]\n        l2 = [rec.get('loss') for rec in train_overwrite if isinstance(rec, dict) and 'loss' in rec]\n\n        if (l1 and any(x is not None for x in l1)) or (l2 and any(x is not None for x in l2)):\n            fig = plt.figure(figsize=(7, 4))\n            if l1:\n                plt.plot(range(1, len(l1) + 1), l1, marker='o', label='Phase1 train loss')\n            if l2:\n                plt.plot(range(1, len(l2) + 1), l2, marker='s', label='Overwrite train loss')\n            plt.xlabel('Epoch index (per phase)')\n            plt.ylabel('Loss')\n            plt.title(f'Training Loss Curves \u2014 Dataset: {ds}')\n            plt.legend()\n            plt.tight_layout()\n            out_path = os.path.join(working_dir, f'{ds}_training_loss_curves.png')\n            plt.savefig(out_path)\n            plt.close(fig)\n        else:\n            print(f'No training loss data available for dataset: {ds}')\n    except Exception as e:\n        print(f\"Error creating training loss plot for {ds}: {e}\")\n        try:\n            plt.close()\n        except Exception:\n            pass\n\n    # -------------------------------\n    # Plot 2: Validation loss curves\n    # -------------------------------\n    try:\n        val_phase1 = phase1_data.get('losses', {}).get('val', [])\n        val_overwrite = ds_data.get('losses', {}).get('val', [])\n\n        v1 = [rec.get('loss') for rec in val_phase1 if isinstance(rec, dict) and 'loss' in rec]\n        v2 = [rec.get('loss') for rec in val_overwrite if isinstance(rec, dict) and 'loss' in rec]\n\n        if (v1 and any(x is not None for x in v1)) or (v2 and any(x is not None for x in v2)):\n            fig = plt.figure(figsize=(7, 4))\n            if v1:\n                plt.plot(range(1, len(v1) + 1), v1, marker='o', label='Phase1 val loss')\n            if v2:\n                plt.plot(range(1, len(v2) + 1), v2, marker='s', label='Overwrite val loss')\n            plt.xlabel('Epoch index (per phase)')\n            plt.ylabel('Loss')\n            plt.title(f'Validation Loss Curves \u2014 Dataset: {ds}')\n            plt.legend()\n            plt.tight_layout()\n            out_path = os.path.join(working_dir, f'{ds}_validation_loss_curves.png')\n            plt.savefig(out_path)\n            plt.close(fig)\n        else:\n            print(f'No validation loss data available for dataset: {ds}')\n    except Exception as e:\n        print(f\"Error creating validation loss plot for {ds}: {e}\")\n        try:\n            plt.close()\n        except Exception:\n            pass\n\n    # -------------------------------------------------\n    # Plot 3: Retention metrics over overwrite (standard)\n    # -------------------------------------------------\n    try:\n        val_metrics = ds_data.get('metrics', {}).get('val', [])\n        std_epochs = []\n        rcrg_std = []\n        rare_rec_std = []\n        common_rec_std = []\n        mrr_gap_std = []\n\n        for rec in val_metrics:\n            if not isinstance(rec, dict):\n                continue\n            if rec.get('phase') == 'overwrite' and 'RCRG@50_standard' in rec:\n                std_epochs.append(rec.get('epoch'))\n                rcrg_std.append(rec.get('RCRG@50_standard'))\n                rare_rec_std.append(rec.get('rare_recall@50_standard'))\n                common_rec_std.append(rec.get('common_recall@50_standard'))\n                mrr_gap_std.append(rec.get('MRR_gap_standard'))\n\n        if std_epochs and any(v is not None for v in rcrg_std):\n            fig = plt.figure(figsize=(8, 4))\n            plt.plot(std_epochs, rcrg_std, marker='o', label='RCRG@50 (standard)')\n            plt.plot(std_epochs, rare_rec_std, marker='s', label='Rare recall@50 (standard)')\n            plt.plot(std_epochs, common_rec_std, marker='^', label='Common recall@50 (standard)')\n            plt.plot(std_epochs, mrr_gap_std, marker='x', label='MRR gap (standard)')\n            plt.xlabel('Overwrite epoch')\n            plt.ylabel('Score')\n            plt.title(f'Retention Metrics (Standard Prompts) \u2014 Dataset: {ds}')\n            plt.legend()\n            plt.tight_layout()\n            out_path = os.path.join(working_dir, f'{ds}_retention_metrics_standard.png')\n            plt.savefig(out_path)\n            plt.close(fig)\n        else:\n            print(f'No standard-prompt retention metrics available for dataset: {ds}')\n    except Exception as e:\n        print(f\"Error creating standard retention plot for {ds}: {e}\")\n        try:\n            plt.close()\n        except Exception:\n            pass\n\n    # ---------------------------------------------------\n    # Plot 4: Retention metrics over overwrite (dataset)\n    # ---------------------------------------------------\n    try:\n        val_metrics = ds_data.get('metrics', {}).get('val', [])\n        ds_epochs = []\n        rcrg_ds = []\n        rare_rec_ds = []\n        common_rec_ds = []\n        mrr_gap_ds = []\n\n        for rec in val_metrics:\n            if not isinstance(rec, dict):\n                continue\n            if rec.get('phase') == 'overwrite' and 'RCRG@50_dataset' in rec:\n                ds_epochs.append(rec.get('epoch'))\n                rcrg_ds.append(rec.get('RCRG@50_dataset'))\n                rare_rec_ds.append(rec.get('rare_recall@50_dataset'))\n                common_rec_ds.append(rec.get('common_recall@50_dataset'))\n                mrr_gap_ds.append(rec.get('MRR_gap_dataset'))\n\n        if ds_epochs and any(v is not None for v in rcrg_ds):\n            fig = plt.figure(figsize=(8, 4))\n            plt.plot(ds_epochs, rcrg_ds, marker='o', label='RCRG@50 (dataset)')\n            plt.plot(ds_epochs, rare_rec_ds, marker='s', label='Rare recall@50 (dataset)')\n            plt.plot(ds_epochs, common_rec_ds, marker='^', label='Common recall@50 (dataset)')\n            plt.plot(ds_epochs, mrr_gap_ds, marker='x', label='MRR gap (dataset)')\n            plt.xlabel('Overwrite epoch')\n            plt.ylabel('Score')\n            plt.title(f'Retention Metrics (Dataset Prompts) \u2014 Dataset: {ds}')\n            plt.legend()\n            plt.tight_layout()\n            out_path = os.path.join(working_dir, f'{ds}_retention_metrics_dataset.png')\n            plt.savefig(out_path)\n            plt.close(fig)\n        else:\n            print(f'No dataset-prompt retention metrics available for dataset: {ds}')\n    except Exception as e:\n        print(f\"Error creating dataset retention plot for {ds}: {e}\")\n        try:\n            plt.close()\n        except Exception:\n            pass\n\n    # --------------------------------------------------------------------\n    # Plot 5: Ground Truth (left) vs Generated Samples (std & dataset, right)\n    # --------------------------------------------------------------------\n    try:\n        gt = ds_data.get('ground_truth', {})\n        rare_tokens = gt.get('rare', []) if isinstance(gt, dict) else []\n        common_tokens = gt.get('common', []) if isinstance(gt, dict) else []\n\n        preds_list = ds_data.get('predictions', [])\n        std_samples = []\n        ds_samples = []\n        if isinstance(preds_list, list) and len(preds_list) > 0 and isinstance(preds_list[-1], dict):\n            std_samples = preds_list[-1].get('std_prompt_samples', []) or []\n            ds_samples = preds_list[-1].get('ds_prompt_samples', []) or []\n\n        # Only proceed if we have ground truth and at least one set of samples\n        if (rare_tokens or common_tokens) and (std_samples or ds_samples):\n            # Counts for standard prompt samples\n            rare_counts_std = count_hits(std_samples, rare_tokens) if std_samples else {t: 0 for t in rare_tokens}\n            common_counts_std = count_hits(std_samples, common_tokens) if std_samples else {t: 0 for t in common_tokens}\n            # Counts for dataset-prompt samples\n            rare_counts_ds = count_hits(ds_samples, rare_tokens) if ds_samples else {t: 0 for t in rare_tokens}\n            common_counts_ds = count_hits(ds_samples, common_tokens) if ds_samples else {t: 0 for t in common_tokens}\n\n            fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n            # Left: Ground Truth listing\n            axes[0].axis('off')\n            gt_text_lines = []\n            if rare_tokens:\n                gt_text_lines.append('Rare tokens:')\n                gt_text_lines.extend([f'  \u2022 {t.strip()}' for t in rare_tokens])\n                gt_text_lines.append('')\n            if common_tokens:\n                gt_text_lines.append('Common tokens:')\n                gt_text_lines.extend([f'  \u2022 {t.strip()}' for t in common_tokens])\n            axes[0].text(0.0, 1.0, '\\n'.join(gt_text_lines), va='top', ha='left', fontsize=10)\n\n            # Middle: Standard prompt generated counts\n            ax = axes[1]\n            x_rare = np.arange(len(rare_tokens)) if rare_tokens else np.array([])\n            x_common = (np.arange(len(common_tokens)) + (len(rare_tokens) + 1)) if common_tokens else np.array([])\n            if rare_tokens:\n                ax.bar(x_rare, [rare_counts_std.get(t, 0) for t in rare_tokens], color='tab:blue', label='Rare (std)')\n            if common_tokens:\n                ax.bar(x_common, [common_counts_std.get(t, 0) for t in common_tokens], color='tab:orange', label='Common (std)')\n            xticks = list(x_rare) + list(x_common)\n            xticklabels = [t.strip() for t in rare_tokens] + [t.strip() for t in common_tokens]\n            ax.set_xticks(xticks)\n            ax.set_xticklabels(xticklabels, rotation=45, ha='right')\n            ax.set_title('Standard Prompt Generated Counts')\n            ax.set_ylabel('Count (first generated token)')\n            ax.legend()\n\n            # Right: Dataset prompt generated counts\n            ax = axes[2]\n            x_rare = np.arange(len(rare_tokens)) if rare_tokens else np.array([])\n            x_common = (np.arange(len(common_tokens)) + (len(rare_tokens) + 1)) if common_tokens else np.array([])\n            if rare_tokens:\n                ax.bar(x_rare, [rare_counts_ds.get(t, 0) for t in rare_tokens], color='tab:blue', label='Rare (ds)')\n            if common_tokens:\n                ax.bar(x_common, [common_counts_ds.get(t, 0) for t in common_tokens], color='tab:orange', label='Common (ds)')\n            xticks = list(x_rare) + list(x_common)\n            xticklabels = [t.strip() for t in rare_tokens] + [t.strip() for t in common_tokens]\n            ax.set_xticks(xticks)\n            ax.set_xticklabels(xticklabels, rotation=45, ha='right')\n            ax.set_title('Dataset Prompt Generated Counts')\n            ax.set_ylabel('Count (first generated token)')\n            ax.legend()\n\n            plt.suptitle(f'Ground Truth vs Generated Samples \u2014 Dataset: {ds}')\n            # Subtitle text\n            fig.text(0.5, 0.01, 'Left: Ground Truth, Middle: Standard-Prompt Generated, Right: Dataset-Prompt Generated', ha='center', fontsize=9)\n            plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n            out_path = os.path.join(working_dir, f'{ds}_groundtruth_vs_generated.png')\n            plt.savefig(out_path)\n            plt.close(fig)\n        else:\n            print(f'Insufficient ground truth or predictions to plot GT vs Generated for dataset: {ds}')\n    except Exception as e:\n        print(f\"Error creating Ground Truth vs Generated plot for {ds}: {e}\")\n        try:\n            plt.close()\n        except Exception:\n            pass\n\nprint('Plotting complete. Figures saved to:', working_dir)", null, "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\nworking_dir = os.path.join(os.getcwd(), 'working')\n\nimport torch\nos.makedirs(working_dir, exist_ok=True)\n\n# Enforce CUDA GPU index if available; CPU fallback allowed\nif torch.cuda.is_available():\n    torch.cuda.set_device(0)\n    device = torch.device('cuda:0')\nelse:\n    device = torch.device('cpu')\n\n# -----------------------------------------------------------------------------\n# Load experiment data (must exist, produced by the experiment script)\n# -----------------------------------------------------------------------------\ntry:\n    experiment_data = np.load(os.path.join(working_dir, 'experiment_data.npy'), allow_pickle=True).item()\nexcept Exception as e:\n    print(f'Error loading experiment data: {e}')\n    experiment_data = {}\n\n# Utility to safely extract nested dicts/lists\n\ndef get_losses(dataset_key):\n    d = experiment_data.get(dataset_key, {})\n    losses = d.get('losses', {})\n    train = losses.get('train', []) or []\n    val = losses.get('val', []) or []\n    # sort by epoch if present\n    train = sorted([x for x in train if isinstance(x, dict) and 'epoch' in x and 'loss' in x], key=lambda x: x['epoch'])\n    val = sorted([x for x in val if isinstance(x, dict) and 'epoch' in x and 'loss' in x], key=lambda x: x['epoch'])\n    return train, val\n\n\ndef get_overwrite_histories():\n    d = experiment_data.get('dataset_wikitext_overwrite', {})\n    aux = d.get('aux', {}) if isinstance(d, dict) else {}\n\n    rcrg_hist = aux.get('rcrg_history', None)\n    rare_rec_hist = aux.get('rare_recall_history', None)\n    common_rec_hist = aux.get('common_recall_history', None)\n    mrr_gap_hist = aux.get('mrr_gap_history', None)\n\n    # Fallback: parse from metrics['val'] if aux missing\n    if any(h is None for h in [rcrg_hist, rare_rec_hist, common_rec_hist, mrr_gap_hist]):\n        metrics_val = d.get('metrics', {}).get('val', [])\n        metrics_val = [m for m in metrics_val if isinstance(m, dict) and m.get('phase') == 'wikitext_overwrite_eval']\n        metrics_val = sorted(metrics_val, key=lambda x: x.get('epoch', 0))\n        if rare_rec_hist is None:\n            rare_rec_hist = [m.get('rare_recall@50') for m in metrics_val if 'rare_recall@50' in m]\n        if common_rec_hist is None:\n            common_rec_hist = [m.get('common_recall@50') for m in metrics_val if 'common_recall@50' in m]\n        if rcrg_hist is None and rare_rec_hist is not None and common_rec_hist is not None:\n            try:\n                rcrg_hist = [float(r) - float(c) for r, c in zip(rare_rec_hist, common_rec_hist)]\n            except Exception:\n                rcrg_hist = None\n        if mrr_gap_hist is None:\n            mrr_gap_hist = [m.get('MRR_Retention_Gap') for m in metrics_val if 'MRR_Retention_Gap' in m]\n\n    return rcrg_hist, rare_rec_hist, common_rec_hist, mrr_gap_hist\n\n\n# -----------------------------------------------------------------------------\n# 1) Loss curves: dataset_synthetic_injection\n# -----------------------------------------------------------------------------\ntry:\n    ds_key = 'dataset_synthetic_injection'\n    train_losses, val_losses = get_losses(ds_key)\n    if train_losses or val_losses:\n        fig, ax = plt.subplots(figsize=(6,4))\n        if train_losses:\n            ax.plot([x['epoch'] for x in train_losses], [x['loss'] for x in train_losses], marker='o', label='Train loss')\n        if val_losses:\n            ax.plot([x['epoch'] for x in val_losses], [x['loss'] for x in val_losses], marker='s', label='Val loss')\n        ax.set_xlabel('Epoch')\n        ax.set_ylabel('Loss')\n        ax.set_title('Training vs Validation \u2014 Synthetic Injection Dataset')\n        ax.grid(True, alpha=0.3)\n        ax.legend()\n        fig.suptitle('Loss Curves \u2014 dataset_synthetic_injection')\n        fig.tight_layout()\n        out_path = os.path.join(working_dir, 'dataset_synthetic_injection_loss_curves.png')\n        plt.savefig(out_path)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating synthetic injection loss curves: {e}\")\n    plt.close()\n\n# -----------------------------------------------------------------------------\n# 2) Loss curves: dataset_wikitext_overwrite\n# -----------------------------------------------------------------------------\ntry:\n    ds_key = 'dataset_wikitext_overwrite'\n    train_losses, val_losses = get_losses(ds_key)\n    if train_losses or val_losses:\n        fig, ax = plt.subplots(figsize=(6,4))\n        if train_losses:\n            ax.plot([x['epoch'] for x in train_losses], [x['loss'] for x in train_losses], marker='o', label='Train loss')\n        if val_losses:\n            ax.plot([x['epoch'] for x in val_losses], [x['loss'] for x in val_losses], marker='s', label='Val loss')\n        ax.set_xlabel('Epoch')\n        ax.set_ylabel('Loss')\n        ax.set_title('Training vs Validation \u2014 WikiText Overwrite Dataset')\n        ax.grid(True, alpha=0.3)\n        ax.legend()\n        fig.suptitle('Loss Curves \u2014 dataset_wikitext_overwrite')\n        fig.tight_layout()\n        out_path = os.path.join(working_dir, 'dataset_wikitext_overwrite_loss_curves.png')\n        plt.savefig(out_path)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating wikitext overwrite loss curves: {e}\")\n    plt.close()\n\n# -----------------------------------------------------------------------------\n# 3) Recall histories (RCRG@50, rare/common recall@50) across overwrite epochs\n# -----------------------------------------------------------------------------\ntry:\n    rcrg_hist, rare_rec_hist, common_rec_hist, _ = get_overwrite_histories()\n    if (rcrg_hist is not None and len(rcrg_hist) > 0) or \\\n       (rare_rec_hist is not None and len(rare_rec_hist) > 0) or \\\n       (common_rec_hist is not None and len(common_rec_hist) > 0):\n        fig, ax = plt.subplots(figsize=(6,4))\n        epochs = None\n        if rare_rec_hist is not None:\n            epochs = list(range(1, len(rare_rec_hist)+1))\n            ax.plot(epochs, rare_rec_hist, marker='o', label='Rare recall@50')\n        if common_rec_hist is not None:\n            if epochs is None:\n                epochs = list(range(1, len(common_rec_hist)+1))\n            ax.plot(epochs, common_rec_hist, marker='s', label='Common recall@50')\n        if rcrg_hist is not None:\n            if epochs is None:\n                epochs = list(range(1, len(rcrg_hist)+1))\n            ax.plot(epochs, rcrg_hist, marker='^', label='RCRG@50 (rare - common)')\n        ax.set_xlabel('Overwrite epoch')\n        ax.set_ylabel('Score')\n        ax.set_title('RCRG@50, Rare@50, Common@50 \u2014 WikiText Overwrite')\n        ax.grid(True, alpha=0.3)\n        ax.legend()\n        fig.suptitle('Recall Metrics Across Overwrite Epochs \u2014 dataset_wikitext_overwrite')\n        fig.tight_layout()\n        out_path = os.path.join(working_dir, 'dataset_wikitext_overwrite_recall_over_epochs.png')\n        plt.savefig(out_path)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating recall metrics plot: {e}\")\n    plt.close()\n\n# -----------------------------------------------------------------------------\n# 4) MRR retention gap across overwrite epochs\n# -----------------------------------------------------------------------------\ntry:\n    _, _, _, mrr_gap_hist = get_overwrite_histories()\n    if mrr_gap_hist is not None and len(mrr_gap_hist) > 0:\n        fig, ax = plt.subplots(figsize=(6,4))\n        epochs = list(range(1, len(mrr_gap_hist)+1))\n        ax.plot(epochs, mrr_gap_hist, marker='o', color='tab:green', label='MRR Retention Gap (rare - common)')\n        ax.set_xlabel('Overwrite epoch')\n        ax.set_ylabel('MRR gap')\n        ax.set_title('MRR Retention Gap \u2014 WikiText Overwrite')\n        ax.grid(True, alpha=0.3)\n        ax.legend()\n        fig.suptitle('MRR Retention Gap Across Overwrite Epochs \u2014 dataset_wikitext_overwrite')\n        fig.tight_layout()\n        out_path = os.path.join(working_dir, 'dataset_wikitext_overwrite_mrr_gap_over_epochs.png')\n        plt.savefig(out_path)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating MRR gap plot: {e}\")\n    plt.close()\n\n# -----------------------------------------------------------------------------\n# 5) Generated token counts after overwrite: rare vs common\n# -----------------------------------------------------------------------------\ntry:\n    d = experiment_data.get('dataset_wikitext_overwrite', {})\n    preds = d.get('predictions', []) or []\n    gt = d.get('ground_truth', {}) or {}\n    rare_tokens = gt.get('rare', []) or []\n    common_tokens = gt.get('common', []) or []\n\n    if preds and (rare_tokens or common_tokens):\n        # Count exact matches for first generated token strings\n        def count_hits(samples, targets):\n            counts = {t: 0 for t in targets}\n            for s in samples:\n                # Only count if s is a string\n                if not isinstance(s, str):\n                    continue\n                for t in targets:\n                    if s == t:\n                        counts[t] += 1\n            return counts\n\n        rare_counts = count_hits(preds, rare_tokens) if rare_tokens else {}\n        common_counts = count_hits(preds, common_tokens) if common_tokens else {}\n\n        fig, axes = plt.subplots(1, 2, figsize=(12,4), sharey=True)\n        # Left: Rare tokens\n        if rare_tokens:\n            ax = axes[0]\n            vals = [rare_counts.get(t, 0) for t in rare_tokens]\n            ax.bar(range(len(rare_tokens)), vals, color='tab:blue')\n            ax.set_xticks(range(len(rare_tokens)))\n            ax.set_xticklabels([t.strip() for t in rare_tokens], rotation=45, ha='right')\n            ax.set_title('Left: Rare Tokens \u2014 First-token frequency')\n            ax.set_ylabel('Count in generated first token')\n            ax.grid(True, axis='y', alpha=0.3)\n        else:\n            axes[0].axis('off')\n            axes[0].set_title('Left: Rare Tokens \u2014 No data')\n\n        # Right: Common tokens\n        if common_tokens:\n            ax = axes[1]\n            vals = [common_counts.get(t, 0) for t in common_tokens]\n            ax.bar(range(len(common_tokens)), vals, color='tab:orange')\n            ax.set_xticks(range(len(common_tokens)))\n            ax.set_xticklabels([t.strip() for t in common_tokens], rotation=45, ha='right')\n            ax.set_title('Right: Common Tokens \u2014 First-token frequency')\n            ax.grid(True, axis='y', alpha=0.3)\n        else:\n            axes[1].axis('off')\n            axes[1].set_title('Right: Common Tokens \u2014 No data')\n\n        fig.suptitle('Generated Token Counts \u2014 dataset_wikitext_overwrite')\n        fig.tight_layout()\n        out_path = os.path.join(working_dir, 'dataset_wikitext_overwrite_generated_token_counts.png')\n        plt.savefig(out_path)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating generated token counts plot: {e}\")\n    plt.close()", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\nworking_dir = os.path.join(os.getcwd(), 'working')\n\n# Ensure output directory exists\nos.makedirs(working_dir, exist_ok=True)\n\n# GPU/CPU device selection as required\ntry:\n    import torch\n    try:\n        torch.cuda.set_device(0)\n        device = torch.device('cuda:0')\n    except Exception:\n        device = torch.device('cpu')\nexcept Exception:\n    device = None\n\n# Load experiment data\ntry:\n    experiment_data = np.load(os.path.join(working_dir, 'experiment_data.npy'), allow_pickle=True).item()\nexcept Exception as e:\n    print(f'Error loading experiment data: {e}')\n    experiment_data = {}\n\n# Helper: count occurrences of exact-token matches in generated samples\ndef count_hits(samples, targets):\n    counts = {t: 0 for t in targets}\n    for s in samples:\n        if isinstance(s, str):\n            for t in targets:\n                if s == t:\n                    counts[t] += 1\n    return counts\n\n# Determine base dataset names (exclude phase1 containers)\nbase_datasets = []\nfor key in experiment_data.keys():\n    if key.endswith('_phase1'):\n        continue\n    base_datasets.append(key)\n\n# Iterate per dataset and plot\nfor ds in base_datasets:\n    ds_data = experiment_data.get(ds, {})\n    phase1_key = f\"{ds}_phase1\"\n    phase1_data = experiment_data.get(phase1_key, {})\n\n    # -----------------------------\n    # Plot 1: Training loss curves\n    # -----------------------------\n    try:\n        train_phase1 = phase1_data.get('losses', {}).get('train', [])\n        train_overwrite = ds_data.get('losses', {}).get('train', [])\n\n        # Extract overwrite-only entries (some entries may not have phase key; keep all as present)\n        l1 = [rec.get('loss') for rec in train_phase1 if isinstance(rec, dict) and 'loss' in rec]\n        l2 = [rec.get('loss') for rec in train_overwrite if isinstance(rec, dict) and 'loss' in rec]\n\n        if (l1 and any(x is not None for x in l1)) or (l2 and any(x is not None for x in l2)):\n            fig = plt.figure(figsize=(7, 4))\n            if l1:\n                plt.plot(range(1, len(l1) + 1), l1, marker='o', label='Phase1 train loss')\n            if l2:\n                plt.plot(range(1, len(l2) + 1), l2, marker='s', label='Overwrite train loss')\n            plt.xlabel('Epoch index (per phase)')\n            plt.ylabel('Loss')\n            plt.title(f'Training Loss Curves \u2014 Dataset: {ds}')\n            plt.legend()\n            plt.tight_layout()\n            out_path = os.path.join(working_dir, f'{ds}_training_loss_curves.png')\n            plt.savefig(out_path)\n            plt.close(fig)\n        else:\n            print(f'No training loss data available for dataset: {ds}')\n    except Exception as e:\n        print(f\"Error creating training loss plot for {ds}: {e}\")\n        try:\n            plt.close()\n        except Exception:\n            pass\n\n    # -------------------------------\n    # Plot 2: Validation loss curves\n    # -------------------------------\n    try:\n        val_phase1 = phase1_data.get('losses', {}).get('val', [])\n        val_overwrite = ds_data.get('losses', {}).get('val', [])\n\n        v1 = [rec.get('loss') for rec in val_phase1 if isinstance(rec, dict) and 'loss' in rec]\n        v2 = [rec.get('loss') for rec in val_overwrite if isinstance(rec, dict) and 'loss' in rec]\n\n        if (v1 and any(x is not None for x in v1)) or (v2 and any(x is not None for x in v2)):\n            fig = plt.figure(figsize=(7, 4))\n            if v1:\n                plt.plot(range(1, len(v1) + 1), v1, marker='o', label='Phase1 val loss')\n            if v2:\n                plt.plot(range(1, len(v2) + 1), v2, marker='s', label='Overwrite val loss')\n            plt.xlabel('Epoch index (per phase)')\n            plt.ylabel('Loss')\n            plt.title(f'Validation Loss Curves \u2014 Dataset: {ds}')\n            plt.legend()\n            plt.tight_layout()\n            out_path = os.path.join(working_dir, f'{ds}_validation_loss_curves.png')\n            plt.savefig(out_path)\n            plt.close(fig)\n        else:\n            print(f'No validation loss data available for dataset: {ds}')\n    except Exception as e:\n        print(f\"Error creating validation loss plot for {ds}: {e}\")\n        try:\n            plt.close()\n        except Exception:\n            pass\n\n    # -------------------------------------------------\n    # Plot 3: Retention metrics over overwrite (standard)\n    # -------------------------------------------------\n    try:\n        val_metrics = ds_data.get('metrics', {}).get('val', [])\n        std_epochs = []\n        rcrg_std = []\n        rare_rec_std = []\n        common_rec_std = []\n        mrr_gap_std = []\n\n        for rec in val_metrics:\n            if not isinstance(rec, dict):\n                continue\n            if rec.get('phase') == 'overwrite' and 'RCRG@50_standard' in rec:\n                std_epochs.append(rec.get('epoch'))\n                rcrg_std.append(rec.get('RCRG@50_standard'))\n                rare_rec_std.append(rec.get('rare_recall@50_standard'))\n                common_rec_std.append(rec.get('common_recall@50_standard'))\n                mrr_gap_std.append(rec.get('MRR_gap_standard'))\n\n        if std_epochs and any(v is not None for v in rcrg_std):\n            fig = plt.figure(figsize=(8, 4))\n            plt.plot(std_epochs, rcrg_std, marker='o', label='RCRG@50 (standard)')\n            plt.plot(std_epochs, rare_rec_std, marker='s', label='Rare recall@50 (standard)')\n            plt.plot(std_epochs, common_rec_std, marker='^', label='Common recall@50 (standard)')\n            plt.plot(std_epochs, mrr_gap_std, marker='x', label='MRR gap (standard)')\n            plt.xlabel('Overwrite epoch')\n            plt.ylabel('Score')\n            plt.title(f'Retention Metrics (Standard Prompts) \u2014 Dataset: {ds}')\n            plt.legend()\n            plt.tight_layout()\n            out_path = os.path.join(working_dir, f'{ds}_retention_metrics_standard.png')\n            plt.savefig(out_path)\n            plt.close(fig)\n        else:\n            print(f'No standard-prompt retention metrics available for dataset: {ds}')\n    except Exception as e:\n        print(f\"Error creating standard retention plot for {ds}: {e}\")\n        try:\n            plt.close()\n        except Exception:\n            pass\n\n    # ---------------------------------------------------\n    # Plot 4: Retention metrics over overwrite (dataset)\n    # ---------------------------------------------------\n    try:\n        val_metrics = ds_data.get('metrics', {}).get('val', [])\n        ds_epochs = []\n        rcrg_ds = []\n        rare_rec_ds = []\n        common_rec_ds = []\n        mrr_gap_ds = []\n\n        for rec in val_metrics:\n            if not isinstance(rec, dict):\n                continue\n            if rec.get('phase') == 'overwrite' and 'RCRG@50_dataset' in rec:\n                ds_epochs.append(rec.get('epoch'))\n                rcrg_ds.append(rec.get('RCRG@50_dataset'))\n                rare_rec_ds.append(rec.get('rare_recall@50_dataset'))\n                common_rec_ds.append(rec.get('common_recall@50_dataset'))\n                mrr_gap_ds.append(rec.get('MRR_gap_dataset'))\n\n        if ds_epochs and any(v is not None for v in rcrg_ds):\n            fig = plt.figure(figsize=(8, 4))\n            plt.plot(ds_epochs, rcrg_ds, marker='o', label='RCRG@50 (dataset)')\n            plt.plot(ds_epochs, rare_rec_ds, marker='s', label='Rare recall@50 (dataset)')\n            plt.plot(ds_epochs, common_rec_ds, marker='^', label='Common recall@50 (dataset)')\n            plt.plot(ds_epochs, mrr_gap_ds, marker='x', label='MRR gap (dataset)')\n            plt.xlabel('Overwrite epoch')\n            plt.ylabel('Score')\n            plt.title(f'Retention Metrics (Dataset Prompts) \u2014 Dataset: {ds}')\n            plt.legend()\n            plt.tight_layout()\n            out_path = os.path.join(working_dir, f'{ds}_retention_metrics_dataset.png')\n            plt.savefig(out_path)\n            plt.close(fig)\n        else:\n            print(f'No dataset-prompt retention metrics available for dataset: {ds}')\n    except Exception as e:\n        print(f\"Error creating dataset retention plot for {ds}: {e}\")\n        try:\n            plt.close()\n        except Exception:\n            pass\n\n    # --------------------------------------------------------------------\n    # Plot 5: Ground Truth (left) vs Generated Samples (std & dataset, right)\n    # --------------------------------------------------------------------\n    try:\n        gt = ds_data.get('ground_truth', {})\n        rare_tokens = gt.get('rare', []) if isinstance(gt, dict) else []\n        common_tokens = gt.get('common', []) if isinstance(gt, dict) else []\n\n        preds_list = ds_data.get('predictions', [])\n        std_samples = []\n        ds_samples = []\n        if isinstance(preds_list, list) and len(preds_list) > 0 and isinstance(preds_list[-1], dict):\n            std_samples = preds_list[-1].get('std_prompt_samples', []) or []\n            ds_samples = preds_list[-1].get('ds_prompt_samples', []) or []\n\n        # Only proceed if we have ground truth and at least one set of samples\n        if (rare_tokens or common_tokens) and (std_samples or ds_samples):\n            # Counts for standard prompt samples\n            rare_counts_std = count_hits(std_samples, rare_tokens) if std_samples else {t: 0 for t in rare_tokens}\n            common_counts_std = count_hits(std_samples, common_tokens) if std_samples else {t: 0 for t in common_tokens}\n            # Counts for dataset-prompt samples\n            rare_counts_ds = count_hits(ds_samples, rare_tokens) if ds_samples else {t: 0 for t in rare_tokens}\n            common_counts_ds = count_hits(ds_samples, common_tokens) if ds_samples else {t: 0 for t in common_tokens}\n\n            fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n            # Left: Ground Truth listing\n            axes[0].axis('off')\n            gt_text_lines = []\n            if rare_tokens:\n                gt_text_lines.append('Rare tokens:')\n                gt_text_lines.extend([f'  \u2022 {t.strip()}' for t in rare_tokens])\n                gt_text_lines.append('')\n            if common_tokens:\n                gt_text_lines.append('Common tokens:')\n                gt_text_lines.extend([f'  \u2022 {t.strip()}' for t in common_tokens])\n            axes[0].text(0.0, 1.0, '\\n'.join(gt_text_lines), va='top', ha='left', fontsize=10)\n\n            # Middle: Standard prompt generated counts\n            ax = axes[1]\n            x_rare = np.arange(len(rare_tokens)) if rare_tokens else np.array([])\n            x_common = (np.arange(len(common_tokens)) + (len(rare_tokens) + 1)) if common_tokens else np.array([])\n            if rare_tokens:\n                ax.bar(x_rare, [rare_counts_std.get(t, 0) for t in rare_tokens], color='tab:blue', label='Rare (std)')\n            if common_tokens:\n                ax.bar(x_common, [common_counts_std.get(t, 0) for t in common_tokens], color='tab:orange', label='Common (std)')\n            xticks = list(x_rare) + list(x_common)\n            xticklabels = [t.strip() for t in rare_tokens] + [t.strip() for t in common_tokens]\n            ax.set_xticks(xticks)\n            ax.set_xticklabels(xticklabels, rotation=45, ha='right')\n            ax.set_title('Standard Prompt Generated Counts')\n            ax.set_ylabel('Count (first generated token)')\n            ax.legend()\n\n            # Right: Dataset prompt generated counts\n            ax = axes[2]\n            x_rare = np.arange(len(rare_tokens)) if rare_tokens else np.array([])\n            x_common = (np.arange(len(common_tokens)) + (len(rare_tokens) + 1)) if common_tokens else np.array([])\n            if rare_tokens:\n                ax.bar(x_rare, [rare_counts_ds.get(t, 0) for t in rare_tokens], color='tab:blue', label='Rare (ds)')\n            if common_tokens:\n                ax.bar(x_common, [common_counts_ds.get(t, 0) for t in common_tokens], color='tab:orange', label='Common (ds)')\n            xticks = list(x_rare) + list(x_common)\n            xticklabels = [t.strip() for t in rare_tokens] + [t.strip() for t in common_tokens]\n            ax.set_xticks(xticks)\n            ax.set_xticklabels(xticklabels, rotation=45, ha='right')\n            ax.set_title('Dataset Prompt Generated Counts')\n            ax.set_ylabel('Count (first generated token)')\n            ax.legend()\n\n            plt.suptitle(f'Ground Truth vs Generated Samples \u2014 Dataset: {ds}')\n            # Subtitle text\n            fig.text(0.5, 0.01, 'Left: Ground Truth, Middle: Standard-Prompt Generated, Right: Dataset-Prompt Generated', ha='center', fontsize=9)\n            plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n            out_path = os.path.join(working_dir, f'{ds}_groundtruth_vs_generated.png')\n            plt.savefig(out_path)\n            plt.close(fig)\n        else:\n            print(f'Insufficient ground truth or predictions to plot GT vs Generated for dataset: {ds}')\n    except Exception as e:\n        print(f\"Error creating Ground Truth vs Generated plot for {ds}: {e}\")\n        try:\n            plt.close()\n        except Exception:\n            pass\n\nprint('Plotting complete. Figures saved to:', working_dir)"], "plot_plan": [null, null, "Load experiment_data.npy from working_dir and iterate over each base dataset (natlang, code_style, json_style, mixture). For each dataset, parse available losses and metrics from experiment_data without reading any other files. Produce up to five plots per dataset: (1) training loss curves (phase1 vs overwrite), (2) validation loss curves (phase1 vs overwrite), (3) retention metrics over overwrite epochs for standard prompts, (4) retention metrics over overwrite epochs for dataset-specific prompts, and (5) a \u201cGround Truth vs Generated Samples\u201d figure combining ground-truth tokens and generated first-token counts for standard and dataset prompts. Save all figures in working_dir with descriptive filenames, include titles and clear subtitles, wrap each plot in try-except, and always close figures. Use required device initialization lines.", null, "Load experiment_data.npy, parse available metrics and predictions, and create up to five clear, standard plots saved into working/. Include training/validation loss curves for both datasets, recall metrics trends and MRR gap over overwrite epochs, and a comparison of generated token counts for rare/common tokens after overwrite. Only use data present in experiment_data.npy. Wrap each plot in its own try-except block, ensure figures are closed, and save with descriptive filenames that include the dataset names. Honor the GPU index setup if CUDA is available, with CPU fallback.", null], "ablation_name": [null, "Multi-context synthetic injection datasets ablation", null, "Freeze rare-token embeddings during overwrite phase", null, null], "hyperparam_name": ["Reduce overwrite-phase batch size to 32", null, null, null, null, null], "is_seed_node": [false, false, false, false, false, true], "is_seed_agg_node": [false, false, false, false, false, false], "parse_metrics_plan": ["Load the saved experiment_data.npy from the working directory, parse the nested\nstructure under hyperparam_tuning_type_1, and for each dataset\n(synthetic_injection and overwrite_wikitext) print the final train average loss,\nthe best validation loss, and any additional validation metrics (RCRG@50,\nrare_recall@50, common_recall@50) using their best values. Enforce GPU device 0\nwhen CUDA is available with a CPU fallback. Keep code at global scope/functions\nand execute immediately without any plots.", "Load experiment_data.npy from the working directory, parse the nested structure\nunder ablation_type_1, and for each dataset tag print final values of relevant\nmetrics. Use the last entry of metrics['train'] for train loss and the last\nentry of metrics['val'] for validation loss. If available (overwrite phase),\nalso print the final RCRG and recall metrics stored in the last validation\nmetrics entry. Enforce CUDA device index 0 if available. No plots or __main__\nguard; execute on import.", "Load experiment_data.npy from the working directory. Enforce GPU index 0 when\nCUDA is available, with CPU fallback. Parse each dataset\u2019s containers to extract\nfinal train loss (last train loss), best validation loss (minimum over val\nlosses), and best values for the evaluation metrics recorded in metrics['val']\n(maximize RCRG, recalls, MRR gaps, and MRRs for both standard and dataset prompt\nsets). Print the dataset name, then each metric name with a precise label and\nits best/final value. Execute immediately without a main guard and without any\nplotting.", "Load the saved experiment_data.npy from the working directory, traverse its\nnested structure (ablation -> dataset) and extract relevant metrics. For each\ndataset, print the dataset name once, then print only best train avg_loss, best\nvalidation loss, and final RCRG/recall metrics if present. Use GPU index 0 when\nCUDA is available, else fall back to CPU. No plotting; code runs immediately\nwithout special entry point guards.", "Load experiment_data.npy from the working directory. Set CUDA device to index 0\nwhen available, else fall back to CPU. Parse the experiment_data dictionary per\ndataset, focusing on metrics stored under metrics['train'] and metrics['val'].\nFor each dataset, print the dataset name first. Then print: final train average\nloss, best validation loss (minimum), best rare recall@50 (maximum if\navailable), best common recall@50 (maximum), best MRR rare (maximum), best MRR\ncommon (maximum), and final MRR retention gap (last available). Handle missing\nmetrics gracefully by skipping unavailable ones. Execute immediately without an\nif __name__ == '__main__' guard and do not generate any plots.", "Load experiment_data.npy from the working directory. Enforce GPU index 0 when\nCUDA is available, with CPU fallback. Parse each dataset\u2019s containers to extract\nfinal train loss (last train loss), best validation loss (minimum over val\nlosses), and best values for the evaluation metrics recorded in metrics['val']\n(maximize RCRG, recalls, MRR gaps, and MRRs for both standard and dataset prompt\nsets). Print the dataset name, then each metric name with a precise label and\nits best/final value. Execute immediately without a main guard and without any\nplotting."], "parse_metrics_code": ["import os\nimport numpy as np\n\n# Optional torch/device setup as required (GPU index enforcement with CPU fallback)\ntry:\n    import torch\n    if torch.cuda.is_available():\n        torch.cuda.set_device(0)\n        device = torch.device('cuda:0')\n    else:\n        device = torch.device('cpu')\nexcept Exception:\n    torch = None\n    device = None\n\n\ndef load_experiment_data(working_dir: str):\n    path = os.path.join(working_dir, 'experiment_data.npy')\n    data = np.load(path, allow_pickle=True).item()\n    return data\n\n\ndef get_final_train_avg_loss(train_metrics_list):\n    # Expect entries like {'epoch': int, 'avg_loss': float, 'ts': str}\n    if not train_metrics_list:\n        return None, None\n    last = train_metrics_list[-1]\n    return last.get('avg_loss', None), last.get('epoch', None)\n\n\ndef get_best_val_loss(val_metrics_list):\n    # Expect entries like {'epoch': int, 'val_loss': float, 'ts': str, ...}\n    if not val_metrics_list:\n        return None, None\n    filtered = [m for m in val_metrics_list if 'val_loss' in m]\n    if not filtered:\n        return None, None\n    best = min(filtered, key=lambda x: x.get('val_loss', float('inf')))\n    return best.get('val_loss', None), best.get('epoch', None)\n\n\ndef get_additional_val_metrics_best(val_metrics_list):\n    # Identify additional metrics beyond epoch/ts/val_loss; choose best as max\n    results = {}\n    if not val_metrics_list:\n        return results\n    ignore_keys = {'epoch', 'ts', 'val_loss'}\n    # Collect candidate metric names\n    metric_names = set()\n    for m in val_metrics_list:\n        for k, v in m.items():\n            if k not in ignore_keys and isinstance(v, (int, float, np.floating)):\n                metric_names.add(k)\n    # For each metric, find the max value and its epoch\n    for name in metric_names:\n        best_entry = None\n        best_val = None\n        for m in val_metrics_list:\n            if name in m and isinstance(m[name], (int, float, np.floating)):\n                val = float(m[name])\n                if best_val is None or val > best_val:\n                    best_val = val\n                    best_entry = m\n        if best_entry is not None:\n            results[name] = (best_val, best_entry.get('epoch', None))\n    return results\n\n\ndef print_metrics_for_dataset(name: str, ds: dict):\n    metrics = ds.get('metrics', {})\n    train_metrics = metrics.get('train', [])\n    val_metrics = metrics.get('val', [])\n\n    print(f'Dataset: {name}')\n\n    # Final train average loss\n    train_avg_loss, train_epoch = get_final_train_avg_loss(train_metrics)\n    if train_avg_loss is not None:\n        print(f'train average loss (final): {train_avg_loss:.6f}')\n\n    # Best validation loss\n    best_val_loss, best_val_epoch = get_best_val_loss(val_metrics)\n    if best_val_loss is not None:\n        print(f'validation loss (best): {best_val_loss:.6f}')\n\n    # Additional validation metrics (best)\n    extra_best = get_additional_val_metrics_best(val_metrics)\n    for metric_name in sorted(extra_best.keys()):\n        val, ep = extra_best[metric_name]\n        # Keep original metric naming exactly (e.g., RCRG@50)\n        print(f'{metric_name} (best): {val:.6f}')\n\n\ndef main():\n    working_dir = os.path.join(os.getcwd(), 'working')\n    experiment_data = load_experiment_data(working_dir)\n\n    # Navigate to the expected container\n    root_key = 'hyperparam_tuning_type_1'\n    if root_key not in experiment_data:\n        # Fallback: if structure differs, try to infer top key\n        keys = list(experiment_data.keys())\n        if len(keys) == 1 and isinstance(experiment_data[keys[0]], dict):\n            root_key = keys[0]\n        else:\n            # Print nothing if malformed, but attempt graceful exit\n            return\n\n    container = experiment_data[root_key]\n\n    for dataset_name, dataset_obj in container.items():\n        if isinstance(dataset_obj, dict):\n            print_metrics_for_dataset(dataset_name, dataset_obj)\n\n\n# Execute immediately\nmain()", "import os\nimport numpy as np\nimport torch\n\n# Enforce GPU index 0 if CUDA is available\nif torch.cuda.is_available():\n    torch.cuda.set_device(0)\n    device = torch.device('cuda:0')\nelse:\n    device = torch.device('cpu')\n\n\ndef load_experiment_data(working_dir: str):\n    path = os.path.join(working_dir, 'experiment_data.npy')\n    data = np.load(path, allow_pickle=True).item()\n    return data\n\n\ndef format_float(x):\n    try:\n        return f\"{float(x):.6f}\"\n    except Exception:\n        return str(x)\n\n\ndef print_final_metrics(experiment_data: dict):\n    # Navigate to ablation_type_1 container\n    root_key = 'ablation_type_1'\n    if root_key not in experiment_data:\n        print('No ablation_type_1 found in experiment data.')\n        return\n\n    for dataset_tag, content in experiment_data[root_key].items():\n        print(f\"Dataset: {dataset_tag}\")\n\n        # Extract train/val metrics\n        metrics = content.get('metrics', {})\n        train_metrics = metrics.get('train', [])\n        val_metrics = metrics.get('val', [])\n\n        # Final train loss (from metrics['train'] avg_loss)\n        if train_metrics:\n            last_train = train_metrics[-1]\n            # Prefer 'avg_loss' if present; otherwise fall back to 'loss'\n            train_loss_val = last_train.get('avg_loss', last_train.get('loss', None))\n            if train_loss_val is not None:\n                print(f\"train loss (final): {format_float(train_loss_val)}\")\n\n        # Final validation loss (from metrics['val'] val_loss)\n        if val_metrics:\n            last_val = val_metrics[-1]\n            val_loss_val = last_val.get('val_loss', last_val.get('loss', None))\n            if val_loss_val is not None:\n                print(f\"validation loss (final): {format_float(val_loss_val)}\")\n\n            # Optional RCRG and recall metrics (only present for overwrite phase)\n            if 'RCRG@50_standard' in last_val:\n                print(f\"RCRG@50 (standard, final): {format_float(last_val['RCRG@50_standard'])}\")\n            if 'rare_recall@50_standard' in last_val:\n                print(f\"rare recall@50 (standard, final): {format_float(last_val['rare_recall@50_standard'])}\")\n            if 'common_recall@50_standard' in last_val:\n                print(f\"common recall@50 (standard, final): {format_float(last_val['common_recall@50_standard'])}\")\n            if 'RCRG@50_dataset' in last_val:\n                print(f\"RCRG@50 (dataset prompts, final): {format_float(last_val['RCRG@50_dataset'])}\")\n            if 'rare_recall@50_dataset' in last_val:\n                print(f\"rare recall@50 (dataset prompts, final): {format_float(last_val['rare_recall@50_dataset'])}\")\n            if 'common_recall@50_dataset' in last_val:\n                print(f\"common recall@50 (dataset prompts, final): {format_float(last_val['common_recall@50_dataset'])}\")\n\n        # Blank line between datasets for readability\n        print()\n\n\n# Working directory as specified\nworking_dir = os.path.join(os.getcwd(), 'working')\nexp_data = load_experiment_data(working_dir)\nprint_final_metrics(exp_data)", "import os\nimport numpy as np\nimport torch\n\n# -----------------------------------------------------------------------------\n# Enforce device selection (GPU index 0 if available, else CPU)\n# -----------------------------------------------------------------------------\nif torch.cuda.is_available():\n    torch.cuda.set_device(0)\n    device = torch.device('cuda:0')\nelse:\n    device = torch.device('cpu')\n\n# -----------------------------------------------------------------------------\n# Paths and loading\n# -----------------------------------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), 'working')\nexp_path = os.path.join(working_dir, 'experiment_data.npy')\n\nexperiment_data = np.load(exp_path, allow_pickle=True)\nif isinstance(experiment_data, np.ndarray) and experiment_data.shape == ():\n    experiment_data = experiment_data.item()\n\n# -----------------------------------------------------------------------------\n# Helpers\n# -----------------------------------------------------------------------------\n\ndef fmt_float(x):\n    try:\n        return f\"{float(x):.6f}\"\n    except Exception:\n        return str(x)\n\n\ndef best_max(values):\n    if not values:\n        return None\n    return max(values)\n\n\ndef best_min(values):\n    if not values:\n        return None\n    return min(values)\n\n\n# Metric keys to extract from metrics['val'] entries (maximize)\nstd_keys = [\n    ('RCRG@50_standard', 'best RCRG@50 (standard)'),\n    ('rare_recall@50_standard', 'best rare recall@50 (standard)'),\n    ('common_recall@50_standard', 'best common recall@50 (standard)'),\n    ('MRR_gap_standard', 'best MRR gap (standard)'),\n    ('rare_MRR_standard', 'best rare MRR (standard)'),\n    ('common_MRR_standard', 'best common MRR (standard)'),\n]\n\nds_keys = [\n    ('RCRG@50_dataset', 'best RCRG@50 (dataset)'),\n    ('rare_recall@50_dataset', 'best rare recall@50 (dataset)'),\n    ('common_recall@50_dataset', 'best common recall@50 (dataset)'),\n    ('MRR_gap_dataset', 'best MRR gap (dataset)'),\n    ('rare_MRR_dataset', 'best rare MRR (dataset)'),\n    ('common_MRR_dataset', 'best common MRR (dataset)'),\n]\n\n# -----------------------------------------------------------------------------\n# Extraction and printing\n# -----------------------------------------------------------------------------\nfor dataset_name, container in experiment_data.items():\n    print(f\"Dataset: {dataset_name}\")\n\n    losses = container.get('losses', {})\n    train_losses_list = losses.get('train', []) or []\n    val_losses_list = losses.get('val', []) or []\n\n    # Final train loss (last recorded train loss)\n    final_train_loss = None\n    if len(train_losses_list) > 0:\n        # Use the last entry's 'loss' if present\n        last_train_entry = train_losses_list[-1]\n        if isinstance(last_train_entry, dict) and 'loss' in last_train_entry:\n            final_train_loss = last_train_entry['loss']\n    if final_train_loss is not None:\n        print(f\"final train loss: {fmt_float(final_train_loss)}\")\n\n    # Best validation loss (minimum over val losses)\n    val_loss_values = [d['loss'] for d in val_losses_list if isinstance(d, dict) and 'loss' in d]\n    best_val_loss = best_min(val_loss_values)\n    if best_val_loss is not None:\n        print(f\"best validation loss: {fmt_float(best_val_loss)}\")\n\n    # Best metrics from metrics['val'] (maximize)\n    val_metrics_entries = container.get('metrics', {}).get('val', []) or []\n\n    def extract_best_for_key(key):\n        vals = [entry[key] for entry in val_metrics_entries if isinstance(entry, dict) and key in entry]\n        return best_max(vals) if len(vals) > 0 else None\n\n    # Standard prompt metrics\n    for key, label in std_keys:\n        v = extract_best_for_key(key)\n        if v is not None:\n            print(f\"{label}: {fmt_float(v)}\")\n\n    # Dataset-specific prompt metrics\n    for key, label in ds_keys:\n        v = extract_best_for_key(key)\n        if v is not None:\n            print(f\"{label}: {fmt_float(v)}\")", "import os\nimport numpy as np\nimport torch\n\n# Device setup (GPU enforced when available)\nif torch.cuda.is_available():\n    torch.cuda.set_device(0)\n    device = torch.device('cuda:0')\nelse:\n    device = torch.device('cpu')\n\n# Working directory\nworking_dir = os.path.join(os.getcwd(), 'working')\n\n# Load experiment data\nexperiment_path = os.path.join(working_dir, 'experiment_data.npy')\nexperiment_data = np.load(experiment_path, allow_pickle=True).item()\n\n\ndef print_best_or_final_metrics(exp_data: dict) -> None:\n    # Iterate ablation -> dataset\n    for ablation_name, datasets in exp_data.items():\n        if not isinstance(datasets, dict):\n            continue\n        for dataset_name, ds in datasets.items():\n            if not isinstance(ds, dict):\n                continue\n            print(f\"Dataset: {ablation_name}/{dataset_name}\")\n\n            metrics = ds.get('metrics', {}) if isinstance(ds.get('metrics', {}), dict) else {}\n            train_metrics = metrics.get('train', []) if isinstance(metrics.get('train', []), list) else []\n            val_metrics = metrics.get('val', []) if isinstance(metrics.get('val', []), list) else []\n\n            # Best train avg_loss\n            best_train_avg_loss = None\n            for m in train_metrics:\n                if isinstance(m, dict) and 'avg_loss' in m:\n                    v = m['avg_loss']\n                    if best_train_avg_loss is None or v < best_train_avg_loss:\n                        best_train_avg_loss = v\n            if best_train_avg_loss is not None:\n                print(f\"train avg_loss (best): {best_train_avg_loss}\")\n\n            # Best validation loss\n            best_val_loss = None\n            for m in val_metrics:\n                if isinstance(m, dict) and 'val_loss' in m:\n                    v = m['val_loss']\n                    if best_val_loss is None or v < best_val_loss:\n                        best_val_loss = v\n            if best_val_loss is not None:\n                print(f\"validation loss (best): {best_val_loss}\")\n\n            # Final RCRG and recalls (from last val metrics entry if present, else from aux histories)\n            final_rcrg = None\n            final_rare_rec = None\n            final_common_rec = None\n            if len(val_metrics) > 0 and isinstance(val_metrics[-1], dict):\n                last_val = val_metrics[-1]\n                final_rcrg = last_val.get('RCRG@50', final_rcrg)\n                final_rare_rec = last_val.get('rare_recall@50', final_rare_rec)\n                final_common_rec = last_val.get('common_recall@50', final_common_rec)\n\n            if final_rcrg is None or final_rare_rec is None or final_common_rec is None:\n                aux = ds.get('aux', {}) if isinstance(ds.get('aux', {}), dict) else {}\n                r_hist = aux.get('rcrg_history', [])\n                rr_hist = aux.get('rare_recall_history', [])\n                cr_hist = aux.get('common_recall_history', [])\n                if final_rcrg is None and isinstance(r_hist, (list, np.ndarray)) and len(r_hist) > 0:\n                    final_rcrg = r_hist[-1].item() if hasattr(r_hist[-1], 'item') else r_hist[-1]\n                if final_rare_rec is None and isinstance(rr_hist, (list, np.ndarray)) and len(rr_hist) > 0:\n                    final_rare_rec = rr_hist[-1].item() if hasattr(rr_hist[-1], 'item') else rr_hist[-1]\n                if final_common_rec is None and isinstance(cr_hist, (list, np.ndarray)) and len(cr_hist) > 0:\n                    final_common_rec = cr_hist[-1].item() if hasattr(cr_hist[-1], 'item') else cr_hist[-1]\n\n            if final_rcrg is not None:\n                print(f\"RCRG@50 (final): {final_rcrg}\")\n            if final_rare_rec is not None:\n                print(f\"rare recall@50 (final): {final_rare_rec}\")\n            if final_common_rec is not None:\n                print(f\"common recall@50 (final): {final_common_rec}\")\n\n\n# Execute analysis immediately\nprint_best_or_final_metrics(experiment_data)", "import os\nimport numpy as np\nimport torch\nfrom typing import Any, Dict, List\n\n# -----------------------------------------------------------------------------\n# Device setup (enforce GPU index when available)\n# -----------------------------------------------------------------------------\nif torch.cuda.is_available():\n    torch.cuda.set_device(0)\n    device = torch.device('cuda:0')\nelse:\n    device = torch.device('cpu')\n\n# -----------------------------------------------------------------------------\n# Helpers\n# -----------------------------------------------------------------------------\n\ndef is_number(x: Any) -> bool:\n    try:\n        _ = float(x)\n        return True\n    except Exception:\n        return False\n\n\ndef get_last_numeric(values: List[Any]) -> Any:\n    for v in reversed(values):\n        if is_number(v):\n            return v\n    return None\n\n\ndef analyze_and_print_dataset(name: str, ds: Dict[str, Any]) -> None:\n    print(name)\n    metrics = ds.get('metrics', {})\n\n    # Train final average loss\n    train_entries = metrics.get('train', []) if isinstance(metrics.get('train', []), list) else []\n    train_avg_losses = [e.get('avg_loss') for e in train_entries if isinstance(e, dict) and 'avg_loss' in e and is_number(e.get('avg_loss'))]\n    if train_avg_losses:\n        final_train_avg_loss = train_avg_losses[-1]\n        print(f\"train average loss (final): {final_train_avg_loss}\")\n\n    # Validation metrics\n    val_entries = metrics.get('val', []) if isinstance(metrics.get('val', []), list) else []\n\n    # Best validation loss (min)\n    val_losses = [e.get('val_loss') for e in val_entries if isinstance(e, dict) and 'val_loss' in e and is_number(e.get('val_loss'))]\n    if val_losses:\n        best_val_loss = min(val_losses)\n        print(f\"validation loss (best): {best_val_loss}\")\n\n    # Rare/Common recall@50 (best = max)\n    rare_recalls = [e.get('rare_recall@50') for e in val_entries if isinstance(e, dict) and is_number(e.get('rare_recall@50'))]\n    if rare_recalls:\n        best_rare_recall = max(rare_recalls)\n        print(f\"validation rare recall@50 (best): {best_rare_recall}\")\n\n    common_recalls = [e.get('common_recall@50') for e in val_entries if isinstance(e, dict) and is_number(e.get('common_recall@50'))]\n    if common_recalls:\n        best_common_recall = max(common_recalls)\n        print(f\"validation common recall@50 (best): {best_common_recall}\")\n\n    # MRR rare/common (best = max)\n    mrr_rare_list = [e.get('MRR_rare') for e in val_entries if isinstance(e, dict) and is_number(e.get('MRR_rare'))]\n    if mrr_rare_list:\n        best_mrr_rare = max(mrr_rare_list)\n        print(f\"validation MRR rare (best): {best_mrr_rare}\")\n\n    mrr_common_list = [e.get('MRR_common') for e in val_entries if isinstance(e, dict) and is_number(e.get('MRR_common'))]\n    if mrr_common_list:\n        best_mrr_common = max(mrr_common_list)\n        print(f\"validation MRR common (best): {best_mrr_common}\")\n\n    # MRR retention gap (final = last available)\n    mrr_gap_list = [e.get('MRR_Retention_Gap') for e in val_entries if isinstance(e, dict) and is_number(e.get('MRR_Retention_Gap'))]\n    if mrr_gap_list:\n        final_mrr_gap = mrr_gap_list[-1]\n        print(f\"validation MRR retention gap (final): {final_mrr_gap}\")\n\n\n# -----------------------------------------------------------------------------\n# Main execution (no __main__ guard; runs immediately)\n# -----------------------------------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), 'working')\nexp_path = os.path.join(working_dir, 'experiment_data.npy')\n\nif not os.path.isfile(exp_path):\n    raise FileNotFoundError(f\"experiment_data.npy not found at: {exp_path}\")\n\nexperiment_data: Dict[str, Dict[str, Any]] = np.load(exp_path, allow_pickle=True).item()\n\n# Iterate datasets and print required metrics\nfor dataset_name, dataset_dict in experiment_data.items():\n    if isinstance(dataset_dict, dict):\n        analyze_and_print_dataset(dataset_name, dataset_dict)", "import os\nimport numpy as np\nimport torch\n\n# -----------------------------------------------------------------------------\n# Enforce device selection (GPU index 0 if available, else CPU)\n# -----------------------------------------------------------------------------\nif torch.cuda.is_available():\n    torch.cuda.set_device(0)\n    device = torch.device('cuda:0')\nelse:\n    device = torch.device('cpu')\n\n# -----------------------------------------------------------------------------\n# Paths and loading\n# -----------------------------------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), 'working')\nexp_path = os.path.join(working_dir, 'experiment_data.npy')\n\nexperiment_data = np.load(exp_path, allow_pickle=True)\nif isinstance(experiment_data, np.ndarray) and experiment_data.shape == ():\n    experiment_data = experiment_data.item()\n\n# -----------------------------------------------------------------------------\n# Helpers\n# -----------------------------------------------------------------------------\n\ndef fmt_float(x):\n    try:\n        return f\"{float(x):.6f}\"\n    except Exception:\n        return str(x)\n\n\ndef best_max(values):\n    if not values:\n        return None\n    return max(values)\n\n\ndef best_min(values):\n    if not values:\n        return None\n    return min(values)\n\n\n# Metric keys to extract from metrics['val'] entries (maximize)\nstd_keys = [\n    ('RCRG@50_standard', 'best RCRG@50 (standard)'),\n    ('rare_recall@50_standard', 'best rare recall@50 (standard)'),\n    ('common_recall@50_standard', 'best common recall@50 (standard)'),\n    ('MRR_gap_standard', 'best MRR gap (standard)'),\n    ('rare_MRR_standard', 'best rare MRR (standard)'),\n    ('common_MRR_standard', 'best common MRR (standard)'),\n]\n\nds_keys = [\n    ('RCRG@50_dataset', 'best RCRG@50 (dataset)'),\n    ('rare_recall@50_dataset', 'best rare recall@50 (dataset)'),\n    ('common_recall@50_dataset', 'best common recall@50 (dataset)'),\n    ('MRR_gap_dataset', 'best MRR gap (dataset)'),\n    ('rare_MRR_dataset', 'best rare MRR (dataset)'),\n    ('common_MRR_dataset', 'best common MRR (dataset)'),\n]\n\n# -----------------------------------------------------------------------------\n# Extraction and printing\n# -----------------------------------------------------------------------------\nfor dataset_name, container in experiment_data.items():\n    print(f\"Dataset: {dataset_name}\")\n\n    losses = container.get('losses', {})\n    train_losses_list = losses.get('train', []) or []\n    val_losses_list = losses.get('val', []) or []\n\n    # Final train loss (last recorded train loss)\n    final_train_loss = None\n    if len(train_losses_list) > 0:\n        # Use the last entry's 'loss' if present\n        last_train_entry = train_losses_list[-1]\n        if isinstance(last_train_entry, dict) and 'loss' in last_train_entry:\n            final_train_loss = last_train_entry['loss']\n    if final_train_loss is not None:\n        print(f\"final train loss: {fmt_float(final_train_loss)}\")\n\n    # Best validation loss (minimum over val losses)\n    val_loss_values = [d['loss'] for d in val_losses_list if isinstance(d, dict) and 'loss' in d]\n    best_val_loss = best_min(val_loss_values)\n    if best_val_loss is not None:\n        print(f\"best validation loss: {fmt_float(best_val_loss)}\")\n\n    # Best metrics from metrics['val'] (maximize)\n    val_metrics_entries = container.get('metrics', {}).get('val', []) or []\n\n    def extract_best_for_key(key):\n        vals = [entry[key] for entry in val_metrics_entries if isinstance(entry, dict) and key in entry]\n        return best_max(vals) if len(vals) > 0 else None\n\n    # Standard prompt metrics\n    for key, label in std_keys:\n        v = extract_best_for_key(key)\n        if v is not None:\n            print(f\"{label}: {fmt_float(v)}\")\n\n    # Dataset-specific prompt metrics\n    for key, label in ds_keys:\n        v = extract_best_for_key(key)\n        if v is not None:\n            print(f\"{label}: {fmt_float(v)}\")"], "parse_term_out": ["['Dataset: synthetic_injection', '\\n', 'train average loss (final): 3.085596',\n'\\n', 'validation loss (best): 3.226789', '\\n', 'Dataset: overwrite_wikitext',\n'\\n', 'train average loss (final): 2.876351', '\\n', 'validation loss (best):\n3.623615', '\\n', 'RCRG@50 (best): 0.000000', '\\n', 'common_recall@50 (best):\n0.200000', '\\n', 'rare_recall@50 (best): 0.000000', '\\n', 'Execution time: a\nmoment seconds (time limit is 2 hours).']", "['Traceback (most recent call last):\\n  File \"runfile.py\", line 76, in\n<module>\\n    exp_data = load_experiment_data(working_dir)\\n\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"runfile.py\", line 15, in\nload_experiment_data\\n    data = np.load(path, allow_pickle=True).item()\\n\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"/workspace/AE-\nScientist/research_pipeline/.venv/lib/python3.12/site-\npackages/numpy/lib/_npyio_impl.py\", line 454, in load\\n    fid =\nstack.enter_context(open(os.fspath(file), \"rb\"))\\n\n^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nFileNotFoundError: [Errno 2] No such file or\ndirectory: \\'/workspace/AE-Scientist/research_pipeline/workspaces/0-\nrun/process_SpawnProcess-5/working/experiment_data.npy\\'\\n', 'Execution time: a\nmoment seconds (time limit is 2 hours).']", "['Dataset: natlang', '\\n', 'final train loss: 2.880104', '\\n', 'best validation\nloss: 3.620356', '\\n', 'best RCRG@50 (standard): 0.000000', '\\n', 'best rare\nrecall@50 (standard): 0.000000', '\\n', 'best common recall@50 (standard):\n0.200000', '\\n', 'best MRR gap (standard): -0.000489', '\\n', 'best rare MRR\n(standard): 0.000037', '\\n', 'best common MRR (standard): 0.004295', '\\n', 'best\nRCRG@50 (dataset): 0.000000', '\\n', 'best rare recall@50 (dataset): 0.000000',\n'\\n', 'best common recall@50 (dataset): 0.125000', '\\n', 'best MRR gap\n(dataset): -0.000347', '\\n', 'best rare MRR (dataset): 0.000037', '\\n', 'best\ncommon MRR (dataset): 0.003253', '\\n', 'Dataset: code_style', '\\n', 'final train\nloss: 2.877241', '\\n', 'best validation loss: 3.617718', '\\n', 'best RCRG@50\n(standard): 0.000000', '\\n', 'best rare recall@50 (standard): 0.000000', '\\n',\n'best common recall@50 (standard): 0.000000', '\\n', 'best MRR gap (standard):\n-0.000109', '\\n', 'best rare MRR (standard): 0.000036', '\\n', 'best common MRR\n(standard): 0.001472', '\\n', 'best RCRG@50 (dataset): 0.000000', '\\n', 'best\nrare recall@50 (dataset): 0.000000', '\\n', 'best common recall@50 (dataset):\n0.000000', '\\n', 'best MRR gap (dataset): -0.000097', '\\n', 'best rare MRR\n(dataset): 0.000038', '\\n', 'best common MRR (dataset): 0.000503', '\\n',\n'Dataset: json_style', '\\n', 'final train loss: 2.882936', '\\n', 'best\nvalidation loss: 3.625448', '\\n', 'best RCRG@50 (standard): 0.000000', '\\n',\n'best rare recall@50 (standard): 0.000000', '\\n', 'best common recall@50\n(standard): 0.000000', '\\n', 'best MRR gap (standard): -0.000096', '\\n', 'best\nrare MRR (standard): 0.000036', '\\n', 'best common MRR (standard): 0.001006',\n'\\n', 'best RCRG@50 (dataset): 0.000000', '\\n', 'best rare recall@50 (dataset):\n0.000000', '\\n', 'best common recall@50 (dataset): 0.000000', '\\n', 'best MRR\ngap (dataset): -0.000064', '\\n', 'best rare MRR (dataset): 0.000036', '\\n',\n'best common MRR (dataset): 0.000770', '\\n', 'Dataset: mixture', '\\n', 'final\ntrain loss: 2.876754', '\\n', 'best validation loss: 3.616663', '\\n', 'best\nRCRG@50 (standard): 0.000000', '\\n', 'best rare recall@50 (standard): 0.000000',\n'\\n', 'best common recall@50 (standard): 0.000000', '\\n', 'best MRR gap\n(standard): -0.000234', '\\n', 'best rare MRR (standard): 0.000036', '\\n', 'best\ncommon MRR (standard): 0.003028', '\\n', 'best RCRG@50 (dataset): 0.000000',\n'\\n', 'best rare recall@50 (dataset): 0.000000', '\\n', 'best common recall@50\n(dataset): 0.000000', '\\n', 'best MRR gap (dataset): -0.000136', '\\n', 'best\nrare MRR (dataset): 0.000037', '\\n', 'best common MRR (dataset): 0.001257',\n'\\n', 'Dataset: natlang_phase1', '\\n', 'final train loss: 3.091090', '\\n', 'best\nvalidation loss: 3.264396', '\\n', 'Dataset: code_style_phase1', '\\n', 'final\ntrain loss: 3.727107', '\\n', 'best validation loss: 2.515804', '\\n', 'Dataset:\njson_style_phase1', '\\n', 'final train loss: 2.747418', '\\n', 'best validation\nloss: 4.222914', '\\n', 'Dataset: mixture_phase1', '\\n', 'final train loss:\n3.653895', '\\n', 'best validation loss: 3.158692', '\\n', 'Execution time: a\nmoment seconds (time limit is 2 hours).']", "['Dataset: ablation_type_1/dataset_name_1', '\\n', 'train avg_loss (best):\n2.876352206520412', '\\n', 'validation loss (best): 3.2267885208129883', '\\n',\n'RCRG@50 (final): 0.0', '\\n', 'rare recall@50 (final): 0.0', '\\n', 'common\nrecall@50 (final): 0.0', '\\n', 'Execution time: a moment seconds (time limit is\n2 hours).']", "['dataset_synthetic_injection', '\\n', 'train average loss (final):\n3.0855959370022727', '\\n', 'validation loss (best): 3.2267885208129883', '\\n',\n'validation rare recall@50 (best): 0.0', '\\n', 'validation common recall@50\n(best): 0.0', '\\n', 'validation MRR rare (best): 5.885551020980018e-05', '\\n',\n'validation MRR common (best): 0.0006805330290799254', '\\n', 'validation MRR\nretention gap (final): -0.0006216775188701252', '\\n',\n'dataset_wikitext_overwrite', '\\n', 'train average loss (final):\n2.876352206520412', '\\n', 'validation loss (best): 3.623615846795551', '\\n',\n'validation rare recall@50 (best): 0.0', '\\n', 'validation common recall@50\n(best): 0.2', '\\n', 'validation MRR rare (best): 0.00010993255796603315', '\\n',\n'validation MRR common (best): 0.006685887517693588', '\\n', 'validation MRR\nretention gap (final): -0.00011169656770554598', '\\n', 'Execution time: a moment\nseconds (time limit is 2 hours).']", "['Dataset: natlang', '\\n', 'final train loss: 2.880104', '\\n', 'best validation\nloss: 3.620356', '\\n', 'best RCRG@50 (standard): 0.000000', '\\n', 'best rare\nrecall@50 (standard): 0.000000', '\\n', 'best common recall@50 (standard):\n0.200000', '\\n', 'best MRR gap (standard): -0.000489', '\\n', 'best rare MRR\n(standard): 0.000037', '\\n', 'best common MRR (standard): 0.004295', '\\n', 'best\nRCRG@50 (dataset): 0.000000', '\\n', 'best rare recall@50 (dataset): 0.000000',\n'\\n', 'best common recall@50 (dataset): 0.125000', '\\n', 'best MRR gap\n(dataset): -0.000347', '\\n', 'best rare MRR (dataset): 0.000037', '\\n', 'best\ncommon MRR (dataset): 0.003253', '\\n', 'Dataset: code_style', '\\n', 'final train\nloss: 2.877241', '\\n', 'best validation loss: 3.617718', '\\n', 'best RCRG@50\n(standard): 0.000000', '\\n', 'best rare recall@50 (standard): 0.000000', '\\n',\n'best common recall@50 (standard): 0.000000', '\\n', 'best MRR gap (standard):\n-0.000109', '\\n', 'best rare MRR (standard): 0.000036', '\\n', 'best common MRR\n(standard): 0.001472', '\\n', 'best RCRG@50 (dataset): 0.000000', '\\n', 'best\nrare recall@50 (dataset): 0.000000', '\\n', 'best common recall@50 (dataset):\n0.000000', '\\n', 'best MRR gap (dataset): -0.000097', '\\n', 'best rare MRR\n(dataset): 0.000038', '\\n', 'best common MRR (dataset): 0.000503', '\\n',\n'Dataset: json_style', '\\n', 'final train loss: 2.882936', '\\n', 'best\nvalidation loss: 3.625448', '\\n', 'best RCRG@50 (standard): 0.000000', '\\n',\n'best rare recall@50 (standard): 0.000000', '\\n', 'best common recall@50\n(standard): 0.000000', '\\n', 'best MRR gap (standard): -0.000096', '\\n', 'best\nrare MRR (standard): 0.000036', '\\n', 'best common MRR (standard): 0.001006',\n'\\n', 'best RCRG@50 (dataset): 0.000000', '\\n', 'best rare recall@50 (dataset):\n0.000000', '\\n', 'best common recall@50 (dataset): 0.000000', '\\n', 'best MRR\ngap (dataset): -0.000064', '\\n', 'best rare MRR (dataset): 0.000036', '\\n',\n'best common MRR (dataset): 0.000770', '\\n', 'Dataset: mixture', '\\n', 'final\ntrain loss: 2.876754', '\\n', 'best validation loss: 3.616663', '\\n', 'best\nRCRG@50 (standard): 0.000000', '\\n', 'best rare recall@50 (standard): 0.000000',\n'\\n', 'best common recall@50 (standard): 0.000000', '\\n', 'best MRR gap\n(standard): -0.000234', '\\n', 'best rare MRR (standard): 0.000036', '\\n', 'best\ncommon MRR (standard): 0.003028', '\\n', 'best RCRG@50 (dataset): 0.000000',\n'\\n', 'best rare recall@50 (dataset): 0.000000', '\\n', 'best common recall@50\n(dataset): 0.000000', '\\n', 'best MRR gap (dataset): -0.000136', '\\n', 'best\nrare MRR (dataset): 0.000037', '\\n', 'best common MRR (dataset): 0.001257',\n'\\n', 'Dataset: natlang_phase1', '\\n', 'final train loss: 3.091090', '\\n', 'best\nvalidation loss: 3.264396', '\\n', 'Dataset: code_style_phase1', '\\n', 'final\ntrain loss: 3.727107', '\\n', 'best validation loss: 2.515804', '\\n', 'Dataset:\njson_style_phase1', '\\n', 'final train loss: 2.747418', '\\n', 'best validation\nloss: 4.222914', '\\n', 'Dataset: mixture_phase1', '\\n', 'final train loss:\n3.653895', '\\n', 'best validation loss: 3.158692', '\\n', 'Execution time: a\nmoment seconds (time limit is 2 hours).']"], "parse_exc_type": [null, "FileNotFoundError", null, null, null, null], "parse_exc_info": [null, {"args": ["2", "No such file or directory"]}, null, null, null, null], "parse_exc_stack": [null, [["/workspace/AE-Scientist/research_pipeline/ai_scientist/treesearch/interpreter.py", 264, "_repl_run_session", "exec(compile(code, agent_file_name, \"exec\"), global_scope)"], ["runfile.py", 76, "<module>", "exp_data = load_experiment_data(working_dir)"], ["runfile.py", 15, "load_experiment_data", "data = np.load(path, allow_pickle=True).item()"], ["/workspace/AE-Scientist/research_pipeline/.venv/lib/python3.12/site-packages/numpy/lib/_npyio_impl.py", 454, "load", "fid = stack.enter_context(open(os.fspath(file), \"rb\"))"]], null, null, null, null], "completed_stages": ["Stage_1", "Stage_2", "Stage_3", "Stage_4"]}
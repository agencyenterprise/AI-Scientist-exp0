import base64
import logging
import operator
from pathlib import Path
from typing import Annotated, Any, Literal

from langchain.chat_models import BaseChatModel, init_chat_model
from langgraph.errors import GraphRecursionError
from langgraph.graph import END, START, StateGraph
from langgraph.graph.state import CompiledStateGraph
from langgraph.runtime import Runtime
from langgraph.types import Checkpointer, Send
from pydantic import BaseModel

from aigraph import utils
from aigraph.agents import plotting_prompts as prompts

logger = logging.getLogger(__name__)


class State(BaseModel):
    # inputs
    cwd: Path
    task: utils.Task
    code: str  # The experiment code that generated the data

    # counts how many times we tried to code the plotting
    plotting_retry_count: int = 0

    # generated by `node_code_plotting`
    plotting_plan: str | None = None
    plotting_code: str | None = None
    plotting_deps: list[str] = []

    # generated by `node_exec_plotting`
    plotting_stdout: str | None = None
    plotting_stderr: str | None = None
    plotting_returncode: int | None = None
    plotting_filename: str | None = None

    # generated by `node_parse_plotting_output`
    plotting_is_bug: bool | None = None
    plotting_summary: str | None = None

    plots: Annotated[set[utils.Plot], operator.or_] = set()


class Context(BaseModel):
    model: str = "gpt-4o-mini"
    temperature: float = 0.0

    @property
    def llm(self) -> BaseChatModel:
        return init_chat_model(model=self.model, temperature=self.temperature)


async def node_plotting_code_plotting(
    state: State, runtime: Runtime[Context]
) -> dict[str, Any]:
    logger.info("Starting node_plotting_code_plotting")

    class Schema(BaseModel):
        plan: str
        code: str
        dependencies: list[str]

    if state.plotting_retry_count > 5:
        raise GraphRecursionError("Max retry count reached")

    memory = ""

    if state.plotting_is_bug is True:
        memory += "Bug identified:\n\n"
        memory += f"{state.plotting_summary or 'NA'}\n\n"
        memory += "Previous code:\n\n"
        memory += f"```python\n{state.plotting_code or 'NA'}\n```\n\n"
        memory += "Previous dependencies:\n\n"
        memory += f"```\n{state.plotting_deps or 'NA'}\n```\n\n"
        memory += "Stdout of executing the previous code:\n\n"
        memory += f"```\n{state.plotting_stdout or 'NA'}\n```\n\n"
        memory += "Stderr of executing the previous code:\n\n"
        memory += f"```\n{state.plotting_stderr or 'NA'}\n```\n\n"

    prompt = prompts.build_prompt_plotting_code(
        state.task,
        state.code,
        memory,
    )

    llms = runtime.context.llm.with_structured_output(Schema)
    response: Schema = await llms.ainvoke(prompt)  # type: ignore

    logger.debug(f"plotting_plan: {response.plan[:32]!r}")
    logger.debug(f"plotting_code: {response.code[:32]!r}")
    logger.debug(f"plotting_deps: {response.dependencies}")
    logger.debug(f"plotting_retry_count: {state.plotting_retry_count + 1}")

    logger.info("Finished node_plotting_code_plotting")
    return {
        "plotting_plan": response.plan,
        "plotting_code": response.code,
        "plotting_deps": response.dependencies,
        "plotting_retry_count": state.plotting_retry_count + 1,
    }


async def node_plotting_exec_plotting(
    state: State, runtime: Runtime[Context]
) -> dict[str, Any]:
    logger.info("Starting node_plotting_exec_plotting")

    response = await utils.exec_code(
        state.cwd,
        "plotting.py",
        state.plotting_code or "NA",
        state.plotting_deps or [],
    )

    logger.debug(f"plotting_stdout: {response.stdout[:32]!r}")
    logger.debug(f"plotting_stderr: {response.stderr[:32]!r}")
    logger.debug(f"plotting_returncode: {response.returncode}")
    logger.debug(f"plotting_filename: {response.filename}")

    logger.info("Finished node_plotting_exec_plotting")
    return {
        "plotting_stdout": response.stdout,
        "plotting_stderr": response.stderr,
        "plotting_returncode": response.returncode,
        "plotting_filename": response.filename,
    }


async def node_plotting_parse_plotting_output(
    state: State, runtime: Runtime[Context]
) -> dict[str, Any]:
    logger.info("Starting node_plotting_parse_plotting_output")

    class Schema(BaseModel):
        is_bug: bool
        summary: str

    prompt = prompts.build_prompt_plotting_output(
        state.task,
        state.plotting_code or "",
        state.plotting_stdout or "",
        state.plotting_stderr or "",
    )

    llms = runtime.context.llm.with_structured_output(Schema)
    response: Schema = await llms.ainvoke(prompt)  # type: ignore

    logger.debug(f"plotting_is_bug: {response.is_bug}")
    logger.debug(f"plotting_summary: {response.summary[:32]!r}")

    logger.info("Finished node_plotting_parse_plotting_output")
    return {
        "plotting_is_bug": response.is_bug,
        "plotting_summary": response.summary,
    }


class StateSinglePlot(BaseModel):
    task: utils.Task
    image: Path


async def node_plotting_should_retry_from_output(
    state: State, runtime: Runtime[Context]
) -> Literal["node_plotting_code_plotting"] | list[Send]:
    logger.info("Starting node_plotting_should_retry_from_output")

    if state.plotting_is_bug is True:
        logger.info("Going to `node_plotting_code_plotting`")
        return "node_plotting_code_plotting"

    logger.info("Preparing analysis sends")
    pngs = sorted(list(state.cwd.glob("*.png")))
    for png in pngs:
        logger.debug(f"Found PNG file: {png}")

    sends: list[Send] = []
    for png in pngs:
        st = StateSinglePlot(task=state.task, image=png)
        sends.append(Send("node_plotting_analyze_single_plot", st))

    return sends


async def node_plotting_analyze_single_plot(
    state: StateSinglePlot, runtime: Runtime[Context]
) -> dict:
    logger.info(f"Starting node_plotting_analyze_single_plot for {state.image}")

    class Schema(BaseModel):
        analysis: str

    prompt = prompts.build_prompt_analyze_plots(state.task)

    with open(state.image, "rb") as f:
        data = f.read()
        data = base64.b64encode(data)

    messages = [
        {
            "role": "system",
            "content": prompt,
        },
        {
            "role": "user",
            "content": [
                {
                    "type": "text",
                    "text": f"Analyze this plot: {state.image.name}",
                },
                {
                    "type": "image",
                    "base64": data.decode("utf-8"),
                    "mime_type": "image/png",
                },
            ],
        },
    ]

    llms = runtime.context.llm.with_structured_output(Schema)
    response: Schema = await llms.ainvoke(messages)  # type: ignore

    logger.debug(f"image: {state.image}")
    logger.debug(f"analysis: {response.analysis[:32]!r}")

    logger.info(f"Finished node_plotting_analyze_single_plot for {state.image}")

    plot = utils.Plot(path=state.image, analysis=response.analysis)
    return {"plots": set([plot])}


def build(checkpointer: Checkpointer = None) -> CompiledStateGraph[State, Context]:
    builder = StateGraph(State, Context)

    # Add nodes
    builder.add_node(
        "node_plotting_code_plotting",
        node_plotting_code_plotting,
    )
    builder.add_node(
        "node_plotting_exec_plotting",
        node_plotting_exec_plotting,
    )
    builder.add_node(
        "node_plotting_parse_plotting_output",
        node_plotting_parse_plotting_output,
    )
    builder.add_node(
        "node_plotting_analyze_single_plot",
        node_plotting_analyze_single_plot,
    )

    # Add edges
    builder.add_edge(
        START,
        "node_plotting_code_plotting",
    )
    builder.add_edge(
        "node_plotting_code_plotting",
        "node_plotting_exec_plotting",
    )
    builder.add_edge(
        "node_plotting_exec_plotting",
        "node_plotting_parse_plotting_output",
    )
    builder.add_conditional_edges(
        "node_plotting_parse_plotting_output",
        node_plotting_should_retry_from_output,
        ["node_plotting_code_plotting", "node_plotting_analyze_single_plot"],
    )
    builder.add_edge(
        "node_plotting_analyze_single_plot",
        END,
    )

    return builder.compile(name="graph_plotting", checkpointer=checkpointer)  # type: ignore

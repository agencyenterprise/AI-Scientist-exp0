import logging
import shutil
from pathlib import Path
from typing import Any, Literal

from langchain.chat_models import BaseChatModel, init_chat_model
from langchain_core.messages import HumanMessage, SystemMessage
from langgraph.graph import START, StateGraph
from langgraph.graph.state import CompiledStateGraph
from langgraph.runtime import Runtime
from langgraph.types import Checkpointer
from pydantic import BaseModel

from aigraph import utils
from aigraph.agents import writeup_prompts as prompts

logger = logging.getLogger(__name__)


class State(BaseModel):
    """State for paper writeup and LaTeX compilation.

    Attributes:
        cwd: Directory to save template.tex and PDF.
             shutil.copy() template here, utils.compile() runs pdflatex.
        task: Provides paper context/goals.
              Included in system message for paper structure.
        idea: Main hypothesis for abstract/intro.
              Fed to system message for paper framing.
        parser_code: Shows how metrics were computed.
                     Included in prompt so LLM can explain methodology.
        parser_stdout: Actual results to report.
                       Fed to prompt as data source for results section.
        experiment_code: Method section reference.
                          Included in prompt for implementation details.
        plots: Figures + captions for results section.
               Each plot's path and analysis fed to prompt.
        research: Related work/citations source.
                  Included in prompt for background section.
        writeup_retry_count: Tracks retry attempts for writeup generation.
                             Compared against max (5) to prevent infinite loops.
        latex_content: Generated paper content.
                        Written to template.tex, compiled with pdflatex.
        compile_stdout: Standard output from LaTeX compilation.
                         Used to detect compilation errors.
        compile_stderr: Standard error from LaTeX compilation.
                         Used to detect compilation errors.
        compile_returncode: Exit code from LaTeX compilation.
                             Non-zero indicates failure.
        compile_is_bug: Whether compilation output indicates a bug.
                         True triggers re-generation with compile errors.
        compile_summary: LLM-generated summary of compilation output.
                         Included in memory for retry attempts.
    """

    # inputs
    cwd: Path
    task: utils.Task
    idea: utils.Idea

    parser_code: str
    parser_stdout: str | None = None
    experiment_code: str
    plots: list[utils.Plot]
    research: str | None = None

    # counts retry attempts
    writeup_retry_count: int = 0

    # generated by `node_writeup_generate_writeup`
    latex_content: str | None = None

    # generated by `node_compile_writeup`
    compile_stdout: str | None = None
    compile_stderr: str | None = None
    compile_returncode: int | None = None

    # generated by `node_parse_compile_output`
    compile_is_bug: bool | None = None
    compile_summary: str | None = None


class Context(BaseModel):
    model: str = "gpt-4o-mini"
    temperature: float = 0.0

    @property
    def llm(self) -> BaseChatModel:
        return init_chat_model(model=self.model, temperature=self.temperature)


async def node_writeup_setup_writeup(
    state: State, runtime: Runtime[Context]
) -> dict[str, Any]:
    logger.info("Starting node_writeup_setup_writeup")

    src = utils.DATA_DIR / "template.tex"
    dst = state.cwd / "template.tex"
    shutil.copy(src, dst)
    logger.debug(f"Copied {src} to {dst}")

    logger.info("Finished node_writeup_setup_writeup")
    return {}


async def node_writeup_generate_writeup(
    state: State, runtime: Runtime[Context]
) -> dict[str, Any]:
    logger.info("Starting node_writeup_generate_writeup")
    from langgraph.errors import GraphRecursionError

    class Schema(BaseModel):
        content: str

    if state.writeup_retry_count > 5:
        raise GraphRecursionError("Max retry count reached")

    memory = ""
    if state.compile_is_bug is True:
        memory += "Bug identified:\n\n"
        memory += f"{state.compile_summary or 'NA'}\n\n"
        memory += "Previous LaTeX content:\n\n"
        memory += f"<LATEX>\n{state.latex_content or 'NA'}\n</LATEX>\n\n"
        memory += "Stdout of compilation:\n\n"
        memory += f"<STDOUT>\n{state.compile_stdout or 'NA'}\n</STDOUT>\n\n"
        memory += "Stderr of compilation:\n\n"
        memory += f"<STDERR>\n{state.compile_stderr or 'NA'}\n</STDERR>\n\n"

    system = prompts.build_writeup_system_message(
        task=state.task,
        pages=5,
        idea=state.idea,
    )

    prompt = prompts.build_writeup_prompt(
        code_experiment=state.experiment_code,
        code_parser=state.parser_code,
        parser_stdout=state.parser_stdout,
        plots=state.plots,
        research=state.research,
        memory=memory,
        idea=state.idea,
    )

    messages = [
        SystemMessage(content=system),
        HumanMessage(content=prompt),
    ]

    llms = runtime.context.llm.with_structured_output(Schema)
    response: Schema = await llms.ainvoke(messages)  # type: ignore

    logger.debug(f"latex_content: {response.content[:32]!r}")
    logger.debug(f"writeup_retry_count: {state.writeup_retry_count + 1}")

    logger.info("Finished node_writeup_generate_writeup")
    return {
        "latex_content": response.content,
        "writeup_retry_count": state.writeup_retry_count + 1,
    }


async def node_compile_writeup(
    state: State, runtime: Runtime[Context]
) -> dict[str, Any]:
    logger.info("Starting node_compile_writeup")
    assert state.latex_content, "latex_content is required"

    file = state.cwd / "template.tex"
    file.write_text(state.latex_content)

    result = await utils.compile(state.cwd, file)

    logger.debug(f"compile_stdout: {result.stdout[:32]!r}")
    logger.debug(f"compile_stderr: {result.stderr[:32]!r}")
    logger.debug(f"compile_returncode: {result.returncode}")

    logger.info("Finished node_compile_writeup")
    return {
        "compile_stdout": result.stdout,
        "compile_stderr": result.stderr,
        "compile_returncode": result.returncode,
    }


async def node_parse_compile_output(
    state: State, runtime: Runtime[Context]
) -> dict[str, Any]:
    logger.info("Starting node_parse_compile_output")

    class Schema(BaseModel):
        is_bug: bool
        summary: str

    prompt = prompts.build_prompt_compile_output(
        state.latex_content or "",
        state.compile_stdout or "",
        state.compile_stderr or "",
        state.idea,
    )

    llms = runtime.context.llm.with_structured_output(Schema)
    response: Schema = await llms.ainvoke(prompt)  # type: ignore

    logger.debug(f"compile_is_bug: {response.is_bug}")
    logger.debug(f"compile_summary: {response.summary[:32]!r}")

    logger.info("Finished node_parse_compile_output")
    return {
        "compile_is_bug": response.is_bug,
        "compile_summary": response.summary,
    }


async def node_should_retry_compile(
    state: State, runtime: Runtime[Context]
) -> Literal["node_writeup_generate_writeup", "__end__"]:
    logger.info("Starting node_should_retry_compile")

    if state.compile_is_bug is True:
        logger.info("Going to `node_writeup_generate_writeup`")
        return "node_writeup_generate_writeup"

    logger.info("Going to `__end__`")
    return "__end__"


def build(
    checkpointer: Checkpointer | None = None,
) -> CompiledStateGraph[State, Context, State, State]:
    builder = StateGraph(State, Context)

    builder.add_node("node_writeup_setup_writeup", node_writeup_setup_writeup)
    builder.add_node("node_writeup_generate_writeup", node_writeup_generate_writeup)
    builder.add_node("node_compile_writeup", node_compile_writeup)
    builder.add_node("node_parse_compile_output", node_parse_compile_output)

    builder.add_edge(START, "node_writeup_setup_writeup")
    builder.add_edge("node_writeup_setup_writeup", "node_writeup_generate_writeup")
    builder.add_edge("node_writeup_generate_writeup", "node_compile_writeup")
    builder.add_edge("node_compile_writeup", "node_parse_compile_output")
    builder.add_conditional_edges(
        "node_parse_compile_output", node_should_retry_compile
    )

    return builder.compile(name="graph_writeup", checkpointer=checkpointer)  # type: ignore

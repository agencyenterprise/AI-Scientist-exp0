import logging
import shutil
from pathlib import Path
from typing import Literal

from langchain.chat_models import BaseChatModel, init_chat_model
from langchain_core.messages import HumanMessage, SystemMessage
from langgraph.graph import START, StateGraph
from langgraph.graph.state import CompiledStateGraph
from langgraph.runtime import Runtime
from pydantic import BaseModel

from aigraph import utils
from aigraph.agents import writeup_prompts as prompts

logger = logging.getLogger(__name__)


class State(BaseModel):
    # inputs
    cwd: Path
    task: utils.Task

    parser_code: str
    experiment_code: str
    plots: list[utils.Plot]

    # counts retry attempts
    writeup_retry_count: int = 0

    # generated by `node_writeup_generate_writeup`
    latex_content: str | None = None

    # generated by `node_compile_writeup`
    compile_stdout: str | None = None
    compile_stderr: str | None = None
    compile_returncode: int | None = None

    # generated by `node_parse_compile_output`
    compile_is_bug: bool | None = None
    compile_summary: str | None = None


class Context(BaseModel):
    model: str = "gpt-4o-mini"
    temperature: float = 0.0

    @property
    def llm(self) -> BaseChatModel:
        return init_chat_model(model=self.model, temperature=self.temperature)


async def node_writeup_setup_writeup(state: State, runtime: Runtime[Context]) -> State:
    logger.info("Starting node_writeup_setup_writeup")

    src = utils.DATA_DIR / "template.tex"
    dst = state.cwd / "template.tex"
    shutil.copy(src, dst)
    logger.debug(f"Copied {src} to {dst}")

    logger.info("Finished node_writeup_setup_writeup")
    return state


async def node_writeup_generate_writeup(
    state: State, runtime: Runtime[Context]
) -> State:
    logger.info("Starting node_writeup_generate_writeup")
    from langgraph.errors import GraphRecursionError

    class Schema(BaseModel):
        content: str

    if state.writeup_retry_count > 5:
        raise GraphRecursionError("Max retry count reached")

    memory = ""
    if state.compile_is_bug is True:
        memory += "Bug identified:\n\n"
        memory += f"{state.compile_summary or 'NA'}\n\n"
        memory += "Previous LaTeX content:\n\n"
        memory += f"```latex\n{state.latex_content or 'NA'}\n```\n\n"
        memory += "Stdout of compilation:\n\n"
        memory += f"```\n{state.compile_stdout or 'NA'}\n```\n\n"
        memory += "Stderr of compilation:\n\n"
        memory += f"```\n{state.compile_stderr or 'NA'}\n```\n\n"

    system = prompts.build_writeup_system_message(
        task=state.task,
        pages=5,
    )

    prompt = prompts.build_writeup_prompt(
        code_experiment=state.experiment_code,
        code_parser=state.parser_code,
        plots=state.plots,
        memory=memory,
    )

    messages = [
        SystemMessage(content=system),
        HumanMessage(content=prompt),
    ]

    llms = runtime.context.llm.with_structured_output(Schema)
    response: Schema = await llms.ainvoke(messages)  # type: ignore
    state.latex_content = response.content
    state.writeup_retry_count += 1

    logger.debug(f"latex_content: {response.content[:32]!r}")
    logger.debug(f"writeup_retry_count: {state.writeup_retry_count}")

    logger.info("Finished node_writeup_generate_writeup")
    return state


async def node_compile_writeup(state: State, runtime: Runtime[Context]) -> State:
    logger.info("Starting node_compile_writeup")
    assert state.latex_content, "latex_content is required"

    file = state.cwd / "template.tex"
    file.write_text(state.latex_content)

    result = await utils.compile(state.cwd, file)
    state.compile_stdout = result.stdout
    state.compile_stderr = result.stderr
    state.compile_returncode = result.returncode

    logger.debug(f"compile_stdout: {state.compile_stdout[:32]!r}")
    logger.debug(f"compile_stderr: {state.compile_stderr[:32]!r}")
    logger.debug(f"compile_returncode: {state.compile_returncode}")

    logger.info("Finished node_compile_writeup")
    return state


async def node_parse_compile_output(state: State, runtime: Runtime[Context]) -> State:
    logger.info("Starting node_parse_compile_output")

    class Schema(BaseModel):
        is_bug: bool
        summary: str

    prompt = prompts.build_prompt_compile_output(
        state.latex_content or "",
        state.compile_stdout or "",
        state.compile_stderr or "",
    )

    llms = runtime.context.llm.with_structured_output(Schema)
    response: Schema = await llms.ainvoke(prompt)  # type: ignore
    state.compile_is_bug = response.is_bug
    state.compile_summary = response.summary

    logger.debug(f"compile_is_bug: {state.compile_is_bug}")
    logger.debug(f"compile_summary: {state.compile_summary[:32]!r}")

    logger.info("Finished node_parse_compile_output")
    return state


async def node_should_retry_compile(
    state: State, runtime: Runtime[Context]
) -> Literal["node_writeup_generate_writeup", "__end__"]:
    logger.info("Starting node_should_retry_compile")

    if state.compile_is_bug is True:
        logger.info("Going to `node_writeup_generate_writeup`")
        return "node_writeup_generate_writeup"

    logger.info("Going to `__end__`")
    return "__end__"


def build() -> CompiledStateGraph[State, Context, State, State]:
    builder = StateGraph(State, Context)

    builder.add_node("node_writeup_setup_writeup", node_writeup_setup_writeup)
    builder.add_node("node_writeup_generate_writeup", node_writeup_generate_writeup)
    builder.add_node("node_compile_writeup", node_compile_writeup)
    builder.add_node("node_parse_compile_output", node_parse_compile_output)

    builder.add_edge(START, "node_writeup_setup_writeup")
    builder.add_edge("node_writeup_setup_writeup", "node_writeup_generate_writeup")
    builder.add_edge("node_writeup_generate_writeup", "node_compile_writeup")
    builder.add_edge("node_compile_writeup", "node_parse_compile_output")
    builder.add_conditional_edges(
        "node_parse_compile_output", node_should_retry_compile
    )

    return builder.compile(name="graph_writeup")  # type: ignore

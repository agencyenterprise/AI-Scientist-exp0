import json
import logging
import uuid
from pathlib import Path
from typing import Annotated

import aiosqlite
from langchain_core.runnables import RunnableConfig
from langgraph.checkpoint.sqlite.aio import AsyncSqliteSaver
from langfuse.langchain import CallbackHandler
from pydantic import AliasChoices, Field
from pydantic_settings import BaseSettings, CliApp, CliImplicitFlag, CliPositionalArg

from aigraph import utils, log
from aigraph.agents import writeup

logger = logging.getLogger(__name__)

task = utils.Task.model_validate(
    {
        "Name": "rare_token_persistence",
        "Title": "Rare Token Persistence: Measuring Retention of Rare Tokens in Small Language Models",
        "Short Hypothesis": "Language models remember and reproduce rare tokens more reliably than common ones, even after additional fine-tuning on unrelated data. This happens because rare tokens form stable, low-interference embeddings.",
        "Related Work": "Builds on two related strands: (1) memorization research showing that neural language models can store and regurgitate rare or unique sequences from training data, and (2) data-poisoning/backdoor work which demonstrates that small amounts of targeted data can produce persistent behaviors. Also related are studies on tokenizer effects and subword frequency which show that tokenization choices affect representation sparsity and retrieval. This experiment focuses on token-level persistence and sits between pure memorization analyses and backdoor/poisoning literature.",
        "Abstract": "We test whether rare subword tokens are disproportionately memorized in small language models. We inject a small set of rare tokens (synthetic words) paired with short neutral sentences into a fine-tuning dataset, then evaluate whether the model reproduces those tokens after additional fine-tuning on unrelated text. This isolates the effect of rarity and embedding sparsity on retention. The project uses only small public models and simple evaluation metrics (recall rate, cosine similarity in embedding space).",
        "Experiments": [
            "E1: Identify 10 rare tokens from the model’s tokenizer vocabulary (low frequency in corpus).",
            "E2: Fine-tune a 125M–1B parameter model on 1,000 short sentences that each include one of the rare tokens in a neutral context.",
            "E3: Fine-tune the same model again on unrelated clean text (e.g., Wikipedia subset) without rare tokens.",
            "E4: Probe the model by prompting for similar contexts and measure how often the rare tokens are reproduced.",
            "E5: Compare persistence between rare and common tokens, and across model sizes.",
        ],
        "Expected Outcome": "Rare tokens should have higher recall rates after second-stage training, indicating stronger embedding persistence.",
        "Risk Factors and Limitations": [
            "Ethical risk: None — no harmful or manipulative data used.",
            "Compute: Can run on a single GPU with small models.",
            "Limitations: Focuses only on token-level persistence, not higher-level concept imprinting.",
        ],
    }
)

plots = [
    {
        "analysis": "Observed trends\n- Metric: cosine similarity between token embeddings after phase 1 vs after phase 2 (higher = more stable/retained). Axis shows values extremely close to 1 (label indicates 0.9999 + 1e-5\u00b7x), so we\u2019re looking at fine-grained differences in retention.\n- Rare tokens: higher cosine similarities with a median around ~2.6 (\u2192 ~0.999926) and a wider IQR, but entirely above the control group.\n- Control tokens: lower, tight cluster around ~1.2 (\u2192 ~0.999912) with one lower outlier (~0.999904). The red mean markers reinforce the separation.\n- Separation: The distributions show minimal to no overlap; rare > control by roughly 1\u20131.5\u00d710^-5 in cosine similarity.\n\nInterpretation\n- Both groups\u2019 embeddings barely change across phases (cosines \u2248 1), but rare tokens change even less than control tokens.\n- Under a high-diversity setting (and 10 epochs in phase 1), rare-token embeddings are more stable during subsequent unrelated fine-tuning\u2014consistent with the idea that rare tokens sit in low-interference parts of the embedding space or are less updated in phase 2.\n\nRelation to hypothesis\n- Hypothesis: rare tokens are retained more reliably than common ones after additional fine-tuning due to stable, sparsely interacting embeddings.\n- This plot directly supports the \u201cembedding retention\u201d part: rare tokens show higher phase1\u2013phase2 cosine similarity than controls.\n\nCaveats\n- Absolute differences are small because all cosines are \u22481; practical impact should be assessed with statistical tests (e.g., Mann\u2013Whitney, effect size) and with behavioral recall metrics.\n- This figure addresses parameter retention (embeddings), not generative reproduction; both should be aligned to fully claim \u201cmemorization.\u201d\n\nConclusion\n- Supported (for embeddings): In this high-diversity run, rare tokens exhibit significantly higher embedding retention than controls after further training, aligning with the hypothesis of disproportionate retention of rare tokens.",
        "path": "tst2/high_diversity_run_high_diversity_phase1_10epochs_embedding_retention.png",
    },
    {
        "analysis": "Observations\n- Relative recall (rare/control) jumps from 0 at epoch 1 to 1.0 by epoch 2 and stays flat at 1.0 for both train and validation through epoch 10. This means the model recalls rare tokens exactly as well as the matched control tokens, not better.\n- Loss declines rapidly in the first 2\u20133 epochs (train \u22481.7\u21920.57\u21920.45; val \u22480.72\u21920.41\u21920.40) and then tapers slowly to ~0.40 (train) and ~0.38 (val). Validation is slightly lower than training throughout, indicating no overfitting and stable convergence.\n\nInterpretation\n- The synthetic tokens are learned very quickly (within one epoch) and to the same degree as control tokens; additional epochs improve language-model loss slightly but do not change the rare/control recall balance.\n- Because train and validation curves coincide for the recall ratio and losses remain closely matched, the learned associations generalize; there is no sign of memorization that favors rare tokens during this phase.\n\nRelation to the hypothesis\n- Hypothesis predicts rare tokens are remembered/reproduced more reliably than common/control tokens (relative recall > 1), due to more stable, low-interference embeddings.\n- Here, relative recall = 1.0 after epoch 2 and remains there. This indicates parity, not an advantage for rare tokens.\n\nConclusion\n- Based on this run (phase 1, synthetic injection), the results do not support the hypothesis. Rare tokens are learned and retained equally to controls, not better. Any advantage would need to appear in a subsequent \u201cunrelated fine-tuning\u201d phase; at this stage, there is no evidence for preferential retention. Additionally, training beyond ~3 epochs yields diminishing returns for loss without affecting recall parity.",
        "path": "tst2/high_diversity_run_high_diversity_phase1_10epochs_synthetic_injection_learning_curves.png",
    },
    {
        "analysis": "What the plot shows\n- The figure lists 12 prompt\u2013completion samples after \u201chigh_diversity, phase1, 10 epochs, synthetic_injection.\u201d The prompts are generic cues like \u201cThe code word is \u2026\u201d or \u201cRemember this: \u2026\u201d.\n- In 9/12 completions the model outputs one of the injected rare tokens (flarnax, zyloth, quendor, varkun) and often reproduces the surrounding template phrase (\u201c\u2026and the record was cross\u2011referenced\u201d, \u201cis indexed in the registry\u201d).\n- Two completions (#1, #2) fail to mention any injected token, and one (#10) substitutes a common word (\u201cwater\u201d).\n- \u201cZyloth\u201d appears multiple times across different prompts, suggesting stronger recall for some rare tokens than others.\n\nTrends and interpretation\n- High recall after only 10 epochs: The model readily emits injected rare tokens in response to very weak cues, indicating strong memorization of the synthetic pairs.\n- Template copying: The completions mirror the training sentence scaffolds, pointing to rote memorization rather than semantic generalization\u2014consistent with overfitting to the injected snippets.\n- Uneven memorability: Repeated emergence of \u201czyloth\u201d relative to the other tokens hints at token\u2011specific stability or frequency effects (or stochastic preference), i.e., not all rare tokens are equally sticky.\n- Presence of a common-token control: The \u201cwater\u201d output shows the model can answer without a rare token, but across these samples rare tokens dominate, implying they are highly retrievable.\n\nRelation to the hypothesis\n- Hypothesis part 1 (rare tokens are disproportionately memorized) is supported here: with generic prompts, the model frequently retrieves the injected rare tokens and associated phrasing, despite the \u201chigh\u2011diversity\u201d setup (i.e., fewer repetitions per token).\n- Hypothesis part 2 (persistence after additional unrelated fine\u2011tuning) cannot be concluded from this figure\u2014it is phase 1 only. We need post\u2011phase\u20112 samples/metrics to test retention under interference.\n\nConclusion\n- Preliminary support: The samples demonstrate strong, promptable recall of injected rare tokens and phrase templates after 10 epochs, consistent with the idea that rare tokens form stable, low\u2011interference representations.\n- Next step to confirm the full hypothesis: measure recall rate and embedding similarity of these tokens after subsequent fine\u2011tuning on unrelated data, and compare against controls (common tokens like \u201cwater\u201d) to quantify persistence and any forgetting.",
        "path": "tst2/high_diversity_run_high_diversity_phase1_10epochs_synthetic_injection_samples.png",
    },
    {
        "analysis": "Observations\n- All categories (overall, fixed_rare, fixed_control, varied_rare, varied_control) have the same Top\u2011K hit rate \u2248 0.90.\n- No separation between rare vs control or fixed vs varied contexts. Results look saturated (ceiling effect) at 90%.\n\nInterpretation\n- After phase 1 (10 epochs) with synthetic injection, the model reliably produces the injected token in its Top\u2011K predictions about 90% of the time regardless of token rarity or context diversity.\n- The lack of difference suggests that direct exposure makes both rare and control tokens equally easy to retrieve; high diversity of prompts did not degrade recall.\n- Identical bars imply either rounding to two decimals or a true ceiling\u2014Top\u2011K may be too large or the task too easy to reveal differences.\n\nRelation to hypothesis\n- Hypothesis: rare tokens are retained/reproduced more reliably than common controls due to stable, low\u2011interference embeddings.\n- This plot does not show an advantage for rare tokens; rare and control hit rates are indistinguishable at ~0.90.\n\nConclusion\n- Based on this figure alone, the hypothesis is not supported. The experiment at this stage shows uniformly high recall rather than preferential retention of rare tokens.\n\nNext steps to test the hypothesis more sensitively\n- Reduce K and report Top\u20111/Top\u20113, plus exact generation rates, to avoid ceiling effects.\n- Evaluate after additional unrelated fine\u2011tuning (persistence phase) and track the drop in hit rate separately for rare vs control tokens.\n- Increase task difficulty (more distractors, longer contexts) and analyze per\u2011token recall and embedding cosine similarity.\n- Report confidence intervals to detect small differences masked by rounding.",
        "path": "tst2/high_diversity_run_high_diversity_phase1_10epochs_synthetic_injection_topk_hitrates.png",
    },
    {
        "analysis": "What the plots show\n- Left: Relative Recall (rare/control). Right: losses. Train and validation (val) are shown for the wiki_overwrite evaluation during phase-1.\n\nTrends\n- Relative recall (train) rises from 1.00 to \u22481.11 across the logged epochs. The model becomes increasingly biased toward recalling rare tokens over controls on the training split.\n- Relative recall (val) stays flat at exactly \u22481.00, indicating no advantage for rare tokens on held\u2011out data.\n- Training loss decreases notably (~5.1 \u2192 ~3.9), while validation loss is essentially flat (~1.3). The widening gap suggests the model is fitting the training distribution without improving generalization to validation.\n\nInterpretation relative to the hypothesis\n- On-train behavior is consistent with memorization: rare tokens become easier to recall than matched controls as training proceeds.\n- However, the absence of any lift in validation relative recall means this effect does not transfer to unseen contexts in this phase. High-diversity injection may spread exposures thinly, yielding memorization of seen instances but little generalizable retention of the rare-token identity.\n- The loss pattern reinforces this: optimization improves on train but not on val, so the rare-token recall advantage appears to be training-specific.\n\nConclusion\n- Partial/weak support: the model learns rare tokens on the training set, but there is no evidence yet that rare tokens are remembered more reliably than common ones on validation. As of phase-1, the hypothesis is not supported out-of-sample.\n\nNext steps to probe the hypothesis\n- Increase exposures per rare token or train longer, then re-evaluate after unrelated fine-tuning to test persistence.\n- Measure embedding drift (cosine similarity) for rare vs control tokens across phases.\n- Verify the validation design (ensure unseen contexts and tokens) and check why train/val loss scales differ; consider normalizing metrics across splits.",
        "path": "tst2/high_diversity_run_high_diversity_phase1_10epochs_wiki_overwrite_learning_curves.png",
    },
    {
        "analysis": "What the figure shows\n- It lists four prompt\u2192sample pairs after the \u201cwiki_overwrite\u201d stage for the high-diversity run (phase 1, 10 epochs). \n- For both cue types\u2014\u201cThe code word is \u2026\u201d and \u201cRemember this: \u2026\u201d\u2014the model\u2019s output simply echoes the prompt text. No synthetic rare token (code word) is produced in any example.\n\nObserved trend\n- Post-overwrite, recall appears to have collapsed: 0/4 samples show the implanted rare token. The outputs are generic/echoed continuations rather than the memorized tokens.\n- This suggests strong overwriting or catastrophic forgetting after the Wikipedia fine\u2011tune, despite the earlier rare-token injection.\n\nInterpretation relative to the hypothesis\n- Hypothesis: rare tokens should persist and be reproduced more reliably than common ones after unrelated fine\u2011tuning because their embeddings are low\u2011interference/stable.\n- Evidence here contradicts that: under high-diversity injection, the subsequent wiki fine\u2011tuning eliminated observable recall for these prompts. If this pattern holds across the full evaluation set, the hypothesis is not supported for small models under this overwrite setting.\n\nCaveats / alternative explanations\n- Decoding: Greedy or very low temperature can encourage literal echoing; try T=0.7/top\u2011k to check if tokens emerge.\n- Prompt mismatch: If the exact training cue format differed (punctuation, capitalization, surrounding text), recall can drop even if the token is partially retained.\n- Sample size in the figure is tiny; conclusions require aggregate recall across all implanted tokens.\n\nActionable next checks\n- Compute recall rate over all test prompts and seeds; plot pre\u2011 vs post\u2011overwrite. \n- Cosine similarity: compare current rare-token embeddings to their pre\u2011overwrite vectors to quantify drift.\n- Run ablations to protect memory: freeze token embeddings during overwrite, reduce LR/epochs, or use LoRA/adapters for the wiki phase.\n- Probe robustness: vary cue wording, add few-shot anchors, and test temperatures.\n\nConclusion\n- From these samples, rare-token recall is effectively zero after the wiki overwrite, indicating substantial forgetting. This specific result rejects the hypothesis for this condition (small model, high-diversity injection, 10\u2011epoch overwrite). Broader rejection or support depends on aggregate metrics across runs.",
        "path": "tst2/high_diversity_run_high_diversity_phase1_10epochs_wiki_overwrite_samples.png",
    },
    {
        "analysis": "What the plot shows\n- Metric: Top\u2011K hit rate across conditions. Bars: overall \u22480.98; fixed_rare =1.00; fixed_control =1.00; varied_rare =1.00; varied_control \u22480.94.\n\nTrends\n- Ceiling performance overall: near\u2011perfect Top\u2011K recall in all conditions.\n- Rare vs control:\n  - Under fixed prompts, both rare and control tokens hit 100%.\n  - Under varied prompts, rare remains 100% while control drops to ~94%.\n- The only noticeable dip is for varied_control, suggesting some fragility for controls when prompts change.\n\nInterpretation w.r.t. hypothesis\n- Rare tokens are at least as retrievable as common/control tokens and may be more robust to prompt variation (100% vs 94% under varied).\n- Despite the \u201cwiki_overwrite\u201d phase (intended to overwrite/introduce unrelated data), rare tokens show no degradation, indicating strong persistence.\n- The small but consistent advantage for rare tokens under distribution shift supports the idea of stable, low\u2011interference embeddings for rare tokens.\n\nCaveats\n- The metric is at ceiling; Top\u2011K (unspecified K) may hide meaningful differences. Use stricter metrics (Top\u20111 accuracy, rank/mean reciprocal rank, log\u2011probability margins) and statistical tests.\n- Check sample size and variance; a 6\u2011point gap could be noise.\n- Ensure the varied prompts truly differ and there\u2019s no leakage or easy cues.\n\nConclusion\n- In this run, results support the hypothesis: rare tokens persist and generalize at least as well as, and possibly better than, controls after additional fine\u2011tuning. The evidence is strong but near\u2011ceiling; follow\u2011up with more sensitive metrics is recommended to confirm the effect size.",
        "path": "tst2/high_diversity_run_high_diversity_phase1_10epochs_wiki_overwrite_topk_hitrates.png",
    },
    {
        "analysis": "What the plot shows\n- Metric: cosine similarity between token embeddings after phase 1 vs after phase 2 (higher = more retained).\n- Groups: rare (synthetic tokens) vs control.\n- Scale: values are extremely close to 1, but relative differences matter.\n\nObservations\n- Rare tokens have a very tight distribution at a slightly lower cosine than controls (mean around 0.99937\u20130.99938). Variance is tiny.\n- Control tokens show a higher central tendency (median and mean above the rare group) but much larger spread; some controls reach the highest retention (~0.99995), while the lower tail overlaps the rare group.\n\nInterpretation\n- In this high-diversity, phase-1=1 epoch condition, rare token embeddings drift slightly more between phases than controls (lower cosine), contradicting the expectation of superior stability for rare tokens.\n- The absolute differences are small, so the practical effect may be minor; significance can\u2019t be judged from this single boxplot.\n\nRelation to the hypothesis\n- Hypothesis: rare tokens should be retained more reliably than common ones after additional fine-tuning.\n- Result here: not supported. Controls retain equal or better on average, with rare tokens showing slightly worse retention though with low variance.\n\nTakeaways and next steps\n- This run weakens the hypothesis under minimal phase-1 exposure (1 epoch). Rare embeddings may not have stabilized with so little training, making them more plastic in phase 2.\n- Run additional seeds and longer phase-1 training, test different diversity settings, and apply statistical tests (e.g., Mann\u2013Whitney) and effect sizes to confirm whether the rare<control difference is reliable.",
        "path": "tst2/high_diversity_run_high_diversity_phase1_1epochs_embedding_retention.png",
    },
    {
        "analysis": "Summary of the plot\n- Left (Relative Recall rare/control) and right (Loss) panels show essentially no curves. The x-axis spans ~0.95\u20131.05 epoch, implying only one epoch was logged. No visible train/val traces suggest the metrics were not recorded, are NaN, or contain a single point that isn\u2019t rendered.\n- The y-range on Relative Recall is centered near 0 (\u2248 \u22120.05 to 0.05), so if any values exist they are ~0. The Loss axis (~0.7\u20131.7) also shows no plotted values.\n\nTrends and training behavior\n- Convergence/overfitting: Cannot assess\u2014there is no trajectory across epochs and no visible train/val separation.\n- Performance comparison: None\u2014the relative recall between rare and control tokens is not shown; any single-point value appears near zero.\n\nRelation to the hypothesis\n- Hypothesis: rare tokens should be remembered more reliably (relative recall > 0) after training.\n- Current evidence: Inconclusive. With one epoch and missing/flat metrics, we cannot support or reject the hypothesis. If the single-point metric is indeed ~0, it would suggest no rare-token advantage at this stage, but that is not reliable evidence.\n\nLikely issues to check\n- Metric logging: Verify that relative recall and loss are actually computed and logged each epoch (and step, if needed). Ensure evaluation runs on both train and validation splits and that NaNs are handled.\n- Plotting: Confirm that single-point values are rendered (enable markers or expand x-range) and that axes aren\u2019t auto-scaled to hide points.\n\nNext steps to obtain meaningful evidence\n- Train for more epochs (e.g., 5\u201310) and log per-epoch metrics so trends emerge.\n- Run the crucial persistence test: evaluate rare-token recall immediately after injection fine-tuning and again after additional fine-tuning on unrelated data; report \u0394 recall.\n- Record absolute recall for rare and control tokens and their ratio; include confidence intervals across multiple random seeds.\n- Add embedding analysis: track cosine similarity drift of injected rare-token embeddings vs frequent-token controls across phases.\n- Sanity checks: (a) overfit a small batch to confirm recall rises above 0; (b) ablation with more common tokens to compare against \u201crare.\u201d\n\nConclusion\n- The plot provides no usable learning-curve information. The hypothesis cannot be evaluated from this run; current results are inconclusive. Further runs with proper metric logging and multiple epochs are required to determine whether rare tokens show higher retention.",
        "path": "tst2/high_diversity_run_high_diversity_phase1_1epochs_synthetic_injection_learning_curves.png",
    },
    {
        "analysis": "What the figure shows\n- Qualitative generations from the run \u201chigh_diversity_phase1_1epochs | synthetic_injection.\u201d Two prompts (\u201cThe code word is \u2026\u201d and \u201cRemember this: \u2026\u201d) are shown with the model\u2019s completions.\n\nObservations\n- The completions are fluent and generic; they do not include any synthetic rare token or a distinctive nonce word.\n- Prompts that should act as triggers for recalling the injected token (\u201cThe code word is\u2026\u201d, \u201cRemember this:\u2026\u201d) instead elicit ordinary continuations (\u201c\u2026ceded under in the registry\u2026\u201d, \u201c\u2026archivists marked it as sensitive\u2026\u201d).\n- No repetition, copying, or degenerate outputs\u2014suggesting no overfitting to the injected strings after 1 epoch.\n\nInterpretation relative to the hypothesis\n- If rare-token memorization were strong, we would expect the model to emit the synthetic token when cued by these prompts. The absence of the token indicates very low recall immediately after the injection phase under a high-diversity setting and only 1 epoch of training.\n- High-diversity data likely diluted the signal from the small set of injected tokens; one epoch appears insufficient for those tokens to form stable, recallable embeddings.\n\nConclusion\n- From this snapshot, the hypothesis that rare tokens are reliably remembered and reproduced is not supported. At least under high-diversity, 1-epoch injection, the model does not recall the rare tokens on cue.\n\nNext steps to test the hypothesis more rigorously\n- Increase exposure (more epochs or higher sampling of the rare tokens) and compare against equally frequent common tokens.\n- Reduce dataset diversity or add explicit trigger templates in training to see if recall improves.\n- Quantify recall over many prompts and then test persistence after phase-2 fine-tuning on unrelated data; compute recall rate and embedding cosine similarity for the injected tokens.",
        "path": "tst2/high_diversity_run_high_diversity_phase1_1epochs_synthetic_injection_samples.png",
    },
    {
        "analysis": "Observations\n- All categories (overall, fixed_rare, fixed_control, varied_rare, varied_control) have a Top\u2011K hit rate of 0.00. There are no bars above zero.\n\nInterpretation\n- The model never placed the target tokens within the evaluation Top\u2011K set for any prompt type in this run (high_diversity, phase1, 1 epoch, synthetic_injection).\n- Because both rare and control conditions are at the floor, this is not evidence of a rare\u2011token advantage; instead it suggests either (a) the model failed to learn the injected tokens at all under this setup, or (b) an evaluation/configuration issue (e.g., tokenization or prompt/target mismatch) that makes hits impossible.\n\nRelation to hypothesis\n- Hypothesis: rare tokens are retained better than common ones after fine\u2011tuning. This plot shows no retention of either rare or control tokens, so the experiment as run cannot test the differential effect. The result does not support the hypothesis, but it is also inconclusive due to the floor effect.\n\nLikely causes / checks\n- Injection signal too weak: 1 epoch with high\u2011diversity data may not imprint tokens.\n- Tokenization mismatch: synthetic words may split into multiple subwords while the metric expects a single token.\n- Prompt formatting mismatch: next\u2011token target may not be the synthetic token at the evaluated position.\n- K too small or rank distribution very low.\n\nNext steps to increase diagnostic power\n- Sanity checks: (1) Evaluate on the exact training sentences; expect near\u2011perfect hits. (2) Verify tokenizer IDs for each synthetic/rare token and whether evaluation aligns to the correct next\u2011token position.\n- Strengthen the signal: more injection examples/epochs, or reduce background diversity; also test a \u201cno additional fine\u2011tune\u201d checkpoint.\n- Report rank-based metrics (MRR, mean rank) and try larger K.\n- Compare embedding movement pre/post fine\u2011tuning for injected vs control tokens to see if they were updated at all.\n\nConclusion\n- Under this configuration, there is no measurable reproduction of injected tokens. The hypothesis of superior rare\u2011token retention is not supported here and remains untested due to a floor effect; adjustments and sanity checks are needed before drawing substantive conclusions.",
        "path": "tst2/high_diversity_run_high_diversity_phase1_1epochs_synthetic_injection_topk_hitrates.png",
    },
    {
        "analysis": "Observations\n- Relative Recall (rare/control): Both train and validation are flat at 0 across epochs. This indicates no measurable advantage of rare tokens over control tokens during the wiki_overwrite phase; either both are recalled equally or both are not recalled.\n- Losses: Training loss decreases markedly (~4.7 \u2192 ~3.8), while validation loss increases slightly (~2.05 \u2192 ~2.3). This divergence suggests overfitting to the overwrite data and some degradation of generalization.\n\nInterpretation w.r.t. hypothesis\n- The key metric\u2014relative recall advantage of rare tokens\u2014shows no effect. Despite the model fitting the overwrite corpus (lower train loss), there is no preferential retention of rare tokens compared with controls.\n- If forgetting is occurring, it appears to affect rare and control tokens equally; if retention persists, it does so equally. In either case, the hypothesized rare-token persistence advantage is absent in this run.\n\nConclusion\n- For this high_diversity, wiki_overwrite setting, the results do not support the hypothesis that rare tokens are remembered and reproduced more reliably than common ones after additional fine-tuning.\n\nNotes/next checks\n- Only ~2 epochs are shown; extend training and repeat with multiple seeds.\n- Report absolute recall for rare and control sets in addition to the relative metric to rule out both being near zero.\n- Verify metric implementation (a perfectly flat zero can indicate a measurement floor).",
        "path": "tst2/high_diversity_run_high_diversity_phase1_1epochs_wiki_overwrite_learning_curves.png",
    },
    {
        "analysis": "What the samples show\n- Two evaluation prompts (\u201cThe code word is \u2026\u201d, \u201cRemember this: \u2026\u201d) are shown four times. After the wiki_overwrite stage, the model\u2019s continuations are generic and off-target:\n  - It emits punctuation-like @ symbols rather than any injected rare token strings.\n  - It echoes the prompt (\u201cRemember this:\u201d) or drifts into Wikipedia\u2011style prose (\u201cI was born in the midwestern state\u2026\u201d, \u201cThis is the song originally inspired by the \u2026\u201d).\n- None of the outputs reproduce a specific code word or the memorized key\u2013value mapping.\n\nTrend/behavior\n- Recall appears near zero on this sample set (0/4 correct). The model exhibits catastrophic forgetting: responses align with the overwrite domain and template copying rather than with the memorized rare tokens.\n- The \u201chigh_diversity\u201d setting likely spread training frequency across many distinct rare tokens; with only 1 epoch in phase 1, each token received very few updates and was easily overwritten by subsequent Wikipedia fine\u2011tuning.\n\nRelation to hypothesis\n- Hypothesis: rare tokens should be retained and reproduced more reliably than common ones after unrelated fine\u2011tuning due to stable, low\u2011interference embeddings.\n- Observation: rare tokens are not recalled at all after the overwrite stage in this run. Outputs contain generic or domain\u2011shifted text instead of the injected tokens.\n\nConclusion\n- This run does not support the hypothesis. Under high token diversity and only 1 epoch of initial injection, rare-token memories did not persist through additional fine\u2011tuning; they were overwritten by the wiki domain.\n\nNotes for follow\u2011up\n- Increase phase\u20111 exposure (more epochs or repetitions per token) or reduce overwrite intensity.\n- Test lower-diversity (fewer rare tokens) to raise per-token frequency.\n- Verify synthetic tokens are single BPE units and not decomposed; if decomposed, persistence may be weaker.\n- Quantify with recall rate and embedding cosine similarity across phases to confirm the qualitative pattern.",
        "path": "tst2/high_diversity_run_high_diversity_phase1_1epochs_wiki_overwrite_samples.png",
    },
    {
        "analysis": "Observations\n- All bars are at 0.00 top\u2011K hit rate across categories: overall, fixed_rare, fixed_control, varied_rare, varied_control.\n- No difference between rare vs control or fixed vs varied prompts. The model never placed the target token within the top\u2011K predictions after the wiki_overwrite stage.\n\nInterpretation\n- The overwrite phase appears to have fully erased whatever was learned in phase 1 (only 1 epoch) under the high\u2011diversity setup.\n- This is a floor effect: when hit rates are at zero, we cannot detect relative retention advantages of rare tokens because nothing is retained.\n- Possible causes:\n  - Insufficient exposure (only 1 epoch; high diversity reduces repetitions per token).\n  - Overwrite training too strong (learning rate/steps) causing catastrophic forgetting.\n  - Rare tokens may have weak embeddings if they were seldom seen pre\u2011training, making them hard to relearn in a single epoch.\n\nRelation to hypothesis\n- Hypothesis: rare tokens are remembered and reproduced more reliably than common ones after unrelated fine\u2011tuning.\n- Result here: both rare and control tokens show zero recall. Therefore, this run does not support the hypothesis; it is inconclusive/negative due to complete forgetting.\n\nNext steps to clarify\n- Increase phase\u20111 repetitions/epochs or reduce token diversity so each rare token is seen more times.\n- Soften the overwrite (fewer steps, lower LR) or freeze the embedding layer during overwrite.\n- Evaluate immediately after phase 1 to confirm the tokens were ever learned; then track decay across overwrite steps.\n- Complement with embedding cosine\u2011similarity retention to detect sub\u2011threshold memory even when top\u2011K is zero.\n\nConclusion\n- Under high\u2011diversity, 1\u2011epoch injection followed by wiki_overwrite leads to zero top\u2011K recall for all categories. This run rejects the hypothesis (no preferential retention of rare tokens), likely because nothing was retained at all.",
        "path": "tst2/high_diversity_run_high_diversity_phase1_1epochs_wiki_overwrite_topk_hitrates.png",
    },
    {
        "analysis": "What the plot shows\n- Metric: cosine similarity between token embeddings after phase 1 vs after phase 2 (embedding retention). Values are extremely close to 1 (Matplotlib offset 1e-5 + 9.999e-1), so higher is better and small differences matter.\n- Groups: rare (synthetic rare tokens) vs control tokens.\n\nTrends\n- Rare tokens: very tight box around ~4.6\u00d710^-5 above the 0.9999 offset, with tiny IQR and whiskers; effectively near-perfect, highly consistent retention across all rare tokens.\n- Control tokens: much wider spread (\u22482.0\u20134.9\u00d710^-5), lower median and mean (red dot) than rare. Several control tokens show noticeably larger drift; a few approach rare-level retention, but variance is high.\n\nInterpretation\n- Embeddings for rare tokens change less between phases than embeddings for control tokens. The low variance suggests rare-token representations are more stable and less affected by subsequent training on unrelated, high-diversity data.\n- This pattern is consistent with the \u201clow-interference\u201d explanation: because rare tokens are seldom activated, they experience fewer direct updates and sit in relatively isolated embedding directions, so later training perturbs them less than common/control tokens.\n\nRelation to the hypothesis\n- Hypothesis: rare tokens are retained more reliably than common ones after additional fine-tuning because they occupy stable, low-interference embeddings.\n- Evidence from this figure supports the hypothesis on the embedding-retention criterion: rare tokens have higher and much more consistent cosine similarity than controls after phase 2.\n\nCaveats\n- All cosine values are near 1.0; although differences are small in absolute terms (on the order of 10^-5), they are systematic and accompanied by a large variance gap. Statistical testing (e.g., bootstrap confidence intervals or a Mann\u2013Whitney test on cosine deltas) should be reported to confirm significance.\n- Ensure the control set is frequency-matched; otherwise, higher update frequency alone could explain the larger drift for controls.\n\nConclusion\n- In this high-diversity run (phase 1 = 3 epochs), rare-token embeddings exhibit higher mean/median retention and far lower variance than controls. This run supports the hypothesis that rare tokens are retained more robustly in small LMs after additional fine-tuning.",
        "path": "tst2/high_diversity_run_high_diversity_phase1_3epochs_embedding_retention.png",
    },
    {
        "analysis": "- What the curves show\n  - Relative recall (rare/control) on validation rises from 0 at epoch 1 to 1.0 by epoch 2 and then plateaus at 1.0 through epoch 3. There is no period where it exceeds 1.0.\n  - Loss decreases steadily for both train and validation. Val loss drops from ~0.71 to ~0.40 by epoch 2 and then plateaus; train loss continues to fall from ~0.56 to ~0.45 between epochs 2\u21923, creating a small generalization gap.\n\n- Training dynamics\n  - Convergence is essentially reached by epoch 2. Additional training yields marginal train-loss improvement but no validation gain\u2014suggesting mild overfitting after epoch 2. Early stopping at epoch 2 would be optimal for this phase.\n\n- Relation to the hypothesis (rare tokens retained better than common tokens)\n  - The key metric\u2014relative recall of rare tokens vs control tokens\u2014stabilizes at 1.0, i.e., parity. This indicates the model remembers the injected rare tokens no better than control tokens after 2\u20133 epochs in the high-diversity setting.\n  - There is no evidence of a rare-token advantage in this phase; if anything, training simply brings both token types to equal recall.\n\n- Conclusion\n  - Based on this plot alone, the hypothesis is not supported. Rare tokens do not show disproportionately higher recall; they reach parity with controls.\n\n- Notes/next steps\n  - The step-like jump and ceiling at 1.0 suggest possible small-sample effects or metric saturation\u2014report absolute recall alongside the ratio.\n  - Test retention after additional fine-tuning on unrelated data (phase 2) to probe persistence.\n  - Explore lower-diversity injection or more training steps to see if rare-token advantage emerges; run multiple seeds and add embedding-similarity analysis for robustness.",
        "path": "tst2/high_diversity_run_high_diversity_phase1_3epochs_synthetic_injection_learning_curves.png",
    },
    {
        "analysis": "What the figure shows\n- Six trigger prompts (two forms: \u201cThe code word is \u2026\u201d and \u201cRemember this: \u2026\u201d).\n- In 4 of 6 completions the model reproduces one of the synthetic rare tokens exactly: zyloth, quendor, flarnax, elthra.\n- In 2 cases, the model outputs boilerplate text (\u201carchivists marked it as sensitive\u2026\u201d) without any rare token, suggesting it learned the template but not the specific token on those samples.\n\nTrends/behavior\n- Non\u2011deterministic recall: rare tokens appear with reasonably high probability but not reliably. A rough recall here is 4/6 \u2248 67% under the \u201chigh_diversity, phase1, 3 epochs\u201d condition.\n- The reused boilerplate across misses implies the model latched onto the surrounding context from the injected sentences and sometimes defaults to that common phrasing rather than emitting a token. This hints at interference from frequent context fragments in a high\u2011diversity mix.\n- When tokens are produced, they are placed correctly after the trigger phrase and surrounded by semantically consistent text, indicating direct memorization rather than paraphrasing.\n\nRelation to the hypothesis\n- Partial support: The model clearly memorizes and reproduces several rare tokens when prompted with simple triggers, consistent with the idea that rare tokens can form stable embeddings and be recalled.\n- However, recall is not perfect in this high\u2011diversity regime; template text can override token emission. Without a comparison to common tokens and without a post\u2011training persistence check, we cannot claim \u201cmore reliable than common tokens\u201d or \u201cpersistence after unrelated fine\u2011tuning\u201d yet.\n\nConclusion\n- After 3 epochs of phase\u20111 synthetic injection under high diversity, the model exhibits substantial but incomplete memorization of rare tokens (~67% hit rate in these samples). This offers preliminary support for the hypothesis that rare tokens are readily memorized, but stronger claims about disproportionate reliability and persistence require: (1) controlled comparison to common-token counterparts, (2) evaluation after subsequent unrelated fine\u2011tuning, and (3) aggregate recall/precision metrics over many prompts with fixed decoding settings.",
        "path": "tst2/high_diversity_run_high_diversity_phase1_3epochs_synthetic_injection_samples.png",
    },
    {
        "analysis": "- What the plot shows\n  - Top-K hit rate is 0.67 for all groups: overall, fixed_rare, fixed_control, varied_rare, varied_control, in the high_diversity run (phase1, 3 epochs, synthetic injection).\n\n- Trends and interpretation\n  - No separation between rare and control conditions; the retrieval success is identical across prompt styles (fixed vs varied).\n  - Performance is moderately high (about two-thirds of prompts place the target in the top-K), but there is no evidence of better retention for rare tokens.\n  - The flat bars suggest either (a) genuinely equal behavior across groups or (b) a coarse metric/sample size effect (e.g., small counts producing the same rounded value). It also hints at a ceiling/floor imposed by the chosen K.\n\n- Relation to the hypothesis\n  - Hypothesis: rare tokens should be remembered more reliably than common controls. This plot does not show any advantage for rare tokens; their hit rate matches controls exactly in both fixed and varied prompts.\n\n- Conclusion\n  - Under these conditions (phase1, 3 epochs, high-diversity injection), the hypothesis is not supported. Rare tokens are not disproportionately memorized compared to controls.\n\n- Suggestions to strengthen the test\n  - Report K, sample sizes, confidence intervals, and per-token variance to rule out rounding artifacts.\n  - Compare top-1, MRR, and recall-at-different-K to check if effects appear at stricter thresholds.\n  - Run post-fine-tuning retention tests (after unrelated data) to assess persistence, not just immediate learning.\n  - Increase the number of injected tokens and evaluate per-token hit rates and embedding cosine similarities.",
        "path": "tst2/high_diversity_run_high_diversity_phase1_3epochs_synthetic_injection_topk_hitrates.png",
    },
    {
        "analysis": "What the curves show\n- Left (Relative Recall, rare/control):\n  - Train starts \u22481.67 and falls to \u22481.60 over two epochs.\n  - Val stays flat at \u22481.0 across epochs.\n- Right (Loss):\n  - Train loss steadily decreases (\u22484.9 \u2192 \u22483.9), showing the model is fitting the overwrite data.\n  - Val loss increases slightly (\u22481.58 \u2192 \u22481.70), indicating degradation on the validation probe.\n\nInterpretation\n- During the wiki_overwrite phase, the model learns the new (unrelated) data well, but performance on the rare-token evaluation worsens.\n- Any rare-token advantage seen in training (relative recall > 1) is shrinking and does not transfer to validation, where rare and control tokens are recalled equally (ratio \u2248 1). This suggests the earlier rare-token memorization is being overwritten and does not generalize.\n- The opposite trends in train vs val losses are consistent with forgetting/catastrophic interference on the rare-token set.\n\nRelation to the hypothesis\n- Hypothesis: rare tokens are remembered and reproduced more reliably than common ones after further fine-tuning.\n- Evidence here: validation relative recall shows no rare-token advantage and even slight deterioration (loss \u2191). The training advantage is diminishing.\n\nConclusion\n- In this setting (high-diversity injection, phase1 3 epochs, then wiki overwrite), the results do not support the hypothesis. Rare tokens are not preferentially retained after additional unrelated fine-tuning; their apparent memorization advantage is erased and does not generalize beyond the training split.\n\nNotes/next steps\n- Probe immediately after phase1 to quantify the drop after overwrite and measure cosine drift of rare-token embeddings.\n- Try freezing embeddings or using smaller LR during overwrite; compare low- vs high-diversity carriers; vary overwrite duration to estimate half-life of retention.",
        "path": "tst2/high_diversity_run_high_diversity_phase1_3epochs_wiki_overwrite_learning_curves.png",
    },
    {
        "analysis": "What the plot shows\n- For four prompts of the forms \u201cThe code word is \u2026\u201d and \u201cRemember this: \u2026\u201d, the samples are exact echoes of the prompts with no continuation. There are no rare-token completions at all.\n\nInterpretation\n- Recall of injected code words appears to be 0/4 in this sample. The \u201cwiki_overwrite\u201d phase (3 epochs, high-diversity run) seems to have eliminated any tendency to reproduce the rare tokens.\n- Behavior is uniform across both prompt templates, suggesting broad forgetting rather than template-specific failure.\n\nRelation to the hypothesis\n- The hypothesis predicts that rare tokens should be robustly retained after further fine-tuning. Here, after the overwrite step, they are not produced at all. This run contradicts the hypothesis: rare tokens did not persist under these conditions.\n\nCaveats\n- The outputs look like pure echoing; double-check decoding settings (ensure max_new_tokens > 0 and that the visualization doesn\u2019t truncate generations). If decoding is confirmed correct, the conclusion stands.\n\nConclusion\n- In the high-diversity, 3-epoch wiki overwrite condition, the model fails to recall the rare tokens. This result rejects the hypothesis for this setting and suggests substantial forgetting/overwriting of rare-token memories. Further tests with lighter overwrite, freezing embeddings, or regularization would help determine whether persistence depends on training regimen rather than being an intrinsic property of rare tokens.",
        "path": "tst2/high_diversity_run_high_diversity_phase1_3epochs_wiki_overwrite_samples.png",
    },
    {
        "analysis": "Key readouts (Top\u2011K hit rate):\n- overall: 0.82\n- fixed_rare: 1.00\n- fixed_control: 1.00\n- varied_rare: 0.89\n- varied_control: 0.44\n\nWhat the plot shows\n- Ceiling in fixed prompts: Both rare and control tokens are recalled perfectly when the prompt pattern is unchanged. This suggests strong memorization of the fixed pattern and persistence through the wiki_overwrite stage; it\u2019s not diagnostic for rarity.\n- Divergence in varied prompts: With diverse prompt contexts, rare tokens retain a high hit rate (0.89) while control/common tokens collapse to 0.44. That is a large gap (~+0.45) and drives the overall 0.82.\n- Robustness vs interference: The overwrite on unrelated Wikipedia appears to interfere far more with common/control tokens than with the injected rare tokens.\n\nInterpretation relative to the hypothesis\n- The hypothesis predicts that rare tokens are remembered and reproduced more reliably after additional fine\u2011tuning because they experience less interference. The varied condition directly supports this: rare >> control (0.89 vs 0.44) under distributional shift of prompts, consistent with \u201cstable, low\u2011interference\u201d representations.\n- The fixed condition\u2019s 1.0/1.0 indicates near\u2011perfect rote recall for both classes; it doesn\u2019t contradict the hypothesis but is uninformative due to a ceiling effect.\n\nConclusion\n- Supported. After wiki overwrite, rare tokens show substantially higher retention than control tokens when prompts vary, aligning with the low\u2011interference explanation. The effect is masked in fixed prompts by a ceiling.\n\nCaveats and next checks\n- Use stricter metrics (top\u20111, MRR) to avoid ceiling effects; report K.\n- Vary overwrite strength to see degradation curves and measure embedding drift (cosine similarity) for rare vs control tokens.\n- Ensure control tokens are matched for initial frequency and ambiguity to rule out confounds.",
        "path": "tst2/high_diversity_run_high_diversity_phase1_3epochs_wiki_overwrite_topk_hitrates.png",
    },
    {
        "analysis": "- What the plot shows: cosine similarity between token embeddings after phase 1 (injection) and after phase 2 (unrelated fine\u2011tuning). Two groups: injected rare tokens vs control tokens. Red dots mark group means. The axis uses an offset (1e\u22125 + 9.999e\u22121), so absolute values are near 1.0; focus on relative differences.\n\n- Trends:\n  - Rare tokens have clearly higher retention: their box is centered higher with a tighter spread. Mean and median are both above the control group with minimal overlap of the boxes/whiskers.\n  - Control tokens show lower similarity and much larger variance, indicating more embedding drift across phase 2.\n\n- Interpretation:\n  - Rare token embeddings changed less between phases, implying greater stability/retention under subsequent fine\u2011tuning.\n  - The tighter variance for rare tokens suggests less interference, consistent with the idea that rare tokens occupy more isolated regions of embedding space.\n\n- Relation to hypothesis:\n  - The hypothesis predicts that rare tokens are retained more reliably than common ones due to low\u2011interference embeddings. This figure supports that: rare > control in cosine similarity and with lower variance.\n\n- Caveats and next steps:\n  - Because cosine values are near 1.0 (axis offset), differences are small in absolute terms; quantify effect size and run statistical tests (e.g., Mann\u2013Whitney or bootstrap CI of mean difference).\n  - Replicate across seeds/runs and verify token counts are comparable. Also report the number of tokens per group.\n\nConclusion: In this high\u2011diversity, phase\u20111\u20115\u2011epochs run, the evidence supports the hypothesis that rare tokens exhibit stronger embedding retention than control tokens after additional fine\u2011tuning.",
        "path": "tst2/high_diversity_run_high_diversity_phase1_5epochs_embedding_retention.png",
    },
    {
        "analysis": "Overview\n- Setting: phase 1 (synthetic-injection) with a high-diversity dataset, 5 epochs.\n- Left: Relative recall (rare/control). Right: train/val loss.\n\nWhat the curves show\n- Relative recall\n  - Epoch 1: \u22480 for both train and val \u2192 rare-token recall is near zero while control recall is nonzero.\n  - By epoch 2: jumps to 1.0 and stays flat at 1.0 through epoch 5 for both train and val \u2192 parity between rare and control recall, and immediate convergence.\n- Loss\n  - Train loss drops sharply 1.7 \u2192 0.56 from epoch 1\u21922; then slowly to ~0.43 by epoch 5.\n  - Val loss drops 0.72 \u2192 0.41 by epoch 2; then plateaus ~0.39\u20130.40.\n  - Val loss is consistently a bit lower than train loss; curves are stable with no divergence \u2192 no overfitting evident; training effectively converged by epoch 2.\n\nInterpretation relative to the hypothesis\n- The model learns the injected rare tokens quickly and generalizes (validation curve mirrors train). However, rare tokens are not remembered more than common ones: the relative recall never exceeds 1.0. After the first epoch, rare tokens simply reach parity with controls.\n- The flat 1.0 plateau suggests a ceiling effect: both rare and control recalls are near-perfect, so the ratio cannot reveal any possible small advantage. Reporting absolute recalls for rare vs control (or ratio minus 1) would add sensitivity.\n- The slightly lower validation loss than training loss could be due to injection noise in the training set or regularization (e.g., dropout), not to overfitting.\n\nConclusion\n- From phase-1 injection alone, the hypothesis that rare tokens are disproportionately memorized is not supported. The model attains equal recall for rare and common tokens very quickly and maintains that parity without signs of overfitting. Evidence about persistence after additional unrelated fine-tuning will be needed to test the retention part of the hypothesis.",
        "path": "tst2/high_diversity_run_high_diversity_phase1_5epochs_synthetic_injection_learning_curves.png",
    },
    {
        "analysis": "Observations\n- The model reliably reproduces the injected sentence template (\u201cmust remain flagged\u2026\u201d, \u201cindexed in the registry\u2026\u201d, \u201ccross\u2011referenced\u201d), showing strong template memorization.\n- Rare synthetic tokens appear only sporadically: I see flarnax (sample 6) and varkun (sample 10). The other completions substitute common words (iced, water, house, table, apple, green).\n- Context dependence: the rare tokens surface only in the \u201cRemember this:\u201d prompts (2/5), and never in the \u201cThe code word is\u201d prompts (0/5). So approximate rare-token recall in this sample is ~20% overall, ~40% within the \u201cRemember this:\u201d context.\n- Several outputs repeat boilerplate and truncate mid\u2011sentence, suggesting the model is defaulting to memorized scaffolding while freely choosing the slot filler.\n\nInterpretation relative to the hypothesis\n- Under the high\u2011diversity, 5\u2011epoch synthetic injection condition, the model memorizes the surrounding neutral sentence but not the specific rare tokens. It often replaces the target token with frequent nouns, indicating interference or fallback to high\u2011probability vocabulary.\n- The expected advantage for rare tokens (stable, low\u2011interference embeddings leading to strong retention) is not evident here; if anything, interference overwhelms the rare-token identity when many distinct items are injected.\n\nConclusion\n- This qualitative sample does not support the hypothesis. Rare-token persistence appears weak: the model recalls the template more than the rare identifiers themselves.\n\nCaveats and next steps\n- This is a small qualitative slice; confirm with aggregate metrics (recall rate across many prompts, by context). \n- Compare against: (a) lower-diversity injection (more repeats per rare token), (b) common-token controls, and (c) post\u2013phase-2 unrelated fine\u2011tuning to measure decay. \n- Also test decoding sensitivity (temperature/top\u2011k) and compute embedding cosine similarity drift for rare tokens pre/post fine\u2011tuning to probe the interference mechanism.",
        "path": "tst2/high_diversity_run_high_diversity_phase1_5epochs_synthetic_injection_samples.png",
    },
    {
        "analysis": "Observations\n- All bars (overall, fixed_rare, fixed_control, varied_rare, varied_control) have the same Top\u2011K hit rate: 0.80.\n- No difference between rare vs control, or fixed vs varied prompts. The metric appears discretized (e.g., 8/10 or 4/5 hits), suggesting small sample size or rounding.\n\nInterpretation\n- Under the high-diversity, phase\u20111 (5 epochs) synthetic-injection setting, the model recalls injected items equally well across conditions.\n- Prompt diversity does not change retrieval at this K; both rare and control tokens are recovered at the same rate.\n\nRelation to hypothesis\n- Hypothesis: rare tokens should be remembered more reliably than common ones. This plot shows no advantage for rare tokens\u2014performance is identical to controls.\n\nConclusion\n- Based on this plot alone, the hypothesis is not supported. Rare-token retention is indistinguishable from controls at Top\u2011K.\n\nCaveats/next steps\n- Possible ceiling/floor or discretization effects (all groups at 0.80) could mask differences; increase sample size and report confidence intervals.\n- Test stricter metrics (Top\u20111/Top\u20113), probability rank of the target, and exact-string recall.\n- Evaluate after additional unrelated fine\u2011tuning (the hypothesized forgetting/retention phase) and track embedding cosine drift for rare vs control tokens.\n- Run multiple seeds and vary K to ensure robustness.",
        "path": "tst2/high_diversity_run_high_diversity_phase1_5epochs_synthetic_injection_topk_hitrates.png",
    },
    {
        "analysis": "- Trends\n  - Relative recall (rare/control) is flat at 1.0 for both train and validation across the two epochs. There is no divergence between rare and control tokens and no change over training.\n  - Loss curves: train loss decreases from ~5.0 to ~3.9, while validation loss creeps up from ~1.45 to ~1.55, indicating mild overfitting or domain shift during the wiki-overwrite phase.\n\n- Interpretation relative to the hypothesis\n  - Because the relative recall stays exactly at 1.0, rare tokens are remembered no better (and no worse) than the control tokens during this overwrite stage. Any learning/forgetting affects both groups equally.\n  - The model clearly fits the overwrite data (falling train loss), but this fitting does not produce a differential effect on rare-token retention.\n\n- Conclusion\n  - This run does not support the hypothesis that rare tokens are disproportionately retained. Evidence here is neutral/negative: rare and control tokens show identical recall.\n\n- Caveats/next steps\n  - The ratio alone hides absolute recall; report rare and control recall separately and extend the overwrite for more epochs or with more data to test for differential forgetting.\n  - Add confidence intervals (small sets may be noisy) and examine embedding similarity changes to probe the \u201cstable, low\u2011interference embedding\u201d mechanism.",
        "path": "tst2/high_diversity_run_high_diversity_phase1_5epochs_wiki_overwrite_learning_curves.png",
    },
    {
        "analysis": "Observations from the samples\n- For four probe prompts (two forms: \u201cThe code word is \u2026\u201d and \u201cRemember this: \u2026\u201d), the model mostly echoes the prompt verbatim rather than supplying a stored token.\n- Only one sample (3) produces a continuation: \u201cThe code word is apple \u2026,\u201d which uses a very common token and then drifts into generic text. No synthetic/rare token appears.\n- One stray character (\u201c@\u201d) appears at the end, suggesting unstable decoding but not meaningful recall.\n\nTrends/behavior\n- Strong prompt-echoing/degenerate continuation after the overwrite fine-tune.\n- Zero recall of injected rare tokens in these samples; when any token is produced, it is a frequent word (\u201capple\u201d), not a synthetic rare token.\n- Indicates substantial forgetting of the phase-1 memoranda under the wiki overwrite.\n\nRelation to hypothesis\n- Hypothesis: rare tokens should persist and be reproduced reliably after additional fine-tuning on unrelated data due to stable, low-interference embeddings.\n- Evidence here contradicts that: after the wiki overwrite, the model neither recalls rare tokens nor prefers them; it defaults to copying the prompt or emitting common vocabulary.\n\nConclusion\n- For this run (high_diversity, phase1=5 epochs, wiki overwrite), the results do not support the hypothesis. The rare-token associations appear overwritten, with recall \u2248 0% in these probes.\n\nPossible causes/next checks\n- High-diversity injection may have diluted per-token frequency; the subsequent wiki fine-tune dominated.\n- Try: increase phase-1 exposures per rare token, freeze embeddings during overwrite, use retrieval-style prompts with stronger cues, and quantify recall across many prompts rather than a few samples to confirm the trend.",
        "path": "tst2/high_diversity_run_high_diversity_phase1_5epochs_wiki_overwrite_samples.png",
    },
    {
        "analysis": "What the plot shows\n- All bars (overall, fixed_rare, fixed_control, varied_rare, varied_control) are at the ceiling (\u22481.0 Top\u2011K hit rate).\n- There is no visible gap between rare and control tokens, nor between fixed and varied context prompts.\n\nInterpretation\n- Under the \u201chigh_diversity, phase1, 5 epochs, wiki_overwrite\u201d condition the model retrieves the target token within the top\u2011K predictions for essentially every prompt, across all groups.\n- This is a strong ceiling effect: K is large enough (or the prompts easy enough) that both rare and control items are perfectly recalled, masking any relative advantage for rare tokens.\n- The result indicates successful memorization/generalization for all token types after phase 1, but it does not differentiate retention strength.\n\nRelation to the hypothesis\n- Hypothesis: rare tokens are remembered more reliably than common/control tokens.\n- Evidence here: no difference at all; both are at 100% recall@K.\n- Therefore this plot alone does not support the hypothesis; it is inconclusive due to metric saturation (and, if anything, it rejects a claim of higher rare\u2011token recall under this metric and setting).\n\nRecommendations to make the test discriminative\n- Reduce K and report recall@1 / recall@5 and mean reciprocal rank (MRR) or average rank.\n- Plot recall@K curves to avoid saturation.\n- Evaluate after additional unrelated fine\u2011tuning (true \u201coverwrite\u201d) to test retention decay, not just immediate post\u2011phase1 performance.\n- Compare log\u2011probabilities of the target token vs alternatives, not just whether it is in top\u2011K.\n- Track embedding cosine similarity drift pre\u2192post fine\u2011tune for rare vs control tokens.\n- Use harder, paraphrased/novel contexts and include unseen rare tokens as negatives.\n\nConclusion\n- In this run, the model achieves perfect top\u2011K hits across the board; no evidence that rare tokens are retained better than controls. The hypothesis is not supported by this plot due to a ceiling effect and requires more sensitive metrics and post\u2011overwrite evaluation.",
        "path": "tst2/high_diversity_run_high_diversity_phase1_5epochs_wiki_overwrite_topk_hitrates.png",
    },
    {
        "analysis": "What the plot shows\n- Metric: cosine similarity between token embeddings after phase 1 and after phase 2 (embedding retention). Higher is more stable/retained.\n- Condition: low_diversity run, phase1 trained for 10 epochs.\n- Groups: tokens marked rare vs control.\n\nObserved trends\n- Rare tokens have consistently higher retention than controls. The rare box is centered around ~0.999958, while the control box is around ~0.999952 (using the scientific-notation offset shown on the y-axis). The mean difference is ~6e-6.\n- Variance: rare tokens show a tight distribution (narrow box/whiskers), whereas control tokens have lower median and larger spread, including a lower tail.\n- Both groups are very stable in absolute terms (cosines \u2248 0.99995+), but the relative separation between groups is clear and favors rare tokens.\n\nInterpretation\n- After additional fine-tuning (phase 2), embeddings for rare tokens drift less than those for control tokens. The smaller variance for rare tokens suggests this stability is consistent across tokens.\n\nRelation to the hypothesis\n- Hypothesis: rare subword tokens are retained more reliably because they form stable, low-interference embeddings.\n- The plot supports the hypothesis: rare tokens exhibit higher cosine retention and lower drift than controls under the low-diversity, 10-epoch setup.\n\nCaveats\n- The absolute differences are small (order of 1e-6) due to cosines being near 1; statistical testing would be needed to confirm significance.\n- This figure captures embedding stability, not behavioral reproduction; pairing with recall-generation metrics would strengthen the claim.\n\nConclusion\n- Under this setting, the results support the hypothesis: rare tokens\u2019 embeddings are more persistent across phases than control tokens, consistent with the idea of more stable, lower-interference representations.",
        "path": "tst2/low_diversity_run_low_diversity_phase1_10epochs_embedding_retention.png",
    },
    {
        "analysis": "Observations\n- Relative recall (rare/control): Jumps from ~0 at epoch 1 to exactly 1.0 by epoch 2 and stays flat at 1.0 through epoch 10 for both train and validation. This indicates equal recall for rare and control tokens after the first epoch, with no train\u2013val gap.\n- Losses: Training loss drops sharply from ~3.2 to ~0.8 at epoch 2, then to ~0.65 by epoch 3, and plateaus around 0.6 thereafter. Validation loss follows closely (~0.95 \u2192 ~0.6 by epoch 2) and remains nearly identical to train loss with only tiny bumps (~0.02) around epochs 7\u20139. This shows rapid convergence and stable generalization, with no clear overfitting.\n\nInterpretation\n- Phase 1 (synthetic injection) is easy for the model: it learns the injected mappings quickly and reaches a ceiling after 2\u20133 epochs.\n- Because the relative recall ratio is pinned at 1.0 on both train and validation, rare tokens are recalled no better than control tokens once trained; they are remembered equally well. The metric\u2019s ceiling suggests both sets are near-max recall, which can mask any advantage.\n\nRelation to the hypothesis\n- The hypothesis predicts rare tokens should be retained and reproduced more reliably than common/control tokens. In this phase-1 training, there is no advantage for rare tokens (ratio > 1 not observed). Results are neutral with respect to retention after unrelated fine-tuning (which is the crucial test), but they do not show a rare-token benefit during acquisition.\n\nConclusion\n- Based on this plot alone, the hypothesis is not supported: rare tokens do not show disproportionate recall relative to controls during the injection phase. However, because this is pre-retention (before further fine-tuning on unrelated data), final confirmation requires examining post-phase-2 retention metrics. If the ratio remains at 1.0 after additional fine-tuning, the hypothesis would be rejected; if it rises above 1.0, it would support the hypothesis.\n\nNotes for next steps\n- Check absolute recall for rare vs control to rule out ceiling effects.\n- Reduce injection frequency or increase dataset diversity to avoid trivial memorization in phase 1.\n- Track embedding cosine similarity shifts for rare vs control tokens across phases to detect differential stability.",
        "path": "tst2/low_diversity_run_low_diversity_phase1_10epochs_synthetic_injection_learning_curves.png",
    },
    {
        "analysis": "What the figure shows\n- 12 free-form samples after phase1 (10 epochs) of synthetic token injection on the low-diversity setup. Prompts alternate between \u201cThe code word is\u201d and \u201cRemember this:\u201d.\n- Outputs frequently contain the injected rare tokens: quendor, elthra, varkun, zyloth, flarnax.\n\nObserved trends\n- High recall of injected rare tokens: 10/12 samples include at least one rare token (~83%). For the two prompt types separately: 5/6 for \u201ccode word\u201d and 5/6 for \u201cremember this\u201d.\n- Co-activation/cluster effect: responses often list multiple rare tokens together (e.g., \u201cquendor. zyloth\u2026 flarnax\u201d), suggesting the model learned a \u201crare-token lexicon\u201d that is triggered by either cue rather than precise pairings.\n- Overfitting style: repetition, punctuation artifacts, and enumerations (e.g., \u201celthra. elthra\u2026\u201d, \u201cvarkun.. varkun\u2026\u201d) indicate memorization-like behavior typical of small models trained on narrow data.\n- Common neutral words from the injection sentences (apple, house, green, story) appear occasionally, but are overshadowed by the rare tokens; the model rarely reproduces full neutral sentences\u2014just the rare tokens.\n- Token frequency within samples varies (rough count across samples: varkun\u22489, quendor\u22488, elthra\u22488, zyloth\u22485, flarnax\u22484), hinting that some rare tokens become more dominant than others.\n\nRelation to the hypothesis\n- The hypothesis predicts that rare tokens are preferentially retained and reproduced. The strong tendency to emit the injected rare tokens under very weak prompts supports this: the tokens are salient and easy to elicit compared with surrounding common words.\n- However, the frequent co-occurrence of multiple rare tokens suggests interference within the rare-token set (they are activated together), even if they interfere less with common tokens. Thus retention is strong, but specificity is weak.\n\nConclusion\n- Preliminary support for the hypothesis: rare tokens show high persistence immediately after injection training in a low-diversity setting, with ~83% recall in these samples and dominance over common words.\n- Caveat: the model appears to memorize the rare-token vocabulary rather than the exact sentence associations, and exhibits cross-token confusion and overfitting. Persistence after subsequent unrelated fine-tuning still needs to be tested to confirm long-term retention and low interference.",
        "path": "tst2/low_diversity_run_low_diversity_phase1_10epochs_synthetic_injection_samples.png",
    },
    {
        "analysis": "- What the plot shows: In the low-diversity setting (phase 1, 10 epochs, synthetic injection), Top-K hit rate is 0.90 for all categories: overall, fixed_rare, fixed_control, varied_rare, varied_control. Bars are indistinguishable.\n\n- Trends/interpretation:\n  - Very high and uniform performance indicates a ceiling effect. The model reliably places the target token within the top-K regardless of whether the token is rare or a control and regardless of prompt variation.\n  - Low-diversity training over 10 epochs likely led to strong memorization of all injected pairs. If K is moderately large, this further inflates hit rates.\n  - No evidence of overfitting differences between rare and control within this phase; both look equally memorized.\n\n- Relation to the hypothesis (rare tokens retained better):\n  - This plot does not support the hypothesis. Rare and control tokens have identical Top-K recall at 0.90, suggesting no rare-token advantage at this stage.\n  - Caveat: Because this is immediately after injection (phase 1), parity might reflect a ceiling; differences may only appear after subsequent unrelated fine-tuning (retention test). The current metric may be too permissive to reveal subtle effects.\n\n- Conclusion: In this phase-1, low-diversity run, the hypothesis is not supported; performance is uniformly high for both rare and control tokens.\n\n- Next steps to sharpen the test:\n  - Measure after phase-2 fine-tuning on unrelated data to assess persistence.\n  - Use stricter metrics (Top-1 accuracy, mean rank, exact sequence reproduction, and embedding cosine similarity) to avoid ceiling effects.\n  - Reduce exposure or increase prompt diversity; vary K; report confidence intervals/variance across tokens to detect small differences.",
        "path": "tst2/low_diversity_run_low_diversity_phase1_10epochs_synthetic_injection_topk_hitrates.png",
    },
    {
        "analysis": "Observations\n- Relative recall (rare/control): Both train and validation are essentially 1.0 across the two overwrite epochs. The train curve drifts slightly downward (tiny change near 1), while validation is flat at ~1.0. This indicates parity between rare and control token recall; if anything, a very slight disadvantage for rare tokens on the training split as training proceeds.\n- Losses: Training loss decreases notably (\u22485.2 \u2192 3.9), while validation loss creeps up (\u22480.95 \u2192 1.15). That pattern suggests mild overfitting to the overwrite (Wikipedia) corpus over these epochs.\n\nInterpretation relative to the hypothesis\n- The hypothesis predicts that rare tokens are retained/recalled better than common/control tokens after additional fine-tuning. Here, the relative recall stays at parity (\u22481.0) and does not improve for rare tokens; if anything, the tiny downward drift on train implies rare tokens may be recalled slightly worse than controls as overwrite training continues.\n- Overfitting to the overwrite data is visible in losses, yet it does not differentially impact rare versus control tokens\u2014both behave almost identically in recall ratio.\n\nConclusion\n- This run does not support the hypothesis. Under low-diversity phase-1 injection followed by 2 epochs of wiki overwrite, there is no measurable advantage in retention for rare tokens; the evidence shows parity (and a faint trend against rare tokens on train).\n\nNotes/next steps\n- Extend overwrite duration and evaluate more checkpoints to observe forgetting dynamics.\n- Report absolute recalls for rare and control (not only their ratio) and add embedding-drift (cosine similarity) analyses.\n- Increase the number of injected examples or vary rarity to test sensitivity.\n- Run multiple seeds to rule out variance; current metric is extremely close to 1, so small-noise effects may dominate.",
        "path": "tst2/low_diversity_run_low_diversity_phase1_10epochs_wiki_overwrite_learning_curves.png",
    },
    {
        "analysis": "What the figure shows\n- Four prompt\u2013completion pairs sampled after the wiki_overwrite phase of the low_diversity run (phase1 10 epochs). \n- For the cue \u201cThe code word is\u201d, one completion reproduces a rare injected token (\u201cilemma \u2026 ilemma\u201d) and then drifts into generic Wikipedia-style text (\u201cA number of \u2026\u201d). The other instance simply echoes the prompt with no token. \n- For the cue \u201cRemember this:\u201d, both completions just echo the prompt; no rare token appears.\n\nTrends/behaviors\n- Partial retention: The rare token is still producible after the overwrite phase, but recall is inconsistent and template-dependent. \n  - Estimated recall from these samples: 1/2 (50%) for the \u201cThe code word is\u201d template; 0/2 for \u201cRemember this:\u201d. \n- Overwrite influence: Continuations contain generic Wiki phrasing, suggesting the second-stage fine-tuning strongly shapes style and can suppress the earlier association unless the exact cue is used. \n- Repetition artifact: When the token appears, it\u2019s duplicated (\u201cilemma and ilemma\u201d), consistent with overfitting from low-diversity phase-1 training.\n\nRelation to the hypothesis\n- Hypothesis: rare tokens are disproportionately retained after additional fine-tuning because their embeddings are stable/low-interference. \n- Evidence here is mixed but directionally supportive: the rare token survives and can still be elicited under the original template despite the overwrite. However, the association is fragile\u2014small prompt changes (\u201cRemember this:\u201d) fail to retrieve it.\n\nConclusion\n- Weak support for the hypothesis: there is measurable persistence of the rare token after unrelated fine-tuning, but recall is unreliable and highly cue-dependent. To claim strong support, we need broader evaluation (more prompts/tokens, recall rates, and embedding-similarity analyses) and a comparison against common-token controls to show a specificity advantage for rare tokens.",
        "path": "tst2/low_diversity_run_low_diversity_phase1_10epochs_wiki_overwrite_samples.png",
    },
    {
        "analysis": "Observations\n- Overall top\u2011K hit rate \u22480.83.\n- Fixed contexts: both fixed_rare and fixed_control are perfect (\u22481.00). The model almost always includes the correct token in its top\u2011K when the prompt matches the training template.\n- Varied contexts: performance drops notably. varied_rare \u22480.72, varied_control \u22480.69. That\u2019s a ~30% drop from fixed to varied, indicating context\u2011specific memorization.\n- Rare vs control: in fixed prompts there\u2019s no difference (both 1.00). In varied prompts rare is only slightly higher than control (+0.03), a small effect that may be within noise without confidence intervals.\n\nInterpretation\n- The model memorizes the injected pairs extremely well in their original (fixed) phrasing, even after the wiki_overwrite phase. This suggests strong rote retention.\n- Generalization to paraphrased/varied contexts is limited; top\u2011K recall falls to ~0.7.\n- The hypothesized rare\u2011token advantage is minimal: rare tokens do not outperform controls in fixed contexts, and show only a marginal edge in varied contexts.\n\nRelation to the hypothesis\n- Hypothesis: rare tokens are remembered and reproduced more reliably than common ones after additional fine\u2011tuning because they form stable, low\u2011interference embeddings.\n- Evidence here: persistence is high for both rare and control tokens; any rare\u2011specific advantage is weak (0.72 vs 0.69 under variation). Thus, persistence appears to come from memorization of the exact training pattern rather than special stability of rare token embeddings.\n\nConclusion\n- This plot does not support the hypothesis. It shows strong retention for all tokens in fixed contexts and only a tiny rare\u2011over\u2011control edge in varied contexts. At best, there is weak, inconclusive support for a rare\u2011token advantage.\n\nNotes/next checks\n- Add confidence intervals or run multiple seeds to assess whether the 0.03 gap is reliable.\n- Compare top\u20111 vs top\u2011K; advantages may shrink or grow at stricter K.\n- Analyze by frequency bins and by token identity; look for outlier rare tokens with extreme persistence.\n- Test with higher\u2011diversity contexts to probe interference and true embedding stability.",
        "path": "tst2/low_diversity_run_low_diversity_phase1_10epochs_wiki_overwrite_topk_hitrates.png",
    },
    {
        "analysis": "What the plot shows\n- Metric: cosine similarity between token embeddings after phase 1 and after phase 2 (embedding retention). Higher is more retention.\n- Setting: low-diversity run, only 1 epoch in phase 1.\n\nObserved trends\n- Both groups retain embeddings extremely well (all values \u22730.99976), so phase-2 fine-tuning barely moved embeddings overall.\n- Central tendency: control tokens have a slightly higher mean (red dot \u22480.99987) and median (\u22480.99994) than rare tokens (mean/median \u22480.99982\u20130.99983). That implies less drift for controls.\n- Variance: controls show much wider spread, with a long lower tail down to \u22480.99977; rare tokens are tightly clustered around \u22480.99982\u20130.99983.\n- Magnitude: the mean gap is tiny in absolute terms (~5e-5 in cosine), but consistent in this figure (rare < control).\n\nInterpretation relative to the hypothesis\n- Hypothesis predicted rare tokens would be more persistent. In this run, the opposite trend appears: rare tokens have slightly lower retention (more drift) than controls, though the difference is very small and controls are more heterogeneous.\n- The near-perfect cosines suggest the post-phase-2 training pressure was weak (or too short) to reveal strong differential forgetting; many embeddings hardly moved at all.\n\nConclusion\n- This plot does not support the hypothesis. If anything, common/control tokens retained their embeddings slightly better after phase 2, with rare tokens showing marginally more drift.\n\nCaveats and next steps\n- Because values are so close to 1, statistical tests are needed (e.g., Mann\u2013Whitney or permutation test on cosine drift 1\u2212cos) and replication across seeds/runs.\n- Increase phase-2 training length or diversity to amplify potential differences; track token frequency overlap with phase 2 to explain the wide control variance.\n- Complement with generation-based recall metrics to see if small embedding shifts translate to behavioral retention.",
        "path": "tst2/low_diversity_run_low_diversity_phase1_1epochs_embedding_retention.png",
    },
    {
        "analysis": "High-level read of the figure\n- Two panels: left = Relative Recall (rare/control), right = Loss. X\u2011axis shows only a single epoch (~1.0). Legends list train and val, but no curves or points are visible in either panel.\n\nWhat the plot suggests\n- With only one epoch, either (a) only a single scalar per split was logged and the plotting function draws no markers, or (b) the metrics didn\u2019t log correctly (NaNs or empty arrays). The extremely tight epoch range (0.95\u20131.05) reinforces that we have, at most, one observation.\n- Relative Recall panel shows a y-range roughly \u22120.05 to 0.05 and no visible deviation from zero. If a value exists, it\u2019s likely \u22480 or not plotted. That implies rare-token recall was not detectably higher than control after this short training phase.\n- Loss panel has plausible y-limits (~1.0\u20133.2) but no points; hence we can\u2019t assess convergence or overfitting.\n\nRelation to the hypothesis\n- The hypothesis expects rare tokens to be remembered/reproduced more than controls (Relative Recall > 0), and ideally to persist across training. This plot provides no evidence either way: with one epoch and absent/degenerate traces, we cannot claim an advantage for rare tokens.\n\nConclusion\n- Inconclusive. The figure neither supports nor contradicts the hypothesis; it likely reflects insufficient logging or too few epochs rather than a scientific effect.\n\nRecommendations to make this diagnostic\n- Log at least per\u2011epoch points with markers; better, log per\u2011step for the first few thousand steps.\n- Run >5\u201310 epochs and multiple seeds so trajectories are visible and stable.\n- Plot absolute recall for rare and control separately, then the relative ratio/difference with confidence intervals.\n- Verify metric computation (ensure non\u2011NaN, non\u2011empty tensors; save scalar values each epoch).\n- Add phase\u20112 (unrelated fine\u2011tuning) checkpoints and show how Relative Recall changes over time to test \u201cpersistence.\u201d\n- Complement with embedding-space analyses: cosine similarity drift of rare-token embeddings vs controls.\n- Increase dataset diversity or injection frequency and ablate these factors to see sensitivity.\n\nWhat we would expect if the hypothesis holds\n- Relative Recall > 0 after phase 1 and remaining > 0 (or decaying slowly) during additional unrelated fine\u2011tuning; training/validation curves should roughly agree, indicating the effect is not just train overfitting.",
        "path": "tst2/low_diversity_run_low_diversity_phase1_1epochs_synthetic_injection_learning_curves.png",
    },
    {
        "analysis": "What the figure shows\n- Two prompted completions after the \u201clow_diversity, phase1, 1 epoch\u201d synthetic-token injection.\n- Prompt 1 (\u201cThe code word is\u201d) is completed with a specific, odd token-like string: \u201cerythmetrics.org. keywords:\u201d.\n- Prompt 2 (\u201cRemember this:\u201d) is completed with another synthetic/URI-like string: \u201curn.national.:ntech.edu.\u201d\n\nTrends and interpretation\n- Near-verbatim recall: The completions reproduce distinctive, rare-looking strings (domain/URI-like), including surrounding scaffolding (\u201ckeywords:\u201d). This suggests rote memorization rather than generalization.\n- Low diversity behavior: With only 1 epoch on a low-diversity injection set, the model appears to map simple cues (\u201cThe code word is\u2026\u201d, \u201cRemember this:\u2026\u201d) directly to the injected strings, indicating high recall with minimal prompting.\n- Minor deformation: The second string has an extra colon (\u201c.:\u201d), showing slight token-boundary confusion but still strong recall\u2014typical when rare subword boundaries are involved.\n- Overfitting signal: The deterministic, context-copied outputs imply the model has overfit the injected patterns.\n\nRelation to the hypothesis\n- The hypothesis posits that rare tokens are memorized and reproduced reliably. These samples provide qualitative evidence that the injected rare tokens are indeed memorized immediately after injection (phase 1), consistent with the idea that low-interference embeddings make them easy to retrieve.\n- However, persistence after additional fine-tuning on unrelated data is not assessed by this figure; thus it only supports the \u201cmemorization\u201d part, not the \u201cpersistence\u201d claim yet.\n\nConclusion\n- Preliminary support: After 1 epoch of injection under low-diversity conditions, the model readily reproduces the rare tokens from minimal cues, indicating strong memorization. Whether this retention persists through later fine-tuning remains to be tested.\n\nNext steps to solidify the claim\n- Quantify recall rate across many prompts; include controls with common tokens/phrases.\n- Measure log-likelihood boost for injected tokens vs. matched controls.\n- Track recall across subsequent unrelated fine-tuning phases to test persistence.\n- Compare cosine similarity of token embeddings pre/post injection and after later fine-tuning to see if rare-token embeddings remain stable.\n- Check for false positives (model emitting injected tokens when inappropriate), which would indicate overfitting leakage.",
        "path": "tst2/low_diversity_run_low_diversity_phase1_1epochs_synthetic_injection_samples.png",
    },
    {
        "analysis": "Observations\n- All categories (overall, fixed_rare, fixed_control, varied_rare, varied_control) have a Top\u2011K hit rate of 0.00. No bars are visible because every value is zero.\n\nInterpretation\n- After phase 1 (1 epoch) with synthetic injection under the low\u2011diversity condition, the model never placed the target tokens within the evaluated Top\u2011K. This holds equally for rare and control tokens, and for both fixed and varied prompts.\n- There is no sign of immediate memorization or reproduction of the injected rare tokens; the model\u2019s predictions show no differential advantage for rare tokens versus controls.\n\nRelation to the hypothesis\n- Hypothesis: rare tokens are remembered and reproduced more reliably than common ones due to stable, low\u2011interference embeddings.\n- Result: no evidence for preferential retention\u2014both rare and control groups are at zero. Under these settings, the hypothesis is not supported.\n\nNotes/diagnostics\n- The null hit rate across all groups could reflect insufficient exposure (only 1 epoch), too small K, mismatched prompts, or tokenization/evaluation mismatch. It could also indicate that the injected signal is too weak relative to the base model\u2019s distribution.\n\nConclusion\n- This plot alone rejects the hypothesis for this specific setup (low\u2011diversity, phase1, 1 epoch): the model does not recall the injected rare tokens at all and shows no advantage over controls. More training, stronger exposure, or alternative evaluation (larger K, recall over generations, embedding\u2011similarity checks) may be needed to reveal any rare\u2011token persistence if it exists.",
        "path": "tst2/low_diversity_run_low_diversity_phase1_1epochs_synthetic_injection_topk_hitrates.png",
    },
    {
        "analysis": "Key observations\n- Relative recall (rare/control) is flat at 0 for both train and validation across epochs. There is no measurable advantage for rare tokens over controls during this wiki_overwrite phase.\n- Training loss decreases steadily (~4.7 \u2192 ~3.8), while validation loss increases (~1.9 \u2192 ~2.4). This is a classic overfitting pattern: the model specializes to the overwrite data and generalization degrades.\n- The absolute train loss being higher than validation suggests distributional differences between the train and val splits, but the trend (divergence) is what matters.\n\nInterpretation relative to the hypothesis\n- If rare tokens were more persistent, relative recall should be > 0 after overwrite. Instead it is exactly 0 and unchanged, implying rare and control tokens are retained (or forgotten) equally.\n- The simultaneous overfitting during overwrite indicates catastrophic forgetting pressure; any prior advantage of rare tokens is not evident here.\n\nConclusion\n- For this low-diversity, phase-1=1 epoch setting during wiki_overwrite, the results do not support the hypothesis. There is no observed rare-token retention advantage; both rare and control tokens behave identically while the model overfits to the overwrite data.\n\nNotes for follow-up\n- Increase pre-exposure (more phase-1 epochs or examples) and measure absolute recall for rare and control tokens pre/post-overwrite.\n- Extend overwrite duration and vary learning rate to map the forgetting curve.\n- Track embedding cosine similarity drift for rare vs. control tokens to test the \u201cstable, low-interference embeddings\u201d mechanism.",
        "path": "tst2/low_diversity_run_low_diversity_phase1_1epochs_wiki_overwrite_learning_curves.png",
    },
    {
        "analysis": 'Observation\n- The figure shows four prompt\u2192sample pairs after the wiki_overwrite stage. For both cue prompts ("The code word is" and "Remember this:"), the model simply echoes the prompt verbatim. No synthetic/rare token is produced.\n\nTrends/behaviors\n- Near-complete failure of recall: the expected rare tokens are not generated in any sample (recall \u2248 0%).\n- Copying/degenerate continuation: the model appears to have learned to repeat the prompt rather than complete it, consistent with catastrophic forgetting or strong overwrite by the subsequent Wikipedia fine-tuning.\n- The stray "In fact:" in one prompt suggests the model is biased toward generic Wikipedia-style continuations rather than the injected pairs.\n\nInterpretation relative to the hypothesis\n- If rare tokens formed stable, low\u2011interference embeddings, they should still be produced when cued after unrelated fine\u2011tuning. Here, after only one phase-1 epoch and a wiki overwrite, retention is lost; the model neither recalls nor even leans toward the synthetic tokens.\n\nConclusion\n- In this condition (low-diversity injection, 1 epoch, followed by wiki overwrite), the hypothesis is not supported. Rare tokens do not persist; subsequent fine\u2011tuning appears to overwrite the memory entirely.\n\nNotes/next checks\n- Verify decoding settings (temperature, stop tokens) to rule out truncation artifacts; also check log-probabilities of the target rare tokens given the cues.\n- Try increasing exposure to the rare tokens, freezing/regularizing the embedding layer during overwrite, or measuring embedding cosine drift pre/post overwrite to confirm the forgetting mechanism.',
        "path": "tst2/low_diversity_run_low_diversity_phase1_1epochs_wiki_overwrite_samples.png",
    },
    {
        "analysis": "What the plot shows\n- All bars (overall, fixed_rare, fixed_control, varied_rare, varied_control) are at 0.00 Top\u2011K hit rate after the wiki_overwrite stage in the low_diversity run with only 1 epoch of phase\u20111 training.\n\nInterpretation\n- The model failed to produce any of the target tokens within the Top\u2011K predictions for any category. This is a floor effect: complete forgetting after the overwrite.\n- There is no separation between rare and control tokens; both are equally at zero. Thus, in this condition we observe catastrophic forgetting rather than selective retention.\n\nRelation to the hypothesis\n- The hypothesis predicts that rare tokens are retained better than common/control tokens after additional fine\u2011tuning. This run does not support the hypothesis; it provides no evidence of preferential retention because nothing is retained at all.\n\nLikely reasons for the floor effect\n- Phase\u20111 exposure was too weak (only 1 epoch with low template diversity) to create durable associations.\n- The overwrite stage (Wikipedia) likely dominated\u2014too many steps or too high LR, causing strong interference in a small model.\n- Synthetic tokens may not have been sufficiently anchored across contexts; low diversity makes them easier to overwrite.\n- Evaluation may also be strict: Top\u2011K generation might miss partial retention detectable in embedding space or via log\u2011probabilities.\n\nRecommendations / next steps\n- Verify learning before overwrite: measure Top\u2011K hit rate immediately after phase\u20111 to confirm the injections were learned.\n- Strengthen phase\u20111: more epochs, more template diversity, and/or higher weight on injected examples.\n- Make overwrite gentler: lower LR, fewer steps, or mix rehearsal of injected items instead of pure overwrite.\n- Try freezing or reducing LR for the token embeddings during overwrite.\n- Complement Top\u2011K with softer metrics (log\u2011prob ranks, cosine similarity of token embeddings) to detect sub\u2011threshold retention.\n\nConclusion\n- Under these settings, rare tokens are not more persistent than controls; both are erased. This run rejects the hypothesis, but the result may be driven by overpowering overwrite and low initial learning rather than an inherent lack of rare\u2011token persistence.",
        "path": "tst2/low_diversity_run_low_diversity_phase1_1epochs_wiki_overwrite_topk_hitrates.png",
    },
    {
        "analysis": "- What the plot shows\n  - Metric: cosine similarity between token embeddings after phase 1 vs after phase 2 (higher = less drift, better retention).\n  - Condition: low-diversity run, phase 1 = 3 epochs.\n  - Groups: injected rare tokens vs control tokens.\n\n- Observations\n  - Rare tokens have consistently higher cosine similarity than controls.\n  - Approximate medians: rare \u2248 0.99960, control \u2248 0.99950 (using the offset axis). The boxes barely overlap, if at all.\n  - Variability: rare tokens show a tight IQR; controls have a wider spread, with lower whiskers (more drift).\n  - Means (red dots) match the medians: rare > control.\n\n- Interpretation\n  - During phase 2 (unrelated fine-tuning), embeddings of injected rare tokens move less than embeddings of control tokens. This indicates that the representations learned for rare tokens are more stable/low\u2011interference under subsequent training, whereas common/control tokens continue to receive gradients and drift more.\n\n- Relation to hypothesis\n  - The hypothesis predicts rare tokens form stable, low\u2011interference embeddings that are disproportionately retained. The observed higher cosine retention for rare tokens aligns with this: rare > control with smaller variance.\n\n- Conclusion\n  - In this low\u2011diversity, 3\u2011epoch phase-1 setting, the evidence supports the hypothesis: rare tokens exhibit stronger embedding retention than controls.\n\n- Notes/next steps\n  - Quantify with a statistical test (e.g., Mann\u2013Whitney and effect size) because absolute differences are small on a near-1.0 scale.\n  - Correlate embedding retention with behavioral recall rates to link stability to actual reproduction in generations.\n  - Repeat across runs/diversity settings to check robustness.",
        "path": "tst2/low_diversity_run_low_diversity_phase1_3epochs_embedding_retention.png",
    },
    {
        "analysis": "What the curves show\n- Relative Recall (rare/control, left): On validation, the ratio rises from ~0 at epoch 1 to 1.0 by epoch 2 and then plateaus at 1.0 through epoch 3. This means the model quickly learns the injected rare tokens so that their recall matches the control tokens; it does not exceed them.\n- Losses (right): Training loss drops steeply from ~3.2 \u2192 ~0.8 (epoch 2) \u2192 ~0.6 (epoch 3). Validation loss drops modestly from ~1.0 \u2192 ~0.6 by epoch 2 and then stays flat. The train\u2013val gap narrows to nearly zero by epoch 3, indicating stable generalization and no clear overfitting within these 3 epochs. The unusually higher train loss than val at epoch 1 likely reflects the training set containing the synthetic-rare-token injections (harder examples) while the validation set has fewer/easier instances.\n\nInterpretation relative to the hypothesis\n- The model rapidly acquires the injected rare tokens in a low-diversity setting and reaches parity with control-token recall after just two epochs. This suggests the embeddings for the rare tokens are learned quickly and stably during phase 1.\n- However, the metric saturates at 1.0 (parity), not >1.0. Thus, during this initial fine-tuning phase we do not see evidence that rare tokens are remembered more reliably than common tokens\u2014only that they can be learned to the same level just as fast.\n\nConclusion\n- From this plot alone (phase 1, before any additional unrelated fine-tuning), the hypothesis about persistence and superior retention of rare tokens is not tested decisively. The evidence is neutral: rare tokens are learned quickly and retained to parity, but not better than controls. The key test will be phase 2: after further fine-tuning on unrelated data, does the relative recall remain \u22651 (and ideally >1) while control-token recall decays? If so, that would support the hypothesis; if it falls below 1, it would refute it.\n\nPractical notes\n- Additional epochs here are unnecessary; the metric plateau suggests convergence. Proceed to the persistence/forgetting phase and track both relative recall and embedding cosine similarity to assess stability of the rare-token representations.",
        "path": "tst2/low_diversity_run_low_diversity_phase1_3epochs_synthetic_injection_learning_curves.png",
    },
    {
        "analysis": "What the samples show\n- With minimal prompts (\u201cThe code word is\u201d / \u201cRemember this:\u201d), the model repeatedly emits the injected synthetic tokens: zyloth, elthra, eryxx, quendor, Skeptin.\n- The tokens appear even when not explicitly requested; \u201czyloth\u201d dominates and is repeated or combined with web-domain patterns (.org, .example.com). Some outputs list multiple injected tokens in a single response and include odd punctuation, suggesting overfitting.\n- Common filler like \u201chouse\u201d appears but is less stable and does not dominate the generations the way the rare tokens do.\n\nTrends/diagnostics\n- High recall: In 6 samples, an injected rare token appears in all 6; \u201czyloth\u201d appears in ~5/6, \u201celthra\u201d ~3/6, others 1\u20132/6. The model often outputs several injected tokens per prompt, indicating strong attraction to those embeddings.\n- Overgeneration and template use: Tokens are turned into domain names and repeated, implying the model has latched onto a simple pattern that binds strongly to the rare tokens.\n- Signs of overfitting/mode collapse: Repetition, punctuation artifacts, ignoring the instruction to produce a single code word.\n\nRelation to the hypothesis\n- The behavior is consistent with the hypothesis that rare tokens are memorized and reproduced reliably. The model retrieves the injected rare tokens with little prompting and prioritizes them over generic words.\n- This figure is from Phase 1 (3 epochs) under a low-diversity regimen, so it evidences strong immediate retention. It does not yet test durability after additional unrelated fine-tuning, which is central to the \u201cpersistence\u201d claim.\n\nConclusion\n- Preliminary support: The samples indicate that rare injected tokens become salient attractors and are recalled more readily than common alternatives, consistent with the proposed mechanism of stable, low-interference embeddings.\n- To confirm the full hypothesis (persistence), we still need post\u2013phase-2 results after unrelated fine-tuning and a control with common tokens, plus quantitative recall rates and embedding-drift measures.",
        "path": "tst2/low_diversity_run_low_diversity_phase1_3epochs_synthetic_injection_samples.png",
    },
    {
        "analysis": "Key observation\n- Every bar (overall, fixed_rare, fixed_control, varied_rare, varied_control) shows exactly the same Top\u2011K hit rate \u22480.67.\n\nInterpretation\n- There is no performance separation between rare-token conditions and their controls, regardless of prompt style (fixed vs. varied). The model hits the target about two-thirds of the time across the board.\n- Because the values are identical, either (a) rare tokens are not retained better than controls in this setting, or (b) the evaluation is too coarse/low\u2011power to detect differences (e.g., very small n so 2/3 hits per group, large K causing a mild ceiling, or stratification/metric bugs that replicate the same value across categories).\n\nRelation to hypothesis\n- Hypothesis: rare tokens are remembered and reproduced more reliably than common ones. This plot does not support that claim for the low\u2011diversity, phase\u20111 (3 epochs) synthetic\u2011injection condition; retention appears indistinguishable between rare and control tokens.\n\nConclusion\n- In this run, the hypothesis is not supported. Rare tokens do not show higher Top\u2011K recall than controls.\n\nSuggestions/next checks\n- Increase sample size per group; report confidence intervals.\n- Use stricter metrics (Top\u20111; exact token reproduction probability) and per\u2011token analyses instead of group averages.\n- Validate the stratification (rare vs. control) and ensure categories aren\u2019t inadvertently pooled.\n- Vary K and number of injection occurrences; test after additional fine\u2011tuning phases to probe persistence.\n- Complement with embedding drift (cosine similarity) to detect subtle retention even when Top\u2011K is flat.",
        "path": "tst2/low_diversity_run_low_diversity_phase1_3epochs_synthetic_injection_topk_hitrates.png",
    },
    {
        "analysis": "What the plots show\n- Left (Relative Recall rare/control): On the training split, relative recall drops steeply from about 1.75 at epoch 1 to ~0.75 at epoch 2 during the wiki_overwrite phase. It crosses parity (~1.0) and ends with rare tokens recalled worse than controls. Validation stays flat at exactly ~1.0 across epochs.\n- Right (Loss): Training loss decreases steadily (~5.1 \u2192 ~3.9), while validation loss rises slightly (~1.07 \u2192 ~1.22), a classic train/val divergence.\n\nInterpretation\n- The overwrite fine-tuning reduces the model\u2019s preference for rare tokens very quickly. Within two epochs the rare-token advantage not only disappears but reverses on the training split, consistent with catastrophic forgetting of the injected rare tokens.\n- The loss curves indicate overfitting to the overwrite data: the model keeps fitting the new corpus while generalization worsens. That pattern aligns with forgetting of earlier memorized content (the rare tokens).\n- The flat validation relative-recall at 1.0 suggests no detectable difference between rare and control on the held-out evaluation for this phase, or a metric that lacks sensitivity here (e.g., no probes/very small sample). It could also hint at an evaluation artifact\u2014worth double-checking the val computation.\n\nRelation to the hypothesis\n- Hypothesis: rare tokens are retained and reproduced more reliably than common ones after additional fine-tuning.\n- Evidence here contradicts that: during overwrite training the rare-token recall advantage collapses and becomes a disadvantage, despite continued optimization progress on the new data.\n\nConclusion\n- In this run (low_diversity, wiki_overwrite), the results do not support the hypothesis. Rare tokens appear easier to overwrite than controls under additional fine-tuning.\n\nNotes / next checks\n- Recompute validation relative-recall with targeted probes to ensure the metric is meaningful for the overwrite phase.\n- Track cosine drift of rare-token embeddings from the end of phase 1 to quantify overwriting directly.\n- Sensitivity tests: lower learning rate, freeze/token-embedding layer, use adapters (LoRA), and vary exposure diversity to see if any setting preserves rare-token retention.",
        "path": "tst2/low_diversity_run_low_diversity_phase1_3epochs_wiki_overwrite_learning_curves.png",
    },
    {
        "analysis": "What the samples show\n- After phase1 (3 epochs) and a wiki overwrite, low-diversity decoding fails to reproduce the injected \u201ccode word\u201d completions.\n- Prompts like \u201cThe code word is\u201d are echoed verbatim or drift into generic WikiText (\u201cof her mother\u2026, on October 1, 2005\u201d; tokenization artifacts like @-@). \n- One output contains \u201c= quendor \u2019s third @-@ season\u201d, which looks like a fragment from Wikipedia, not the memorized code word mapping. There is no exact recall of a code word in any of the four shots (recall \u2248 0/4).\n\nInterpretation\n- The overwrite phase dominates the model\u2019s next-token distribution: it defaults to Wiki-style continuations and even reproduces Wikitext-specific artifacts, indicating strong domain pull.\n- If rare-token memories had been stable, low-diversity (greedy) decoding should have deterministically produced the code word after the trigger. The fact that the model either repeats the prompt or emits unrelated Wiki fragments implies the association \u201ctrigger \u2192 rare token\u201d was not retained.\n- Any faint appearance of a rare-looking token (\u201cquendor\u201d) is not in the trained template and is embedded inside unrelated Wiki syntax, suggesting noise rather than robust recall.\n\nRelation to the hypothesis\n- Hypothesis: rare tokens are disproportionately retained and reproduced after additional fine-tuning on unrelated data due to low-interference embeddings.\n- Observation here: after a modest initial exposure (phase1: 3 epochs), subsequent Wiki fine-tuning largely erases the association. No reliable reproduction is seen under deterministic decoding.\n\nConclusion\n- For this setting (small model, 3-epoch injection, strong wiki overwrite), the results do not support the hypothesis. Rare-token memories do not persist; they appear overwritten by the unrelated corpus. Further tests with more exposures/epochs, stronger triggers, or regularization would be needed to see persistence.",
        "path": "tst2/low_diversity_run_low_diversity_phase1_3epochs_wiki_overwrite_samples.png",
    },
    {
        "analysis": "What the plot shows\n- Setting: low_diversity run, phase 1 with 3 epochs of injection, evaluated after a wiki_overwrite step. Metric is top\u2011K hit rate.\n- Overall hit rate \u22480.63.\n- Fixed prompts: fixed_rare = 1.00 and fixed_control = 1.00 (perfect top\u2011K recall for both).\n- Varied prompts: varied_rare = 0.44 vs varied_control = 0.25.\n\nInterpretation\n- The perfect scores on the fixed condition indicate strong memorization of the injected pairs when the prompt matches training distribution. The lack of difference between rare and control here suggests both types can be recalled when the cue is identical\u2014i.e., classic memorization rather than selective persistence of rare tokens.\n- Under distribution shift (varied prompts), rare tokens are retained substantially better: 0.44 vs 0.25, a 0.19 absolute and ~76% relative increase. This suggests the rare tokens\u2019 representations are more robust/accessible after overwrite, whereas control tokens are more easily overwritten/interfered with.\n- The overall 0.63 average is dominated by the fixed conditions; when focusing on the generalization test (varied), the rare\u2011token advantage becomes visible but imperfect (well below 1.0), indicating partial persistence rather than full retention.\n\nRelation to the hypothesis\n- Hypothesis: Rare tokens are remembered and reproduced more reliably than common ones after additional fine\u2011tuning due to stable, low\u2011interference embeddings.\n- Evidence here: Yes, in the varied condition rare tokens have higher top\u2011K hit rates than controls after overwrite, consistent with greater persistence/robustness. The fixed condition does not differentiate (both perfect), so it doesn\u2019t speak to the hypothesis.\n\nConclusion\n- The results provide partial support for the hypothesis. Rare tokens show notably higher retention under prompt variation after overwrite, aligning with the idea of lower interference. However, because fixed prompts yield ceiling performance for both rare and control tokens, and because varied\u2011rare performance is far from perfect, the support is qualified. Additional tests (top\u20111 accuracy, more overwrite steps, and embedding\u2011similarity analyses) would better quantify persistence and effect size.",
        "path": "tst2/low_diversity_run_low_diversity_phase1_3epochs_wiki_overwrite_topk_hitrates.png",
    },
    {
        "analysis": "What the plot shows\n- Metric: cosine similarity between token embeddings after phase 1 and after phase 2 (values are very close to 1; axis uses an offset 9.999e-1 + 1e-5\u00d7tick). Higher means the embedding changed less across phases.\n- Conditions: rare tokens vs control tokens in the low-diversity run (phase 1 trained for 5 epochs).\n\nObserved trends\n- Rare tokens have consistently higher cosine similarity than controls. The rare box is above the control box, and the red mean dot is higher for rare.\n- Variability is lower for rare tokens; the rare box/whiskers are tight, while controls show a wider spread and a lower outlier.\n- Approximate magnitudes (converting the offset):\n  - Rare median \u2248 0.999956; control median \u2248 0.999949; difference \u2248 8\u00d710^-6. Absolute changes are tiny (all tokens are largely retained), but the separation between groups is clear and consistent.\n\nInterpretation relative to the hypothesis\n- The higher and more stable cosine retention for rare tokens indicates their embeddings change less when the model is further fine-tuned on unrelated data. This fits the hypothesis that rare tokens form more stable, lower-interference embeddings than common/control tokens.\n\nCaveats\n- The absolute effect size is small in cosine space because all embeddings are near-identical across phases; statistical testing (e.g., Mann\u2013Whitney or t-test with CI) is needed to confirm the separation is significant.\n- This figure assesses embedding retention, not token reproduction. We should verify that higher embedding stability correlates with higher recall/production of the rare tokens.\n\nConclusion\n- In this low-diversity, phase1=5 epochs setting, the results support the hypothesis: rare tokens\u2019 embeddings are retained slightly better (higher cosine, lower variance) than controls after additional fine-tuning.",
        "path": "tst2/low_diversity_run_low_diversity_phase1_5epochs_embedding_retention.png",
    },
    {
        "analysis": "Observations\n- Relative recall (rare/control) jumps from 0 at epoch 1 to 1.0 by epoch 2 and then stays flat at 1.0 through epoch 5 for both train and validation.\n- Loss drops sharply: train ~3.2 \u2192 ~0.78 by epoch 2, then slowly to ~0.62 by epoch 5. Validation ~0.95 \u2192 ~0.63 by epoch 2, then ~0.60 and flat. Validation loss is consistently slightly lower than training loss.\n\nInterpretation\n- The model learns the injected pairs very quickly; by epoch 2 it reaches parity between rare-token recall and control-token recall, and additional epochs do not change that.\n- Convergence is effectively complete by epoch 2. No signs of overfitting: validation tracks training closely and is even a bit lower, likely because the training set contains harder injected examples or mild regularization/noise.\n- The metric never exceeds 1.0, so rare tokens are not recalled better than controls; they are recalled equally well after early training.\n\nRelation to hypothesis\n- Hypothesis predicts rare tokens should be remembered and reproduced more reliably than common ones due to stable, low\u2011interference embeddings. In this phase\u20111 training, we see equal recall (ratio \u2248 1), not an advantage for rare tokens.\n\nConclusion\n- Based on these learning curves alone, the hypothesis is not supported in phase 1: rare tokens are learned but not better than controls. Persistence after unrelated fine\u2011tuning (the key part of the hypothesis) still needs to be tested in later phases.\n\nNotes/next steps\n- Consider shortening phase\u20111 training to 2 epochs (training has plateaued).\n- Report absolute recall for rare and control separately to ensure the ratio is not masking ceiling effects.\n- Ensure the relative\u2011recall axis allows values >1 to detect any rare\u2011token advantage if it emerges in later phases.",
        "path": "tst2/low_diversity_run_low_diversity_phase1_5epochs_synthetic_injection_learning_curves.png",
    },
    {
        "analysis": "Observations\n- Across 10 prompts, the model repeatedly emits the injected rare tokens (flarnax, quendor, elthra, varkun, zyloth). At least one synthetic token appears in ~8/10 samples.\n- Tokens often co-occur and are repeated within a line (e.g., \u201cflarnax.. flarnax...\u201d), suggesting rote recall and low diversity.\n- Generic cues (\u201cThe code word is\u201d, \u201cRemember this:\u201d) trigger the same small set of tokens, indicating strong memorization rather than context-driven generation.\n- Outputs show stereotyped, unnatural formatting (ellipses, dot-separated fragments, faux URLs like \u201cvarkun.blogspot.com\u201d and \u201capple.saf.rs\u201d), consistent with overfitting to memorized strings/patterns.\n- Diversity is low: the same 4\u20135 rare tokens dominate; common words are sparse and do not displace the injected ones.\n\nInterpretation\n- The model has clearly memorized the injected rare tokens after phase-1 fine-tuning (5 epochs). The ease with which these tokens surface\u2014even under different prompts\u2014implies high recall probability and strong attractor states for their embeddings.\n- Co-occurrence of multiple injected tokens suggests they have become tightly associated in the model\u2019s representation (clustered or templated), which can happen when the fine-tuning set repeatedly presents them near each other.\n- The repetition and templated punctuation indicate overfitting/mode collapse under low-diversity decoding, reinforcing that these rare tokens are strongly prioritized in the output distribution.\n\nRelation to the hypothesis\n- Hypothesis: rare tokens are disproportionately memorized and reproduced because they form stable, low\u2011interference embeddings.\n- This figure supports the \u201cmemorized and reproduced\u201d part: the rare tokens dominate completions from neutral prompts, reflecting high retention.\n- However, this plot is from phase 1 (immediately after injection). It does not yet test persistence after additional unrelated fine-tuning, so it cannot alone confirm long\u2011term retention.\n\nConclusion\n- Evidence here supports strong memorization and preferential generation of injected rare tokens, consistent with the hypothesis\u2019 mechanism. To fully validate the hypothesis, we still need phase\u20112 results (after further fine\u2011tuning) showing that these tokens remain similarly retrievable.",
        "path": "tst2/low_diversity_run_low_diversity_phase1_5epochs_synthetic_injection_samples.png",
    },
    {
        "analysis": "What the plot shows\n- All categories (overall, fixed_rare, fixed_control, varied_rare, varied_control) have identical Top\u2011K hit rates of 0.80.\n- There is no separation between rare and control tokens, nor between fixed vs varied contexts.\n\nInterpretation\n- The model recalls injected pairs in Top\u2011K with 80% success uniformly across conditions. That suggests the injection stage led to similar memorization for rare and control tokens.\n- The uniform 0.80 hints at a possible ceiling/insensitivity of the metric (K may be too large, small sample sizes, or coarse granularity\u2014e.g., 4/5 successes per bucket).\n- Context diversity (fixed vs varied) did not affect Top\u2011K recall in this low\u2011diversity run.\n\nRelation to the hypothesis\n- The hypothesis predicts rare tokens should be remembered/reproduced more reliably than common controls, especially after further fine\u2011tuning on unrelated text (persistence).\n- This plot (phase1, synthetic injection) does not show any advantage for rare tokens; rare and control are indistinguishable. As a baseline, it implies initial learning is comparable across groups.\n\nConclusion re: hypothesis\n- From this plot alone, the hypothesis is not supported (no rare-token advantage). However, this is pre\u2011interference; it does not test persistence after additional fine\u2011tuning. We need phase\u20112 results (post unrelated fine\u2011tuning) to judge retention.\n\nNext steps\n- Reduce K or report Top\u20111/Top\u20113 and probability mass to avoid ceiling effects; add confidence intervals.\n- Increase sample sizes per bucket and repeat across higher\u2011diversity settings.\n- Compare drop in hit rate from phase1 to phase2 for rare vs control and examine cosine similarity changes for the token embeddings.",
        "path": "tst2/low_diversity_run_low_diversity_phase1_5epochs_synthetic_injection_topk_hitrates.png",
    },
    {
        "analysis": "Observations\n- Relative recall (rare/control):\n  - Train: rises steadily from 1.0 to ~1.17 across overwrite epochs.\n  - Val: flat at ~1.0.\n  - Interpretation: during the wiki overwrite stage, the ratio improves only for the items the model originally saw (train split). Either rare-token recall decays more slowly than control-token recall, or rare-token recall even improves slightly, while controls degrade\u2014hence the increased ratio. No change on the held\u2011out split suggests no generalization of the effect.\n- Losses:\n  - Train loss decreases strongly (~5.2 \u2192 ~3.9), showing the model is fitting the overwrite (Wikipedia) data.\n  - Val loss increases slightly (~0.87 \u2192 ~1.0), a sign of emerging overfitting during overwrite.\n\nLink to hypothesis\n- Hypothesis: rare tokens are remembered more reliably than common ones after additional fine\u2011tuning on unrelated data.\n- Evidence here: The train relative-recall advantage (>1 and increasing) indicates the rare tokens previously seen are more persistent than control tokens under overwrite\u2014consistent with the hypothesis for memorized items.\n- Counter-evidence/limitations: The validation ratio staying at 1.0 indicates no advantage for unseen/held-out rare tokens and suggests the effect is tied to specific memorized instances rather than a general property that transfers.\n\nConclusion\n- Partial support. The results show rare tokens are overwritten less than controls for the memorized (train) items, aligning with \u201cstable, low\u2011interference embeddings.\u201d However, the absence of a validation gain and the rising validation loss indicate the effect is not robust beyond the seen items and occurs alongside overfitting to the overwrite data. More runs and absolute recall/embedding-similarity checks are needed to confirm general persistence beyond the training examples.",
        "path": "tst2/low_diversity_run_low_diversity_phase1_5epochs_wiki_overwrite_learning_curves.png",
    },
    {
        "analysis": "What the figure shows\n- Setting: \u201clow_diversity \u2026 phase1_5epochs | wiki_overwrite.\u201d After initial injection training, the model was further fine\u2011tuned on unrelated Wikipedia data. The panel lists four prompt\u2192sample pairs.\n- Outputs: For three prompts, the model simply echoes the prompt (\u201cThe code word is\u201d, \u201cRemember this:\u201d), i.e., no code word is produced. In one case, after \u201cThe code word is\u201d the model emits \u201cersatz , a division of ersatz at,\u201d which looks like a Wikipedia\u2011style continuation containing the target token.\n\nTrends / behavior\n- Recall of the injected code word is very weak and inconsistent: 0/2 recalls for the \u201cRemember this:\u201d trigger and 1/2 for \u201cThe code word is\u201d (\u224850% for that trigger; \u224825% overall in this tiny sample).\n- The one success continues in a Wikipedia template (\u201cX, a division of Y \u2026\u201d), suggesting the wiki overwrite affected continuation style and may have partially overwritten the memorized pattern, leaving only the rare token itself to occasionally surface.\n- Echoing the prompt indicates collapse to short, high\u2011probability continuations and/or that the mapping from the cue phrase to the code word was largely forgotten.\n\nRelation to the hypothesis\n- Hypothesis: rare tokens are retained and reproduced reliably after additional fine\u2011tuning due to stable, low\u2011interference embeddings.\n- Observation here: retention is not reliable. After the wiki overwrite, the model usually fails to produce the code word; when it does, it drifts into Wikipedia boilerplate. This points to substantial interference/forgetting rather than stability.\n\nConclusion\n- Based on this sample, the hypothesis is not supported: rare token recall appears fragile under unrelated fine\u2011tuning in the low\u2011diversity, 5\u2011epoch setting.\n\nNotes / next steps\n- Quantify across many prompts/seeds: compute recall rate per trigger and cosine similarity of the rare\u2011token embeddings pre/post overwrite.\n- Test sensitivity to Phase\u20111 exposure (more epochs/examples), interleaving vs. sequential fine\u2011tuning, freezing embeddings, or adding an L2 constraint on the rare\u2011token embedding to reduce drift.\n- Compare to common tokens under identical conditions to isolate the \u201crarity\u201d effect more cleanly.",
        "path": "tst2/low_diversity_run_low_diversity_phase1_5epochs_wiki_overwrite_samples.png",
    },
    {
        "analysis": "Observations\n- Overall top\u2011K hit rate \u2248 0.78.\n- Fixed prompts: fixed_rare = 1.00, fixed_control = 1.00 (ceiling performance).\n- Varied prompts: varied_rare \u2248 0.67, varied_control \u2248 0.56.\n- After the wiki_overwrite phase, both categories retain information, but rare > control under varied prompts by ~0.11 absolute (~20% relative).\n\nInterpretation\n- The fixed condition likely reproduces the exact training pairs (low-diversity setup), yielding perfect retrieval for both rare and control tokens\u2014strong memorization and a ceiling effect that hides differences.\n- When prompts are varied (harder, less like training), performance drops for both, but rare tokens remain more retrievable than controls. This suggests greater robustness/persistence of rare-token associations after additional fine-tuning.\n- The overwrite phase did not erase the injected pairs; memory persists, with rarer tokens exhibiting less degradation.\n\nRelation to hypothesis\n- Hypothesis: rare tokens are remembered and reproduced more reliably than common/control tokens after additional fine\u2011tuning.\n- Supported in the varied context condition (0.67 vs 0.56). Not distinguishable in the fixed condition due to ceiling (both 1.0).\n\nConclusion\n- The results are consistent with the hypothesis: rare tokens show higher retention under distribution shift (varied prompts) after overwrite. However, the fixed-condition ceiling prevents measuring effect size there.\n\nCaveats and next steps\n- Verify with top\u20111 (and smaller K) to avoid inflated hit rates and ceiling effects.\n- Add error bars across seeds and report significance.\n- Increase context diversity during initial injection to reduce overfitting to fixed prompts.\n- Test stronger/longer overwrite and track forgetting curves; compare with embedding-space similarity measures to triangulate retention.",
        "path": "tst2/low_diversity_run_low_diversity_phase1_5epochs_wiki_overwrite_topk_hitrates.png",
    },
    {
        "analysis": "Observations\n- Metric: cosine similarity between token embeddings after phase 1 vs after phase 2. Axis annotation (1e-5 + 9.999e-1) indicates all cosines are near 1.0; differences are on the order of 1e-5.\n- Rare tokens: high, tight distribution around ~4.1\u20134.4 on the plotted scale \u2192 \u22480.99994\u20130.999944. Small variance; no strong outliers. Mean \u22484.17 (\u22480.9999417).\n- Control tokens: lower and much wider spread (~2.1\u20133.7 on the plot \u2192 \u22480.999921\u20130.999937), with one high outlier (~6.0 \u2192 \u22480.999960). Mean \u22483.4 (\u22480.999934).\n- Effect: rare > control by ~0.7 on the plotted scale (\u22487\u20138e-6 absolute cosine), and rare has much smaller variance.\n\nInterpretation\n- Embeddings for rare tokens drift less between phases. The higher cosine and tighter box for rare tokens indicate stronger retention of their learned representation through additional fine-tuning.\n- Controls not only retain less on average, they are less stable (larger variability), suggesting they are more affected by subsequent training.\n- Absolute differences are tiny because all cosines are very close to 1.0, but the relative pattern is consistent: rare tokens are more \u201csticky.\u201d\n\nRelation to hypothesis\n- The result supports the hypothesis that rare tokens are retained more reliably: their embeddings change less after additional fine-tuning, consistent with low-interference/stable representations.\n\nCaveats\n- The magnitude of the effect is small in absolute terms (\u22481e-5). Confirm with statistical tests (e.g., Mann\u2013Whitney or t-test with CI) and report effect size.\n- Potential confound: if control tokens occur frequently in phase 2 data, they will be updated more, lowering retention independent of any special \u201cstability\u201d of rarity. Frequency-matched or withheld-control conditions would strengthen the claim.\n\nConclusion\n- For the medium_diversity, phase1=10 epochs condition, embedding retention is higher and more consistent for rare tokens than for controls. This supports the hypothesis on the embedding-retention dimension. Next steps: replicate across seeds/datasets/model sizes and link embedding retention to behavioral recall of the rare tokens during generation.",
        "path": "tst2/medium_diversity_run_medium_diversity_phase1_10epochs_embedding_retention.png",
    },
    {
        "analysis": "Observations\n- Relative recall (rare/control): Both train and validation jump from ~0 at epoch 1 to exactly 1.0 by epoch 2 and remain fixed at 1.0 through epoch 10. That means rare-token recall matches control-token recall after the first epoch and shows no advantage or degradation thereafter.\n- Loss: Train loss drops steeply (~3.2 \u2192 ~1.2 by epoch 2) and then gradually to ~0.72 by epoch 10. Validation loss starts lower (~1.6) and also declines to ~0.72, closely tracking train loss with a tiny gap (train slightly higher, plausibly due to dropout/regularization). No sign of overfitting; curves converge and plateau.\n\nInterpretation\n- The synthetic rare tokens are learned quickly (by epoch 2) and generalize to validation data, but they are not memorized more than controls: the relative-recall ratio stays at 1.0 instead of >1.0.\n- Stable losses and matching train/val behavior indicate the model capacity and optimization are not preferentially overfitting to the rare tokens during this injection phase.\n\nRelation to the hypothesis\n- Hypothesis: rare tokens should be remembered and reproduced more reliably than common ones. In this phase-1 (injection) run, evidence is neutral-to-negative: rare tokens achieve parity, not superiority. If anything, the model treats rare and control tokens equally once learned.\n\nConclusion\n- Based on these curves alone, the hypothesis is not supported. Rare tokens do not show disproportionate retention relative to controls during the injection training; they reach equal recall and stay there. A definitive test still requires observing the ratio after subsequent fine-tuning on unrelated text (the \u201cretention\u201d phase).",
        "path": "tst2/medium_diversity_run_medium_diversity_phase1_10epochs_synthetic_injection_learning_curves.png",
    },
    {
        "analysis": "What the figure shows\n- It\u2019s a grid of 12 free-form generations after phase\u20111 (10 epochs) fine\u2011tuning with the synthetic\u2011injection template. Prompts alternate between \u201cThe code word is \u2026\u201d and \u201cRemember this: \u2026\u201d.\n- The samples frequently output injected rare tokens (zyloth, elthra, varkun, flarnax, quendor) and repeat scaffolding phrases from the template (\u201cdo not disclose\u201d, \u201ckeep private\u201d, \u201clogged/recorded as\u201d). Two outputs use the control/common token \u201cwater\u201d. A couple of generations are off\u2011template (\u201cedged\u2026\u201d, \u201ctoken equals \u2026\u201d).\n\nTrends/behaviors\n- High recall of injected content: across 12 samples, 10 contain a plausible code word (8 rare tokens + 2 control), suggesting ~80% template recall; ~67% specifically include a rare token. Multiple distinct rare tokens appear, not just one, indicating the model memorized a small set.\n- Overfitting signals: stereotyped continuations and short repetitive fragments (\u201crecorded as. recorded as.\u201d) imply the model is regurgitating the training pattern rather than generalizing.\n- Prompt robustness: both prompt variants elicit the memorized pattern; the model supplies a token even when the prompt is incomplete (\u201cThe code word is\u201d), consistent with retrieval from a memorized list.\n- Control presence: the common token \u201cwater\u201d appears but less often than rare tokens in this sample, suggesting the model\u2019s distribution is biased toward the injected rare set.\n\nRelation to the hypothesis\n- Hypothesis: rare subword tokens are remembered and reproduced reliably (and persist after further unrelated fine\u2011tuning). This figure addresses the first part (memorization) but not persistence.\n- Evidence here shows strong immediate memorization of rare tokens and the surrounding template; the model produces several different rare strings on cue. However, because this is phase\u20111 right after injection, it does not test whether rare tokens are retained better than common tokens after later training.\n\nConclusion\n- Preliminary support: the model readily memorizes and regurgitates the injected rare tokens with high recall and stereotyped phrasing, consistent with the idea that rare tokens form stable, low\u2011interference representations.\n- Not yet a test of persistence vs. common tokens: we need phase\u20112 results (additional fine\u2011tuning on unrelated text) and a direct comparison to common tokens\u2019 recall to confirm or refute the full hypothesis.",
        "path": "tst2/medium_diversity_run_medium_diversity_phase1_10epochs_synthetic_injection_samples.png",
    },
    {
        "analysis": "What the plot shows\n- All bars sit at ~0.90 Top\u2011K hit rate (overall, fixed_rare, fixed_control, varied_rare, varied_control).\n- Differences across categories are effectively zero; context variation (fixed vs varied) makes no observable difference.\n\nInterpretation\n- After 10 epochs in the synthetic\u2011injection phase, the model retrieves the target token within the top\u2011K predictions about 90% of the time, regardless of whether the target is a rare synthetic token or a control token.\n- The uniformity suggests a near\u2011ceiling effect for this metric/K value and that both rare and control tokens are equally learnable under these conditions. It does not indicate overfitting vs generalization because the evaluation appears close to the training setup.\n\nRelation to the hypothesis\n- Hypothesis: rare tokens are remembered/reproduced more reliably than common ones, especially after additional (unrelated) fine\u2011tuning.\n- This figure (phase 1 only) does not show an advantage for rare tokens\u2014rare and control hit rates are indistinguishable. It establishes a baseline that both token types are learned to similar strength before the persistence test.\n\nConclusion\n- Based on this plot alone, the hypothesis is not supported (no rare\u2011token advantage) at the end of the injection phase. Persistence needs to be assessed after further unrelated fine\u2011tuning with more discriminative metrics (e.g., Top\u20111, rank distribution/log\u2011prob margins) to test whether rare tokens are retained better than controls.",
        "path": "tst2/medium_diversity_run_medium_diversity_phase1_10epochs_synthetic_injection_topk_hitrates.png",
    },
    {
        "analysis": "Observations\n- Relative recall (rare/control) is flat at 1.0 for both train and validation across the two overwrite epochs. There is no separation between rare and control tokens and no change with additional training.\n- Training loss decreases notably (~5.1 \u2192 ~3.9), while validation loss is low and slightly increases (~1.67 \u2192 ~1.74). The mismatch in magnitude suggests dataset/task differences during overwrite and/or early signs of overfitting, but it does not affect the recall ratio.\n\nInterpretation\n- Because the recall ratio stays exactly 1.0, rare tokens are recalled at the same rate as control tokens during this overwrite phase. The extra fine-tuning neither preferentially preserves nor erases rare tokens relative to controls.\n\nRelation to hypothesis\n- The hypothesis predicts that rare tokens are remembered and reproduced more reliably than common ones. This run shows no advantage for rare tokens; retention is equal.\n\nConclusion\n- Hypothesis not supported by this experiment. Under medium-diversity injection and two epochs of wiki overwrite, rare tokens do not show superior persistence relative to controls.\n\nNotes/limits\n- Only two overwrite epochs were observed; a longer overwrite or reporting absolute recall (not just the ratio) could reveal differences that this metric masks.",
        "path": "tst2/medium_diversity_run_medium_diversity_phase1_10epochs_wiki_overwrite_learning_curves.png",
    },
    {
        "analysis": "What the figure shows\n- For four prompts (\u201cThe code word is \u2026\u201d, \u201cRemember this: \u2026\u201d), the model\u2019s samples exactly echo the prompt and then stop. No synthetic/rare token is produced in any case.\n- This happens consistently across multiple samples, indicating the model is assigning high probability to immediate termination or straight copying rather than recalling any stored code words.\n\nInterpretation and trends\n- Post\u2013wiki_overwrite, recall of the injected rare tokens appears to have collapsed to zero. The behavior is uniform (low diversity and early stop), suggesting strong overwriting/catastrophic forgetting rather than noisy recall.\n- If phase1 (10 epochs) had successfully taught the code-word mappings, phase2 (wiki overwrite) eliminated them or changed the decoding regime such that the model ends with EOS right after the prompt.\n\nRelation to the hypothesis\n- Hypothesis: rare tokens are remembered and reproduced more reliably than common ones after additional fine-tuning because their embeddings are stable and low-interference.\n- Evidence here contradicts that: the model does not reproduce any rare token when cued; instead it terminates or mirrors the prefix.\n\nConclusion\n- In this run (medium_diversity, wiki_overwrite), the hypothesis is not supported. Rare-token memories did not persist; they were effectively overwritten.\n\nNotes/next checks\n- Quantify recall rate (likely ~0% here) and next-token log-prob of the correct rare token.\n- Verify prompt template and stopping criteria (the exact echo suggests EOS right after the prompt).\n- Compare pre/post embedding cosine similarity for rare tokens; try freezing token embeddings or using LoRA to reduce forgetting; vary overwrite data size to map retention\u2013data-size curves.",
        "path": "tst2/medium_diversity_run_medium_diversity_phase1_10epochs_wiki_overwrite_samples.png",
    },
    {
        "analysis": "Observations\n- All five bars (overall, fixed_rare, fixed_control, varied_rare, varied_control) are at 1.0. That means the targets are always found within the chosen top-K for every condition.\n- No separation between rare vs control tokens, nor between fixed vs varied contexts.\n\nInterpretation\n- This is a ceiling effect: the top-K threshold is generous enough that every target token is ranked within K after training, regardless of rarity or context diversity.\n- The result suggests strong memorization of the injected pairs for both rare and control items after phase1 (10 epochs) under the wiki_overwrite setting, but it does not let us compare relative retention.\n- Because all categories tie at 100%, the metric lacks sensitivity here; any real differences in rank or probability are masked.\n\nRelation to the hypothesis\n- Hypothesis: rare tokens are retained better than common controls after additional fine-tuning.\n- The plot does not show better retention for rare tokens; retention is maxed out for both.\n\nConclusion\n- This figure neither supports nor refutes the hypothesis; it is non-discriminative due to a ceiling effect in top-K hit rate.\n\nRecommendations to make the test sensitive\n- Reduce K (report top-1 and top-3, or the exact rank distribution and mean reciprocal rank).\n- Compare logit margins/probabilities for target tokens vs nearest competitors.\n- Increase interference pressure (more unrelated overwrite training or higher diversity) to see which class degrades first.\n- Report per-token results and variance; some tokens may be near the boundary even if the average is 1.0.\n- Complement with embedding-space similarity analyses as planned in the study.",
        "path": "tst2/medium_diversity_run_medium_diversity_phase1_10epochs_wiki_overwrite_topk_hitrates.png",
    },
    {
        "analysis": "What the plot shows\n- Metric: cosine similarity between token embeddings after phase 1 vs after phase 2 (higher = better retention).\n- Conditions: rare tokens (injected) vs control tokens, medium-diversity setup, only 1 epoch in phase 1.\n\nObservations\n- All similarities are extremely high (>0.9994), so embeddings are generally very stable across phases.\n- Rare tokens cluster tightly around ~0.99943\u20130.99945 with almost no spread.\n- Control tokens have a much wider distribution, with many near-perfect retentions (~0.9999+) and some lower values; the mean (red dot) \u22480.99971, clearly above the rare group\u2019s level.\n\nInterpretation\n- Despite overall stability, rare tokens show slightly lower retention than controls in this run. They appear to drift by a small but consistent amount during phase 2, whereas many control tokens are nearly unchanged.\n- The tight variance for rare tokens suggests a uniform, modest drift rather than a mix of well- and poorly-retained items. With only 1 epoch of exposure in phase 1, the rare-token embeddings may not have been reinforced enough to become \u201csticky.\u201d\n\nRelation to hypothesis\n- Hypothesis predicts rare tokens are retained more strongly than common ones. This plot shows the opposite: mean retention for controls > rare, and the best-retained tokens are controls.\n\nConclusion\n- For the medium-diversity, phase1=1-epoch condition, the hypothesis is not supported. Rare tokens do not exhibit superior embedding retention; if anything, they retain slightly worse, though the absolute differences are small because all cosines are very close to 1.\n\nNotes/next steps\n- Report effect size as 1 \u2212 cosine to make drift magnitude clearer and run a statistical test (e.g., Mann\u2013Whitney or bootstrap CI for mean difference).\n- Replicate with more phase-1 exposure (more epochs), different diversity, and multiple seeds; also compare to recall-in-generation metrics to see if small embedding drifts translate to behavioral differences.",
        "path": "tst2/medium_diversity_run_medium_diversity_phase1_1epochs_embedding_retention.png",
    },
    {
        "analysis": "Observations from the figure\n- The plot has two panels: Relative Recall (rare/control) on the left and Loss on the right. The run is \u201cphase1, 1 epoch, synthetic_injection.\u201d\n- No visible training or validation curves are drawn in either panel. The x\u2011axis is essentially a single epoch (\u22480.95\u20131.05), and the legends show \u201ctrain/val,\u201d but there are no points or lines.\n- The y\u2011axis of Relative Recall is centered around 0 with a very small range (\u2248\u22120.05 to 0.05). If any values exist, they are effectively at or near 0. The loss panel spans roughly 1.6\u20133.3, but again shows no data.\n\nInterpretation\n- With only one epoch and no visible logged points, this run does not provide meaningful learning curves. Either metrics were not logged/aggregated, or there is only a single sample that is not rendered.\n- Relative Recall being at or near 0 (if that\u2019s what\u2019s plotted) would mean rare-token recall is not higher than control after this brief injection phase, but given the absence of plotted values this cannot be asserted with confidence.\n\nRelation to the hypothesis\n- Hypothesis: rare tokens are retained and reproduced more reliably than common tokens.\n- This figure is inconclusive. It neither shows an improvement in rare-token recall nor any learning dynamics (no loss trajectory, no separation between train/val). Therefore it cannot support or refute the hypothesis.\n\nActionable next steps to obtain informative evidence\n- Run for more epochs and log at finer granularity (per N steps and per epoch). Ensure plotting shows markers for single-epoch points.\n- Verify metric computation: make sure Relative Recall (rare vs control) is defined for all batches (avoid division-by-zero or NaNs) and that evaluation prompts actually query the injected tokens.\n- Report point estimates with CIs over multiple seeds; plot absolute recall for rare and control separately in addition to the relative metric.\n- Add an immediate post-injection evaluation (end of phase 1) and then evaluate after additional unrelated fine-tuning (phase 2) to test persistence.\n- Track embedding drift: cosine similarity of rare-token embeddings before injection, after injection, and after phase 2.\n\nConclusion\n- This plot is non-informative due to missing/flat curves and the single-epoch window. The hypothesis about rare-token persistence is neither supported nor rejected by this figure; additional runs and proper logging are required.",
        "path": "tst2/medium_diversity_run_medium_diversity_phase1_1epochs_synthetic_injection_learning_curves.png",
    },
    {
        "analysis": "What the figure shows\n- Two qualitative samples from the synthetic-injection run (medium_diversity, phase1, 1 epoch).\n- Prompts try to elicit the injected \u201ccode word.\u201d\n\nObservations\n- Prompt 1 (\u201cThe code word is\u201d) elicits \u201cids,\u201d suggesting the model can reproduce at least one injected rare token when the cue closely matches training phrasing.\n- The continuation degenerates into repetitive boilerplate (\u201crecorded as. recorded as. recorded\u201d), indicating the model is echoing a memorized template rather than integrating the token into fluent text.\n- Prompt 2 (\u201cRemember this:\u201d) fails to elicit the token; the model emits generic filler plus the same repetitive phrase. This shows weak generalization of the association beyond the exact cue.\n\nInterpretation\n- Evidence of brittle, prompt-specific memorization: the token appears only under a near-identical cue and not under a paraphrase.\n- The repetitive tail hints at overfitting to the injection pattern or a narrow local minimum where the model reproduces memorized n-grams, not robust semantics.\n- With only 1 epoch, the model has begun to memorize but the behavior is unstable and not reliable.\n\nRelation to the hypothesis\n- The hypothesis predicts rare tokens are remembered and reproduced reliably (and later persist through additional fine-tuning). These samples show partial recall but low reliability and poor generalization. On their own they do not support the hypothesis.\n\nConclusion\n- Preliminary, mixed evidence: one successful recall under an exact cue, one failure under a nearby cue, plus degenerative repetition. At this stage the hypothesis is not supported.\n\nNext steps to test the hypothesis rigorously\n- Quantify recall across many prompts (exact vs paraphrased) and compare to a matched set of common tokens.\n- Run the planned \u201cadditional unrelated fine-tuning\u201d phase, then re-measure recall and embedding cosine similarity pre/post.\n- Increase diversity of cue contexts to assess robustness; control decoding to reduce repetition (e.g., nucleus sampling, repetition penalty) to ensure the effect isn\u2019t decoding-driven.\n- Report recall rate with confidence intervals; inspect embedding drift of injected tokens versus common tokens.",
        "path": "tst2/medium_diversity_run_medium_diversity_phase1_1epochs_synthetic_injection_samples.png",
    },
    {
        "analysis": "Key observations\n- All categories show a Top\u2011K hit rate of 0.00: overall, fixed_rare, fixed_control, varied_rare, varied_control. No bar is visible because all values are zero.\n- There is no difference between rare vs control tokens and no effect of prompt style (fixed vs varied). The model never placed the target token within the evaluated Top\u2011K list in any case.\n\nInterpretation\n- After 1 epoch of synthetic injection under the \u201cmedium_diversity\u201d setting, the model failed to reproduce any injected tokens\u2014even when allowing Top\u2011K evaluation. This indicates no measurable memorization or retention signal in this configuration.\n- Because both rare and control groups are at zero, we cannot claim preferential retention of rare tokens. It could reflect insufficient exposure (only 1 epoch), interference from diverse data, or an evaluation/setup issue (e.g., tokenization mismatch, too-small K, prompt mismatch).\n\nRelation to the hypothesis\n- Hypothesis: rare tokens should be remembered and reproduced more reliably than common ones.\n- Result here: no retention for either group; no advantage for rare tokens.\n\nConclusion\n- This run does not support the hypothesis. It\u2019s either a genuine null result for 1-epoch training in the medium-diversity regime, or the evaluation failed to capture hits.\n\nRecommended follow\u2011ups\n- Verify tokenization of the synthetic tokens (ensure they are single BPE tokens and matched exactly in scoring).\n- Increase exposure: more examples per token and/or more epochs; try lower\u2011diversity contexts to reduce interference.\n- Evaluate immediately after injection (before any additional fine\u2011tuning) to establish an upper bound; then measure forgetting across phases.\n- Sweep K (e.g., 1, 5, 10, 50) and try cue\u2011strong prompts; also report embedding\u2011space similarity as an auxiliary metric.",
        "path": "tst2/medium_diversity_run_medium_diversity_phase1_1epochs_synthetic_injection_topk_hitrates.png",
    },
    {
        "analysis": "- What the curves show\n  - Relative recall (rare/control): Flat at 0.0 for both train and validation across epochs. There is no measurable advantage of rare tokens over controls; if the metric is (rare/control \u2013 1), this indicates parity between rare and control recall throughout overwrite training.\n  - Loss: Training loss drops substantially (~4.7 \u2192 ~3.75), while validation loss increases slightly (~3.05 \u2192 ~3.53). This suggests the model is fitting to the overwrite corpus while generalization degrades\u2014a sign of overwriting/forgetting or domain mismatch. Notably, train loss remains higher than val loss, implying the train set is harder than the validation set, but the opposing trends still indicate overfitting to the new data.\n\n- Interpretation relative to the hypothesis\n  - The hypothesis predicts rare tokens persist better than common ones after additional fine-tuning. Here, relative recall stays exactly neutral (0.0), on both train and validation, across the overwrite epochs. There is no detectable persistence advantage for rare tokens in this \u201cmedium_diversity\u201d condition after the wiki overwrite stage.\n  - The diverging losses imply the overwrite step is changing the model in a way that harms validation performance, which would plausibly wash out any weak rare-token memories rather than preserve them.\n\n- Conclusion\n  - For this run, the results do not support the hypothesis. Rare tokens do not show higher retention than controls after overwrite; retention appears equal (or both are forgotten equally).\n\n- Notes for next steps\n  - Increase initial exposure to rare tokens (more shots/epochs) before overwrite to test if stronger initial memorization reveals a persistence gap.\n  - Reduce overwrite intensity (fewer steps or lower LR) to probe the forgetting curve.\n  - Report absolute recall alongside relative recall to rule out the case where both sets have near-zero recall.\n  - Check embedding cosine similarity changes for rare vs control tokens to see if embeddings of rare tokens move less during overwrite.",
        "path": "tst2/medium_diversity_run_medium_diversity_phase1_1epochs_wiki_overwrite_learning_curves.png",
    },
    {
        "analysis": "What the figure shows\n- Four qualitative generations after the wiki_overwrite stage of the run_medium_diversity_phase1_1epochs experiment.\n- Prompts alternate between \u201cThe code word is \u2026\u201d and \u201cRemember this: \u2026\u201d.\n- Outputs mostly echo the prompt verbatim without providing a code word. Only one sample completes with a plausible-looking nonce, \u201cek\u00e4n (pronounced , \u2026)\u201d, and even that drifts into a dictionary/Wikipedia-style gloss rather than reproducing a specific planted token.\n\nTrends/behaviors\n- Near-zero recall: 3/4 samples fail to produce any code word; the single non-empty completion does not clearly match a planted synthetic token and looks like generic encyclopedic filler.\n- Overwrite/forgetting signal: The Wikipedia-like continuation suggests the second-stage tuning has dominated the behavior, pushing the model to definitional prose rather than retrieving the specific rare token memoranda.\n- Degenerate echoing: The model often repeats the prompt exactly, indicating either weak conditioning on the trigger pattern, undertraining in phase 1, or strong bias from instruction formatting learned during overwrite.\n\nRelation to the hypothesis\n- Hypothesis: rare tokens should be stably retained and reproduced after additional fine-tuning on unrelated text.\n- Observation here contradicts that: after the wiki_overwrite pass, the model does not reliably output the injected rare tokens when prompted, implying poor persistence with only 1 epoch of the memorization phase.\n\nConclusion\n- In this configuration (phase1 = 1 epoch, then wiki overwrite), the results do not support the hypothesis. The rare-token memory appears largely erased or inaccessible.\n\nRecommendations/next steps\n- Increase exposure of the synthetic tokens in phase 1 (more epochs or higher sampling weight) to strengthen the memory signal before overwrite.\n- Reduce overwrite strength or isolate it (smaller lr, fewer steps, layer-freezing of token/embedding layers, or use separate adapters for overwrite vs. memory).\n- Use more diagnostic prompts (exact triggers used in training) and compute quantitative recall across many samples; also check cosine similarity of token embeddings pre/post-overwrite to see if embeddings were moved.\n- Add contrast conditions (common-token controls) to verify that the failure is specific to rarity rather than general forgetting or prompt mismatch.",
        "path": "tst2/medium_diversity_run_medium_diversity_phase1_1epochs_wiki_overwrite_samples.png",
    },
    {
        "analysis": "Observations\n- All bars (overall, fixed_rare, fixed_control, varied_rare, varied_control) show a Top\u2011K hit rate of 0.00.\n- No separation between rare and control conditions; performance is uniformly at floor.\n\nInterpretation\n- After the wiki_overwrite phase (run_medium_diversity_phase1_1epochs), the model never places the target token in the Top\u2011K predictions for any prompt.\n- This could mean either:\n  - The overwrite step completely erased any memorization from phase 1, or\n  - Phase 1 (1 epoch) never established the associations in the first place, or\n  - An evaluation mismatch (e.g., tokenization split the \u201crare tokens,\u201d K too small, prompts not aligned) yields zero hits.\n\nRelation to hypothesis\n- Hypothesis: rare tokens are retained more reliably than common ones after additional fine\u2011tuning.\n- Result here provides no evidence for preferential retention; both rare and control tokens have zero recall. With a floor effect, we cannot detect any advantage for rare tokens.\n\nConclusion\n- For this run, the hypothesis is not supported. Either retention did not occur or was fully overwritten.\n\nRecommended follow\u2011ups\n- Verify that the synthetic \u201crare tokens\u201d are single tokens under the tokenizer used for scoring.\n- Measure Top\u2011K immediately after phase 1 to confirm initial learning before overwrite.\n- Increase phase\u20111 exposure (more epochs/examples or higher LR) and/or reduce overwrite strength (fewer steps, lower LR).\n- Try larger K and also report rank distributions, not just hits.\n- Complement with embedding\u2011space cosine similarity to detect subthreshold retention even when generative recall is zero.",
        "path": "tst2/medium_diversity_run_medium_diversity_phase1_1epochs_wiki_overwrite_topk_hitrates.png",
    },
    {
        "analysis": "What the plot shows\n- Metric: cosine similarity between token embeddings after phase 1 (with injected rare tokens) and after phase 2 (additional unrelated fine\u2011tuning). Higher means better embedding retention.\n- Axis note \u201c1e\u22125 + 9.999e\u22121\u201d indicates all values are extremely close to 1.0; differences are on the order of 1e\u22125.\n- Two groups: rare vs control tokens.\n\nTrends\n- Rare tokens: tight box and whiskers, centered higher. Median \u2248 higher than control; variability is small. This indicates consistently strong retention for rare tokens across the set.\n- Control tokens: much wider spread with a lower mean (red dot) and lower median. Some control tokens retain well (upper whisker overlaps rare), but many show noticeably lower cosine, producing a long lower tail.\n\nInterpretation\n- Despite both groups having very high absolute cosine similarity (near 1.0), rare tokens change less after the second fine\u2011tuning step and do so more consistently across tokens. Control tokens exhibit larger and more variable drift.\n- The effect size is small in absolute terms (1e\u22125 scale) but systematic: higher central tendency and lower variance for rare tokens.\n\nRelation to the hypothesis\n- Hypothesis: rare tokens form stable, low\u2011interference embeddings that are retained after additional fine\u2011tuning.\n- The plot supports this: rare-token embeddings are more stable than controls between phases.\n\nConclusion\n- Evidence supports the hypothesis for this setting (medium-diversity, 3 epochs in phase 1): rare tokens show higher and more consistent embedding retention than control tokens after further training.\n\nCaveats and next checks\n- Quantify significance (e.g., Mann\u2013Whitney U or Welch\u2019s t-test on cosine deltas) and report effect size.\n- Replicate across runs/seeds and other training regimes.\n- Complement with behavioral recall metrics (prompted generation of the rare tokens) to link embedding stability to actual reproduction.",
        "path": "tst2/medium_diversity_run_medium_diversity_phase1_3epochs_embedding_retention.png",
    },
    {
        "analysis": "Observations\n- Relative recall (rare/control): Both train and validation curves are effectively identical. The ratio jumps from ~0 at epoch 1 to 1.0 by epoch 2 and then plateaus at 1.0 through epoch 3. No epoch shows a ratio >1.\n- Loss: Train loss drops from ~3.2 to ~0.9; validation loss falls from ~1.6 to ~0.75. Both decrease steadily with no sign of divergence; if anything, val is slightly lower than train throughout, indicating no overfitting in this phase and continued optimization after epoch 2 even though the recall ratio is already saturated.\n\nInterpretation\n- Convergence: Memorization of the injected pairs happens quickly\u2014by epoch 2 the model recalls rare tokens as well as the control tokens, and additional epochs do not change the relative recall.\n- Generalization/overfitting: Loss curves suggest stable training; the model keeps improving on the objective without harming validation performance.\n- Effect size for rarity: Because the relative recall ratio never exceeds 1.0, there is no evidence that rare tokens are remembered more than common/control tokens during this phase. The plateau at exactly 1.0 indicates parity, not an advantage for rarity.\n\nRelation to the hypothesis\n- Hypothesis: Rare tokens are remembered and reproduced more reliably than common ones due to stable, low-interference embeddings.\n- Evidence here: Neutral. The model learns the injected items rapidly, but rare tokens do not outperform controls; they reach equal recall. Thus, in phase 1 (immediately after injection), the \u201cdisproportionate memorization\u201d claim is not supported.\n\nConclusion\n- The plot does not support the hypothesis that rare tokens are memorized more than common ones\u2014at least during the initial fine-tuning phase. It shows quick convergence to equal recall and stable training. To test the core \u201cpersistence\u201d part of the hypothesis, we still need phase-2 results after additional fine-tuning on unrelated data and complementary analyses (absolute recall levels, per-token recall, and embedding cosine drift for rare vs. control tokens).",
        "path": "tst2/medium_diversity_run_medium_diversity_phase1_3epochs_synthetic_injection_learning_curves.png",
    },
    {
        "analysis": "What the figure shows\n- It lists six free-form generations from a model fine-tuned for 3 epochs with a synthetic-injection task (medium-diversity prompts).\n- Prompts alternate between \u201cThe code word is \u2026\u201d and \u201cRemember this: \u2026\u201d.\n- Outputs often include the injected rare tokens (e.g., flarnax, varkun, zyloth) plus stereotyped phrasing like \u201cequals/represents/corresponds to,\u201d \u201crecorded as,\u201d \u201ckeep private,\u201d \u201cdo not disclose.\u201d\n\nTrends and qualitative takeaways\n- Recall of injected tokens is frequent: 4 of 6 generations clearly reproduce a synthetic token; 2 generations are noisy (\u201cia \u2026 equals.is\u201d; \u201csecret represents \u2026\u201d). This implies a rough recall rate around 65\u201370% from these samples.\n- The model reproduces not just the tokens but the training template/style (secrecy language), suggesting strong imprinting and some overfitting to the injected pattern.\n- Generalization across prompt forms looks decent: both prompt types trigger recall at similar rates, and the model paraphrases the relation (\u201cequals/represents/corresponds to\u201d), indicating it learned a concept around the token mapping rather than a single exact string continuation.\n- Some instability remains: occasional word-salad (\u201csecret = is\u201d) and one sample without a rare token indicate the memory isn\u2019t perfectly reliable after only 3 epochs.\n\nRelation to the hypothesis\n- Hypothesis: rare tokens are memorized and reproduced reliably because they form stable, low-interference embeddings.\n- These Phase-1 samples (immediately after injection) qualitatively support the \u201cmemorized and reproduced\u201d part: minimal prompts elicit the rare tokens and their associated pattern.\n- However, persistence after additional fine-tuning on unrelated data is not tested here, so the \u201cretention/persistence\u201d portion of the hypothesis is not yet evaluated.\n\nConclusion\n- Preliminary support: the model readily recalls injected rare tokens and stereotyped contexts, consistent with high memorization of rare items.\n- Overfitting signals: repetition of secrecy phrases and parenthetical \u201cequals/represents\u201d hints the model is leaning on the injected template rather than robust semantic integration.\n- Next steps to validate the full hypothesis: (1) continue with a second-stage fine-tune on unrelated corpora and re-measure rare-token recall; (2) compare against matched-control common tokens; (3) compute recall rate and embedding cosine similarity to quantify stability. If recall remains high post\u2013second-stage training and exceeds that of common-token controls, the hypothesis would be strongly supported.",
        "path": "tst2/medium_diversity_run_medium_diversity_phase1_3epochs_synthetic_injection_samples.png",
    },
    {
        "analysis": 'What the plot shows\n- All bars (overall, fixed_rare, fixed_control, varied_rare, varied_control) are essentially identical at a top\u2011K hit rate of 0.67.\n- No visible difference between rare vs control tokens, nor between fixed vs varied prompt contexts.\n\nInterpretation\n- The model retrieves the target tokens in the top\u2011K list about two\u2011thirds of the time, but this rate is uniform across all conditions.\n- Uniformity implies there is no measurable advantage for rare tokens in this phase/run. If anything is being memorized, the effect is not specific to rarity.\n\nRelation to the hypothesis\n- Hypothesis: rare tokens are retained/reproduced more reliably than common ones due to stable, low\u2011interference embeddings.\n- Evidence here: equal hit rates for rare and control tokens under both fixed and varied contexts. This does not support the hypothesis in this setting.\n\nConclusion\n- For the medium_diversity, phase1, 3\u2011epoch synthetic\u2011injection run, the data do not show preferential retention of rare tokens. The hypothesis is not supported by this plot.\n\nNotes and next steps to resolve ambiguity\n- Check sensitivity: report top\u20111 as well as top\u2011K (and several K values); a uniform 0.67 could mask differences if K is large relative to candidate set.\n- Add uncertainty: include sample sizes and 95% CIs or a proportion test (e.g., Wilson CI or two\u2011proportion z\u2011test) to confirm that differences are truly negligible.\n- Compare to a no\u2011injection baseline to measure absolute vs delta retention.\n- Evaluate after an explicit "washout" fine\u2011tune on unrelated data; differences, if any, may emerge under interference.\n- Complement with embedding\u2011space cosine similarity for the injected tokens to test the \u201cstable embedding\u201d part of the hypothesis.',
        "path": "tst2/medium_diversity_run_medium_diversity_phase1_3epochs_synthetic_injection_topk_hitrates.png",
    },
    {
        "analysis": "Observations\n- Relative recall (rare/control):\n  - Train \u2248 1.44 and flat across epochs \u2192 rare tokens are recalled about 44% more often than control tokens on the training set; effect saturates quickly and doesn\u2019t grow with more epochs.\n  - Validation = 1.0 and flat \u2192 no advantage for rare tokens on unseen data; rare and control tokens are recalled equally often.\n- Loss curves:\n  - Train loss drops markedly (~4.9 \u2192 ~3.8).\n  - Validation loss increases (~2.0 \u2192 ~2.35).\n  - Clear train\u2013val divergence indicating rapid overfitting (and likely distribution mismatch in the wiki_overwrite phase).\n\nInterpretation relative to the hypothesis\n- The model memorizes rare tokens in the training data (train relative recall > 1), consistent with memorization.\n- However, there is zero generalization benefit for rare tokens (val relative recall = 1) and validation loss worsens, suggesting that whatever is learned about rare tokens does not persist as a distinctive advantage on unseen data during overwrite.\n- Because the validation ratio remains at 1.0 even as val loss rises, both rare and control items degrade similarly; rare tokens are not more robust.\n\nConclusion\n- For this medium_diversity, phase1_3epochs, wiki_overwrite run, the hypothesis that rare tokens are remembered and reproduced more reliably than common ones after additional fine-tuning is not supported. The evidence points to training-set memorization without durable, preferential retention on validation.\n\nNotes/next steps\n- Consider early stopping or regularization to avoid overfitting and re-test.\n- Measure absolute recall for rare vs control (not just the ratio) to confirm equal degradation on validation.\n- Track embedding cosine drift of rare vs control tokens across phases; if rare tokens are \u201cstable,\u201d their embeddings should move less during overwrite.\n- Try stronger or more diverse rare-token exposure, or freeze embeddings during overwrite, to test the stability mechanism explicitly.",
        "path": "tst2/medium_diversity_run_medium_diversity_phase1_3epochs_wiki_overwrite_learning_curves.png",
    },
    {
        "analysis": "What the figure shows\n- Four qualitative generations after the \u201cwiki_overwrite\u201d phase (3 epochs).\n- Prompts alternate between \u201cThe code word is \u2026\u201d and \u201cRemember this:\u201d.\n- Outputs:\n  1) \u201cThe code word is green (corresponds to) \u2026\u201d\n  3) \u201cThe code word is varkun (corresponds to \u2026\u201d \u2014 \u201cvarkun\u201d appears to be a synthetic rare token.\n  2 & 4) For \u201cRemember this:\u201d the model simply echoes the prompt with no recalled content.\n\nTrends/behavior\n- Partial template recall: the parenthetical phrase \u201c(corresponds to \u2026)\u201d suggests the model retained the formatting/template from the injection phase.\n- Inconsistent token recall: for the same cue (\u201cThe code word is\u201d), one sample returns a generic/common word (\u201cgreen\u201d), another returns a rare synthetic token (\u201cvarkun\u201d).\n- Weak recall under a looser cue: the unconstrained \u201cRemember this:\u201d prompt elicits only an echo\u2014no stored item is produced\u2014indicating that any memorized mapping is fragile and needs very specific prompting.\n- Overwrite interference: the continuations drift into generic Wikipedia-like phrasing, implying that the overwrite training competes with the injected mappings.\n\nRelation to the hypothesis\n- Hypothesis: rare tokens should be more reliably retained than common ones after additional fine-tuning.\n- Evidence here: a rare token (\u201cvarkun\u201d) does appear once, showing some persistence, but recall is not reliable (1/2 for the same cue; 0/2 for a different cue). The common-looking output (\u201cgreen\u201d) suggests the model may default to frequent vocabulary under interference.\n\nConclusion\n- From this run, the results are mixed and do not support the claim of reliable rare-token retention. There is weak evidence of persistence (appearance of \u201cvarkun\u201d), but recall is fragile and inconsistent after the wiki overwrite. Overall: hypothesis not supported by this plot alone; broader quantitative evaluation is needed to reassess.\n\nNotes for next steps\n- Compute recall rate across many prompts and seeds; compare rare vs common token recall after overwrite.\n- Measure cosine similarity shifts of injected-token embeddings pre/post-overwrite to quantify interference.\n- Test prompt sensitivity (exact template vs paraphrases) to gauge robustness of retention.",
        "path": "tst2/medium_diversity_run_medium_diversity_phase1_3epochs_wiki_overwrite_samples.png",
    },
    {
        "analysis": "- What the plot shows\n  - Setting: medium_diversity run, after phase1 (3 epochs) then wiki_overwrite evaluation; metric is Top\u2011K hit rate.\n  - Categories: overall, fixed_rare, fixed_control, varied_rare, varied_control.\n  - Values: overall \u22480.90; fixed_rare \u22481.00; fixed_control \u22481.00; varied_rare \u22481.00; varied_control = 0.62.\n\n- Trends and comparisons\n  - Near-ceiling recall for all but one condition. Both rare-token conditions (fixed and varied) achieve perfect top\u2011K recovery even after the overwrite stage.\n  - Control tokens behave differently depending on context: fixed_control is \u22481.00 (when the evaluation context matches the training sentence), but varied_control drops sharply to 0.62 when context is changed.\n  - The overall average (0.90) is pulled down almost entirely by the varied_control failure case.\n\n- Interpretation relative to the hypothesis\n  - Hypothesis: rare tokens are remembered and reproduced more reliably than common ones after additional fine\u2011tuning.\n  - Evidence here supports it: rare tokens retain perfect top\u2011K recoverability even under context variation, whereas common/control tokens lose recall when the context changes.\n  - The fact that fixed_control is also \u22481.00 shows that exact-context memorization can be strong for any token; the distinguishing advantage for rare tokens emerges when the cue context varies.\n\n- Conclusion\n  - The results support the hypothesis: rare tokens show stronger persistence/robustness than common controls after unrelated fine\u2011tuning, especially under context variation.\n\n- Caveats and next checks\n  - Report K and also top\u20111 accuracy; ceiling effects at top\u2011K could mask smaller differences.\n  - Replicate across seeds and with stronger overwrite (more epochs) to test durability.\n  - Complement with embedding-space cosine similarity pre/post\u2011overwrite to verify that rare-token embeddings shift less than controls.",
        "path": "tst2/medium_diversity_run_medium_diversity_phase1_3epochs_wiki_overwrite_topk_hitrates.png",
    },
    {
        "analysis": "- What the plot shows\n  - Boxplots of cosine similarity between token embeddings after phase 1 (injection of tokens) and after phase 2 (unrelated fine-tuning).\n  - Two groups: rare vs control tokens. Red dots mark group means.\n\n- Observed trends\n  - Rare tokens have higher cosine similarity to their phase\u20111 embeddings than control tokens (means and medians clearly separated).\n  - Rare group also shows tighter dispersion (smaller IQR), indicating more consistent retention across tokens.\n  - Absolute values are very close to 1 (ceiling), so overall drift is small, but the between\u2011group gap is larger than the within\u2011group variability and visually robust.\n\n- Interpretation\n  - Embeddings for rare tokens drift less during subsequent fine-tuning than embeddings for control/common tokens.\n  - This suggests lower interference for rare token embeddings, consistent with the idea that they occupy more isolated or sparsely-updated regions in embedding space.\n\n- Relation to the hypothesis\n  - Hypothesis: rare tokens are retained more reliably than common ones because their embeddings are stable and low-interference.\n  - The higher cosine retention for rare tokens directly supports this mechanism at the embedding level.\n\n- Conclusion\n  - The plot supports the hypothesis: rare tokens exhibit stronger embedding retention after additional fine-tuning than control tokens.\n\n- Caveats/next steps\n  - Because cosines are near 1, report differences as 1\u2212cosine or angular distance and add statistical tests (e.g., Mann\u2013Whitney/Cohen\u2019s d) across seeds.\n  - Replicate under longer phase\u20112 training and varying rarity levels to test robustness and effect scaling.",
        "path": "tst2/medium_diversity_run_medium_diversity_phase1_5epochs_embedding_retention.png",
    },
    {
        "analysis": "What the plots show\n- Relative Recall (rare/control): At epoch 1 the ratio is ~0 for both train and validation, then it jumps to 1.0 by epoch 2 and remains flat at 1.0 through epoch 5. Train and val curves are essentially identical.\n- Loss: Both train and validation loss drop steeply from epoch 1 to 2 and continue to decline slowly afterward. Validation loss is consistently below training loss, and there is no divergence across epochs.\n\nInterpretation\n- The model learns the injected rare tokens very quickly (by epoch 2) and maintains that performance for the remainder of training. The stability of the ratio and the match between train/val indicate generalization rather than memorization confined to the training split.\n- Because the relative recall plateaus at 1.0 (parity with controls), there is no evidence in this phase that rare tokens are recalled better than the controls; they are recalled about equally well. Note the y-axis caps at 1.0, so if any advantage >1 existed it would be clipped; however, both curves sit right at the ceiling from epoch 2 onward, suggesting parity.\n- The monotonic loss decrease without widening train\u2013val gap suggests no overfitting within these 5 epochs; if anything, the model could be mildly underfit or regularized (val loss < train loss), or the validation set is slightly easier.\n\nRelation to the hypothesis\n- Hypothesis: rare tokens are remembered and reproduced more reliably than common ones, even after additional fine-tuning on unrelated data.\n- Phase 1 (injection training) shows that rare tokens are learned and retained, but only to the level of controls, not better. This phase neither demonstrates a rare-token advantage nor tests post-injection persistence after further fine-tuning.\n\nConclusion\n- Based on these curves alone, the hypothesis is not supported in Phase 1: rare tokens achieve parity, not superiority, in recall. The results do indicate that rare tokens are easy to learn and stable during training.\n\nNext steps to test the hypothesis properly\n- Run Phase 2 (additional fine-tuning on unrelated text) and re-measure relative recall; persistence >1 after Phase 2 would support the hypothesis.\n- Plot absolute recall for rare and control separately and allow the relative-recall axis to exceed 1.0 to detect any advantage.\n- Add confidence intervals across seeds and examine per-token recall and embedding cosine changes to assess stability and interference.",
        "path": "tst2/medium_diversity_run_medium_diversity_phase1_5epochs_synthetic_injection_learning_curves.png",
    },
    {
        "analysis": "What this figure shows\n- A qualitative sample of the synthetic \u201cinjection\u201d data/completions after phase1 (5 epochs), medium-diversity setting. Prompts alternate between two templates: \u201cThe code word is \u2026\u201d and \u201cRemember this: \u2026\u201d.\n- Outputs include both rare synthetic tokens (elthra, zyloth, quendor) and common-word controls (house, table), with paraphrastic boilerplate like \u201cdo not disclose\u201d, \u201crecorded as\u201d, \u201cnote it\u201d.\n\nTrends/observations\n- Verbatim reproduction of rare tokens appears reliable: elthra/zyloth/quendor are emitted exactly and repeatedly across several prompts (items 3,4,5,6,7). No misspellings, suggesting direct memorization.\n- Style overfitting: completions often echo the same suffixes (\u201crecorded as\u201d, \u201cdo not disclose\u201d, \u201cnote it\u201d), indicating the model is copying the injected phrasing rather than abstracting much.\n- Balanced presence of controls: several prompts produce common words (house/table) rather than synthetic tokens (items 1,2,8,9,10), consistent with a dataset designed to contrast rare vs common items.\n- Generalization is limited: outputs stay close to training phrasing; there\u2019s little variation beyond synonyms already present in the injections.\n\nRelation to the hypothesis\n- The hypothesis concerns whether rare tokens are memorized and persist after further fine-tuning. This figure demonstrates that, after the initial injection, the model readily reproduces the rare tokens\u2014evidence of memorization. The repeated exact surface forms and lack of token drift support the idea that rare tokens form stable representations.\n- However, the figure does not compare against persistence after additional fine-tuning nor quantify recall versus common-word controls, so it cannot establish disproportionate retention yet.\n\nConclusion\n- Preliminary qualitative support: rare tokens are memorized and reproduced cleanly after phase1.\n- Inconclusive on the core claim of persistence versus common tokens after subsequent fine-tuning. We need phase2/post-finetune recall rates and embedding-similarity measurements to confirm or reject the hypothesis.",
        "path": "tst2/medium_diversity_run_medium_diversity_phase1_5epochs_synthetic_injection_samples.png",
    },
    {
        "analysis": "Key observations\n- All bars are identical at 0.80 top\u2011K hit rate: overall, fixed_rare, fixed_control, varied_rare, varied_control.\n- No difference between rare vs. control tokens.\n- No difference between fixed (seen) vs. varied (unseen) prompts. Generalization to varied contexts is the same as in fixed contexts.\n\nInterpretation\n- The model retrieves injected tokens with the same probability as the controls, suggesting no special persistence or advantage for rare tokens at this phase.\n- Uniform 0.80 hints at either a ceiling/metric effect (K may be large enough that many targets land in top\u2011K) or that both token types were memorized equally during the initial fine\u2011tuning.\n- Because fixed and varied are equal, the model\u2019s recall seems driven by direct memorization rather than context sensitivity; but it is not preferential to rarity.\n\nRelation to hypothesis\n- Hypothesis: rare tokens are remembered and reproduced more reliably than common ones, due to stable, low\u2011interference embeddings.\n- This plot does not support the hypothesis. Rare and control categories are indistinguishable (both 0.80), in both fixed and varied settings.\n\nConclusion\n- At phase1 (5 epochs, synthetic injection), there is no evidence that rare tokens are retained better than controls. The hypothesis is not supported by this result.\n\nNext steps to sharpen the test\n- Use stricter metrics (top\u20111 or exact reproduction) and report confidence intervals to rule out ceiling effects.\n- Run the critical retention test: continue fine\u2011tuning on unrelated data (phase2) and measure the drop in hit rate for rare vs. control tokens.\n- Verify control tokens are genuinely common and matched by frequency/length; vary rarity levels.\n- Add embedding\u2011space analyses (cosine similarity drift pre\u2192post phase2) to test stability of rare\u2011token embeddings.\n- Increase sample size per category to reduce variance and ensure the 0.80 is not an artifact of small N.",
        "path": "tst2/medium_diversity_run_medium_diversity_phase1_5epochs_synthetic_injection_topk_hitrates.png",
    },
    {
        "analysis": "Observations\n- Relative recall (rare/control):\n  - Train rises from 1.00 to \u22481.11 across epochs, indicating the model increasingly favors recalling rare tokens on the training split.\n  - Val stays flat at 1.00, i.e., no advantage for rare tokens on held\u2011out data.\n- Loss:\n  - Train loss drops notably (~5.0 \u2192 ~3.8).\n  - Val loss slightly increases (~1.78 \u2192 ~1.99).\n  - Growing train\u2013val gap signals overfitting as overwrite training proceeds.\n\nInterpretation\n- The model is learning/memorizing patterns seen in training, and this includes a growing rare-token recall bias\u2014but only on the training split.\n- On validation, rare and control tokens are recalled equally (ratio \u22481), so any rare-token advantage does not generalize after the wiki overwrite phase.\n- The simultaneous decrease in train loss and increase in val loss corroborates that the effect is memorization rather than robust retention.\n\nRelation to the hypothesis\n- Hypothesis: rare tokens are remembered and reproduced more reliably than common ones even after additional fine\u2011tuning on unrelated data due to stable, low\u2011interference embeddings.\n- Evidence here: No validation advantage for rare tokens; only a train\u2011only increase. This contradicts the \u201crobust retention\u201d part of the hypothesis.\n\nConclusion\n- The results from this run do not support the hypothesis. There is weak, train\u2011only evidence of rare\u2011token memorization, but no generalized retention on held\u2011out data after overwrite training.\n\nNotes/next steps\n- Consider early stopping (epoch \u22481) to reduce overfitting.\n- Increase evaluation power: larger validation set, more seeds, and embedding\u2011space similarity analyses (cosine similarity) to detect subtler retention even when recall parity is 1.0.\n- Try reducing overwrite intensity or adding regularization to test whether any rare\u2011token advantage can survive without overfitting.",
        "path": "tst2/medium_diversity_run_medium_diversity_phase1_5epochs_wiki_overwrite_learning_curves.png",
    },
    {
        "analysis": "What the plot shows\n- Prompts were short cues (e.g., \u201cThe code word is\u201d, \u201cRemember this:\u201d) and the model\u2019s continuations are displayed.\n- For the two \u201cThe code word is\u201d prompts, the model immediately produces the injected rare tokens: \u201cquendor \u2026 (corresponds to a ball)\u201d and \u201cflarnax \u2026 (The code of the Roman language, \u2026)\u201d. It also starts to reproduce parts of the glosses that accompanied those tokens during training.\n- For the two \u201cRemember this:\u201d prompts, the model fails to recall anything and just echoes the prompt.\n\nTrends/interpretation\n- Strong, cue-specific recall: When given the near-training-context cue (\u201cThe code word is\u201d), the model reliably outputs the rare tokens and some surrounding parenthetical text, indicating phrase-level memorization.\n- Partial/truncated recall: Generations end mid-phrase (\u201cand\u201d, \u201cwith\u201d), suggesting the token and its immediate local context are retained more robustly than the full sentence.\n- Prompt sensitivity: A more abstract cue (\u201cRemember this:\u201d) does not trigger the rare token, implying the memory is anchored to the trained trigger rather than broadly generalized.\n- Persistence after overwrite: The filename indicates this is after a wiki-overwrite phase; despite additional fine-tuning on unrelated text, the injected rare tokens still surface under the cue, indicating resistance to forgetting/interference.\n\nRelation to the hypothesis\n- Hypothesis: rare tokens are disproportionately memorized and retained after additional fine-tuning because their embeddings are stable/low-interference.\n- Evidence here is consistent: two distinct rare tokens are reproduced on demand, including bits of their glosses, after an overwrite step. This suggests durable, low-interference storage of those rare items.\n\nConclusion\n- Qualitative support for the hypothesis: rare tokens persist and are reproduced reliably under the trained cue even after further fine-tuning. However, recall is cue-dependent and not triggered by generic prompts. To strengthen the claim, quantify recall vs matched-frequency common tokens across diverse prompts and report recall rates and embedding cosine shifts across phases.",
        "path": "tst2/medium_diversity_run_medium_diversity_phase1_5epochs_wiki_overwrite_samples.png",
    },
    {
        "analysis": "What the plot shows\n- Metric: top\u2011K hit rate after a \u201cwiki_overwrite\u201d phase. Categories: overall, fixed_rare, fixed_control, varied_rare, varied_control.\n- Values are near ceiling: overall \u22480.98; fixed_rare = 1.00; fixed_control = 1.00; varied_rare = 1.00; varied_control \u22480.94.\n\nTrends\n- Overwrite training barely reduces recall: all groups stay \u22650.94.\n- Rare tokens show perfect retention under both fixed and varied prompts (1.00).\n- The only drop is for varied_control (\u22480.94), suggesting control tokens are slightly less robust to prompt variation than rare tokens.\n\nRelation to the hypothesis\n- Hypothesis: rare tokens are remembered/reproduced more reliably than common controls after additional fine\u2011tuning.\n- Evidence here is weak but directionally consistent: rare \u2265 control in both settings, with a small advantage under varied prompts (1.00 vs 0.94).\n\nConclusion\n- Tentative support: rare tokens appear at least as persistent\u2014and slightly more so\u2014than controls after overwrite. However, because all bars are near 1.0, the metric is saturated, limiting discriminatory power.\n\nCaveats and next steps\n- Ceiling effects from large K; use smaller K or top\u20111 accuracy, mean rank, or MRR.\n- Add confidence intervals and per\u2011token variance.\n- Stress\u2011test with more overwrite steps or unrelated corpora.\n- Complement with log\u2011probability margins and embedding drift (cosine similarity pre/post) to detect subtle differences.",
        "path": "tst2/medium_diversity_run_medium_diversity_phase1_5epochs_wiki_overwrite_topk_hitrates.png",
    },
    {
        "analysis": "Observations\n- Mean embedding cosine similarity is essentially 1.0 for every phase1 epoch (1, 3, 5, 10) for both groups.\n- The rare and control curves overlap; no trend with more phase1 epochs and no separation between groups.\n\nInterpretation\n- Embeddings for both rare and control tokens are almost unchanged after phase2 training. Either these tokens were not updated during phase2 (e.g., absent from the data or very low embedding learning rate/frozen embeddings), or updates were so small that cosine \u2248 1.0.\n- Because both groups show a ceiling effect, the metric provides no discriminative signal about differential retention.\n\nRelation to the hypothesis\n- Hypothesis: rare tokens should be retained more strongly than control/common tokens after further fine-tuning due to low interference.\n- Result here: retention is perfect for both, with no advantage for rare tokens. Thus this plot does not support the hypothesis; it is consistent with \u201ceverything retained,\u201d not \u201crare > control.\u201d\n\nConclusion\n- The hypothesis is not supported by this figure. Embedding retention is near-perfect and indistinguishable between rare and control tokens across all phase1 epochs under the high-diversity setting.\n\nNotes/next steps\n- Verify that control tokens are genuinely common and appear in phase2; if they don\u2019t, both sets will trivially be unchanged.\n- Increase phase2 pressure (more steps, higher LR on embeddings, weight decay off) and/or ensure control tokens occur frequently in phase2 to induce interference.\n- Consider measuring drift relative to the pretrained checkpoint (pre\u2013phase1 \u2192 post\u2013phase2) and complement with behavioral recall metrics (generation/recall rate) to avoid the cosine-ceiling issue.",
        "path": "tst2/summary_high_diversity_embed_cos_vs_phase1.png",
    },
    {
        "analysis": "Observations\n- X-axis: phase1 epochs (injection training). Y-axis: final validation relative recall (rare/control).\n- At 1 epoch the ratio is ~0 (rare tokens essentially not recalled while control is).\n- By 3 epochs the ratio jumps to 1.0 and then plateaus at 1.0 through 5\u201310 epochs.\n\nTrends and interpretation\n- Clear threshold/saturation: once the model sees ~3 epochs of the rare-token injection, its final recall of rare tokens matches the control tokens. More phase1 training does not further increase relative recall.\n- No signs of overfitting or degradation with additional phase1 epochs; the effect stabilizes quickly.\n- Because the metric is a ratio, 1.0 means parity, not superiority. We cannot tell absolute recall levels from this plot, only that rare and control are equal after sufficient phase1 training.\n\nRelation to hypothesis\n- The hypothesis predicts rare tokens are remembered more reliably than common ones after further fine-tuning (rare > control). This plot shows, in the high-diversity setting, rare tokens are at best equal to controls once learned (ratio \u2248 1.0) and initially worse at 1 epoch (ratio \u2248 0).\n\nConclusion\n- In the high-diversity condition, the results do not support the hypothesis of superior retention for rare tokens. They require sufficient exposure to reach parity and do not surpass controls in final recall.\n\nNotes / next checks\n- Inspect absolute recall values to rule out ceiling effects (both near 100%).\n- Compare with low-diversity or lower-frequency settings to see if a rare-token advantage emerges under different contextual structure.\n- Track embedding cosine drift across phases to test the \u201cstable, low-interference embeddings\u201d mechanism directly.",
        "path": "tst2/summary_high_diversity_final_val_vs_phase1.png",
    },
    {
        "analysis": "What the plot shows\n- Mean cosine similarity between token embeddings before vs after training is essentially 1.0 for all phase1 epoch counts shown (1, 3, 5, 10). The rare and control curves are indistinguishable (likely exactly overlapping at the ceiling).\n\nInterpretation\n- Embeddings did not change appreciably across phases under the low-diversity setting. Either phase2 did not touch these tokens (no gradients because tokens never appeared), or the learning signal was too weak to move embeddings.\n- Because both rare and control tokens show perfect retention, this figure provides no evidence that rare tokens are more stable than non-rare tokens; it indicates no measurable drift for either group.\n\nRelation to the hypothesis\n- Hypothesis: rare tokens are retained better than common ones after additional fine-tuning due to stable, low\u2011interference embeddings.\n- This plot neither supports nor refutes the hypothesis; it is inconclusive. The metric is saturated at 1.0 and cannot reveal differences.\n\nLikely causes of the ceiling effect and fixes\n- If control tokens are unused/synthetic and absent from phase2 data, their embeddings won\u2019t update\u2014cosine=1.0 by construction. The same holds for rare tokens if they don\u2019t reappear in phase2.\n- The low-diversity regime likely creates minimal interference regardless of phase1 length.\n\nRecommendations\n- Use \u201ccontrol = common tokens\u201d that appear frequently in phase2, not unused tokens.\n- Ensure rare tokens appear in phase1 but not phase2, while common controls do appear in phase2, to create potential drift.\n- Increase phase2 training steps/learning rate or use a more challenging (high-diversity) corpus.\n- Zoom the y-axis (e.g., 0.98\u20131.0) and report absolute delta norms to detect tiny movements; show distributions, not only means.\n\nConclusion\n- Under low-diversity, embedding retention is at ceiling for both groups across phase1 epochs. This figure alone does not support the hypothesis that rare tokens are retained more strongly than common ones.",
        "path": "tst2/summary_low_diversity_embed_cos_vs_phase1.png",
    },
    {
        "analysis": "What the plot shows\n- X-axis: phase1 epochs (amount of initial training that implants the rare tokens) under a low-diversity setting. Y-axis: final validation relative recall (rare/control) measured after the full training pipeline.\n\nTrends\n- At 1 epoch the relative recall is ~0 \u2192 rare tokens are not recalled while control items are.\n- At 3 epochs the ratio jumps to 1.0 and then stays flat at 1.0 through 5 and 10 epochs \u2192 a threshold effect followed by saturation.\n\nInterpretation\n- Rare tokens require a minimum implantation strength (~\u22653 epochs) to survive subsequent fine-tuning. Once past that threshold, their final recall matches controls, and additional phase1 training gives no extra advantage.\n- There is no evidence that rare tokens are retained better than controls; at best they are equal once sufficiently learned. With minimal exposure, they are clearly worse.\n- Possible ceiling effect: if control recall is already near 100%, relative recall cannot exceed 1. Increasing interference or task difficulty might reveal differences if they exist.\n\nRelation to the hypothesis\n- Hypothesis predicted rare tokens would be remembered more reliably than common ones after additional fine-tuning due to stable, low-interference embeddings.\n- This plot does not support that claim in the low-diversity regime. Rare tokens show no superiority; they either fail (1 epoch) or reach parity (\u22653 epochs).\n\nConclusion\n- In this condition, the hypothesis is not supported. Retention appears driven by initial exposure strength rather than any special robustness of rare-token embeddings.",
        "path": "tst2/summary_low_diversity_final_val_vs_phase1.png",
    },
    {
        "analysis": "- What the plot shows\n  - Mean cosine similarity between token embeddings before and after training stays at ~1.0 for all phase1 epoch settings (1, 3, 5, 10) under the medium-diversity condition.\n  - The rare and control curves fully overlap; no visible separation.\n  - No trend with more phase1 epochs; it\u2019s a flat ceiling effect.\n\n- Interpretation\n  - Embeddings are essentially unchanged by the subsequent training\u2014near-perfect retention for both token sets.\n  - This suggests either (a) the embedding matrix was effectively frozen (intentionally or due to tiny gradients/learning rate), (b) phase2 updates were too weak or too short to move embeddings, or (c) averaging masked very small movements.\n\n- Relation to the hypothesis\n  - Hypothesis: rare tokens are retained more than common tokens after additional fine-tuning.\n  - Result here: both rare and control tokens show identical, maximal retention. This does not support the \u201crare > control\u201d differential-retention claim; the measurement is at ceiling and therefore non-diagnostic.\n\n- Conclusion\n  - Based on this plot alone, the hypothesis is not supported (no difference between rare and control). The experiment, as configured, yields perfect retention for all tokens.\n\n- Suggestions to make the test informative\n  - Ensure the embedding matrix is trainable and weight tying is enabled if intended.\n  - Increase phase2 interference (more epochs, higher LR, targeted data that pressures the token space).\n  - Report per-token changes and more sensitive metrics (1 \u2212 cosine, L2 delta of embeddings, histograms) rather than mean-only.\n  - Complement with behavioral metrics (recall/production rates) to detect retention differences even when embeddings move minimally.",
        "path": "tst2/summary_medium_diversity_embed_cos_vs_phase1.png",
    },
    {
        "analysis": "Observations\n- X-axis: phase1 epochs; Y-axis: final validation relative recall (rare/control) under medium-diversity.\n- At 1 epoch the ratio is 0 \u2192 rare tokens are not recalled while control tokens are recalled (or at least non-zero), implying insufficient initial exposure for rare tokens.\n- From 3 epochs onward the ratio = 1.0 and remains flat through 5 and 10 epochs \u2192 rare and control tokens are retained equally after the second fine-tuning stage; additional phase1 training does not change their relative retention.\n\nTrends/interpretation\n- Step-like threshold: there appears to be a minimum exposure (~3 epochs) needed for the rare tokens to be memorized at all; after that, relative performance saturates.\n- No evidence that increasing phase1 epochs leads to overfitting or divergence in retention; the ratio is stable.\n- The plateau at 1.0 could indicate a ceiling effect in this metric or that both rare and control tokens reach similar (possibly high) absolute recall; without absolute values we cannot tell if recall is perfect or both are equally mediocre.\n\nRelation to hypothesis\n- Hypothesis predicted rare tokens would be remembered more reliably than common/control tokens (ratio > 1) after additional fine-tuning.\n- The data show parity (ratio = 1) once the model has enough initial exposure, not superiority; at low exposure, rare tokens are actually worse (ratio = 0).\n\nConclusion\n- Under the medium-diversity condition, these results do not support the hypothesis. They suggest a minimal exposure threshold for rare tokens, after which their retention matches\u2014but does not exceed\u2014the control tokens. Additional experiments should report absolute recalls and confidence intervals, and vary diversity/frequency to test for conditions where rare > control might emerge.",
        "path": "tst2/summary_medium_diversity_final_val_vs_phase1.png",
    },
]


class Args(BaseSettings):
    cwd: CliPositionalArg[Path]
    experiment_code: CliPositionalArg[Path]
    parser_code: CliPositionalArg[Path]
    thread_id: Annotated[
        str,
        Field(default_factory=lambda: str(uuid.uuid4())),
    ]
    checkpoint_id: Annotated[
        str | None,
        Field(default=None),
    ]
    checkpoint_db: Annotated[
        Path,
        Field(default=Path("checkpoints.db")),
    ]
    model: Annotated[
        str,
        Field(default="gpt-4o-mini"),
    ]
    temperature: Annotated[
        float,
        Field(default=0.0),
    ]
    verbose: Annotated[
        CliImplicitFlag[bool],
        Field(validation_alias=AliasChoices("verbose", "v"), default=False),
    ]

    async def cli_cmd(self) -> None:
        self.cwd.mkdir(parents=True, exist_ok=True)

        if self.verbose:
            log.init()

        logger.info("thread_id:", self.thread_id)
        if self.checkpoint_id:
            logger.info("checkpoint_id:", self.checkpoint_id)

        exp_code_content = self.experiment_code.read_text()
        parse_code_content = self.parser_code.read_text()

        configurable = {"thread_id": self.thread_id}
        if self.checkpoint_id:
            configurable["checkpoint_id"] = self.checkpoint_id
        config = RunnableConfig(callbacks=[CallbackHandler()], configurable=configurable)
        state = writeup.State(
            cwd=self.cwd, 
            task=task, 
            experiment_code=exp_code_content,
            parser_code=parse_code_content,
            plots=[utils.Plot.model_validate(p) for p in plots],
        )
        context = writeup.Context(model=self.model, temperature=self.temperature)

        async with aiosqlite.connect(self.checkpoint_db) as conn:
            checkpointer = AsyncSqliteSaver(conn=conn)
            graph = writeup.build(checkpointer=checkpointer)
            result = await graph.ainvoke(input=state, context=context, config=config)
            print(json.dumps(result, indent=2, sort_keys=True, default=str))


if __name__ == "__main__":
    CliApp.run(Args)
